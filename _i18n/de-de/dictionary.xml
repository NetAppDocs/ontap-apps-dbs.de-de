<?xml version="1.0" encoding="UTF-8"?>
<blocks>
  <block id="d41d8cd98f00b204e9800998ecf8427e" category="summary"></block>
  <block id="30d965eef5ba25c6b9998ae38270b43e" category="doc">Rechtliche Hinweise</block>
  <block id="e9c44bbfd795a5d63d74c6a77afee70d" category="paragraph">Rechtliche Hinweise ermöglichen den Zugriff auf Copyright-Erklärungen, Marken, Patente und mehr.</block>
  <block id="6016a2b341113bf496b719905398ecd2" category="section-title">Urheberrecht</block>
  <block id="52009bb7ee17227f566cd26a02caee56" category="inline-link-macro"><block ref="52009bb7ee17227f566cd26a02caee56" category="inline-link-rx"></block></block>
  <block id="a1a9afcf552a769c282769271829889a" category="paragraph"><block ref="a1a9afcf552a769c282769271829889a" category="inline-link-macro-rx"></block></block>
  <block id="126a02652da6de02962cf1b654fd6376" category="section-title">Marken</block>
  <block id="c4ce4761e466527d26b3e3d5ed1006fd" category="paragraph">NetApp, das NETAPP Logo und die auf der NetApp Markenseite aufgeführten Marken sind Marken von NetApp Inc. Andere Firmen- und Produktnamen können Marken der jeweiligen Eigentümer sein.</block>
  <block id="f99aa604031e5049799e73b5c3748a98" category="inline-link-macro"><block ref="f99aa604031e5049799e73b5c3748a98" category="inline-link-rx"></block></block>
  <block id="5d545fe5152641e2ebe654e336e520e5" category="paragraph"><block ref="5d545fe5152641e2ebe654e336e520e5" category="inline-link-macro-rx"></block></block>
  <block id="be89498d2f8a22ce47c02ba9795fe2af" category="section-title">Patente</block>
  <block id="d0b19d36be2c5f16e9aef46c8a452d3d" category="paragraph">Eine aktuelle Liste der NetApp Patente finden Sie unter:</block>
  <block id="88e5eabd3917048b6927c42496b98f86" category="inline-link-macro"><block ref="88e5eabd3917048b6927c42496b98f86" category="inline-link-rx"></block></block>
  <block id="dd38f906b37d412de7d1c1dcf4cbf31c" category="paragraph"><block ref="dd38f906b37d412de7d1c1dcf4cbf31c" category="inline-link-macro-rx"></block></block>
  <block id="56c34c6410dd45c5cec44149ad0ce037" category="section-title">Datenschutzrichtlinie</block>
  <block id="8acb58cbd50ef1b468a020ee0bd351d3" category="inline-link-macro"><block ref="8acb58cbd50ef1b468a020ee0bd351d3" category="inline-link-rx"></block></block>
  <block id="2352c4e1f4d0024ade0869e00e6243f4" category="paragraph"><block ref="2352c4e1f4d0024ade0869e00e6243f4" category="inline-link-macro-rx"></block></block>
  <block id="c0227cef6f07a8cd2ac72f2945b031aa" category="section-title">Open Source</block>
  <block id="9b73989307c1975dfa4d5e1581e4afe8" category="paragraph">In den Benachrichtigungsdateien finden Sie Informationen zu Urheberrechten und Lizenzen von Drittanbietern, die in der NetApp Software verwendet werden.</block>
  <block id="253b40ae359ba25b56231803430c4873" category="section-title">ONTAP</block>
  <block id="856c8958afd787f748a4a025f649154a" category="inline-link-macro">Hinweis für ONTAP 9.13.1</block>
  <block id="b22b3b2970d843f99e7e6904bea05207" category="inline-link-macro">Hinweis zu ONTAP 9.12.1</block>
  <block id="0358f41254df2d512849db5a04b7e3d4" category="inline-link-macro">Hinweis zu ONTAP 9.12.0</block>
  <block id="28f1290102a277ef2fd452d558c74219" category="inline-link-macro">Hinweis zu ONTAP 9.11.1</block>
  <block id="57b07f14c8eb4660f94a86d29d53362d" category="inline-link-macro">Hinweis zu ONTAP 9.10.1</block>
  <block id="396712eb9c1644241047ac30619b2b3e" category="inline-link-macro">Hinweis für ONTAP 9.10.0</block>
  <block id="1e6000d4849ef9f3e08d1d9908e9f163" category="inline-link-macro">Hinweis zu ONTAP 9.9.1</block>
  <block id="6f408b9c999245c7aa32bc9cb1a020f6" category="inline-link-macro">Hinweis zu ONTAP 9.8</block>
  <block id="04b0bd5b1b4d414fdde93f809162d36d" category="inline-link-macro">Hinweis für ONTAP 9.7</block>
  <block id="0c1d7dffcba488555d5eb39b8991e822" category="inline-link-macro">Hinweis für ONTAP 9.6</block>
  <block id="a11ac6880e72412c0f54ae19bea3d191" category="inline-link-macro">Hinweis für ONTAP 9.5</block>
  <block id="e49c3c01b15761b5f011d0bd2a0661a3" category="inline-link-macro">Hinweis für ONTAP 9.4</block>
  <block id="bf7dcf6467a8a03b05b2d37d31d6eccd" category="inline-link-macro">Hinweis für ONTAP 9.3</block>
  <block id="0328352fdfda84af6968462d1a67d3a6" category="inline-link-macro">Hinweis für ONTAP 9.2</block>
  <block id="83904100c7d6fe0102e8b2b5bd8ec4bb" category="inline-link-macro">Hinweis für ONTAP 9.1</block>
  <block id="5672f5979be77bb31dd559817c9e1e76" category="paragraph"><block ref="f7a2b1db149ed9886af0ce846dbc3e14" category="inline-link-macro-rx"></block>
<block ref="b349c509ad858348b30db7e73307e3aa" category="inline-link-macro-rx"></block>
<block ref="0dce234dfded58bd461541473b86e42a" category="inline-link-macro-rx"></block>
<block ref="9760ec4df13f0afbdfec88ae16c871ae" category="inline-link-macro-rx"></block>
<block ref="b6dab2933dfb92cf0c1355707a4aec7c" category="inline-link-macro-rx"></block>
<block ref="1b7c80b26162b03bd0addd587f70df55" category="inline-link-macro-rx"></block>
<block ref="14faf912aa42102a6628af4551e02583" category="inline-link-macro-rx"></block>
<block ref="a90f36d649d3be5d386cc3563ab044fb" category="inline-link-macro-rx"></block>
<block ref="2cd65b4a044075cfd9ad4a91f42fdff4" category="inline-link-macro-rx"></block>
<block ref="5e764cc3fdcc19ff667796e414159bdc" category="inline-link-macro-rx"></block>
<block ref="561451f09c7bca700ea0d7833cd9e92e" category="inline-link-macro-rx"></block>
<block ref="d23d341a344216fbf99a91152429d49c" category="inline-link-macro-rx"></block>
<block ref="b35e8fbd7b0369b23734510994911ec4" category="inline-link-macro-rx"></block>
<block ref="41d4305cf7a6acb595086f123121a781" category="inline-link-macro-rx"></block>
<block ref="ea685649fabe77da53e843fec56f72b8" category="inline-link-macro-rx"></block></block>
  <block id="07ee2fe6f236deffba69a7cf80a680fd" category="section-title">ONTAP Mediator für MCC IP</block>
  <block id="f089ab2b9f25f609795bdd46ae636f18" category="inline-link-macro">9.9.1 Hinweis für ONTAP Mediator für MCC IP</block>
  <block id="239794a299abe62705440f2dab3114cb" category="inline-link-macro">9.8 Hinweis für ONTAP Mediator für MCC IP</block>
  <block id="51fcca20d278d2d03192c01120f17442" category="inline-link-macro">9.7 Hinweis für ONTAP Mediator für MCC IP</block>
  <block id="3ba2aeb22339424d5f5b15dafd2c3eca" category="paragraph"><block ref="c8696a7854fcd089ea112145e4968b10" category="inline-link-macro-rx"></block>
<block ref="4d19e06382f392d0f1a50df789d77c13" category="inline-link-macro-rx"></block>
<block ref="fe4ac88b6b3f1cb9f1dc6d5d4b5086ee" category="inline-link-macro-rx"></block></block>
  <block id="9e476387322a5c250893cf9c5c4ce78c" category="doc">Richtlinien</block>
  <block id="b9e18a3460bc17eb9ea65b03f0167453" category="paragraph">Dies ist bei Datenbanken üblich. Datenbanken, für die bekanntermaßen inaktive Blöcke enthalten sind, eignen sich auch für das FabricPool Tiering. Beispielsweise kann eine Supply-Chain-Management-Datenbank historische Informationen enthalten, die bei Bedarf verfügbar sein müssen, aber während des normalen Betriebs nicht aufgerufen werden. Mit FabricPool können die inaktiven Blöcke selektiv verschoben werden.</block>
  <block id="95e955bbbe5dd9520a6bf45b0d8a9d4c" category="paragraph">Beispielsweise Datendateien, die auf einem FabricPool Volume mit einem ausgeführt werden<block ref="e5e88684921dd21f3f86c28343a3082f" prefix=" " category="inline-code"></block> Im Zeitraum von 90 Tagen werden sämtliche Blöcke aufbewahrt, auf die in den vorangegangenen 90 Tagen auf der Performance Tier zugegriffen wurde. Alle Daten, auf die 90 Tage lang nicht zugegriffen wird, werden jedoch auf die Kapazitäts-Tier verlagert. In anderen Fällen bleiben bei normalen Applikationsaktivitäten die richtigen Blöcke auf der richtigen Tier erhalten. Wenn beispielsweise eine Datenbank normalerweise dazu verwendet wird, die Daten der letzten 60 Tage regelmäßig zu verarbeiten, ist dies wesentlich geringer<block ref="e5e88684921dd21f3f86c28343a3082f" prefix=" " category="inline-code"></block> Zeitraum kann festgelegt werden, da die natürliche Aktivität der Anwendung dafür sorgt, dass Blöcke nicht vorzeitig verschoben werden.</block>
  <block id="c33af7c93d461803ceaf8531e861017d" category="paragraph">Der<block ref="9df22f196a33acd0b372fe502de51211" prefix=" " category="inline-code"></block> Richtlinien sollten mit Vorsicht bei Datenbanken verwendet werden. Viele Datenbanken verfügen über periodische Aktivitäten wie etwa Vorgänge zum Quartalsende oder die Neuindizierung. Wenn der Zeitraum dieser Vorgänge größer ist als der<block ref="e5e88684921dd21f3f86c28343a3082f" prefix=" " category="inline-code"></block> Es können Performance-Probleme auftreten. Wenn zum Quartalsende beispielsweise 1 TB an Daten verarbeitet werden müssen, die ansonsten nicht verarbeitet wurden, befinden sich diese Daten möglicherweise nun auf der Kapazitäts-Tier. Lesezugriffe von der Kapazitäts-Tier sind oft extrem schnell und verursachen möglicherweise keine Performance-Probleme. Die genauen Ergebnisse hängen jedoch von der Objektspeicher-Konfiguration ab.</block>
  <block id="03431a55183cb73a12c1bbc3e1927678" category="paragraph">Der<block ref="e5e88684921dd21f3f86c28343a3082f" prefix=" " category="inline-code"></block> Die Richtlinie sollte so hoch eingestellt werden, dass Dateien, die auf der Performance-Tier erforderlich sind, aufbewahrt werden. Beispielsweise müsste eine Datenbank, in der die letzten 60 Tage Daten bei einer optimalen Performance benötigt werden, die festlegen<block ref="e5e88684921dd21f3f86c28343a3082f" prefix=" " category="inline-code"></block> Zeitraum bis 60 Tage. Ähnliche Ergebnisse lassen sich auch anhand der Zugriffsmuster von Dateien erzielen. Wenn beispielsweise die Daten der letzten 90 Tage benötigt werden und die Applikation auf diese 90-Tage-Datenspanne zugreift, verbleiben die Daten in der Performance-Tier. Einstellen des<block ref="e5e88684921dd21f3f86c28343a3082f" prefix=" " category="inline-code"></block> Zeitraum bis 2 Tage würde die Daten sofort nach dem Zeitpunkt verschieben, an dem die Daten weniger aktiv sind.</block>
  <block id="25d9496e96e698b08c4fc713bfc9a5ca" category="paragraph">Der<block ref="9df22f196a33acd0b372fe502de51211" prefix=" " category="inline-code"></block> Eine Richtlinie ist für das Tiering dieser Blöcke erforderlich, da nur die<block ref="9df22f196a33acd0b372fe502de51211" prefix=" " category="inline-code"></block> Die Richtlinie wirkt sich auf Blöcke aus, die sich im aktiven Filesystem befinden.</block>
  <block id="55fad400d892fb6062e67904fa9be485" category="admonition">Jeder Zugriff auf Daten setzt die Heatmap-Daten zurück. Daher verhindert die Überprüfung der vollständigen Tabelle der Datenbank und sogar die Backup-Aktivitäten, die die Quelldateien lesen, Tiering, da die erforderlichen<block ref="e5e88684921dd21f3f86c28343a3082f" prefix=" " category="inline-code"></block> Schwellenwert wird nie erreicht.</block>
  <block id="117c4b6bad0236ab23e0fe29aead8aef" category="paragraph">Obwohl die LUN-Größenänderung eine Option ist, um die Kapazität zu erhöhen, ist es im Allgemeinen besser, eine LVM zu verwenden, einschließlich Oracle ASM. Einer der Hauptgründe für die Existenz von LVMs ist, dass keine LUN-Größe benötigt wird. Mit einer LVM werden mehrere LUNs zu einem virtuellen Speicherpool verknüpft. Die aus diesem Pool ausgearbeiteten logischen Volumes werden von der LVM gemanagt und können problemlos in der Größe geändert werden. Ein weiterer Vorteil besteht darin, dass Hotspots auf einem bestimmten Laufwerk vermieden werden, indem ein bestimmtes logisches Volume auf alle verfügbaren LUNs verteilt wird. Transparente Migration kann in der Regel mithilfe des Volume-Managers durchgeführt werden, um die zugrunde liegenden Extents eines logischen Volumes auf neue LUNs zu verschieben.</block>
  <block id="4d4855a15e1f9d6fd8f8bdf1668c537e" category="doc">NVFAIL manuell erzwungen</block>
  <block id="8772c1c8bed97f5c942657feeb8bfb6f" category="admonition">Dieser Abschnitt erweitert die Erläuterung der grundlegenden ONTAP NVFAIL, um MetroCluster-spezifische Themen zu behandeln.</block>
  <block id="14d74316044293d1ebd8c5a01ff90055" category="paragraph">Bei MetroCluster wird ein Schreibvorgang erst bestätigt, wenn er in lokalem NVRAM und NVRAM auf mindestens einem anderen Controller angemeldet wurde. Dieser Ansatz stellt sicher, dass ein Hardware-Ausfall oder ein Stromausfall nicht zum Verlust der aktiven I/O führen Wenn der lokale NVRAM ausfällt oder die Verbindung zu anderen Nodes ausfällt, werden die Daten nicht mehr gespiegelt.</block>
  <block id="d820d86d09ea05a0de19c3aacbfb72b2" category="paragraph">Wenn der lokale NVRAM einen Fehler meldet, wird der Node heruntergefahren. Dieses Herunterfahren führt zu einem Failover auf einen Partner-Controller, wenn HA-Paare verwendet werden. Bei MetroCluster hängt das Verhalten von der gewählten Gesamtkonfiguration ab, kann jedoch zu einem automatischen Failover auf die entfernte Notiz führen. In jedem Fall gehen keine Daten verloren, da der Controller den Schreibvorgang nicht bestätigt hat.</block>
  <block id="886174de078cee4595eb8a8d07f81703" category="paragraph">Komplizierter wird dies, wenn die Verbindung zwischen Standorten ausfällt, die die NVRAM-Replizierung auf Remote-Nodes blockiert. Schreibvorgänge werden nicht mehr auf die Remote-Nodes repliziert. Dadurch besteht die Möglichkeit eines Datenverlusts, falls ein schwerwiegender Fehler auf einem Controller auftritt. Noch wichtiger ist, dass der Versuch, während dieser Bedingungen ein Failover auf einen anderen Node durchzuführen, zu Datenverlust führt.</block>
  <block id="790ec042c9b89dac2390ea81b9c29a51" category="paragraph">Der Steuerungsfaktor ist, ob NVRAM synchronisiert wird. Bei NVRAM-Synchronisierung kann ein Node-to-Node Failover ohne das Risiko eines Datenverlusts fortgesetzt werden. Wenn in einer MetroCluster Konfiguration NVRAM und die zugrunde liegenden Aggregat-Plexe synchron sind, ist es sicher, mit der Umschaltung fortzufahren, ohne das Risiko eines Datenverlusts zu verursachen.</block>
  <block id="3d936bb059b98a2fc7c177d20eb755c9" category="paragraph">ONTAP lässt kein Failover oder Switchover zu, wenn die Daten nicht synchron sind, es sei denn, das Failover oder die Umschaltung ist erzwungen. Durch das Erzwingen einer solchen Änderung der Bedingungen wird bestätigt, dass Daten im ursprünglichen Controller zurückgelassen werden können und dass ein Datenverlust akzeptabel ist.</block>
  <block id="3d37a3a8ed77bebc986238aedccecbc9" category="paragraph">Datenbanken sind besonders anfällig für Beschädigungen, wenn ein Failover oder Switchover erzwungen wird, da Datenbanken größere interne Daten-Caches auf der Festplatte beibehalten. Wenn ein erzwungenes Failover oder eine Umschaltung auftritt, werden zuvor bestätigte Änderungen effektiv verworfen. Der Inhalt des Storage Arrays springt effektiv zurück in die Zeit, und der Zustand des Datenbank-Cache entspricht nicht mehr dem Status der Daten auf der Festplatte.</block>
  <block id="7ad23b7fa394c8666b132d78a58b1987" category="paragraph">Um Applikationen vor dieser Situation zu schützen, können mit ONTAP Volumes für speziellen Schutz vor NVRAM-Ausfällen konfiguriert werden. Wenn dieser Schutzmechanismus ausgelöst wird, gelangt ein Volume in den Status „NVFAIL“. Dieser Status führt zu I/O-Fehlern, die dazu führen, dass Applikationen heruntergefahren werden, sodass keine veralteten Daten verwendet werden. Daten sollten nicht verloren gehen, da alle bestätigten Schreibvorgänge noch auf dem Speichersystem vorhanden sind, und bei Datenbanken sollten alle festgeschriebenen Transaktionsdaten in den Protokollen vorhanden sein.</block>
  <block id="99259586124503e22927506a7ed3738d" category="paragraph">Als Nächstes muss ein Administrator die Hosts vollständig herunterfahren, bevor die LUNs und Volumes manuell wieder online geschaltet werden. Obwohl diese Schritte etwas Arbeit erfordern können, ist dieser Ansatz der sicherste Weg, um die Datenintegrität zu gewährleisten. Nicht alle Daten erfordern diesen Schutz. Daher kann ein NVFAIL-Verhalten auf Volume-Basis konfiguriert werden.</block>
  <block id="13fbc5a220fe8007dcaea69217bba134" category="paragraph">Die sicherste Option, um ein Switchover mit einem Anwendungs-Cluster (einschließlich VMware, Oracle RAC und anderen) zu erzwingen, das über Standorte verteilt ist, ist durch Angabe<block ref="71e644310ff0f1164d905d6e80174023" prefix=" " category="inline-code"></block> An der Kommandozeile. Diese Option ist als Notfallmaßnahme verfügbar, um sicherzustellen, dass alle zwischengespeicherten Daten gelöscht werden. Wenn ein Host Speicherressourcen verwendet, die sich ursprünglich am Standort mit Notfällen befinden, erhält er entweder I/O-Fehler oder eine veraltete Dateihandle <block ref="a3c6541ac12f1f06a81cc9b03e6bd094" prefix="(" category="inline-code"></block>) Fehler. Oracle Datenbanken stürzen ab und Dateisysteme gehen entweder vollständig offline oder wechseln in den schreibgeschützten Modus.</block>
  <block id="dc6683d37e50abd82911fa91c036fbb2" category="paragraph">Nachdem die Umschaltung abgeschlossen ist, wird der angezeigt<block ref="6b0a5ec5ecf08db5d4b32d860214d098" prefix=" " category="inline-code"></block> Flag muss gelöscht werden und die LUNs müssen in den Online-Modus versetzt werden. Nach Abschluss dieser Aktivität kann die Datenbank neu gestartet werden. Diese Aufgaben können automatisiert werden, um die RTO zu reduzieren.</block>
  <block id="a2626552f293b2377efe829e69d14daa" category="section-title">dr-Force-NV-Fehler</block>
  <block id="f0cc4bbe3d196251009dbe9f0ac42ffc" category="paragraph">Stellen Sie als allgemeine Sicherheitsmaßnahme die ein<block ref="a2626552f293b2377efe829e69d14daa" prefix=" " category="inline-code"></block> Markieren Sie alle Volumes, auf die während des normalen Betriebs von einem Remote-Standort aus zugegriffen werden kann, d. h. sie sind Aktivitäten, die vor dem Failover verwendet werden. Das Ergebnis dieser Einstellung ist, dass ausgewählte Remote-Volumes beim Aufrufen nicht mehr verfügbar sind<block ref="6b0a5ec5ecf08db5d4b32d860214d098" prefix=" " category="inline-code"></block> Während einer Umschaltung. Nachdem die Umschaltung abgeschlossen ist, wird der angezeigt<block ref="6b0a5ec5ecf08db5d4b32d860214d098" prefix=" " category="inline-code"></block> Flag muss gelöscht und die LUNs müssen in den Online-Modus versetzt werden. Nach Abschluss dieser Aktivitäten können die Anwendungen neu gestartet werden. Diese Aufgaben können automatisiert werden, um die RTO zu reduzieren.</block>
  <block id="5f6aa76cc0fe886c07f242f921486ef7" category="paragraph">Das Ergebnis ist wie bei der Verwendung von<block ref="71e644310ff0f1164d905d6e80174023" prefix=" " category="inline-code"></block> Markierung für manuelle Umschaltung. Die Anzahl der betroffenen Volumes kann jedoch auf die Volumes beschränkt werden, die vor Anwendungen oder Betriebssystemen mit veralteten Caches geschützt werden müssen.</block>
  <block id="4df566a29b44806612369c0c1f67521b" category="paragraph">Es gibt zwei entscheidende Anforderungen an eine Umgebung, die nicht verwendet wird<block ref="a2626552f293b2377efe829e69d14daa" prefix=" " category="inline-code"></block> Auf Anwendungsvolumes:</block>
  <block id="aaf1cc67bd88c39a71e691d413ded49f" category="list-text">Ein erzwungenes Switchover darf nicht mehr als 30 Sekunden nach dem Ausfall des primären Standorts erfolgen.</block>
  <block id="7f9cc623e2a11875714cf4bc64f148fd" category="list-text">Eine Umschaltung darf nicht während Wartungsaufgaben oder unter anderen Bedingungen erfolgen, unter denen SyncMirror Plexe oder NVRAM-Replikation nicht synchron sind. Die erste Anforderung ist über eine Tiebreaker Software möglich, die im Fall eines Standortausfalls innerhalb von 30 Sekunden umgeschaltet wird. Dies bedeutet jedoch nicht, dass die Umschaltung innerhalb von 30 Sekunden nach Erkennung eines Standortausfalls durchgeführt werden muss. Das bedeutet, dass es nicht mehr sicher ist, eine Umschaltung zu erzwingen, wenn 30 Sekunden vergangen sind, seit die Betriebsbereitschaft eines Standorts bestätigt wurde.</block>
  <block id="0929cc8043c21dcf0163f06424677ede" category="paragraph">Die zweite Anforderung wird teilweise erfüllt, indem alle Funktionen zum automatisierten Switchover deaktiviert werden, wenn bekannt ist, dass die MetroCluster-Konfiguration nicht synchron ist. Eine bessere Option ist die Nutzung einer Tiebreaker Lösung, mit der der Systemzustand der NVRAM-Replizierung und der SyncMirror Plexe überwacht werden kann. Wenn das Cluster nicht vollständig synchronisiert ist, sollte Tiebreaker keine Umschaltung auslösen.</block>
  <block id="a168430c68d0310385371eabe149a118" category="paragraph">Die NetApp-MCTB-Software kann den Synchronisierungsstatus nicht überwachen, daher sollte sie deaktiviert werden, wenn MetroCluster aus irgendeinem Grund nicht synchron ist. ClusterLion verfügt über Funktionen zur NVRAM-Überwachung und Plex-Überwachung und kann so konfiguriert werden, dass das Switchover nur ausgelöst wird, wenn für das MetroCluster-System eine vollständige Synchronisierung bestätigt wurde.</block>
  <block id="baba038803e218b2ac3b2688bc2fd5db" category="doc">LUN-Anzahl</block>
  <block id="b0e4db975ae00108abe9f47db9be5668" category="paragraph">Eine LUN ist ein virtualisiertes Objekt auf ONTAP, das über alle Laufwerke im Hosting-Aggregat hinweg existiert. Die Performance der LUN wird daher von ihrer Größe nicht beeinflusst, da die LUN unabhängig von der gewählten Größe das volle Performance-Potenzial des Aggregats schöpft.</block>
  <block id="7235d4b71fadc2fe03d09d863c7cdd66" category="paragraph">Aus praktischen Gründen möchten Kunden möglicherweise eine LUN einer bestimmten Größe verwenden. Wenn beispielsweise eine Datenbank auf einer LVM oder einer Oracle ASM-Datenträgergruppe erstellt wird, die aus zwei LUNs mit jeweils 1 TB besteht, muss diese Datenträgergruppe in Schritten von 1 TB erweitert werden. Es könnte besser sein, die Datenträgergruppe aus acht LUNs mit jeweils 500 GB zu erstellen, damit die Datenträgergruppe in kleineren Schritten erhöht werden kann.</block>
  <block id="4b1ffe65479a23391a2c7f9caf467a35" category="paragraph">Die Praxis, eine universelle Standard-LUN-Größe zu etablieren, wird davon abgeraten, da dies die Managebarkeit erschweren kann. Beispielsweise funktioniert eine standardmäßige LUN-Größe von 100 GB gut, wenn eine Datenbank oder ein Datastore im Bereich von 1 TB bis 2 TB liegt, jedoch erfordert eine Datenbank oder ein Datenspeicher mit einer Größe von 20 TB 200 LUNs. Das bedeutet, dass der Server-Neustart länger dauert, mehr Objekte in den verschiedenen Benutzeroberflächen zu verwalten sind und Produkte wie SnapCenter eine Erkennung für viele Objekte durchführen müssen. Derartige Probleme werden durch die Verwendung von weniger und größeren LUNs vermieden.</block>
  <block id="4afa3de974c36a09c2055d30989bb405" category="list-text">Die Anzahl der LUNs ist wichtiger als die LUN-Größe.</block>
  <block id="691c70133d96d57796a9299359666f80" category="list-text">Die LUN-Größe wird überwiegend durch die Anforderungen der LUN-Anzahl gesteuert.</block>
  <block id="8af9e525c143179b948a11fc382a331e" category="list-text">Erstellen Sie nicht mehr LUNs als erforderlich.</block>
  <block id="407b2218ad77513a7e3964f169d07e66" category="paragraph">Anders als die LUN-Größe wirkt sich die Anzahl der LUNs auf die Performance aus. Die Applikations-Performance hängt häufig von der Fähigkeit ab, parallelen I/O über die SCSI-Schicht auszuführen. Dadurch bieten zwei LUNs eine bessere Performance als eine einzelne LUN. Die Verwendung einer LVM wie Veritas VxVM, Linux LVM2 oder Oracle ASM ist die einfachste Methode, um die Parallelität zu erhöhen.</block>
  <block id="39143fe6204f383e4ce3bb3b77926455" category="paragraph">NetApp Kunden konnten im Allgemeinen nur einen minimalen Nutzen aus der Erhöhung der Anzahl von LUNs über sechzehn hinaus verzeichnen, obwohl sich bei den Tests mit 100 % SSD-Umgebungen mit sehr hoher zufälliger I/O-Last weitere Verbesserungen auf bis zu 64 LUNs gezeigt haben.</block>
  <block id="9875f7503e59521e91e519abd87f5c9e" category="paragraph">*NetApp empfiehlt* Folgendes:</block>
  <block id="57153ab478a4958250d76ac6bf4e3ac0" category="paragraph">Im Allgemeinen reichen vier bis sechzehn LUNs aus, um die I/O-Anforderungen jedes gegebenen Datenbank-Workloads zu unterstützen. Aufgrund der Einschränkungen bei Host-SCSI-Implementierungen könnten weniger als vier LUNs zu Performance-Einschränkungen führen.</block>
  <block id="de932976b195d4755fcbea64295fc7cb" category="doc">Einstellungen für das Host-Betriebssystem</block>
  <block id="f62cb371f65c322cd9e17a5c2cecd1c8" category="paragraph">Die Dokumentation der meisten Anwendungsanbieter enthält bestimmte TCP- und ethernet-Einstellungen, die sicherstellen sollen, dass die Anwendung optimal funktioniert. Diese Einstellungen reichen in der Regel aus, um auch eine optimale IP-basierte Speicherleistung zu erzielen.</block>
  <block id="ae7a0bb210cbd1edb935128116a21c55" category="section-title">Ethernet-Flusskontrolle</block>
  <block id="a3c15fb208efc85bdfe72c57d56c92b8" category="paragraph">Mit dieser Technologie kann ein Client verlangen, dass ein Sender die Datenübertragung vorübergehend stoppt. Dies geschieht normalerweise, weil der Empfänger eingehende Daten nicht schnell genug verarbeiten kann. Die Anforderung, dass ein Sender die Übertragung abbricht, war zu einem Zeitpunkt weniger störend, als dass ein Empfänger Pakete verwirft, weil die Puffer voll waren. Dies ist bei den heute in Betriebssystemen verwendeten TCP-Stacks nicht mehr der Fall. Tatsächlich verursacht die Flusskontrolle mehr Probleme als sie löst.</block>
  <block id="950d31923e253d170d6c994801ce7cec" category="paragraph">Leistungsprobleme, die durch die Ethernet-Flusssteuerung verursacht werden, haben in den letzten Jahren zugenommen. Der Grund dafür ist, dass die Ethernet-Flusssteuerung auf der physischen Ebene ausgeführt wird. Wenn eine Netzwerkkonfiguration es einem Host-Betriebssystem ermöglicht, eine Ethernet-Datenflusssteuerungsanforderung an ein Storage-System zu senden, führt dies zu einer I/O-Pause für alle verbundenen Clients. Da immer mehr Clients von einem einzelnen Storage Controller bedient werden, steigt die Wahrscheinlichkeit, dass ein oder mehrere dieser Clients Flow Control-Anfragen senden. Das Problem ist bei Kundenstandorten mit umfassender Betriebssystemvirtualisierung häufig aufgetreten.</block>
  <block id="6bfd8563627c68f73c30581843441a74" category="paragraph">Eine NIC auf einem NetApp-System sollte keine Anfragen zur Flusskontrolle empfangen. Die Methode, mit der dieses Ergebnis erzielt wird, hängt vom Hersteller des Netzwerk-Switches ab. In den meisten Fällen kann die Flusssteuerung auf einem Ethernet-Switch eingestellt werden<block ref="a67b5ddb674c9ca32d9c9e1ca81578ee" prefix=" " category="inline-code"></block> Oder<block ref="f4eb0bfa09695eb47ff4f3bd3ca4449d" prefix=" " category="inline-code"></block>, Das bedeutet, dass eine Durchflussregelanforderung nicht an den Speichercontroller weitergeleitet wird. In anderen Fällen lässt die Netzwerkverbindung auf dem Storage Controller möglicherweise die Deaktivierung der Flusssteuerung nicht zu. In diesen Fällen müssen die Clients so konfiguriert werden, dass sie keine Flow-Control-Anforderungen senden, entweder indem sie auf die NIC-Konfiguration auf dem Host-Server selbst oder auf die Switch-Ports wechseln, mit denen der Host-Server verbunden ist.</block>
  <block id="7496f3ff64e30d4732c2c64880faf186" category="admonition">*NetApp empfiehlt* sicherzustellen, dass NetApp-Speicher-Controller keine Ethernet-Flow-Control-Pakete empfangen. Dies kann im Allgemeinen durch Einstellen der Switch Ports geschehen, an die der Controller angeschlossen ist. Bei einigen Switch-Hardware bestehen jedoch Einschränkungen, die stattdessen clientseitige Änderungen erfordern können.</block>
  <block id="ae6d0fc57efaf02ad7dfdacd3575e315" category="section-title">MTU-Größen</block>
  <block id="ff13ea04765cd9c9aed7b839f15eb2b4" category="paragraph">Der Einsatz von Jumbo Frames hat gezeigt, dass sich die Performance in 1-GB-Netzwerken durch Reduzierung des CPU- und Netzwerk-Overheads verbessert. Die Vorteile sind jedoch in der Regel nicht signifikant.</block>
  <block id="ee3f364287a30ef10dfdce2f37d94ed2" category="admonition">*NetApp empfiehlt*, wenn möglich Jumbo Frames zu implementieren, sowohl um potenzielle Leistungsvorteile zu realisieren als auch um die Lösung zukunftssicher zu machen.</block>
  <block id="2c6ba27b7ed602a9089da6ad9f762c9a" category="paragraph">Die Verwendung von Jumbo Frames in einem 10-Gbit-Netzwerk ist fast zwingend erforderlich. Der Grund dafür ist, dass die meisten 10-GB-Implementierungen vor Erreichen der 10-GB-Marke ohne Jumbo-Frames eine Grenze von Paketen pro Sekunde erreichen. Die Verwendung von Jumbo Frames verbessert die Effizienz bei der TCP/IP-Verarbeitung, da Betriebssystem, Server, NICs und Speichersystem weniger, aber größere Pakete verarbeiten können. Die Leistungsverbesserung variiert von NIC zu NIC, ist jedoch signifikant.</block>
  <block id="a44be1bbfde97e4a64b50282325165e7" category="paragraph">Bei Jumbo-Frame-Implementierungen besteht die allgemeine, aber falsche Annahme, dass alle verbundenen Geräte Jumbo-Frames unterstützen müssen und dass die MTU-Größe End-to-End entsprechen muss Stattdessen verhandeln die beiden Netzwerkendpunkte beim Herstellen einer Verbindung die höchste für beide Seiten akzeptable Frame-Größe. In einer typischen Umgebung ist ein Netzwerk-Switch auf eine MTU-Größe von 9216, der NetApp-Controller auf 9000 und die Clients auf 9000 und 1514 eingestellt. Clients, die eine MTU von 9000 unterstützen, können Jumbo-Frames verwenden, und Clients, die nur 1514 unterstützen, können einen niedrigeren Wert aushandeln.</block>
  <block id="a31484167f31e1c3f36f7cea821bc581" category="paragraph">Probleme mit dieser Anordnung sind in einer komplett geschalteten Umgebung selten. Achten Sie jedoch in einer gerouteten Umgebung darauf, dass kein Zwischenrouter gezwungen ist, Jumbo-Frames zu fragmentieren.</block>
  <block id="c805e9846e6fca449dbe3233cc5dbdf5" category="paragraph">*NetApp empfiehlt* die Konfiguration folgender Komponenten:</block>
  <block id="b4446b5ca60d915111af271495bd4c17" category="list-text">Jumbo Frames sind wünschenswert, jedoch nicht erforderlich mit 1Gb Ethernet (GbE).</block>
  <block id="5b1ea13ac12a9c8be0d09303f637dba4" category="list-text">Jumbo Frames sind für maximale Performance mit 10 GbE und schneller erforderlich.</block>
  <block id="08a8dce78637f5dd14ed052163feb9da" category="section-title">TCP-Parameter</block>
  <block id="1a999618685598bee637262fe589de70" category="paragraph">Drei Einstellungen sind oft falsch konfiguriert: TCP-Zeitstempel, selektive Bestätigung (SACK) und TCP-Fenster-Skalierung. Viele veraltete Dokumente im Internet empfehlen, einen oder mehrere dieser Parameter zu deaktivieren, um die Leistung zu verbessern. Vor vielen Jahren war diese Empfehlung verdienlich, als die CPU-Kapazitäten wesentlich geringer waren und der Overhead für die TCP-Verarbeitung, wenn möglich, reduziert werden konnte.</block>
  <block id="6a594ec6f0bb742c1d2b0f631cf65ba1" category="paragraph">Bei modernen Betriebssystemen führt die Deaktivierung dieser TCP-Funktionen jedoch in der Regel nicht zu nachweisbaren Vorteilen und kann gleichzeitig die Leistung beeinträchtigen. In virtualisierten Netzwerkumgebungen sind Performance-Schäden besonders wahrscheinlich, da diese Funktionen für eine effiziente Handhabung von Paketverlusten und Änderungen der Netzwerkqualität erforderlich sind.</block>
  <block id="cdc44d05b1633e8a8c7835010c423dd6" category="admonition">*NetApp empfiehlt*, TCP-Zeitstempel, SACK und TCP-Fenster-Skalierung auf dem Host zu aktivieren, und alle drei dieser Parameter sollten in jedem aktuellen Betriebssystem standardmäßig aktiviert sein.</block>
  <block id="72a921ac9177188a9be32ec711fc15d8" category="doc">Pfadzugriff</block>
  <block id="544c599da087dba677a820c3df344503" category="paragraph">Bei SnapMirror Business Continuity (SM-BC) handelt es sich im Grunde um eine erweiterte SnapMirror Funktion für SAN, mit der Hosts sowohl von dem System, das die LUN hostet, als auch von dem System, das dessen Replikat hostet, auf eine LUN zugreifen können.</block>
  <block id="6139cdabb39d5ceac18a60642497c6a7" category="paragraph">SM-BC und SnapMirror Sync (SM-S) nutzen eine Replizierungs-Engine, SM-BC enthält jedoch zusätzliche Funktionen wie transparentes Applikations-Failover und Failback für Enterprise-Applikationen.</block>
  <block id="a73743f15de974052b0640c60f489d90" category="paragraph">In der Praxis funktioniert es ähnlich wie eine granulare Version von MetroCluster, indem es eine selektive und granulare synchrone RPO=0-Replizierung für individuelle Workloads ermöglicht. Das Verhalten der Pfade auf niedriger Ebene unterscheidet sich sehr von MetroCluster, aber das Endergebnis aus der Sicht des Hosts ist ähnlich.</block>
  <block id="b3bf85c7b0a17286752c110f404a7035" category="paragraph">SM-BC macht Speichergeräte für Host-Betriebssysteme sowohl von den primären als auch von den Remote-Speicher-Arrays sichtbar. Pfade werden über das Asymmetric Logical Unit Access (ALUA)-Protokoll verwaltet. Hierbei handelt es sich um ein branchenübliches Protokoll zur Identifizierung optimierter Pfade zwischen einem Storage-System und einem Host.</block>
  <block id="cbf0bd4f4096570f567049c984f8c9d3" category="paragraph">Der Gerätepfad, der den kürzesten Zugriff auf E/A hat, wird als aktiv/optimiert betrachtet, und der Rest der Pfade gilt als aktiv/nicht optimiert.</block>
  <block id="350b9208772a185e0d0943b105765d89" category="paragraph">Die SM-BC-Beziehung besteht zwischen einem SVMs-Paar, das sich auf verschiedenen Clustern befindet. Beide SVMs können Daten bereitstellen. ALUA verwendet jedoch bevorzugt die SVM, die derzeit Eigentümer der Laufwerke ist, auf denen sich die LUNs befinden. IO an die Remote-SVM wird über den SM-BC-Interconnect als Proxy verwendet.</block>
  <block id="341d84aa26cb4521474864e04ea2a63b" category="inline-image-macro">Fehler: Fehlendes Grafikbild</block>
  <block id="532db5273379dd6149d97b7ab6e420b6" category="paragraph"><block ref="532db5273379dd6149d97b7ab6e420b6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b56265ceb6311e42003e668438136a59" category="section-title">Synchrone Replizierung</block>
  <block id="8159c40a86db91b72e00c2eb5cf751fe" category="paragraph">Im normalen Betrieb ist die Remote-Kopie jederzeit ein synchrones RPO=0-Replikat, mit einer Ausnahme. Wenn Daten nicht repliziert werden können, gibt SM-BC die Notwendigkeit frei, Daten zu replizieren und die Bereitstellung von E/A-Vorgängen fortzusetzen. Diese Option wird von Kunden bevorzugt, die den Verlust des Replikationslinks in einem Notfall erwägen oder die nicht möchten, dass der Geschäftsbetrieb unterbrochen wird, wenn Daten nicht repliziert werden können.</block>
  <block id="0cf4a786acebd750bbfdfc4416c89406" category="section-title">Storage-Hardware</block>
  <block id="f0fd4c8ee2422af8e335cc85c485ccbf" category="paragraph">Im Gegensatz zu anderen Disaster Recovery-Lösungen für Storage bietet SM-BC asymmetrische Plattformflexibilität. Die Hardware an den einzelnen Standorten muss nicht identisch sein. Mit dieser Funktion können Sie die Größe der Hardware anpassen, die zur Unterstützung von SM-BC verwendet wird. Das Remote-Storage-System kann identisch mit dem primären Standort sein, wenn es einen vollständigen Produktions-Workload unterstützen muss. Wenn jedoch ein Ausfall zu einer Verringerung der I/O führt, könnte ein kleineres System am Remote-Standort kostengünstiger sein.</block>
  <block id="ea9f3de5dd21190fbc6bca180b2040f1" category="section-title">ONTAP Mediator</block>
  <block id="b378eb5f2b386494f24a3f09afd8ae1f" category="paragraph">Der ONTAP Mediator ist eine Softwareanwendung, die vom NetApp Support heruntergeladen wird. Der Mediator automatisiert Failover-Vorgänge für das Storage-Cluster am primären und Remote-Standort. Es kann auf einer kleinen Virtual Machine (VM) implementiert werden, die entweder vor Ort oder in der Cloud gehostet wird. Nach der Konfiguration fungiert er als dritter Standort, um Failover-Szenarien für beide Standorte zu überwachen.</block>
  <block id="0f54fb931dbdeea735f18a8e73f9eab5" category="doc">Datensicherung mit SyncMirror</block>
  <block id="d7023f86951b6c3c009891a468c3effd" category="paragraph">Auf der einfachsten Ebene bedeutet synchrone Replikation, dass jede Änderung an beiden Seiten des gespiegelten Speichers vorgenommen werden muss, bevor sie bestätigt wird. Wenn beispielsweise eine Datenbank ein Protokoll schreibt oder ein VMware Gast gepatcht wird, darf ein Schreibvorgang nie verloren gehen. Als Protokollebene darf das Storage-System den Schreibvorgang erst dann bestätigen, wenn es auf nichtflüchtigen Medien an beiden Standorten gespeichert wurde. Nur dann ist es sicher, ohne das Risiko eines Datenverlusts zu gehen.</block>
  <block id="eee4f7a4e0ed3a8646a97bcf3e118fb9" category="paragraph">Die Verwendung einer Technologie zur synchronen Replizierung ist der erste Schritt beim Entwurf und Management einer Lösung zur synchronen Replizierung. Die wichtigste Überlegung ist, zu verstehen, was in verschiedenen geplanten und ungeplanten Ausfallszenarien passieren könnte. Nicht alle Lösungen zur synchronen Replizierung bieten dieselben Funktionen. Wenn Sie eine Lösung benötigen, die einen Recovery Point Objective (RPO) von null bietet, d. h. keinen Datenverlust verursacht, müssen alle Ausfallszenarien in Betracht gezogen werden. Welches ist insbesondere das erwartete Ergebnis, wenn die Replikation aufgrund des Verlusts der Verbindung zwischen Standorten nicht möglich ist?</block>
  <block id="71554672a088c43ab21c759ddd161928" category="section-title">SyncMirror Datenverfügbarkeit</block>
  <block id="bec293a9cf8e49ec40e6a4fdc02b9146" category="paragraph">Die MetroCluster-Replizierung basiert auf der NetApp SyncMirror Technologie, mit der effizient in den synchronen Modus bzw. aus dem synchronen Modus gewechselt werden kann. Diese Funktion erfüllt die Anforderungen von Kunden, die synchrone Replizierung benötigen, aber auch Hochverfügbarkeit für ihre Datenservices benötigen. Wenn beispielsweise die Verbindung zu einem Remote-Standort getrennt ist, ist es im Allgemeinen besser, das Storage-System weiterhin in einem nicht replizierten Zustand zu betreiben.</block>
  <block id="9a9ce41f4b23474045b6c6e0ac7752af" category="paragraph">Viele Lösungen zur synchronen Replizierung können nur im synchronen Modus betrieben werden. Diese Art der alles-oder-nichts-Replikation wird manchmal Domino-Modus genannt. Solche Storage-Systeme stellen keine Daten mehr bereit, statt dass lokale und Remote-Kopien der Daten unsynchronisiert werden. Wenn die Replikation gewaltsam unterbrochen wird, kann die Resynchronisierung äußerst zeitaufwendig sein und einen Kunden während der Wiederherstellung der Spiegelung einem vollständigen Datenverlust aussetzen.</block>
  <block id="8646bb558f8f18a200cce2f70602627a" category="paragraph">SyncMirror kann nicht nur nahtlos aus dem synchronen Modus wechseln, wenn der Remote-Standort nicht erreichbar ist, sondern auch bei der Wiederherstellung der Konnektivität schnell zu einem RPO = 0-Zustand neu synchronisieren. Die veraltete Kopie der Daten am Remote-Standort kann während der Resynchronisierung auch in einem nutzbaren Zustand aufbewahrt werden. Auf diese Weise ist gewährleistet, dass lokale und Remote-Kopien der Daten jederzeit vorhanden sind.</block>
  <block id="995f5151d2d1c0a4e8371b2b3c9b6e5b" category="paragraph">Wo der Domino-Modus erforderlich ist, bietet NetApp SnapMirror Synchronous (SM-S) an. Darüber hinaus gibt es Optionen auf Applikationsebene wie Oracle DataGuard oder erweiterte Timeouts für Host-seitige Plattenspiegelung. Wenden Sie sich an Ihren NetApp oder Ihr Partner Account Team, um weitere Informationen und Optionen zu erhalten.</block>
  <block id="1d12d7a206d9b5337ae6fa442f23d377" category="doc">Nur Snapshot</block>
  <block id="64c29f2f2feedeb607ff588b13d9758b" category="paragraph">Der<block ref="8805d416ce540c5f2df34af5b18d742b" prefix=" " category="inline-code"></block><block ref="964193481f440d73ce3474a7a09bc3ac" prefix=" " category="inline-code"></block> Gilt nur für Blöcke, die nicht mit dem aktiven Dateisystem gemeinsam genutzt werden. Im Wesentlichen führt dies zum Tiering von Datenbank-Backups. Blöcke eignen sich als Tiering-Kandidaten, nachdem ein Snapshot erstellt wurde und der Block dann überschrieben wird. Das Ergebnis ist ein Block, der nur innerhalb des Snapshots vorhanden ist. Die Verzögerung vor einem<block ref="8805d416ce540c5f2df34af5b18d742b" prefix=" " category="inline-code"></block> Der Block wird als cool betrachtet und wird vom gesteuert<block ref="e5e88684921dd21f3f86c28343a3082f" prefix=" " category="inline-code"></block> Einstellung für die Lautstärke. Der Bereich ab ONTAP 9.8 liegt zwischen 2 und 183 Tagen.</block>
  <block id="ebd9889c847a7a3ddeccd2717ead46f2" category="paragraph">Viele Datensätze verfügen über niedrige Änderungsraten, wodurch diese Richtlinien nur minimal eingespart werden. Eine typische Datenbank mit ONTAP hat beispielsweise eine Änderungsrate von weniger als 5 % pro Woche. Protokolle für Datenbankarchive können umfangreichen Speicherplatz belegen, existieren jedoch normalerweise weiterhin im aktiven File-System und sind daher nicht für Tiering im Rahmen dieser Richtlinie geeignet.</block>
  <block id="06b9281e396db002010bde1de57262eb" category="section-title">Automatisch</block>
  <block id="ecf602bd5abbd6a605debedbb6c3d4e0" category="paragraph">Der<block ref="9df22f196a33acd0b372fe502de51211" prefix=" " category="inline-code"></block> die Tiering-Richtlinie erweitert das Tiering sowohl auf Snapshot-spezifische Blöcke als auch auf Blöcke innerhalb des aktiven File-Systems. Die Verzögerung, bevor ein Block als cool betrachtet wird, wird vom gesteuert<block ref="e5e88684921dd21f3f86c28343a3082f" prefix=" " category="inline-code"></block> Einstellung für die Lautstärke. Der Bereich ab ONTAP 9.8 liegt zwischen 2 und 183 Tagen.</block>
  <block id="6256ce48698ff0bde6f818679cdfb382" category="paragraph">Dieser Ansatz ermöglicht Tiering-Optionen, die mit dem nicht verfügbar sind<block ref="8805d416ce540c5f2df34af5b18d742b" prefix=" " category="inline-code"></block> Richtlinie: Eine Datensicherungsrichtlinie kann beispielsweise die Aufbewahrung bestimmter Protokolldateien von 90 Tagen erfordern. Wenn Sie einen Abkühlzeitraum von 3 Tagen festlegen, werden Protokolldateien, die älter als 3 Tage sind, aus der Performance-Schicht verschoben. Dadurch wird ein erheblicher Teil des Speicherplatzes auf dem Performance-Tier freigesetzt, und Sie können die Daten der gesamten 90 Tage anzeigen und managen.</block>
  <block id="6adf97f83acf6453d4a6a4b1070f3754" category="section-title">Keine</block>
  <block id="7026ff5c5d4ab3946ff2d86f0e2cca6f" category="paragraph">Der<block ref="334c4a4c42fdb79d7ebc3e73b517e6f8" prefix=" " category="inline-code"></block> die tiering-Richtlinie verhindert, dass zusätzliche Blöcke von der Storage-Ebene aus verschoben werden, doch alle Daten, die sich noch in der Kapazitäts-Tier befinden, bleiben bis sie gelesen werden. Wenn der Block dann gelesen wird, wird er zurückgezogen und auf die Performance-Tier platziert.</block>
  <block id="d152c7b0939fb6d35fdb0433de0d6369" category="paragraph">Der Hauptgrund für die Verwendung des<block ref="334c4a4c42fdb79d7ebc3e73b517e6f8" prefix=" " category="inline-code"></block> mittels tiering-Richtlinie soll verhindert werden, dass Blöcke in Tiers verschoben werden, es könnte sich jedoch nützlich sein, die Richtlinien im Laufe der Zeit zu ändern. Nehmen wir beispielsweise an, dass ein bestimmter Datensatz häufig auf die Kapazitätsebene gestaffelt ist, doch entsteht ein unerwarteter Bedarf an vollständigen Performance-Funktionen. Die Richtlinie kann geändert werden, um ein zusätzliches Tiering zu vermeiden und sicherzustellen, dass alle Blöcke, die bei einer Zunahme der I/O-Vorgänge zurückgelesen werden, weiterhin in der Performance-Tier verbleiben.</block>
  <block id="b1c94ca2fbc3e78fc30069c8d0f01680" category="section-title">Alle</block>
  <block id="84826d7e23dfac7549819d5115fdcedd" category="paragraph">Der<block ref="a181a603769c1f98ad927e7367c7aa51" prefix=" " category="inline-code"></block> Die tiering-Richtlinie ersetzt die<block ref="402051f4be0cc3aad33bcf3ac3d6532b" prefix=" " category="inline-code"></block> Richtlinie ab ONTAP 9.6. Der<block ref="402051f4be0cc3aad33bcf3ac3d6532b" prefix=" " category="inline-code"></block> Richtlinie gilt nur für Datensicherungs-Volumes, d. h. ein Ziel für SnapMirror oder NetApp SnapVault. Der<block ref="a181a603769c1f98ad927e7367c7aa51" prefix=" " category="inline-code"></block> Richtlinienfunktionen identisch, aber nicht beschränkt auf Datensicherungs-Volumes</block>
  <block id="10d8500e282e8bbacd668af6f773f412" category="paragraph">Mit dieser Richtlinie gelten Blöcke sofort als „cool“ und können sofort auf die Kapazitätsebene verschoben werden.</block>
  <block id="ec583de0216b95bc673c84e4ec9356e6" category="paragraph">Diese Richtlinie eignet sich besonders für langfristige Backups. Es kann auch als eine Form von Hierarchical Storage Management (HSM) verwendet werden. In der Vergangenheit wurde HSM häufig verwendet, um die Datenblöcke einer Datei auf Band zu verschieben, während die Datei selbst im Dateisystem sichtbar gehalten wurde. Ein FabricPool Volume mit dem<block ref="a181a603769c1f98ad927e7367c7aa51" prefix=" " category="inline-code"></block> Richtlinien ermöglichen das Speichern von Dateien in einem sichtbaren und leicht zu verwaltenden System, wobei jedoch so gut wie kein Speicherplatz auf der lokalen Storage Tier belegt wird.</block>
  <block id="79768a069a539d4f130e672a660bf45f" category="doc">Zoning</block>
  <block id="79da1502ddfac887bfdf0d92f2428fe6" category="paragraph">Dies umfasst typische Planungsmaßnahmen wie die Sicherstellung einer ausreichenden Bandbreite auf dem SAN zwischen dem Host und dem Speichersystem, die Überprüfung, ob alle SAN-Pfade zwischen allen erforderlichen Geräten vorhanden sind, unter Verwendung der FC-Port-Einstellungen, die Ihr FC-Switch-Anbieter benötigt, und vermeidet ISL-Konflikte, und ordnungsgemäße Überwachung des SAN-Fabrics verwenden.</block>
  <block id="a0bdb98e8b9da585816478d24278e42f" category="paragraph">Eine FC-Zone sollte nie mehr als einen Initiator enthalten. Eine solche Anordnung mag zunächst zu funktionieren scheinen, doch Crosstalk zwischen Initiatoren beeinträchtigt letztendlich die Performance und Stabilität.</block>
  <block id="8ef958d9e25538841b306960ab117626" category="paragraph">Multitarget-Zonen werden allgemein als sicher angesehen, obwohl in seltenen Fällen das Verhalten von FC-Zielports unterschiedlicher Anbieter Probleme verursacht hat. Es ist beispielsweise zu vermeiden, die Ziel-Ports von einem NetApp und einem nicht-NetApp Storage-Array in derselben Zone zu integrieren. Darüber hinaus besteht mit noch größerer Wahrscheinlichkeit die Gefahr, dass ein NetApp Storage-System und ein Bandgerät in dieselbe Zone platziert werden.</block>
  <block id="642223473862db290604321fe2ebe763" category="doc">SVMs</block>
  <block id="47ea917cf14ad91c68c407f90a7a189d" category="paragraph">Eine SVM, in der ONTAP CLI als vServer bezeichnet, ist eine grundlegende Funktionseinheit des Storage. Es ist hilfreich, eine SVM mit einem Gast auf einem VMware ESX Server zu vergleichen.</block>
  <block id="9efbaa34de852e33319ca8ceb1861832" category="paragraph">Bei der Erstinstallation verfügt ESX über keine vorkonfigurierten Funktionen, wie z. B. das Hosting eines Gastbetriebssystems oder die Unterstützung einer Endbenutzeranwendung. Es ist ein leerer Container, bis eine Virtual Machine (VM) definiert ist. ONTAP ist ähnlich. Die erste Installation von ONTAP umfasst keine Datenserverfunktionen, bis eine SVM erstellt wurde. Die Datenservices werden von der SVM-Persönlichkeit definiert.</block>
  <block id="13ce2622b2cc2118c44d3aae7df8167d" category="paragraph">Wie bei anderen Aspekten der Storage-Architektur hängen die besten Optionen für das Design von SVMs und Logical Interface (LIF) stark von den Skalierungsanforderungen und geschäftlichen Anforderungen ab.</block>
  <block id="8fb41a27984f0beba2e12fb920a486aa" category="paragraph">Es gibt keine offizielle Best Practice für die Bereitstellung von SVMs für ONTAP. Der richtige Ansatz hängt von Management- und Sicherheitsanforderungen ab.</block>
  <block id="f4d8541bb6d07f7533a6b5aa6cfb2455" category="paragraph">Die meisten Kunden betreiben für die meisten ihrer täglichen Anforderungen eine primäre SVM, erstellen jedoch für besondere Anforderungen eine geringe Anzahl an SVMs. Sie können beispielsweise Folgendes erstellen:</block>
  <block id="259908e9e431c0fbb9d425249ceb7930" category="list-text">Eine SVM für eine kritische Geschäftsdatenbank, die von einem Expertenteam gemanagt wird</block>
  <block id="0e10f2715884f3538282397d69b2cd00" category="list-text">Eine SVM für eine Entwicklungsgruppe, der eine vollständige administrative Kontrolle gegeben wurde, damit sie ihren eigenen Storage unabhängig managen können</block>
  <block id="7624156e307247e4ea1ec8bf574136a1" category="list-text">Eine SVM für sensible Geschäftsdaten wie Personaldaten oder Daten für Finanzberichte, für die das Administrationsteam begrenzt werden muss</block>
  <block id="e5e09031843479ef9ef8cbbd4c2f404c" category="inline-link-macro">NetApp Hardware Universe</block>
  <block id="bd32656670155eb09690047819fc0971" category="paragraph">In einer mandantenfähigen Umgebung können die Daten jedes Mandanten eine dedizierte SVM zugewiesen werden. Die Obergrenze für die Anzahl der SVMs und LIFs pro Cluster, HA-Paar und Node ist abhängig vom verwendeten Protokoll, dem Node-Modell und der Version von ONTAP.  Konsultieren Sie die <block ref="41f66f34b3a905f864500c9319fdff8f" category="inline-link-macro-rx"></block> Für diese Grenzwerte.</block>
  <block id="fb012f1e7970d8285bd5d6c5a7f7d523" category="doc">SSD-Aggregate, einschließlich AFF Systeme</block>
  <block id="cb8e4651c457f71d5788f38eac01471f" category="paragraph">Der freie Speicherplatz wird definiert als jeder Speicherplatz, der nicht für tatsächliche Daten verwendet wird. Er umfasst nicht zugewiesenen Speicherplatz im Aggregat selbst und ungenutzten Speicherplatz innerhalb der einzelnen Volumes. Thin Provisioning ist ebenfalls zu berücksichtigen. Ein Volume kann beispielsweise eine LUN mit 1 TB enthalten, von der nur 50 % von echten Daten genutzt werden. In einer Thin Provisioning Umgebung wird hierdurch scheinbar 500 GB Speicherplatz belegt. In einer vollständig bereitgestellten Umgebung scheint jedoch die volle Kapazität von 1 TB genutzt zu sein. Der nicht zugewiesene Speicherplatz von 500 GB ist ausgeblendet. Dieser Platz wird von tatsächlichen Daten nicht genutzt und sollte daher bei der Berechnung des gesamten freien Speicherplatzes berücksichtigt werden.</block>
  <block id="d3487661d9a0702bd5915d49070f62dc" category="paragraph">NetApp Empfehlungen für Storage-Systeme, die für Enterprise-Applikationen verwendet werden, sind wie folgt:</block>
  <block id="678e476783bceae80094bcb4c1f32969" category="admonition">*NetApp empfiehlt* mindestens 10% freien Platz. Dazu gehört der gesamte ungenutzte Speicherplatz, einschließlich freiem Speicherplatz innerhalb des Aggregats oder eines Volumes und sämtlicher freier Speicherplatz, der aufgrund der vollständigen Bereitstellung zugewiesen wird, aber nicht von tatsächlichen Daten genutzt wird. Logischer Speicherplatz ist dabei unwichtig. Die Frage lautet, wie viel tatsächlich freier physischer Speicherplatz für Daten zur Verfügung steht.</block>
  <block id="2171d172d184f1202a686849c85dce91" category="paragraph">Die Empfehlung von 10 % freiem Platz ist sehr konservativ. SSD-Aggregate können Workloads mit noch höherer Auslastung ohne Auswirkungen auf die Performance unterstützen. Wenn die Auslastung des Aggregats jedoch nicht sorgfältig überwacht wird, steigt auch das Risiko, dass der Speicherplatz nicht ausgelastet wird. Darüber hinaus kann es bei der Ausführung eines Systems mit einer Kapazität von 99 % nicht zu einer Performance-Beeinträchtigung kommen, doch wäre damit wahrscheinlich ein Management-Aufwand verbunden, um zu verhindern, dass das System während der Bestellung zusätzlicher Hardware vollständig gefüllt wird. Zudem kann es einige Zeit dauern, bis zusätzliche Laufwerke beschaffen und installiert sind.</block>
  <block id="789243e17acb0b134f435d6c4c1350f2" category="section-title">HDD-Aggregate, einschließlich Flash Pool Aggregaten</block>
  <block id="7302e9f16fb8c5bc30f6035fe4098b52" category="admonition">*NetApp empfiehlt* mindestens 15% freien Speicherplatz, wenn rotierende Laufwerke verwendet werden. Dazu gehört der gesamte ungenutzte Speicherplatz, einschließlich freiem Speicherplatz innerhalb des Aggregats oder eines Volumes und sämtlicher freier Speicherplatz, der aufgrund der vollständigen Bereitstellung zugewiesen wird, aber nicht von tatsächlichen Daten genutzt wird. Die Leistung wird bei 10 % der Redefreiheit beeinträchtigt.</block>
  <block id="0b0a68e2dedde9c0b9a3ea4276f4b85c" category="paragraph">Der<block ref="9df22f196a33acd0b372fe502de51211" prefix=" " category="inline-code"></block> Die Richtlinie ist die am besten geeignete Richtlinie für Backup-Daten. Dadurch wird ein sofortiges Tiering sichergestellt, wenn der Kühlschwellenwert erreicht wurde, unabhängig davon, ob die Dateien gelöscht wurden oder weiterhin im primären Dateisystem vorhanden sind. Das Speichern aller potenziell erforderlichen Dateien an einem zentralen Speicherort im aktiven Dateisystem vereinfacht ebenfalls das Management. Es gibt keinen Grund, Snapshots zu durchsuchen, um eine Datei zu finden, die wiederhergestellt werden muss.</block>
  <block id="11a75a1257cc68a4a46bc553dabe0c0d" category="paragraph">Der<block ref="8805d416ce540c5f2df34af5b18d742b" prefix=" " category="inline-code"></block> Richtlinien können zwar funktionieren, sie gelten jedoch nur für Blöcke, die sich nicht mehr im aktiven File-System befinden. Daher müssen Dateien auf einer NFS- oder SMB-Freigabe vor dem Daten-Tiering zuerst gelöscht werden.</block>
  <block id="b4af96e8cea99b56592db816cab30fce" category="paragraph">Diese Richtlinie wäre bei einer LUN-Konfiguration sogar noch weniger effizient, da beim Löschen einer Datei aus einer LUN nur Dateiverweise aus den Metadaten des Filesystems entfernt werden. Die tatsächlichen Blöcke auf den LUNs bleiben vorhanden, bis sie überschrieben werden. Dies kann zu einer sehr langen Verzögerung zwischen dem Löschen einer Datei und dem Überschreiben der Blöcke führen und zu Tiering-Kandidaten werden. Der Wechsel des bietet einige Vorteile<block ref="8805d416ce540c5f2df34af5b18d742b" prefix=" " category="inline-code"></block> Blöcke auf die Kapazitäts-Tier, aber insgesamt funktioniert das FabricPool Management von Backup-Daten am besten mit der<block ref="9df22f196a33acd0b372fe502de51211" prefix=" " category="inline-code"></block> Richtlinie:</block>
  <block id="1c237d1ebcdeff13ae0145c741d9401d" category="admonition">Mit diesem Ansatz können Benutzer den für Backups erforderlichen Speicherplatz effizienter managen. FabricPool selbst ist jedoch keine Backup-Technologie. Das Tiering von Backup-Dateien in Objektspeicher vereinfacht das Management, da die Dateien noch auf dem ursprünglichen Storage-System sichtbar sind, die Datenblöcke im Zielspeicherort jedoch vom ursprünglichen Storage-System abhängig sind. Wenn das Quell-Volume verloren geht, sind die Objektspeicher-Daten nicht mehr nutzbar.</block>
  <block id="a19665c8f7c0210f96ad2934ad0ee361" category="paragraph">Auf einem ONTAP-System wird der Storage in 4-KB-Einheiten organisiert. Ein Datenbank- oder Filesystem-8-KB-Block sollte exakt zwei 4-KB-Blöcken zugeordnet werden. Wenn ein Fehler in der LUN-Konfiguration die Ausrichtung um 1 KB in beide Richtungen verschiebt, wäre jeder 8-KB-Block auf drei verschiedenen 4-KB-Storage-Blöcken vorhanden anstatt auf zwei. Diese Anordnung würde zu einer erhöhten Latenz führen und dazu führen, dass zusätzliche I/O-Vorgänge innerhalb des Speichersystems ausgeführt werden.</block>
  <block id="211a9fe299057fe8665b591dddbac56d" category="paragraph">Die Ausrichtung wirkt sich auch auf LVM-Architekturen aus. Wenn ein physisches Volume innerhalb einer logischen Volume-Gruppe auf dem gesamten Laufwerk definiert wird (es werden keine Partitionen erstellt), wird der erste 4-KB-Block auf der LUN auf den ersten 4-KB-Block im Storage-System ausgerichtet. Dies ist eine korrekte Ausrichtung. Probleme ergeben sich bei Partitionen, da sie den Startort verschieben, an dem das Betriebssystem die LUN verwendet. Solange der Offset in ganzen 4-KB-Einheiten verschoben wird, ist die LUN ausgerichtet.</block>
  <block id="7c8a0aad1f59988f8160921a07203bb4" category="paragraph">Erstellen Sie in Linux-Umgebungen logische Volume-Gruppen auf dem gesamten Laufwerkgerät. Wenn eine Partition erforderlich ist, überprüfen Sie die Ausrichtung, indem Sie ausführen<block ref="16ae8c2dc7757a3180ce37bad780251a" prefix=" " category="inline-code"></block> Es wird überprüft, ob die Starts jeder Partition ein Vielfaches von acht sind. Dies bedeutet, dass die Partition bei einem Vielfachen von acht 512-Byte-Sektoren beginnt, was 4 KB ist.</block>
  <block id="e98a692d783d8d778aab49ed4c55e214" category="doc">Schutz vor Standortausfällen: NVRAM und MetroCluster</block>
  <block id="186577daf29184ed8a55cf899ba2979c" category="paragraph">MetroCluster erweitert die NVRAM-Datensicherung auf folgende Weise:</block>
  <block id="679f5a5873d7d3378cf4b3035fd5cb13" category="list-text">In einer Konfiguration mit zwei Nodes werden NVRAM-Daten mithilfe von Inter-Switch Links (ISLs) zum Remote-Partner repliziert.</block>
  <block id="00bec98f52b9151dd2e0c760becd4ca8" category="list-text">In einer HA-Paar-Konfiguration werden NVRAM-Daten sowohl auf den lokalen Partner als auch auf einen Remote-Partner repliziert.</block>
  <block id="94deccfbf8f798c1661000b27a568b18" category="list-text">Ein Schreibvorgang wird erst bestätigt, wenn er für alle Partner repliziert wird. Diese Architektur schützt aktive I/O-Vorgänge vor Standortausfällen, indem NVRAM-Daten zu einem Remote-Partner repliziert werden. Dieser Prozess ist nicht mit der Datenreplizierung auf Laufwerksebene verbunden. Der Controller, der die Aggregate besitzt, ist für die Datenreplizierung verantwortlich, indem er auf beide Plexe im Aggregat schreibt. Bei einem Standortausfall muss jedoch weiterhin ein Schutz vor inaktiven I/O-Datenverlusten gewährleistet sein. Replizierte NVRAM-Daten werden nur verwendet, wenn ein Partner-Controller für einen ausgefallenen Controller übernehmen muss.</block>
  <block id="996aa1ed8a906e55c7f157a1643021b7" category="section-title">Schutz vor Standort- und Shelf-Ausfällen: SyncMirror und Plexe</block>
  <block id="1c114a932963683e04dc7dece97c15c9" category="paragraph">SyncMirror ist eine Spiegelungstechnologie, die RAID DP oder RAID-TEC verbessert, aber nicht ersetzt. Es spiegelt den Inhalt von zwei unabhängigen RAID-Gruppen. Die logische Konfiguration ist wie folgt:</block>
  <block id="b4b4f1d65cb5f1370402220b00584e79" category="list-text">Laufwerke werden je nach Standort in zwei Pools konfiguriert. Ein Pool besteht aus allen Laufwerken an Standort A und der zweite Pool besteht aus allen Laufwerken an Standort B</block>
  <block id="418f0763b76bff8e324f1afdd5456b49" category="list-text">Ein gemeinsamer Storage Pool, auch bekannt als Aggregat, wird dann auf der Basis gespiegelter Gruppen von RAID-Gruppen erstellt. Von jedem Standort wird eine gleiche Anzahl von Laufwerken gezogen. Ein SyncMirror Aggregat für 20 Laufwerke würde beispielsweise aus 10 Laufwerken an Standort A und 10 Laufwerken an Standort B bestehen</block>
  <block id="51bf74357f742acfa0a7cd11ce52ed7f" category="list-text">Jeder Laufwerkssatz an einem bestimmten Standort wird automatisch als eine oder mehrere vollständig redundante RAID DP- oder RAID-TEC-Gruppen konfiguriert, und zwar unabhängig von der Verwendung von Spiegelung. Diese Verwendung von RAID unter der Spiegelung bietet Datensicherheit auch nach dem Verlust eines Standorts.</block>
  <block id="8a35ad1e53533c7a3a8ff427bda0deb2" category="paragraph"><block ref="8a35ad1e53533c7a3a8ff427bda0deb2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="abf64dbc3ac20af1b4a30150a016ca58" category="paragraph">Die Abbildung oben zeigt eine Beispiel-SyncMirror-Konfiguration. Es wurde ein Aggregat mit 24 Laufwerken auf dem Controller mit 12 Laufwerken aus einem an Standort A zugewiesenen Shelf und 12 Laufwerken aus einem an Standort B zugewiesenen Shelf erstellt Die Laufwerke wurden in zwei gespiegelte RAID-Gruppen gruppiert. RAID-Gruppe 0 enthält einen Plex mit 6 Laufwerken an Standort A, der auf einen Plex mit 6 Laufwerken an Standort B gespiegelt wurde Ebenso enthält die RAID-Gruppe 1 einen Plex mit 6 Laufwerken an Standort A, der auf einen Plex mit 6 Laufwerken an Standort B gespiegelt wird</block>
  <block id="d9945e1dbadc87ba8e52a5e69376005c" category="paragraph">Normalerweise wird SyncMirror für die Remote-Spiegelung bei MetroCluster Systemen verwendet, wobei eine Kopie der Daten an jedem Standort vorhanden ist. Gelegentlich wurde es verwendet, um eine zusätzliche Redundanz in einem einzigen System bereitzustellen. Insbesondere bietet sie Redundanz auf Shelf-Ebene. Ein Festplatten-Shelf enthält bereits duale Netzteile und Controller und ist im Großen und Ganzen etwas mehr als Bleche, doch in einigen Fällen ist möglicherweise der zusätzliche Schutz gewährleistet. Ein NetApp Kunde beispielsweise hat SyncMirror für eine mobile Echtzeitanalyse-Plattform für Automobiltests implementiert. Das System wurde in zwei physische Racks mit unabhängigen Stromeinspeisungen und unabhängigen USV-Systemen getrennt.</block>
  <block id="f3495a1e6cf563a617c71164f3b11ca3" category="section-title">Redundanzfehler: NVFAIL</block>
  <block id="c7474a3ed1a224804e4741a256bdd953" category="paragraph">Wie zuvor bereits erläutert, wird ein Schreibvorgang erst bestätigt, wenn er in lokalem NVRAM und NVRAM auf mindestens einem anderen Controller angemeldet wurde. Dieser Ansatz stellt sicher, dass ein Hardware-Ausfall oder ein Stromausfall nicht zum Verlust der aktiven I/O führen Wenn der lokale NVRAM ausfällt oder die Verbindung zu anderen Nodes ausfällt, werden die Daten nicht mehr gespiegelt.</block>
  <block id="4774101e81ea03c43fe20e0d7f2d21d1" category="paragraph">Der Steuerungsfaktor ist, ob NVRAM synchronisiert wird. Bei NVRAM-Synchronisierung kann ein Node-to-Node Failover ohne das Risiko eines Datenverlusts fortgesetzt werden. Wenn in einer MetroCluster Konfiguration NVRAM und die zugrunde liegenden Aggregat-Plexe synchron sind, kann ohne das Risiko eines Datenverlusts eine Umschaltung durchgeführt werden.</block>
  <block id="03e97c023521445cd70307afabdcf0d5" category="paragraph">Datenbanken und andere Applikationen sind besonders anfällig für Beschädigungen, wenn ein Failover oder Switchover erzwungen wird, da sie größere interne Daten-Caches auf Festplatten beibehalten. Wenn ein erzwungenes Failover oder eine Umschaltung auftritt, werden zuvor bestätigte Änderungen effektiv verworfen. Der Inhalt des Storage Arrays springt effektiv zurück in die Zeit, und der Cache-Status gibt nicht mehr den Status der Daten auf der Festplatte wieder.</block>
  <block id="ff7a32ed70b7df57dd29a3ed75e8c787" category="paragraph">Um dies zu verhindern, können Volumes mit ONTAP für speziellen Schutz vor NVRAM-Ausfällen konfiguriert werden. Wenn dieser Schutzmechanismus ausgelöst wird, gelangt ein Volume in den Status „NVFAIL“. Dieser Zustand führt zu I/O-Fehlern, die einen Absturz der Applikation verursachen. Dieser Absturz führt dazu, dass die Applikationen heruntergefahren werden, damit keine veralteten Daten verwendet werden. Daten dürfen nicht verloren gehen, da alle festzugebenden Transaktionsdaten in den Protokollen vorhanden sein sollten. Als Nächstes muss ein Administrator die Hosts vollständig herunterfahren, bevor die LUNs und Volumes manuell wieder online geschaltet werden. Obwohl diese Schritte etwas Arbeit erfordern können, ist dieser Ansatz der sicherste Weg, um die Datenintegrität zu gewährleisten. Nicht alle Daten erfordern diesen Schutz. Daher kann ein NVFAIL-Verhalten auf Volume-Basis konfiguriert werden.</block>
  <block id="637d4b37868fb7825461df6edd674158" category="section-title">HA-Paare und MetroCluster</block>
  <block id="9d8738f531e6c6a809ba66315beaa2f4" category="paragraph">MetroCluster ist in zwei Konfigurationen erhältlich: Zwei Nodes und ein HA-Paar. Die Konfiguration mit zwei Nodes verhält sich in Bezug auf NVRAM wie ein HA-Paar. Im Falle eines plötzlichen Ausfalls kann der Partner-Node NVRAM-Daten wiedergeben, um die Laufwerke konsistent zu machen und sicherzustellen, dass keine bestätigten Schreibvorgänge verloren gegangen sind.</block>
  <block id="936f4311b16ee4dc74a5564892f8976d" category="paragraph">Die HA-Paar-Konfiguration repliziert NVRAM auch auf den lokalen Partner-Node. Ein einfacher Controller-Ausfall führt zu einer NVRAM-Wiedergabe auf dem Partner-Node, wie dies bei einem Standalone HA-Paar ohne MetroCluster der Fall ist. Bei einem plötzlichen vollständigen Standortausfall verfügt der Remote Standort außerdem über den NVRAM, der erforderlich ist, um die Laufwerke konsistent zu gestalten und Daten bereitzustellen.</block>
  <block id="83b6c3c3018b913ecf1aca67e0daa35e" category="paragraph">Ein wichtiger Aspekt von MetroCluster ist, dass die Remote Nodes unter normalen Betriebsbedingungen keinen Zugriff auf Partnerdaten haben. Jeder Standort funktioniert im Wesentlichen als ein unabhängiges System, das die Persönlichkeit des gegenüberliegenden Standorts übernehmen kann. Dieser Prozess wird als Umschaltung bezeichnet und umfasst ein geplantes Switchover, bei dem Standortvorgänge unterbrechungsfrei zum anderen Standort migriert werden. Auch ungeplante Situationen, in denen ein Standort verloren geht und bei der Disaster Recovery ein manuelles oder automatisches Switchover erforderlich ist, werden berücksichtigt.</block>
  <block id="58504b36cfdfd10d5f2802d7b943a379" category="section-title">Umschaltung und Switchback</block>
  <block id="d505751d1708fb5d57b0e23d089507a9" category="paragraph">Die Begriffe Switchover und Switchback beziehen sich auf den Prozess, bei dem Volumes zwischen Remote Controllern in einer MetroCluster Konfiguration migriert werden. Dieser Vorgang gilt nur für die Remote-Knoten. Wenn MetroCluster in einer Konfiguration mit vier Volumes zum Einsatz kommt, entspricht das lokale Node Failover dem zuvor beschriebenen Takeover- und Giveback-Prozess.</block>
  <block id="1127608e73df5ede22b149c8f19fc860" category="section-title">Geplante Umschaltung und Umschaltung</block>
  <block id="a6733335678588619c977608e891e54e" category="paragraph">Ein geplanter Switchover oder Switchback ähnelt einer Übernahme oder einem Giveback zwischen Nodes. Der Prozess umfasst mehrere Schritte und scheint möglicherweise mehrere Minuten zu erfordern. Aber was wirklich geschieht, ist eine mehrstufige Übertragung der Storage- und Netzwerkressourcen. Der Moment, in dem Kontrolltransfers schneller erfolgen, als der vollständige Befehl ausgeführt werden muss.</block>
  <block id="4bb5647dcff332f0b53819ecd631303c" category="paragraph">Der Hauptunterschied zwischen Takeover/Giveback und Switchover/Switchback besteht in den Auswirkungen auf die FC SAN-Konnektivität. Durch lokale Übernahme/Giveback wird der Verlust aller FC-Pfade zum lokalen Node durch den Host erlebbar und verlässt sich auf natives MPIO, um auf verfügbare alternative Pfade umzusteigen. Ports werden nicht verlegt. Mit Switchover und Switchback werden die virtuellen FC-Ziel-Ports der Controller zum anderen Standort übertragen. Sie existieren praktisch einen Moment lang nicht mehr auf dem SAN und werden dann auf einem alternativen Controller wieder angezeigt.</block>
  <block id="0ba902ec3f6ce91c2e801715bb8b96fa" category="section-title">SyncMirror-Timeouts</block>
  <block id="9c8a1814b60b84d1aa68fa7bba69138b" category="paragraph">Bei SyncMirror handelt es sich um eine ONTAP-Spiegelungstechnologie, die Schutz vor Shelf-Ausfällen bietet. Wenn Shelfs über eine Entfernung voneinander getrennt sind, führt dies zu einer Remote-Datensicherung.</block>
  <block id="68cf36f65a7e56ff3b6c0894be3ed9e8" category="paragraph">SyncMirror bietet kein universelles synchrones Spiegeln. Das Ergebnis ist eine höhere Verfügbarkeit. Einige Speichersysteme nutzen eine konstante Spiegelung alles oder nichts, die manchmal auch Domino-Modus genannt wird. Diese Form der Spiegelung ist in der Anwendung beschränkt, da alle Schreibaktivitäten unterbrochen werden müssen, wenn die Verbindung zum Remote-Standort verloren geht. Andernfalls würde ein Schreiben an einer Stelle, aber nicht an der anderen existieren. Solche Umgebungen sind normalerweise so konfiguriert, dass LUNs offline geschaltet werden, wenn die Verbindung zwischen Standorten länger als einen kurzen Zeitraum (wie etwa 30 Sekunden) unterbrochen wird.</block>
  <block id="84ad4c21def9c355e80ef250d910bfa2" category="paragraph">Dieses Verhalten ist für eine kleine Untermenge von Umgebungen wünschenswert. Die meisten Anwendungen benötigen jedoch eine Lösung, die eine garantierte synchrone Replikation unter normalen Betriebsbedingungen bietet, aber die Replikation unterbrechen kann. Ein vollständiger Verlust der Verbindung zwischen Standorten wird häufig als nahezu katastrophennahe Situation betrachtet. In der Regel werden solche Umgebungen online gehalten und stellen Daten bereit, bis die Konnektivität repariert wird oder eine formale Entscheidung getroffen wird, die Umgebung zum Schutz der Daten herunterzufahren. Eine Notwendigkeit für das automatische Herunterfahren der Anwendung allein aufgrund eines Fehlers bei der Remote-Replikation ist ungewöhnlich.</block>
  <block id="e3bd381a7bbaee6c741aee230972acf4" category="paragraph">SyncMirror unterstützt Anforderungen an die synchrone Spiegelung mit der Flexibilität einer Zeitüberschreitung. Wenn die Verbindung zum Remote-Controller und/oder Plex unterbrochen wird, beginnt ein 30-Sekunden-Timer zu zählen. Wenn der Zähler 0 erreicht, wird die Schreib-I/O-Verarbeitung mithilfe der lokalen Daten fortgesetzt. Die Remote-Kopie der Daten ist nutzbar, wird aber rechtzeitig eingefroren, bis die Verbindung wiederhergestellt ist. Die Neusynchronisierung nutzt Snapshots auf Aggregatebene, um das System so schnell wie möglich in den synchronen Modus zurückzuversetzen.</block>
  <block id="0c919cd6511df6d83b811234b0448374" category="paragraph">Bemerkenswert ist, dass in vielen Fällen diese Art universeller Domino-Modus-Replikation auf Anwendungsebene besser implementiert wird. Beispielsweise verfügt Oracle DataGuard über einen maximalen Schutzmodus, der unter allen Umständen eine Replizierung mit einer langen Instanz garantiert. Wenn die Replikationsverbindung für einen Zeitraum fehlschlägt, der ein konfigurierbares Timeout überschreitet, werden die Datenbanken heruntergefahren.</block>
  <block id="ba92cbe464cfee8aa12c41e6aecd1071" category="section-title">Automatische, unbeaufsichtigte Umschaltung mit Fabric Attached MetroCluster</block>
  <block id="515094655d10031595da776c94b3d710" category="paragraph">AUSO (Automatic unbeaufsichtigter Switchover) ist eine Fabric Attached MetroCluster Funktion, die eine Form standortübergreifender Hochverfügbarkeit bietet. Wie zuvor erläutert, gibt es bei MetroCluster zwei Typen: Einen einzigen Controller an jedem Standort oder ein HA-Paar an jedem Standort. Der Hauptvorteil der HA-Option besteht darin, dass bei geplanter oder ungeplanter Controller-Abschaltung alle I/O-Vorgänge weiterhin lokal ausgeführt werden können. Der Vorteil der Single-Node-Option liegt in der Reduzierung der Kosten, der Komplexität und der Infrastruktur.</block>
  <block id="29d4da26af76b66db3a172a39edf8367" category="paragraph">Der wichtigste Vorteil von AUSO ist die Verbesserung der Hochverfügbarkeitsfunktionen von Fabric Attached MetroCluster Systemen. Jeder Standort überwacht den Zustand des anderen Standorts. Falls kein Node mehr vorhanden ist, um Daten bereitzustellen, ermöglicht AUSO ein schnelles Switchover. Dieser Ansatz erweist sich insbesondere für MetroCluster Konfigurationen mit nur einem einzigen Node pro Standort, da er die Konfiguration in Bezug auf die Verfügbarkeit näher an ein HA-Paar bringt.</block>
  <block id="6b3a5f7923b2d803fd3b28c255fef420" category="paragraph">AUSO kann auf Ebene eines HA-Paars kein umfassendes Monitoring bieten. Ein HA-Paar kann für eine extrem hohe Verfügbarkeit sorgen, da es zwei redundante physische Kabel für eine direkte Kommunikation zwischen den Nodes umfasst. Darüber hinaus haben beide Nodes in einem HA-Paar Zugriff auf den gleichen Satz an Festplatten in redundanten Loops, die einen weiteren Weg für einen Node zur Überwachung des Systemzustands eines anderen bereitstellen.</block>
  <block id="da87dad268507a3523bc38275b1d3fbc" category="paragraph">MetroCluster Cluster sind über Standorte verteilt, bei denen sowohl die Node-to-Node-Kommunikation als auch der Festplattenzugriff auf die Site-to-Site-Netzwerkverbindung angewiesen sind. Die Fähigkeit, den Heartbeat des restlichen Clusters zu überwachen, ist begrenzt. AUSO muss zwischen Situationen unterscheiden, in denen der andere Standort aufgrund eines Netzwerkproblems nicht verfügbar ist, sondern tatsächlich ausgefallen ist.</block>
  <block id="e8e4f55c4203e7fb24d4543a7a0f65da" category="paragraph">So kann ein Controller in einem HA-Paar eine Übernahme veranlassen, wenn ein Controller-Ausfall erkannt wird, der aus einem bestimmten Grund, wie z. B. einem Systempanik, aufgetreten ist. Es kann auch zu einem Takeover führen, wenn ein vollständiger Verbindungsverlust besteht, manchmal auch als verlorener Herzschlag bezeichnet.</block>
  <block id="91aa4ce36cb243281f3777d66c8f89e0" category="paragraph">Ein MetroCluster System kann eine automatische Umschaltung nur sicher durchführen, wenn ein bestimmter Fehler am ursprünglichen Standort erkannt wird. Darüber hinaus muss der Controller, der das Storage-System übernimmt, in der Lage sein, die Synchronisierung von Festplatten- und NVRAM-Daten zu gewährleisten. Der Controller kann die Sicherheit einer Umschaltung nicht garantieren, nur weil er den Kontakt zum Quellstandort verloren hat, der noch betriebsbereit sein könnte. Weitere Optionen zur Automatisierung einer Umschaltung finden Sie im nächsten Abschnitt zur MetroCluster Tiebreaker Lösung (MCTB).</block>
  <block id="8e7705fe4aea384d7f6a99ab6dc0f408" category="section-title">MetroCluster Tiebreaker mit Fabric Attached MetroCluster</block>
  <block id="897b7698cb343dbc3452e845705ab0f3" category="inline-link">NetApp MetroCluster Tiebreaker</block>
  <block id="9c093f14319e8253b8c9b37290597239" category="inline-link">NetApp Support Website</block>
  <block id="a1d9fc4fb49119a9fe9b39abec0a769b" category="paragraph">Der<block ref="9332969062716487f0feefe076babf99" category="inline-link-rx"></block> Die Software kann an einem dritten Standort ausgeführt werden, um den Zustand der MetroCluster Umgebung zu überwachen, Benachrichtigungen zu senden und in einer Notfallsituation optional eine Umschaltung zu erzwingen. Eine vollständige Beschreibung des Tiebreaker finden Sie auf dem<block ref="c21658567f794984b03c21186a56713d" category="inline-link-rx"></block>, Aber der primäre Zweck des MetroCluster Tiebreaker ist es, Standortverluste zu erkennen. Außerdem muss zwischen Standortausfällen und Verbindungsverlust unterschieden werden. So sollte beispielsweise keine Umschaltung erfolgen, da der primäre Standort nicht erreichbar war. Aus diesem Grund überwacht Tiebreaker auch die Fähigkeit des Remote-Standorts, mit dem primären Standort in Kontakt zu treten.</block>
  <block id="6f29b1849750ceee5eb7f6f02d100e6b" category="paragraph">Die automatische Umschaltung mit AUSO ist auch mit der MCTB kompatibel. AUSO reagiert sehr schnell, da es darauf ausgelegt ist, bestimmte Fehlerereignisse zu erkennen und dann die Umschaltung nur dann aufzurufen, wenn NVRAM und SyncMirror Plexe synchron sind.</block>
  <block id="6f5c7ae76595eca2ca83c5dd30cd8e9f" category="paragraph">Im Gegensatz dazu befindet sich das Tiebreaker Remote und muss daher warten, bis ein Timer verstrichen ist, bevor ein Standort für tot erklärt wird. Über Tiebreaker wird schließlich festgestellt, wie ein Controller-Ausfall von AUSO abgedeckt ist, doch im Allgemeinen hat AUSO bereits die Umschaltung gestartet und möglicherweise die Umschaltung abgeschlossen, bevor es Tiebreaker wirkt. Der resultierende zweite Switchover-Befehl aus dem Tiebreaker würde abgelehnt.</block>
  <block id="842547e1622bb12d9201167b0c39cf6d" category="paragraph">*Achtung: *Die MCTB-Software überprüft nicht, ob NVRAM und/oder Plexe synchron sind, wenn eine Umschaltung erzwungen wird. Sofern konfiguriert, sollte die automatische Umschaltung während Wartungsaktivitäten deaktiviert werden, die zu einem Verlust der Synchronisierung von NVRAM- oder SyncMirror-Plexen führen.</block>
  <block id="7110edd59c3d0f25a584723f6fea26a0" category="paragraph">Darüber hinaus geht die MCTB möglicherweise nicht bei einem rollierenden Notfall ein, der zu der folgenden Ereignisabfolge führt:</block>
  <block id="93d732b784eaf1a323f191e75c10f233" category="list-text">Die Konnektivität zwischen Standorten wird für mehr als 30 Sekunden unterbrochen.</block>
  <block id="81d4275cc3534a9fa8cfdcdb5172eb94" category="list-text">Die SyncMirror-Replizierung ist zeitgemäß, und der Betrieb wird am primären Standort fortgesetzt, sodass das Remote-Replikat nicht mehr zeitgemäß ist.</block>
  <block id="44441f68631008a941ce92e985131ff9" category="list-text">Der primäre Standort geht verloren.das Ergebnis sind nicht replizierte Änderungen am primären Standort. Eine Umschaltung könnte dann aus verschiedenen Gründen unerwünscht sein, unter anderem aus folgenden Gründen:</block>
  <block id="499527dd40fad77b119b8b33c99cd614" category="list-text">Am primären Standort befinden sich möglicherweise kritische Daten, und diese Daten können nach und nach wiederhergestellt werden. Mit einer Umschaltung, die eine Weiterführung des Betriebs der Applikation ermöglichte, würden die kritischen Daten praktisch verworfen.</block>
  <block id="86de4e3737e3d871dacf8ffef353fc31" category="list-text">Möglicherweise haben Daten im Cache einer Applikation gespeichert, die am verbleibenden Standort zum Zeitpunkt des Standortverlusts die Storage-Ressourcen am primären Standort nutzte. Durch ein Switchover würde eine veraltete Version der Daten eingeführt, die nicht mit dem Cache übereinstimmt.</block>
  <block id="dbb2a01afe28c8310daf781bb80b795f" category="list-text">Möglicherweise haben Daten im Cache eines Betriebssystems, das auf dem verbleibenden Standort zum Zeitpunkt eines Standortausfalls Speicherressourcen am primären Standort genutzt hat, gespeichert. Durch ein Switchover würde eine veraltete Version der Daten eingeführt, die nicht mit dem Cache übereinstimmt. Am sichersten ist es, dass Sie Tiebreaker so konfigurieren, dass eine Warnmeldung ausgegeben wird, wenn ein Standortausfall erkannt wird und anschließend eine Person Entscheidungen darüber treffen muss, ob eine Umschaltung erzwungen werden soll. Applikationen und/oder Betriebssysteme müssen möglicherweise zunächst heruntergefahren werden, um zwischengespeicherte Daten zu löschen. Darüber hinaus können die NVFAIL-Einstellungen verwendet werden, um einen zusätzlichen Schutz zu bieten und den Failover-Prozess zu rationalisieren.</block>
  <block id="ec6b0ea9c511479c118aa0f028f6519d" category="section-title">ONTAP Mediator mit MetroCluster IP</block>
  <block id="8ada6a626a475d631df231bbb3a88ac9" category="paragraph">Der ONTAP Mediator wird mit MetroCluster IP und bestimmten anderen ONTAP-Lösungen verwendet. Es fungiert als herkömmlicher Tiebreaker Service, ähnlich wie die oben beschriebene MetroCluster Tiebreaker Software, verfügt aber auch über eine wichtige Funktion zum automatisierten, unbeaufsichtigten Switchover.</block>
  <block id="991d7d7d7388ccdd87c65ca09aa804f2" category="paragraph">Ein Fabric-Attached MetroCluster hat direkten Zugriff auf die Storage-Geräte am gegenüberliegenden Standort. Dadurch kann ein MetroCluster-Controller den Zustand der anderen Controller überwachen, indem er die Heartbeat-Daten von den Laufwerken liest. So kann ein Controller den Ausfall eines anderen Controllers erkennen und eine Umschaltung durchführen.</block>
  <block id="db2e932a11478bcf14c75d38e8b9a170" category="paragraph">Im Gegensatz dazu leitet die MetroCluster IP Architektur alle I/O ausschließlich über die Controller-Controller-Verbindung weiter; es besteht kein direkter Zugriff auf Speichergeräte am Remote-Standort. Dadurch wird die Fähigkeit eines Controllers eingeschränkt, Ausfälle zu erkennen und eine Umschaltung durchzuführen. Der ONTAP Mediator ist daher als Tiebreaker-Gerät erforderlich, um Standortverluste zu erkennen und automatisch eine Umschaltung durchzuführen.</block>
  <block id="fed81cab21bffffef4cc425583569036" category="section-title">Mediator Automatic Unbeaufsichtigte Umschaltung (MAUSO)</block>
  <block id="8004e6d63f487a456290225b74768a6c" category="section-title">Virtueller dritter Standort mit ClusterLion</block>
  <block id="f1d5a7305654a402a719675fbec810e7" category="paragraph">ClusterLion ist eine fortschrittliche MetroCluster Monitoring-Appliance, die als virtueller dritter Standort fungiert. Dieser Ansatz ermöglicht die sichere Implementierung von MetroCluster in einer Konfiguration mit zwei Standorten und einer vollständig automatisierten Umschaltfunktion. Des Weiteren kann ClusterLion zusätzliche Überwachung auf Netzwerkebene durchführen und Vorgänge nach der Umschaltung ausführen. Die vollständige Dokumentation ist bei ProLion erhältlich.</block>
  <block id="a60b8f728a13371898fea9947ef1e0dc" category="paragraph"><block ref="a60b8f728a13371898fea9947ef1e0dc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f8aae92ec17ec82868ef9ffc767dbd03" category="list-text">Die ClusterLion Appliances überwachen den Zustand der Controller mit direkt angeschlossenem Ethernet und seriellen Kabeln.</block>
  <block id="c5f8963a91e3d8e7ac0abda2eab9f17d" category="list-text">Die beiden Geräte sind über redundante 3G-Wireless-Verbindungen miteinander verbunden.</block>
  <block id="24de16a13a1b584832d19117982cbfa6" category="list-text">Die Stromversorgung des ONTAP-Controllers erfolgt über interne Relais. Bei einem Standortausfall trennt ClusterLion, das ein internes USV-System enthält, die Stromanschlüsse, bevor eine Umschaltung initiiert wird. Dieser Prozess stellt sicher, dass kein Split-Brain-Zustand auftritt.</block>
  <block id="b2bcd3c3c555e2e4f27d453de4e0f06d" category="list-text">ClusterLion führt eine Umschaltung innerhalb der SyncMirror-Zeitüberschreitung von 30 Sekunden oder überhaupt nicht aus.</block>
  <block id="390fb5f827a3fbcdc7d05e6e7db03223" category="list-text">ClusterLion führt nur eine Umschaltung durch, wenn die Zustände NVRAM und SyncMirror Plexe synchron sind.</block>
  <block id="f322f850d55e87946f9660e4ccb1bbb6" category="list-text">Da ClusterLion nur umgeschaltet wird, wenn die MetroCluster vollständig synchron ist, ist das NVFAIL nicht erforderlich. Diese Konfiguration ermöglicht es, standortübergreifende Umgebungen wie beispielsweise einen erweiterten Oracle RAC auch während einer ungeplanten Umschaltung online zu bleiben.</block>
  <block id="5c132e05fb0e306f56955603619de359" category="list-text">Die Unterstützung umfasst sowohl Fabric-Attached MetroCluster als auch MetroCluster IP</block>
  <block id="86bcf99dbc3944da56f06b48074d09f6" category="doc">Normaler Betrieb</block>
  <block id="16dd4928055f2caf6f6fb8119ef69bcc" category="paragraph">SM-BC unterstützt zwei Arten von Speicher-Failover-Operationen: Geplant und ungeplant, die auf leicht unterschiedliche Weise arbeiten. Ein geplantes Failover wird manuell vom Administrator initiiert, um eine schnelle Umschaltung auf einen Remote-Standort zu ermöglichen, während der ungeplante Failover automatisch vom Mediator am dritten Standort initiiert wird. Der primäre Zweck eines geplanten Failovers ist die Durchführung inkrementeller Patches und Upgrades, Durchführung von Disaster Recovery-Tests oder die Einführung einer formellen Richtlinie für den Wechsel zwischen Standorten während des ganzen Jahres, um die volle Business Continuity-Funktionalität zu belegen.</block>
  <block id="63d4f976530f4faffa1ecd40fe8843f4" category="paragraph">Die Diagramme zeigen die Vorgänge während des normalen Failover und Failback-Vorgangs an. Zur einfachen Illustration zeigen sie eine replizierte LUN. In einer tatsächlichen SM-BC-Konfiguration basiert die Replikation auf Volumes, wobei jedes Volume eine oder mehrere LUNs enthält. Um das Bild jedoch zu vereinfachen, wurde die Volume-Schicht entfernt.</block>
  <block id="e48472f7daf781b63506f9e296443027" category="paragraph">Im normalen Betrieb kann auf eine LUN entweder über das lokale oder Remote-Replikat zugegriffen werden. Die rote Linie zeigt den optimierten Pfad an, wie von ALUA angekündigt, und das Ergebnis sollte sein, dass IO bevorzugt über diesen Pfad gesendet wird.</block>
  <block id="ef1d805ecb3b65664c42a1d32d8120d5" category="paragraph">Die grüne Linie ist ein aktiver Pfad, aber es würde mehr Latenz verursachen, da IO auf diesem Pfad über den SM-BC-Pfad weitergeleitet werden müsste. Die zusätzliche Latenz hängt von der Geschwindigkeit der Verbindung zwischen den Standorten ab, die für SM-BC verwendet werden.</block>
  <block id="e139a585510a502bbf1841cf589f5086" category="section-title">Ausfall</block>
  <block id="7ed516552b652790c92df0bf237264b2" category="paragraph">Wenn die aktive gespiegelte Kopie aufgrund eines geplanten oder ungeplanten Failover nicht mehr verfügbar ist, ist sie offensichtlich nicht mehr nutzbar. Das Remote-System verfügt jedoch über ein synchrones Replikat, und es sind bereits SAN-Pfade zum Remote-Standort vorhanden. Das Remote-System kann E/A für diese LUN bedienen.</block>
  <block id="89a4933a199f7b0e286c8bcb1606905a" category="paragraph">Ob die Remote-Kopie sofort verwendet wird, hängt davon ab, ob SM-BC im Sync- oder StrictSync-Modus betrieben wird.</block>
  <block id="af43c542f512c4f7dc1b137d5de49d40" category="paragraph"><block ref="af43c542f512c4f7dc1b137d5de49d40" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7388404ef116c3ff812bfd290b094d9e" category="section-title">Failover</block>
  <block id="997dfe060d2107e84407cfb41e692c54" category="paragraph">Durch Failover wird die Remote-Kopie zur aktiven Kopie. Die Pfade werden von „aktiv“ in „aktiv/optimiert“ geändert und I/O-Vorgänge werden weiterhin ohne Datenverlust verarbeitet.</block>
  <block id="52da4ea35ba60090f331eefab5d6c612" category="paragraph"><block ref="52da4ea35ba60090f331eefab5d6c612" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0493d27e20d11e356e53e0a730b0ad08" category="section-title">Reparieren</block>
  <block id="4f125c91283d9dc1751ad99a7a171420" category="paragraph">Sobald das Quellsystem wieder in Betrieb genommen wird, kann SM-BC die Replikation neu synchronisieren, aber in die andere Richtung ausführen. Die Konfiguration ist jetzt im Wesentlichen dieselbe wie der Startpunkt, mit Ausnahme, dass die Active-Mirror-Standorte gespiegelt wurden.</block>
  <block id="5c647f57a104a05d7d8b55d089efefbe" category="paragraph"><block ref="5c647f57a104a05d7d8b55d089efefbe" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6d80a3efb80520f47b63dc279e1bea3d" category="section-title">Failback</block>
  <block id="d47f47372b9b94d274cceb3638b28845" category="paragraph">Auf Wunsch kann ein Administrator ein Failback durchführen und die aktive Kopie der LUN(s) zurück auf die ursprünglichen Controller verschieben.</block>
  <block id="0c99cedb6f39d8ac16d5b4c01c162c23" category="paragraph">Die Datenbank-Wiederherstellungs-/Transaktionsprotokollierung erzeugt normalerweise nicht ausgerichtete I/O-Vorgänge, die irreführende Warnungen zu falsch ausgerichteten LUNs auf ONTAP verursachen können.</block>
  <block id="b2f7bb8e75b21ee3e883141c6ac1defe" category="paragraph">Die Protokollierung führt einen sequenziellen Schreibvorgang der Protokolldatei mit unterschiedlich großen Schreibvorgängen durch. Ein Protokollschreibvorgang, der sich nicht an 4-KB-Grenzen ausrichtet, verursacht normalerweise keine Performance-Probleme, da der nächste Protokollschreibvorgang den Block abgeschlossen hat. Das Ergebnis: ONTAP ist in der Lage, fast alle Schreibvorgänge als komplette 4-KB-Blöcke zu verarbeiten, obwohl die Daten in einigen 4-KB-Blöcken in zwei separaten Operationen geschrieben wurden.</block>
  <block id="0e635e1f8ffad809203304cf41ed45c4" category="inline-link-macro">Überprüfung der WAFL-Ausrichtung</block>
  <block id="bf837d24f10c904e697e3c0092da43b9" category="paragraph">Überprüfen Sie die Ausrichtung mithilfe von Dienstprogrammen wie<block ref="40883add63f1fbabc7fe6158f93c1246" prefix=" " category="inline-code"></block> Oder<block ref="1aabac6d068eef6a7bad3fdf50a05cc8" prefix=" " category="inline-code"></block> Sie können I/O mit einer definierten Blockgröße generieren. Die I/O-Ausrichtungsstatistiken auf dem Storage-System können mit dem angezeigt werden<block ref="446501053769c06c565094b26d26e8ef" prefix=" " category="inline-code"></block> Befehl. Siehe <block ref="ebccec7997af507c87f985ec4ccec634" category="inline-link-macro-rx"></block> Finden Sie weitere Informationen.</block>
  <block id="b5ffbfb0c082804ad41d0f61c87525ed" category="paragraph">Viele Applikationsdatensätze sind nach Datum geordnet. Solche Daten sind im Allgemeinen immer seltener zugänglich, wenn sie älter werden. Beispielsweise verfügt eine Bank möglicherweise über ein Repository mit PDF-Dateien, die fünf Jahre Kundenabrechnungen enthalten, aber nur die letzten Monate sind aktiv. FabricPool kann verwendet werden, um ältere Datendateien in die Kapazitäts-Tier zu verschieben. Eine Abkühlzeit von 14 Tagen würde dafür sorgen, dass die letzten 14 Tage der PDF-Dateien auf der Performance-Ebene verbleiben. Darüber hinaus würden Dateien, die mindestens alle 14 Tage gelesen werden, „heiß“ bleiben und daher auf der Performance-Ebene verbleiben.</block>
  <block id="ed7e2cc7ff107d4b2032fe65cf4e756a" category="paragraph">Um einen dateibasierten Tiering-Ansatz zu implementieren, müssen Sie über Dateien verfügen, die geschrieben und nicht nachträglich geändert werden. Der<block ref="e5e88684921dd21f3f86c28343a3082f" prefix=" " category="inline-code"></block> Richtlinien sollten so hoch eingestellt werden, dass Dateien, die Sie möglicherweise benötigen, auf der Performance-Tier verbleiben. Ein Datensatz, für den die letzten 60 Tage Daten mit optimaler Performance benötigt werden, erfordert beispielsweise die Einstellung<block ref="e5e88684921dd21f3f86c28343a3082f" prefix=" " category="inline-code"></block> Bis 60. Ähnliche Ergebnisse lassen sich auch anhand der Dateizugriffsmuster erzielen. Wenn beispielsweise die Daten der letzten 90 Tage benötigt werden und die Applikation auf diese 90-Tage-Zeitspanne zugreift, verbleiben die Daten in der Performance-Tier. Durch Einstellen der<block ref="e5e88684921dd21f3f86c28343a3082f" prefix=" " category="inline-code"></block> Zeitraum bis 2, erhalten Sie prompt Tiering, nachdem die Daten weniger aktiv werden.</block>
  <block id="8a467b35326e4738b1bd39865c3b21a0" category="admonition">Jeder Zugriff auf Daten setzt die Heatmap-Daten zurück. Virus-Scan, Indizierung und sogar Backup-Aktivitäten, die die Quelldateien lesen, verhindern Tiering, da dies erforderlich ist<block ref="e5e88684921dd21f3f86c28343a3082f" prefix=" " category="inline-code"></block> Schwellenwert wird nie erreicht.</block>
  <block id="7a1920d61156abc05a60135aefe8bc67" category="doc">Standard</block>
  <block id="5ba46d288640832c345e169b04a7458a" category="paragraph">Alle FabricPool-Volumes sind zunächst auf festgelegt<block ref="c21f969b5f03d33d43e04f8f136e7682" prefix=" " category="inline-code"></block>, D.h. das Verhalten wird durch die `Cloud-Retrieval-Policy gesteuert. `das genaue Verhalten hängt von der verwendeten Tiering Policy ab.</block>
  <block id="5ec354970d7934d92ba67ccaa0de0121" category="list-text"><block ref="9df22f196a33acd0b372fe502de51211" prefix="" category="inline-code"></block>– Nur abrufen zufällig gelesenen Daten</block>
  <block id="74092cfa5efab8e6ddc5c2991ee2cfc9" category="list-text"><block ref="8805d416ce540c5f2df34af5b18d742b" prefix="" category="inline-code"></block>– Abrufen aller sequentiellen oder zufällig gelesenen Daten</block>
  <block id="2de036541477f953c6fd33d14a8db0e8" category="list-text"><block ref="334c4a4c42fdb79d7ebc3e73b517e6f8" prefix="" category="inline-code"></block>– Abrufen aller sequentiellen oder zufällig gelesenen Daten</block>
  <block id="b6ffdb7ccf86e99ecf73899ec23bdd46" category="list-text"><block ref="a181a603769c1f98ad927e7367c7aa51" prefix="" category="inline-code"></block>– Daten nicht aus der Kapazitäts-Tier abrufen</block>
  <block id="d556a0d2cad80695d1d803ebb49de9cd" category="section-title">Gelesen</block>
  <block id="7c39eb141ca855e5a211b468bd67636c" category="paragraph">Einstellung<block ref="d253e682212338dd6cbe577947f0511e" prefix=" " category="inline-code"></block> Das Lesen überschreibt das Standardverhalten, sodass ein Lesen von Tiered-Daten dazu führt, dass diese Daten an die Performance-Tier zurückgegeben werden.</block>
  <block id="e07df43ea07fecb178484ef278644eb2" category="paragraph">Ein Volume könnte beispielsweise lange Zeit unter der wenig verwendet worden sein<block ref="9df22f196a33acd0b372fe502de51211" prefix=" " category="inline-code"></block> die tiering-Richtlinie, und die meisten Blöcke sind nun Tiered Storage.</block>
  <block id="98c8614a9e0467f220df33a02cf7550a" category="paragraph">Wenn bei einer unerwarteten Änderung des Geschäfts ein Teil der Daten wiederholt gescannt werden muss, um einen bestimmten Bericht zu erstellen, kann es wünschenswert sein, den zu ändern<block ref="d253e682212338dd6cbe577947f0511e" prefix=" " category="inline-code"></block> Bis<block ref="0ba0dc933ac714a0bef4467360437336" prefix=" " category="inline-code"></block> Um sicherzustellen, dass alle gelesenen Daten in die Performance-Tier zurückgegeben werden, einschließlich sequenzieller und zufällig gelesener Daten. Dies würde die Performance sequenzieller I/O-Vorgänge für das Volume verbessern.</block>
  <block id="3ea4ba4aadef21fbda74c9b242c99efa" category="section-title">Heraufstufen</block>
  <block id="cb674c0cbcbaa23bdd3c8e4f6182f865" category="paragraph">Das Verhalten der „heraufstufen“-Richtlinie hängt von der Tiering-Richtlinie ab. Wenn die Tiering-Richtlinie lautet<block ref="9df22f196a33acd0b372fe502de51211" prefix=" " category="inline-code"></block>, Dann Einstellung der<block ref="723c2b1883eb9949dd821267c2d1b5c7" prefix=" " category="inline-code"></block> Ruft beim nächsten Tiering-Scan alle Blöcke aus der Kapazitäts-Tier zurück.</block>
  <block id="452d85cc34fd3a4cf55ac61e732239f4" category="paragraph">Wenn die Tiering-Richtlinie lautet<block ref="8805d416ce540c5f2df34af5b18d742b" prefix=" " category="inline-code"></block>, Dann sind die einzigen Blöcke, die zurückgegeben werden, die mit dem aktiven Dateisystem verbunden sind. Normalerweise hätte dies keine Auswirkung, weil die einzigen Blöcke unter das gestaffelt wären<block ref="8805d416ce540c5f2df34af5b18d742b" prefix=" " category="inline-code"></block> Richtlinie wären Blöcke, die ausschließlich mit Snapshots verknüpft wären. Es gäbe keine Tiered Blocks im aktiven File-System.</block>
  <block id="d6269fb1a970b6c261fedbc79464b3dc" category="paragraph">Wenn jedoch die Daten auf einem Volume von einem Volume-SnapRestore oder Datei-Klon-Vorgang aus einem Snapshot wiederhergestellt wurden, können einige der Blöcke, die aufgrund ihrer lediglich mit Snapshots verknüpften Speicherebenen verschoben wurden, jetzt vom aktiven File-System benötigt werden. Es kann wünschenswert sein, die vorübergehend zu ändern<block ref="d253e682212338dd6cbe577947f0511e" prefix=" " category="inline-code"></block> Richtlinie an<block ref="eeefc0add5ccd6e20ac4214923d27fbc" prefix=" " category="inline-code"></block> Alle lokal erforderlichen Blöcke schnell abrufen.</block>
  <block id="6e7b34fa59e1bd229b207892956dc41c" category="section-title">Nie</block>
  <block id="c45e30a0f86af155e2feb17dd7ba6e44" category="paragraph">Nehmen Sie keine Blöcke aus der Kapazitäts-Tier heraus.</block>
  <block id="2d242bb36ec91b32005f9296ff03a912" category="doc">Der Netapp Architektur Sind</block>
  <block id="ac30d4a74ecef302adab70e9669a4bf2" category="paragraph">FabricPool ist eine Tiering-Technologie, mit der Blöcke als „heiß“ oder „kalt“ klassifiziert werden und in dem Storage Tier platziert werden, der am besten geeignet ist. Die Performance-Tier befindet sich am häufigsten auf SSD-Storage und hostet die wichtigen Datenblöcke. Die Kapazitäts-Tier befindet sich in einem Objektspeicher und hostet die kühlen Datenblöcke. Unterstützung für Objekt-Storage: NetApp StorageGRID, ONTAP S3, Microsoft Azure Blob Storage, Alibaba Cloud Object Storage-Service, IBM Cloud Object Storage, Google Cloud Storage und Amazon AWS S3</block>
  <block id="f9f5fe2f7456d37c955f3291744c93b6" category="paragraph">Es stehen mehrere Tiering-Richtlinien zur Verfügung, die steuern, wie Blöcke als „heiß“ oder „kalt“ klassifiziert werden. Die Richtlinien lassen sich für einzelne Volumes festlegen und bei Bedarf ändern. Es werden nur die Datenblöcke zwischen den Performance- und Kapazitäts-Tiers verschoben. Die Metadaten, die die Struktur der LUN und des File-Systems definieren, verbleiben immer auf der Performance-Tier. Dadurch wird das Management auf ONTAP zentralisiert. Dateien und LUNs unterscheiden sich offenbar nicht von Daten, die auf einer anderen ONTAP-Konfiguration gespeichert sind. Der NetApp AFF oder FAS Controller wendet die definierten Richtlinien an, um Daten auf die entsprechende Tier zu verschieben.</block>
  <block id="156a1cf692c4ba9a4f9574fb16428b01" category="paragraph"><block ref="156a1cf692c4ba9a4f9574fb16428b01" category="inline-image-macro-rx" type="image"></block></block>
  <block id="616ce0475334fe37834d13972a168ca5" category="section-title">Objektspeicher-Anbieter</block>
  <block id="71e79501cc067e6b35ac3d3e97c940a4" category="paragraph">Bei Objekt-Storage-Protokollen werden einfache HTTP- oder HTTPS-Anfragen zum Speichern einer großen Anzahl von Datenobjekten verwendet. Der Zugriff auf den Objektspeicher muss zuverlässig sein, da der Datenzugriff von ONTAP von der umgehende Erfüllung von Anfragen abhängt. Zu den Optionen gehören Amazon S3 Standard und infrequent Access sowie Microsoft Azure Hot and Cool Blob Storage, IBM Cloud und Google Cloud. Archivierungsoptionen wie Amazon Glacier und Amazon Archive werden nicht unterstützt, da die zum Abrufen von Daten erforderliche Zeit die Toleranzen der Host-Betriebssysteme und -Applikationen überschreiten kann.</block>
  <block id="e114e830308285cd9085063fad91662c" category="paragraph">Zudem wird NetApp StorageGRID unterstützt und stellt eine optimale Lösung der Enterprise-Klasse dar. Es ist ein hochperformantes, skalierbares und hochsicheres Objekt-Storage-System, das geografische Redundanz für FabricPool Daten und andere Objektspeicher-Applikationen bietet, die zunehmend Teil von Enterprise-Applikationsumgebungen sind.</block>
  <block id="fb318c5cd9ed18c79e1f7a298dd96665" category="paragraph">StorageGRID kann zudem die Kosten senken, indem es die Egress-Gebühren vermeidet, die viele Public-Cloud-Provider beim Lesen der Daten aus ihren Services auferlegen.</block>
  <block id="119d8a1213b5b7cae4bb567153b028cf" category="section-title">Daten und Metadaten</block>
  <block id="b59d6123a3191bd85fe14e57b7a01e11" category="paragraph">Beachten Sie, dass der Begriff „Daten“ hier für die tatsächlichen Datenblöcke gilt, nicht für die Metadaten. Es werden nur Datenblöcke als Tiering übertragen, wobei die Metadaten in der Performance-Tier verbleiben. Darüber hinaus wird der Status eines Blocks als „heiß“ oder „kalt“ nur beeinflusst, wenn der eigentliche Datenblock gelesen wird. Das einfache Lesen des Namens, des Zeitstempels oder der Eigentümermetadaten einer Datei hat keine Auswirkung auf den Speicherort der zugrunde liegenden Datenblöcke.</block>
  <block id="1414cdc093d39dd56d0b0d20049e17fc" category="section-title">Backups</block>
  <block id="e0b766a7a0a7633679ecddd0f78a7390" category="paragraph">Obwohl FabricPool den Storage-Platzbedarf deutlich reduzieren kann, ist es nicht für sich genommen eine Backup-Lösung. NetApp WAFL Metadaten bleiben immer auf der Performance-Tier. Falls ein schwerwiegender Ausfall die Performance-Tier zerstört, kann keine neue Umgebung aus den Daten auf der Kapazitäts-Tier erstellt werden, da sie keine WAFL-Metadaten enthält.</block>
  <block id="7a25ce12890e524732cb71784b5915ab" category="paragraph">FabricPool kann jedoch Teil einer Backup-Strategie werden. FabricPool lässt sich beispielsweise mit der Replizierungstechnologie NetApp SnapMirror konfigurieren. Jede Hälfte der Spiegelung kann über eine eigene Verbindung mit einem Objekt-Storage-Ziel verfügen. Daraus ergeben sich zwei unabhängige Kopien der Daten. Die primäre Kopie besteht aus den Blöcken auf der Performance-Tier und den zugehörigen Blöcken auf der Kapazitäts-Tier, während das Replikat einen zweiten Satz von Performance- und Kapazitätsblöcken darstellt.</block>
  <block id="82af841589057aa8922b1ac3bb4a28a4" category="doc">Komprimierung</block>
  <block id="e242ff0701d9ed7d8317b32fd762a100" category="paragraph">Funktionen für Platzeffizienz wie Komprimierung, Data-Compaction und Deduplizierung sind darauf ausgelegt, die Menge der logischen Daten zu einer bestimmten Menge des physischen Storage zu erhöhen. Das Ergebnis sind niedrigere Kosten und geringerer Management-Overhead.</block>
  <block id="13b992c3d358d786db03341886472c4f" category="paragraph">Auf hohem Niveau ist Komprimierung ein mathematischer Prozess, bei dem Muster in Daten erkannt und so kodiert werden, dass der Platzbedarf reduziert wird. Dagegen erkennt die Deduplizierung tatsächlich wiederholte Datenblöcke und entfernt die fremden Kopien. Durch Data-Compaction können mehrere logische Datenblöcke denselben physischen Block auf den Medien gemeinsam nutzen.</block>
  <block id="786d7cc1b18aa3d9c3e8d3e30865240e" category="paragraph">Vor der Verfügbarkeit von All-Flash-Storage-Systemen war die Array-basierte Komprimierung nur eingeschränkt verfügbar, da die meisten I/O-intensiven Workloads eine sehr große Anzahl von Spindeln erforderten, um eine akzeptable Performance zu erreichen. Als Nebeneffekt der großen Anzahl von Laufwerken enthielten Storage-Systeme grundsätzlich viel mehr Kapazität als erforderlich. Mit dem Trend hin zu Solid-State-Storage hat sich die Situation verändert. Eine enorme Überprovisionierung von Laufwerken entfällt, nur weil eine gute Performance erzielt werden kann. Der Speicherplatz in einem Storage-System kann den tatsächlichen Kapazitätsanforderungen angepasst werden.</block>
  <block id="b207c460d31fea9e1cfab71057e8152c" category="paragraph">Die gesteigerte IOPS-Fähigkeit von Solid-State-Laufwerken (SSDs) bringt im Vergleich zu rotierenden Laufwerken fast immer Kosteneinsparungen mit sich. Allerdings kann die Komprimierung durch eine höhere effektive Kapazität von Solid-State-Medien weitere Einsparungen erzielen.</block>
  <block id="bd6c983943da8bf0ead08c643f0e75f3" category="paragraph">Es gibt verschiedene Möglichkeiten, Daten zu komprimieren. Viele Datenbanken verfügen über eigene Komprimierungsfunktionen, dies wird jedoch in Kundenumgebungen selten beobachtet. Der Grund dafür ist in der Regel die Performance-Einbußen bei einem *Wechsel* auf komprimierte Daten, und es entstehen oft hohe Lizenzkosten. Und schließlich gibt es noch die allgemeinen Performance-Auswirkungen auf die Datenbankvorgänge. Es macht wenig Sinn, für eine CPU, die Datenkomprimierung und -Dekomprimierung durchführt, hohe Lizenzkosten pro CPU zu zahlen, anstatt eine echte Datenbankarbeit zu erledigen. Eine bessere Option ist, die Komprimierungsarbeiten auf das Storage-System zu verlagern.</block>
  <block id="6296c8b7406b90d37edf269f1ea6f6ee" category="section-title">Anpassungsfähige Komprimierung</block>
  <block id="1245fef302b5da2c27766d9a98ad358c" category="paragraph">Die adaptive Komprimierung wurde vollständig mit Enterprise-Workloads getestet, ohne dabei die Performance zu beeinträchtigen – selbst in einer All-Flash-Umgebung, in der die Latenz im Mikrosekunden-Bereich gemessen wird. Einige Kunden haben bei Verwendung der Komprimierung sogar eine Performance-Steigerung festgestellt, da die Daten im Cache komprimiert bleiben. Dadurch konnte die Menge des verfügbaren Cache in einem Controller erhöht werden.</block>
  <block id="93e0a644c8f1b7f7f378bc071d15d1e9" category="paragraph">ONTAP managt physische Blöcke in 4-KB-Einheiten. Die anpassungsfähige Komprimierung verwendet eine Standardkomprimierung von 8 KB. Dies bedeutet, dass Daten in 8-KB-Einheiten komprimiert werden. Dies entspricht der 8-KB-Blockgröße, die von relationalen Datenbanken am häufigsten verwendet wird. Kompressionsalgorithmen werden effizienter, da mehr Daten als eine Einheit komprimiert werden. Eine Komprimierungs-Blockgröße von 32 KB wäre speichereffizienter als eine Komprimierungsblockeinheit mit 8 KB. Das bedeutet, dass die adaptive Komprimierung bei Verwendung der standardmäßigen 8-KB-Blockgröße zu etwas niedrigeren Effizienzraten führt, jedoch bietet die Verwendung kleinerer Blockgrößen zur Komprimierung auch einen signifikanten Vorteil. Datenbank-Workloads umfassen einen großen Anteil an Überschreibungsaktivitäten. Beim Überschreiben eines komprimierten 32-KB-Datenblocks müssen die gesamten 32-KB-Daten zurückgelesen, dekomprimiert, der erforderliche 8-KB-Bereich aktualisiert, neu komprimiert und dann die gesamten 32-KB-Daten wieder auf die Laufwerke geschrieben werden. Dies ist für ein Storage-System ein sehr teurer Vorgang und der Grund dafür, dass bei einigen Storage Arrays anderer Anbieter, die auf größeren Komprimierungsblockgrößen basieren, auch die Performance bei Datenbank-Workloads erheblich beeinträchtigt wird.</block>
  <block id="096cc7f8e7e1861c3ee0269a90fc27e3" category="admonition">Die von der anpassungsfähigen Komprimierung verwendete Blockgröße kann auf bis zu 32 KB gesteigert werden. Dies kann die Speichereffizienz verbessern und sollte für stillgelegte Dateien wie Archivprotokolle und Backup-Dateien in Betracht gezogen werden, wenn eine große Menge solcher Daten auf dem Array gespeichert wird. In manchen Situationen profitieren aktive Datenbanken mit 16-KB- oder 32-KB-Blockgröße möglicherweise auch von der Erhöhung der Blockgröße der anpassungsfähigen Komprimierung. Wenden Sie sich an einen Mitarbeiter von NetApp oder einen unserer Partner, um Rat zu erhalten, ob diese Lösung für Ihren Workload geeignet ist.</block>
  <block id="f291779c724993ded5e79421d88f3e55" category="admonition">Blockgrößen der Komprimierung von mehr als 8 KB sollten nicht zusammen mit der Deduplizierung an Streaming-Backup-Zielen verwendet werden. Der Grund dafür ist, dass kleine Änderungen an den gesicherten Daten das 32-KB-Komprimierungsfenster beeinflussen. Wenn sich das Fenster verschiebt, unterscheiden sich die resultierenden komprimierten Daten in der gesamten Datei. Die Deduplizierung erfolgt nach der Komprimierung. Das heißt, die Deduplizierungs-Engine sieht jedes komprimierte Backup unterschiedlich. Wenn eine Deduplizierung von Streaming-Backups (wie beispielsweise Oracle RMAN) erforderlich ist, sollte nur eine anpassungsfähige 8-KB-Blockkomprimierung verwendet werden. Die adaptive Komprimierung ist vorzuziehen, da sie bei kleineren Blöcken arbeitet und die Deduplizierungseffizienz nicht stört. Aus ähnlichen Gründen wirkt sich die Host-seitige Komprimierung auch in die Effizienz der Deduplizierung aus.</block>
  <block id="1f9367b7afff301ee24188d35050ae0a" category="section-title">Temperaturempfindliche Speichereffizienz</block>
  <block id="78aa8c12abb3bf9f61a08df0f9b403de" category="paragraph">Temperature Sensitive Storage Efficiency (TSSE) ist eine Verfügbarkeit in ONTAP 9.8 und höher. Sie basiert auf Blockzugriff-Heatmaps, um selten genutzte Blöcke zu identifizieren und sie mit höherer Effizienz zu komprimieren.</block>
  <block id="02e44d620def629a6c145ccd0d9a0fd3" category="section-title">Kompressionsausrichtung</block>
  <block id="3b6e6c232a02ab9c64199eb9efae012c" category="paragraph">Die anpassungsfähige Komprimierung in einer Datenbankumgebung erfordert bestimmte Überlegungen zur Blockausrichtung der Komprimierung. Dies ist nur für Daten relevant, die Random Überschreibungen sehr spezifischer Blöcke unterliegen. Dieser Ansatz ähnelt im Konzept der gesamten Filesystem-Ausrichtung, wobei der Beginn eines Dateisystems an einer Grenze von 4K-Geräten ausgerichtet werden muss und die Blockgröße eines Dateisystems ein Vielfaches von 4K sein muss.</block>
  <block id="327a36f7ca539411197c2f867b501719" category="paragraph">Ein Schreibvorgang von 8 KB in eine Datei wird beispielsweise nur komprimiert, wenn er an einer 8-KB-Grenze innerhalb des Dateisystems selbst ausgerichtet ist. Dieser Punkt bedeutet, dass er auf die ersten 8 KB der Datei, die zweiten 8 KB der Datei usw. fallen muss. Daten wie RMAN Backups oder Archivprotokolle werden sequenziell geschrieben und umfassen mehrere Blöcke, die alle komprimiert werden. Daher besteht keine Notwendigkeit, eine Ausrichtung zu erwägen. Das einzige I/O-Muster, das Bedenken aushinsichtlich des zufälligen Überschreibens von Dateien hat, ist das zufällige Überschreiben von Dateien.</block>
  <block id="1d1a594959ec615f56516f5d0f5e8ddb" category="section-title">NFS</block>
  <block id="8dae8f7054353dae17cd9da8deb0e091" category="paragraph">Mithilfe von NFS wird der Datei-I/O ausgerichtet. Jeder Block einer Datei wird an dem Anfang der Datei ausgerichtet.</block>
  <block id="62a0282d39568be094470486eaf70c4f" category="section-title">San</block>
  <block id="b0762e9957c8485f911e57bfd027eddb" category="paragraph">SAN-Umgebungen müssen Daten an einer 8-KB-Grenze ausgerichtet sein, um eine optimale Komprimierung zu erzielen. Es gibt zwei Aspekte der Ausrichtung für SAN: Das LUN und das Filesystem. Die LUN muss entweder als gesamtes Laufwerkgerät (keine Partition) oder als Partition konfiguriert werden, die an eine 8-KB-Grenze ausgerichtet ist.</block>
  <block id="ad16b6d5634739ef4ceb795c5beea659" category="admonition">Lesen Sie die Abschnitte zu Thin Provisioning für eine Erläuterung des Wechselspiels zwischen Komprimierung und fraktionaler Reservierung.</block>
  <block id="14c3c56ff2a98d1a9c47b63a917f67a3" category="section-title">Data-Compaction</block>
  <block id="546168bb7b68da66be7b6c0e60a23460" category="paragraph">Data-Compaction ist eine in ONTAP eingeführte Technologie zur Verbesserung der Komprimierungseffizienz. Wie bereits erwähnt, erzielt die anpassungsfähige Komprimierung allein schon Einsparungen von 2:1, da sie auf das Speichern eines 8-KB-I/O-Blocks in einem 4-KB-WAFL-Block beschränkt ist. Komprimierungsmethoden mit größeren Blockgrößen verbessern die Effizienz. Sie sind jedoch nicht für Daten geeignet, die mit Überschreibungen kleiner Blöcke verbunden sind. Die Dekomprimierung von 32-KB-Dateneinheiten durch die Aktualisierung eines 8-KB-Abschnitts, die Datenkomprimierung und das Zurückschreiben auf die Laufwerke verursacht Overhead.</block>
  <block id="0b01f66d49b9df153ee76048de44f6eb" category="paragraph">Data-Compaction sorgt dafür, dass mehrere logische Blöcke innerhalb physischer Blöcke gespeichert werden können. Beispielsweise kann eine Datenbank mit stark komprimierbaren Daten wie Text oder teilweise vollständigen Blöcken von 8 KB bis 1 KB komprimieren. Ohne Data-Compaction belegen diese 1 KB Daten immer noch einen gesamten 4-KB-Block. Durch die Inline-Data-Compaction können 1 KB komprimierte Daten zusammen mit anderen komprimierten Daten auf nur 1 KB physischen Speicherplatz gespeichert werden. Es handelt sich nicht um eine Komprimierungstechnologie. Es ist einfach eine effizientere Möglichkeit, Speicherplatz auf den Laufwerken zuzuweisen und sollte daher keine erkennbaren Performance-Auswirkungen verursachen.</block>
  <block id="07b153ed9b6a6f9f334f2ad1fe94651e" category="paragraph">Der Grad der erzielten Einsparungen variiert. Bereits komprimierte oder verschlüsselte Daten können in der Regel nicht weiter komprimiert werden. Daher profitieren diese Datensätze von der Data-Compaction nicht. Neu initialisierte Oracle Datendateien, die etwas mehr als Block-Metadaten enthalten, und Nullen komprimieren bis zu 80:1. Das schafft eine sehr große Bandbreite an Möglichkeiten.</block>
  <block id="83f45cad5e6f535ff10e564a526baad0" category="section-title">Deduplizierung</block>
  <block id="f591ef30da06841378ee7f595e63a93c" category="paragraph">Deduplizierung ist die Entfernung von Blockduplikaten aus einem Datensatz. Wenn beispielsweise derselbe 4-KB-Block in 10 verschiedenen Dateien vorhanden war, leitet die Deduplizierung diesen 4-KB-Block innerhalb aller 10 Dateien auf denselben physischen 4-KB-Block um. Im Ergebnis würde sich die Effizienz dieser Daten um 10:1 verbessern.</block>
  <block id="699c85c5df1985b2af588f9e6c1ad353" category="paragraph">Daten wie Boot-LUNs von VMware lassen sich in der Regel sehr gut deduplizieren, da sie aus mehreren Kopien derselben Betriebssystemdateien bestehen. Es wurde eine Effizienz von 100:1 und höher festgestellt.</block>
  <block id="c3ed34b88ac0b8efff210a99f19a4b9b" category="paragraph">Einige Daten enthalten keine Datenduplikate. Ein Oracle-Block enthält beispielsweise einen Header, der global nur für die Datenbank gilt, und einen Trailer, der fast einzigartig ist. Aus diesem Grund führt die Deduplizierung einer Oracle Database selten zu Einsparungen von mehr als 1 %.</block>
  <block id="9653a3d4907877aae00bb7d39eeec66d" category="paragraph">In einigen Fällen wurde eine Speicherersparnis von bis zu 15 % bei Datenbanken mit 16 KB und großen Blockgrößen beobachtet. Die ersten 4-KB-Blöcke enthalten die global eindeutige Kopfzeile, und der letzte 4-KB-Block enthält den nahezu einzigartigen Trailer. Die internen Blöcke eignen sich für eine Deduplizierung, obwohl dies in der Praxis fast vollständig der Deduplizierung von gelöschten Daten zugeordnet ist.</block>
  <block id="89d6ec0df0a54d3cdcc8f0573a6b37c5" category="paragraph">Viele Arrays anderer Anbieter behaupten, Oracle-Datenbanken unter der Annahme zu deduplizieren, dass eine Datenbank mehrfach kopiert wird. In dieser Hinsicht kann auch NetApp Deduplizierung eingesetzt werden, allerdings bietet ONTAP die bessere Option: NetApp FlexClone Technologie. Das Endergebnis ist dasselbe: Es werden mehrere Kopien einer Oracle Datenbank erstellt, die sich die meisten zugrunde liegenden physischen Blöcke teilen. Die Verwendung von FlexClone ist viel effizienter, als Dateien zu kopieren und dann zu deduplizieren. Der Effekt ist die Nichtdeduplizierung und nicht die Deduplizierung, da ein Duplikat von vornirgends erstellt wird.</block>
  <block id="32aeb47267cb2045610b468115f3ae0e" category="section-title">Effizienz und Thin Provisioning</block>
  <block id="3381946611f34fb44ad8a38a0c44e0a8" category="paragraph">Effizienzfunktionen sind Formen von Thin Provisioning. Beispielsweise kann eine 100-GB-LUN, die ein 100-GB-Volume belegt, bis zu 50 GB komprimiert werden. Es wurden noch keine tatsächlichen Einsparungen realisiert, da das Volume noch 100 GB beträgt. Das Volume muss zunächst verkleinert werden, damit der eingesparte Speicherplatz an anderer Stelle im System genutzt werden kann. Wenn spätere Änderungen an der 100GB-LUN dazu führen, dass die Daten weniger komprimierbar werden, dann vergrößert sich die LUN und das Volume könnte sich füllen.</block>
  <block id="20132d08f816a6401f40a29feb68df8d" category="paragraph">Thin Provisioning wird nachdrücklich empfohlen, da es das Management vereinfachen und gleichzeitig eine deutliche Verbesserung der nutzbaren Kapazität mit den damit verbundenen Kosteneinsparungen ermöglichen kann. Der Grund hierfür ist einfach: Oracle-Umgebungen enthalten oft viel leeren Speicherplatz, eine große Anzahl von Volumes und LUNs sowie komprimierbare Daten. Durch Thick Provisioning wird Speicherplatz auf Storage für Volumes und LUNs reserviert, für den Fall, dass sie eines Tages zu 100 % voll werden und 100 % nicht komprimierbare Daten enthalten. Das wird wohl nie passieren. Dank Thin Provisioning kann dieser Speicherplatz zurückgewonnen und an anderer Stelle verwendet werden. Das Kapazitätsmanagement kann auf dem Storage-System selbst basieren, anstatt auf vielen kleineren Volumes und LUNs.</block>
  <block id="38ef8b6f2fc332958c293d93c61d7756" category="paragraph">Einige Kunden bevorzugen Thick Provisioning entweder für bestimmte Workloads oder generell basierend auf bestehenden Betriebs- und Beschaffungsmethoden.</block>
  <block id="f8ea8eaa5ca0e58c6a43ec0117b7bd8d" category="paragraph">*Achtung:* Wenn ein Volume mit Thick Provisioning bereitgestellt wird, ist darauf zu achten, dass alle Effizienzfunktionen für dieses Volume, einschließlich Dekomprimierung und Entfernung der Deduplizierung mit dem, vollständig deaktiviert werden<block ref="3cfeff511a11b8c5f54ce9749a719a58" prefix=" " category="inline-code"></block> Befehl. Das Volume sollte nicht in angezeigt werden<block ref="df899f2d908ec33afe1d01ee26b3dd47" prefix=" " category="inline-code"></block> Ausgabe: Ist dies der Fall, ist das Volume für Effizienzfunktionen noch teilweise konfiguriert. Daher funktionieren Überschreibungsgarantien anders. Dies erhöht die Wahrscheinlichkeit, dass Konfigurationsübersehungen dazu führen, dass das Volume unerwartet aus dem Speicherplatz kommt und zu Datenbank-I/O-Fehlern führt.</block>
  <block id="0e7c78164adb6d4650ea685a79d8e99e" category="section-title">Best Practices für Effizienz</block>
  <block id="d67dd6ae62908b7781805cf297fa8d87" category="paragraph">NetApp bietet die folgenden Empfehlungen für ONTAP 9 und höher. Für ONTAP-Versionen vor ONTAP 9 wenden Sie sich bitte an Ihren NetApp Ansprechpartner.</block>
  <block id="ec499ad25fa5a765ba43ec2c87819623" category="section-title">AFF-Standards</block>
  <block id="38b7d52fb2d518d07c1c857b20ebbbd2" category="paragraph">Volumes, die auf ONTAP erstellt wurden und auf einem rein Flash-basierten AFF System ausgeführt werden, werden über Thin Provisioning mit allen Inline-Effizienzfunktionen bereitgestellt. Obwohl Oracle Datenbanken im Allgemeinen keine Vorteile durch Deduplizierung bieten und nicht komprimierbare Daten umfassen können, sind die Standardeinstellungen trotzdem für fast alle Workloads geeignet. ONTAP wurde mit dem Ziel entwickelt, alle Arten von Daten und I/O-Muster effizient zu verarbeiten. Dabei spielt es keine Rolle, ob es zu Einsparungen kommt oder nicht. Standardwerte sollten nur dann geändert werden, wenn die Gründe vollständig verstanden sind und es einen Vorteil gibt, dass sie abweichen.</block>
  <block id="9f7127e69d50bf7b844ff3723b86fbd1" category="section-title">Allgemeine Empfehlungen</block>
  <block id="2c24e4751310e03f119a4df187a3bc08" category="list-text">Wenn Volumes und/oder LUNs nicht über Thin Provisioning bereitgestellt werden, müssen Sie alle Effizienzeinstellungen deaktivieren, da die Verwendung dieser Funktionen keine Einsparungen bietet. Die Kombination von Thick Provisioning mit aktivierter Speicherplatzeffizienz kann zu unerwartetem Verhalten führen, einschließlich Fehlern aufgrund von fehelterem Speicherplatz.</block>
  <block id="4922fe547c351d6a121465da036d478e" category="list-text">Wenn Daten nicht überschrieben werden, wie etwa bei Backups oder Datenbanktransaktionsprotokollen, können Sie die Effizienz steigern, indem Sie TSSE mit einem niedrigen Kühlzeitraum aktivieren.</block>
  <block id="e75fd383e4106eb78482b18896975daf" category="list-text">Einige Dateien enthalten möglicherweise eine beträchtliche Menge an nicht komprimierbaren Daten. Ein Beispiel: Wenn die Komprimierung bereits auf Applikationsebene aktiviert ist, werden Dateien verschlüsselt. Wenn eines dieser Szenarien zutrifft, sollten Sie die Komprimierung deaktivieren, um einen effizienteren Betrieb auf anderen Volumes mit komprimierbaren Daten zu ermöglichen.</block>
  <block id="11845fef1d21077d7b23ce880868b556" category="list-text">Verwenden Sie für Datenbank-Backups nicht sowohl die 32-KB-Komprimierung als auch die Deduplizierung. Siehe Abschnitt „“<block ref="57ee2712afc5e59236f86db0537b05dc" category="inline-xref-macro-rx"></block>„“ für weitere Informationen.</block>
  <block id="64d5def835c194cac8afe4fafded756e" category="doc">Richtlinien: Lokale Snapshots</block>
  <block id="baa596d0db91317fa83739a95649752e" category="paragraph">Die erste Version von FabricPool war auf den Backup-Anwendungsfall ausgerichtet. Als einzige Art von Blöcken, die Tiering ermöglichen konnten, handelte es sich um Blöcke, die nicht mehr mit Daten im aktiven File-System verknüpft waren. Daher können nur die Snapshot Datenblöcke auf diese Kapazitäts-Tier verschoben werden. Dies bleibt eine der sichersten Tiering-Optionen, wenn Sie sicherstellen müssen, dass die Performance nie beeinträchtigt wird.</block>
  <block id="b21eb7f0b67c3e27e915183638bf92cf" category="paragraph">Es gibt zwei Optionen für das Tiering inaktiver Snapshot-Blöcke auf die Kapazitäts-Tier. Zunächst einmal die<block ref="8805d416ce540c5f2df34af5b18d742b" prefix=" " category="inline-code"></block> Die Richtlinie zielt nur auf die Snapshot-Blöcke ab. Obwohl der<block ref="9df22f196a33acd0b372fe502de51211" prefix=" " category="inline-code"></block> Die Richtlinie umfasst die<block ref="8805d416ce540c5f2df34af5b18d742b" prefix=" " category="inline-code"></block> Blöcke, sondern auch Tiering Blöcke aus dem aktiven File-System. Dies ist möglicherweise nicht wünschenswert.</block>
  <block id="eeba990304f236b36a9fec2434c77470" category="paragraph">Der<block ref="e5e88684921dd21f3f86c28343a3082f" prefix=" " category="inline-code"></block> Der Wert sollte auf einen Zeitraum festgelegt werden, in dem Daten, die während einer Wiederherstellung erforderlich sein könnten, auf der Performance-Tier zur Verfügung stehen. So enthalten die meisten Wiederherstellungsszenarien einer kritischen Produktionsdatenbank zu einem bestimmten Zeitpunkt in den letzten Tagen einen Wiederherstellungspunkt. Einstellung A<block ref="e5e88684921dd21f3f86c28343a3082f" prefix=" " category="inline-code"></block> Mit dem Wert 3 würde sichergestellt, dass bei einer Wiederherstellung der Datei eine Datei entsteht, die sofort die maximale Performance liefert. Alle Blöcke in den aktiven Dateien befinden sich immer noch auf schnellem Storage, ohne dass eine Wiederherstellung aus dem Kapazitäts-Tier erforderlich ist.</block>
  <block id="baf531ed01ad56f5614e1a68e8a2e7aa" category="section-title">Richtlinien – replizierte Snapshots</block>
  <block id="27e5121a4c75181022e7be2b738339d0" category="paragraph">Ein Snapshot, der mit SnapMirror oder SnapVault repliziert wird, der nur für die Wiederherstellung verwendet wird, sollte im Allgemeinen die FabricPool verwenden<block ref="a181a603769c1f98ad927e7367c7aa51" prefix=" " category="inline-code"></block> Richtlinie: Bei dieser Richtlinie werden Metadaten repliziert. Alle Datenblöcke werden jedoch sofort an die Kapazitäts-Tier gesendet, was maximale Performance liefert. Die meisten Recovery-Prozesse arbeiten mit sequenziellem I/O, was von vornherein effizient ist. Die Recovery-Zeit vom Zielort des Objektspeichers ist zu bewerten, in einer gut durchdachten Architektur muss dieser Recovery-Prozess jedoch nicht wesentlich langsamer sein als die Wiederherstellung von lokalen Daten.</block>
  <block id="639e481de0ffe002bd83251b26a2540a" category="paragraph">Wenn die replizierten Daten auch für das Klonen verwendet werden sollen, wird der verwendet<block ref="9df22f196a33acd0b372fe502de51211" prefix=" " category="inline-code"></block> Die Politik ist angemessener, mit einem<block ref="e5e88684921dd21f3f86c28343a3082f" prefix=" " category="inline-code"></block> Wert, der Daten umfasst, von denen erwartet wird, dass sie regelmäßig in einer Klonumgebung verwendet werden. Der aktive Arbeitsdatensatz einer Datenbank kann beispielsweise Daten enthalten, die in den letzten drei Tagen gelesen oder geschrieben wurden, aber es können auch weitere Verlaufsdaten von 6 Monaten enthalten sein. Wenn ja, dann die<block ref="9df22f196a33acd0b372fe502de51211" prefix=" " category="inline-code"></block> Durch eine Richtlinie am Ziel von SnapMirror wird das Arbeitsdatensatz auf der Performance-Ebene verfügbar.</block>
  <block id="ace0bd0c1be3a9e17d9736d93e7a1da2" category="doc">IOPS QoS</block>
  <block id="786ee59e0cdaa09335e12fea3a168653" category="paragraph">Insbesondere die zunehmende Verbreitung von All-Flash-Storage ermöglicht die Konsolidierung von Workloads. Storage-Arrays mit rotierenden Medien unterstützten in der Regel nur eine begrenzte Anzahl I/O-intensiver Workloads, da die IOPS-Funktionen einer älteren Rotationslaufwerkstechnologie begrenzt sind. Ein oder zwei hochaktive Datenbanken würden die zugrunde liegenden Laufwerke lange sättigen, bevor die Storage-Controller ihre Grenzen erreichten. Das hat sich geändert. Die Performance-Fähigkeit einer relativ kleinen Anzahl von SSD-Laufwerken kann sogar die leistungsstärksten Storage-Controller auslasten. So können Sie alle Funktionen der Controller nutzen, ohne die Gefahr eines plötzlichen Performance-Einbruchs aufgrund von Latenzspitzen der rotierenden Medien befürchten zu müssen.</block>
  <block id="270d79669200ef485add1ecc1833cc94" category="paragraph">Ein einfaches HA-AFF A800 System mit zwei Nodes kann bis zu eine Million zufällige IOPS verarbeiten, bevor die Latenz auf über eine Millisekunde steigt. Für sehr wenige einzelne Workloads wird erwartet, dass sie ein solches Niveau erreichen. Die vollständige Nutzung dieses AFF A800 System-Arrays beinhaltet das Hosting mehrerer Workloads. Für eine sichere Durchführung sind QoS-Kontrollen erforderlich, um die Vorhersehbarkeit zu gewährleisten.</block>
  <block id="4dca0c3547523a2e5bd1b8d0e2ff8de5" category="paragraph">ONTAP bietet zwei Arten von Quality of Service (QoS): IOPS und Bandbreite. QoS-Steuerungen können auf SVMs, Volumes, LUNs und Dateien angewendet werden.</block>
  <block id="3ea539ed2021ba46a3658039e8af419f" category="paragraph">Eine Steuerung der IOPS-QoS basiert offensichtlich auf dem IOPS-Wert einer bestimmten Ressource. Es gibt jedoch eine Reihe von Aspekten der IOPS-QoS, die möglicherweise nicht intuitiv sind. Einige Kunden waren anfangs verwirrt über den scheinbaren Anstieg der Latenz, wenn ein IOPS-Schwellenwert erreicht wurde. Die steigende Latenz ist das natürliche Ergebnis der IOPS-Begrenzung. Logischerweise funktioniert es ähnlich wie ein Token-System. Wenn beispielsweise ein bestimmtes Volume mit Datendateien über ein Limit von 10.000 IOPS verfügt, muss jede eintreffende I/O zuerst ein Token erhalten, um die Verarbeitung fortzusetzen. Solange in einer bestimmten Sekunde nicht mehr als 10.000 Token verbraucht wurden, sind keine Verzögerungen vorhanden. Wenn I/O-Vorgänge auf den Erhalt ihres Tokens warten müssen, wird diese Wartezeit als zusätzliche Latenz angezeigt. Je schwieriger eine Workload das QoS-Limit erreicht, desto länger muss jede I/O in der Warteschlange warten, bis sie verarbeitet wird. Dies scheint für den Benutzer eine höhere Latenz zu sein.</block>
  <block id="34a96885dd7f4501920b13026e7f2cab" category="admonition">Gehen Sie vorsichtig vor, wenn Sie QoS-Kontrollen auf Datenbanktransaktions-/Wiederherstellungsprotokolldaten anwenden. Die Performance-Anforderungen der Wiederherstellungsprotokollierung sind in der Regel viel, viel niedriger als Datendateien, jedoch erfolgt die Aktivität des Wiederherstellungsprotokolls sprunghafter. Die I/O-Vorgänge erfolgen in kurzen Impulsen, und ein QoS-Limit, das für die durchschnittlichen Wiederherstellungs-I/O-Level angemessen erscheint, kann für die tatsächlichen Anforderungen zu niedrig sein. Das Ergebnis können schwerwiegende Performance-Einschränkungen sein, wenn die QoS sich mit jedem Burst des Wiederherstellungsprotokolls befasst. Die Wiederherstellungs- und Archivprotokollierung sollte im Allgemeinen nicht durch QoS beschränkt sein.</block>
  <block id="c79dc76371299e08f4b4ebd609314ca4" category="section-title">Bandbreiten QoS</block>
  <block id="b9d5c520039715de9b997c5a69f4aeaa" category="paragraph">Nicht alle I/O-Größen sind gleich. Beispielsweise führt eine Datenbank möglicherweise eine große Anzahl kleiner Blocklesevorgänge durch, wodurch der IOPS-Schwellenwert erreicht wird. Datenbanken führen aber möglicherweise auch einen vollständigen Tabellenscan durch, der aus einer sehr kleinen Anzahl an großen Blocklesevorgängen bestehen würde, die eine sehr große Menge an Bandbreite verbrauchen, aber relativ wenig IOPS.</block>
  <block id="4930ae83bb8dd5e539dc9f7e73c6d74c" category="paragraph">Ebenso könnte eine VMware Umgebung eine sehr hohe Anzahl zufälliger IOPS während des Startvorgangs verursachen, würde jedoch während eines externen Backups weniger, aber größere I/O-Vorgänge ausführen.</block>
  <block id="eabb5a523a77d4521c12622ee9388aa6" category="paragraph">Manchmal erfordert ein effektives Performance-Management entweder Einschränkungen für die IOPS-Leistung oder die Bandbreite oder sogar beides.</block>
  <block id="13dac55a5f26cefab26368ea5a67e29f" category="section-title">Minimum/garantierte QoS</block>
  <block id="68559688130772c84bb39b2a9ca2c2af" category="paragraph">Viele Kunden wünschen sich eine Lösung mit garantierter QoS, was schwieriger zu erreichen ist, als sie möglicherweise verschwenderisch erscheint. Wenn Sie beispielsweise 10 Datenbanken mit einer Garantie von 10.000 IOPS platzieren, müssen Sie ein System für ein Szenario dimensionieren, in dem alle 10 Datenbanken gleichzeitig mit 10.000 IOPS, also insgesamt 100.000, laufen.</block>
  <block id="c0938f706c890ea85c86388391ffad22" category="paragraph">Eine minimale QoS-Steuerung soll am besten zum Schutz kritischer Workloads eingesetzt werden. Ein Beispiel wäre ein ONTAP Controller mit maximal 500.000 IOPS und einer Kombination aus Produktions- und Entwicklungs-Workloads. Sie sollten maximale QoS-Richtlinien auf Entwicklungs-Workloads anwenden, um zu verhindern, dass eine gegebene Datenbank den Controller für sich einmonopolisiert. Sie würden dann minimale QoS-Richtlinien auf Produktions-Workloads anwenden, um sicherzustellen, dass immer die erforderlichen IOPS bei Bedarf zur Verfügung stehen.</block>
  <block id="acdda1c20fb3985ce840929f7525c803" category="section-title">Anpassungsfähige QoS</block>
  <block id="dd5bc58ed6ab031b170a409470d9a763" category="paragraph">Adaptive QoS bezeichnet die ONTAP-Funktion, bei der die QoS-Begrenzung auf der Kapazität des Storage-Objekts basiert. Sie wird selten bei Datenbanken eingesetzt, da zwischen der Größe einer Datenbank und ihren Performance-Anforderungen in der Regel keine Verknüpfung besteht. Große Datenbanken können nahezu inert sein, während kleinere Datenbanken die IOPS-intensivsten sein können.</block>
  <block id="eb595833577352045f92d14ac4315ad2" category="paragraph">Adaptive QoS kann bei Virtualisierungs-Datastores sehr hilfreich sein, da die IOPS-Anforderungen solcher Datensätze in der Regel mit der Gesamtgröße der Datenbank korrelieren. Ein neuerer Datenspeicher mit 1 TB VMDK-Dateien benötigt wahrscheinlich etwa die Hälfte der Performance als 2-TB-Datenspeicher. Durch anpassungsfähige QoS können Sie die QoS-Limits automatisch vergrößern, wenn der Datastore mit Daten gefüllt wird.</block>
  <block id="23f3d415bb4fe6f99165df604b24da0e" category="paragraph">Tiering ein Datensatz mit FabricPool ergibt eine Abhängigkeit zwischen dem primären Storage Array und der Objektspeicher-Ebene. Es gibt zahlreiche Objektspeicher-Optionen, die eine unterschiedliche Verfügbarkeit bieten. Es ist wichtig, die Auswirkungen eines möglichen Verbindungsverlusts zwischen dem primären Storage-Array und dem Objekt-Storage-Tier zu verstehen.</block>
  <block id="7e856c11a853d276fd5d6274bf60fafd" category="paragraph">Wenn ein an ONTAP ausgehändigt I/O Daten aus der Kapazitäts-Tier benötigt und ONTAP die Kapazitäts-Tier nicht erreichen kann, um Blöcke abzurufen, wird schließlich ein Ausfall des I/O-Systems erreicht. Die Auswirkung dieses Timeouts hängt vom verwendeten Protokoll ab. In einer NFS-Umgebung antwortet ONTAP je nach Protokoll entweder mit einer EJUKEBOX- oder EDELAY-Antwort. Einige ältere Betriebssysteme interpretieren dies möglicherweise als Fehler, aber aktuelle Betriebssysteme und aktuelle Patch-Level des Oracle Direct NFS-Clients behandeln dies als Retrievable-Fehler und warten weiterhin auf den Abschluss des I/O.</block>
  <block id="207d9fe0f57910936bfa043248f3afca" category="paragraph">Ein kürzeres Timeout gilt für SAN-Umgebungen. Wenn ein Block in der Objektspeicherumgebung erforderlich ist und zwei Minuten lang nicht erreichbar bleibt, wird ein Lesefehler an den Host zurückgegeben. Das ONTAP Volume und die LUNs bleiben online, das Host-Betriebssystem kennzeichnet das Filesystem jedoch möglicherweise als fehlerhaft.</block>
  <block id="c9251835da8df507ca4f6ce02d4216be" category="paragraph">Konnektivitätsprobleme bei Objekt-Storage<block ref="8805d416ce540c5f2df34af5b18d742b" prefix=" " category="inline-code"></block> Die Richtlinie ist weniger bedenklich, da nur Backup-Daten als Tiering übertragen werden. Kommunikationsprobleme würden die Datenwiederherstellung verlangsamen, würden jedoch die aktive Nutzung der Daten nicht beeinträchtigen. Der<block ref="9df22f196a33acd0b372fe502de51211" prefix=" " category="inline-code"></block> Und<block ref="a181a603769c1f98ad927e7367c7aa51" prefix=" " category="inline-code"></block> Mithilfe von Richtlinien wird das Tiering „kalter“ Daten von der aktiven LUN ermöglicht. Ein Fehler beim Abrufen von Objektspeicher-Daten kann sich somit auf die Datenbankverfügbarkeit auswirken. Eine SAN-Implementierung mit diesen Richtlinien sollte nur mit Objektspeicher der Enterprise-Klasse und Netzwerkverbindungen genutzt werden, die auf Hochverfügbarkeit ausgelegt sind. NetApp StorageGRID ist die überlegene Option.</block>
  <block id="0f8062f9220efe4f38e7236fe8885379" category="paragraph">Die meisten relationalen Datenbanken arbeiten im Transaktionsprotokoll-Archivierungsmodus, um Point-in-Time Recovery bereitzustellen. Änderungen an den Datenbanken werden durch die Aufzeichnung der Änderungen in den Transaktionsprotokollen vorgenommen und das Transaktionsprotokoll wird ohne Überschreibung beibehalten. Dies kann zur Anforderung führen, eine enorme Menge an archivierten Transaktions-Logs aufzubewahren. Ähnliche Beispiele gibt es bei vielen anderen Applikations-Workflows, die Daten generieren, die aufbewahrt werden müssen, auf die jedoch mit hoher Wahrscheinlichkeit jemals zugegriffen werden wird.</block>
  <block id="229384bbfb1db19c4897d87ba4b9bc2d" category="paragraph">FabricPool löst diese Probleme mit einer einzigen Lösung mit integriertem Tiering. Dateien werden gespeichert und bleiben an ihrem üblichen Speicherort zugänglich, belegen jedoch praktisch keinen Speicherplatz auf dem primären Array.</block>
  <block id="f60aec7aaed8420e09f17a8cfd1d7d37" category="paragraph">Verwenden Sie A<block ref="e5e88684921dd21f3f86c28343a3082f" prefix=" " category="inline-code"></block> Eine Richtlinie von wenigen Tagen führt zur Aufbewahrung von Blöcken in den kürzlich erstellten Dateien (die Dateien sind, die in naher Zukunft am wahrscheinlichsten erforderlich sind) auf der Performance-Tier. Die Datenblöcke aus älteren Dateien werden dann auf die Kapazitäts-Tier verschoben.</block>
  <block id="485e24df9e0ebeecf416daa6e5441bba" category="paragraph">Der<block ref="9df22f196a33acd0b372fe502de51211" prefix=" " category="inline-code"></block> Erzwingt sofortiges Tiering, wenn der Kühlschwellenwert erreicht wurde, unabhängig davon, ob die Protokolle gelöscht wurden oder weiterhin im primären Dateisystem vorhanden sind. Auch das Speichern aller potenziell erforderlichen Protokolle an einer zentralen Stelle im aktiven Filesystem vereinfacht das Management. Es gibt keinen Grund, Snapshots zu durchsuchen, um eine Datei zu finden, die wiederhergestellt werden muss.</block>
  <block id="bbe0132696bc482e0ba7a1f293d80083" category="paragraph">Einige Applikationen, wie z. B. Microsoft SQL Server, schneiden Transaktions-Log-Dateien während von Backup-Vorgängen ab, sodass sich die Protokolle nicht mehr im aktiven File-System befinden. Die Kapazität kann mithilfe des gespeichert werden<block ref="8805d416ce540c5f2df34af5b18d742b" prefix=" " category="inline-code"></block> tiering-Richtlinie, aber die<block ref="9df22f196a33acd0b372fe502de51211" prefix=" " category="inline-code"></block> Die Richtlinie ist für Protokolldaten nicht nützlich, da Protokolldaten im aktiven Dateisystem selten abgekühlt werden sollten.</block>
  <block id="0694b4972669f201ca85f9427a230208" category="doc">MetroCluster ist in 3 verschiedenen Konfigurationen erhältlich</block>
  <block id="948676ffa8073153cbe404795950ad85" category="list-text">HA-Paare mit IP-Konnektivität</block>
  <block id="ef012b81fd45a95681a584a59f8df77e" category="list-text">HA-Paare mit FC-Konnektivität</block>
  <block id="6ffec869ba36dff4e093b5ed8bac798a" category="list-text">Single Controller mit FC-Konnektivität</block>
  <block id="6fa7041982bed9488213a7bd2ecccfdf" category="paragraph">[HINWEIS]der Begriff „Konnektivität“ bezieht sich auf die Cluster-Verbindung, die für die standortübergreifende Replizierung verwendet wird. Er bezieht sich nicht auf die Host-Protokolle. Unabhängig von der Art der Verbindung, die für die Kommunikation zwischen den Clustern verwendet wird, werden alle Host-seitigen Protokolle wie gewohnt in einer MetroCluster-Konfiguration unterstützt.</block>
  <block id="4767099b22895a8101a1cba45d8cf6e9" category="section-title">MetroCluster IP</block>
  <block id="adc397d87c1a7827f2df9fdd362d5ff7" category="paragraph">Die HA-Paar-MetroCluster IP-Konfiguration nutzt zwei oder vier Nodes pro Standort. Diese Konfigurationsoption erhöht die Komplexität und die Kosten im Vergleich zur Option mit zwei Nodes, bietet aber einen wichtigen Vorteil: intrasite-Redundanz. Bei einem einfachen Controller-Ausfall ist kein Datenzugriff über das WAN erforderlich. Der Datenzugriff bleibt über den alternativen lokalen Controller lokal.</block>
  <block id="c15560f2ae5432223c591c5f5d9db5c1" category="paragraph">Die meisten Kunden entscheiden sich für IP-Konnektivität, da die Infrastrukturanforderungen einfacher sind. In der Vergangenheit war die Bereitstellung von ultraschnellen standortübergreifenden Verbindungen über Dark Fibre und FC Switches im Allgemeinen einfacher, heute sind jedoch ultraschnelle IP-Verbindungen mit niedriger Latenz schneller verfügbar.</block>
  <block id="b28c5a429800ea9669a191a402a72b49" category="paragraph">Auch die Architektur ist einfacher, da die einzigen standortübergreifenden Verbindungen für die Controller gelten. Bei FC SAN Attached MetroCluster schreibt ein Controller direkt auf die Laufwerke am entgegengesetzten Standort und benötigt somit zusätzliche SAN-Verbindungen, Switches und Bridges. Ein Controller in einer IP-Konfiguration hingegen schreibt über den Controller auf die entgegengesetzten Laufwerke.</block>
  <block id="457b0075e8f0333975a8e2aaeaceb149" category="inline-link">Architektur und Design der MetroCluster IP-Lösung</block>
  <block id="82aa44c8aa5ebe78f1496c8fc80cb954" category="paragraph">Weitere Informationen finden Sie in der offiziellen ONTAP-Dokumentation und<block ref="03a3c76178d2d43147a2756857a0985e" category="inline-link-rx"></block>.</block>
  <block id="68cf128ce140240c63e9a47e2a82a333" category="paragraph"><block ref="68cf128ce140240c63e9a47e2a82a333" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0d2d438a72f6c558744351265fa49a62" category="section-title">HA-Paar FC SAN Attached MetroCluster</block>
  <block id="3e9133ff590581b29a911d9631ab1737" category="paragraph">Die HA-Paar-Konfiguration von MetroCluster FC nutzt zwei oder vier Nodes pro Standort. Diese Konfigurationsoption erhöht die Komplexität und die Kosten im Vergleich zur Option mit zwei Nodes, bietet aber einen wichtigen Vorteil: intrasite-Redundanz. Bei einem einfachen Controller-Ausfall ist kein Datenzugriff über das WAN erforderlich. Der Datenzugriff bleibt über den alternativen lokalen Controller lokal.</block>
  <block id="7ea740801794ba8a2ce3f87db010c319" category="paragraph"><block ref="7ea740801794ba8a2ce3f87db010c319" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4bc2926f030255369db3e4435de5c774" category="paragraph">Einige Infrastrukturen mehrerer Standorte sind nicht für den aktiv/aktiv-Betrieb konzipiert, sondern werden eher als primärer Standort und Disaster-Recovery-Standort genutzt. In dieser Situation ist eine MetroCluster-Option für HA-Paare aus den folgenden Gründen im Allgemeinen vorzuziehen:</block>
  <block id="5f49f48dd22b405a813e2ef7cc02e9f8" category="list-text">Obwohl es sich bei einem MetroCluster Cluster mit zwei Nodes um ein HA-System handelt, müssen für einen unerwarteten Ausfall eines Controllers oder einer geplanten Wartung die Datenservices am anderen Standort online geschaltet werden. Wenn die Netzwerkverbindung zwischen Standorten die erforderliche Bandbreite nicht unterstützen kann, ist die Performance beeinträchtigt. Die einzige Option wäre auch ein Failover der verschiedenen Host-Betriebssysteme und der damit verbundenen Services zum alternativen Standort. Das HA-Paar MetroCluster Cluster eliminiert dieses Problem, da der Verlust eines Controllers zu einfachem Failover innerhalb desselben Standorts führt.</block>
  <block id="0ce798a4f2e77d6aa1a6e0d718fa8e98" category="list-text">Einige Netzwerktopologien sind nicht für den standortübergreifenden Zugriff ausgelegt, sondern verwenden stattdessen unterschiedliche Subnetze oder isolierte FC-SANs. In diesen Fällen fungiert der MetroCluster Cluster mit zwei Nodes nicht mehr als HA-System, da der alternative Controller keine Daten für die Server am gegenüberliegenden Standort bereitstellen kann. Um vollständige Redundanz zu gewährleisten, ist die MetroCluster Option für das HA-Paar erforderlich.</block>
  <block id="098fa44ef37572e0f8ea717199ac72e6" category="list-text">Wird eine Infrastruktur mit zwei Standorten als eine einzelne hochverfügbare Infrastruktur angesehen, eignet sich die MetroCluster Konfiguration mit zwei Nodes. Falls das System jedoch nach einem Standortausfall über einen längeren Zeitraum hinweg funktionieren muss, ist ein HA-Paar vorzuziehen, da es weiterhin HA innerhalb eines einzelnen Standorts bereitstellen muss.</block>
  <block id="ea8bb3e5a357ca97851352f6944342c9" category="section-title">FC SAN-Attached MetroCluster mit zwei Nodes</block>
  <block id="b759079fef92c80eca80e7349bf84363" category="paragraph">Die MetroCluster Konfiguration mit zwei Nodes verwendet nur einen Node pro Standort. Dieses Design ist einfacher als die Option für HA-Paare, da weniger Komponenten konfiguriert und gewartet werden müssen. Zudem wurden die Infrastrukturanforderungen hinsichtlich Verkabelung und FC-Switching gesenkt. Und schließlich senkt es die Kosten.</block>
  <block id="5bfcbf762ac959212294cdf71bbec2b5" category="paragraph"><block ref="5bfcbf762ac959212294cdf71bbec2b5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bcf549481eb36a62594e938bca6a10bb" category="paragraph">Ein solches Design hat ganz offensichtlich zur Folge, dass der Controller-Ausfall an einem einzigen Standort dazu führt, dass die Daten am entgegengesetzten Standort verfügbar sind. Diese Einschränkung ist nicht unbedingt ein Problem. Viele Unternehmen verfügen über standortübergreifende Datacenter-Betriebsabläufe mit verteilten, schnellen Netzwerken mit niedriger Latenz, die im Wesentlichen als eine einzige Infrastruktur fungieren. In diesen Fällen ist die MetroCluster Version mit zwei Nodes die bevorzugte Konfiguration. Systeme mit zwei Nodes werden derzeit im Petabyte-Bereich von mehreren Service-Providern eingesetzt.</block>
  <block id="78558542e724655ba80fc4879399f103" category="section-title">Funktionen zur Ausfallsicherheit von MetroCluster</block>
  <block id="5427d2eb91f25a425f13544e56fb12c4" category="paragraph">Es gibt keine Single Points of Failure in einer MetroCluster Lösung:</block>
  <block id="6a988bf07e73bcbf69f62ce9724dd0f3" category="list-text">Jeder Controller verfügt über zwei unabhängige Pfade zu den Laufwerk-Shelfs am lokalen Standort.</block>
  <block id="2c98a75e02c6e103b43724f02e99e393" category="list-text">Jeder Controller verfügt über zwei unabhängige Pfade zu den Laufwerk-Shelfs am Remote-Standort.</block>
  <block id="e18f703538cd1f5af3b9185eed57b49b" category="list-text">Jeder Controller verfügt über zwei unabhängige Pfade zu den Controllern am gegenüberliegenden Standort.</block>
  <block id="800ec0ea85a62c2fb192ac2f79ee1d02" category="list-text">In der HA-Paar-Konfiguration besitzt jeder Controller zwei Pfade zu seinem lokalen Partner.</block>
  <block id="a3d7a569ad6ea771a0ad9b995619251b" category="paragraph">Zusammenfassend lässt sich sagen, dass jede Komponente der Konfiguration entfernt werden kann, ohne dass die Fähigkeit von MetroCluster zur Datenbereitstellung beeinträchtigt wird. Der einzige Unterschied in Bezug auf die Ausfallsicherheit zwischen den beiden Optionen ist, dass die HA-Paar-Version nach einem Standortausfall weiterhin ein insgesamt HA-Storage-System ist.</block>
  <block id="9b4c3976d453e66a3dd22e2793fc3a8e" category="doc">Speicherplatzmanagement</block>
  <block id="e89d3732a2fbc592923c30e54522dcdb" category="paragraph">Thin Provisioning ist in vielerlei Form verfügbar und integraler Bestandteil zahlreicher Funktionen von ONTAP für Enterprise-Applikationsumgebungen. Aus diesem Grund steht Thin Provisioning auch eng mit Effizienztechnologien im Zusammenhang: Mithilfe von Effizienzfunktionen können mehr logische Daten gespeichert werden, als dies technisch auf dem Storage-System möglich ist.</block>
  <block id="537642ed3bfef7f2bb3e580b3b266bd3" category="paragraph">Fast jede Verwendung von Snapshots beinhaltet Thin Provisioning. Zum Beispiel umfasst eine typische 10-TB-Datenbank auf NetApp Storage etwa 30 Tage Snapshots. Diese Anordnung führt dazu, dass ca. 10 TB Daten im aktiven File-System sichtbar sind und 300 TB für Snapshots dediziert. Die insgesamt 310 TB Storage-Kapazität befindet sich in der Regel auf einem Speicherplatz von 12 TB bis 15 TB. Die aktive Datenbank benötigt 10 TB Storage. Die verbleibenden 300 TB an Daten benötigen nur 2 TB bis 5 TB Speicherplatz, da nur die Änderungen an den Originaldaten gespeichert werden.</block>
  <block id="a19609016ad1cb6b7bae7cac796a26a4" category="paragraph">Das Klonen ist ebenfalls ein Beispiel für Thin Provisioning. Ein großer NetApp Kunde hat 40 Klone einer 80-TB-Datenbank für die Entwicklung erstellt. Wenn alle 40 Entwickler, die diese Klone verwenden, jeden Block in jeder Datendatei übergeschrieben haben, wäre mehr als 3,2 PB Storage erforderlich. In der Praxis sind Umsätze gering und der kollektive Platzbedarf liegt bei näher bei 40 TB, da nur Änderungen auf den Laufwerken gespeichert werden.</block>
  <block id="2433af6347e4871be5af0f2af0f6bd6e" category="paragraph">Bei Thin Provisioning in einer Applikationsumgebung ist Vorsicht geboten, da sich die Datenänderungsraten unerwartet erhöhen können. Beispielsweise kann der Speicherplatzverbrauch aufgrund von Snapshots schnell ansteigen, wenn Datenbanktabellen neu indiziert werden, oder es werden umfangreiche Patches für VMware Gäste angewendet. Ein falsch platziertes Backup kann in sehr kurzer Zeit große Datenmengen schreiben. Schließlich kann es schwierig sein, einige Anwendungen wiederherzustellen, wenn ein Dateisystem unerwartet über den freien Speicherplatz verfügt.</block>
  <block id="5cf4dc4d1ce52ff655ea7f1157a72e2e" category="paragraph">Glücklicherweise können diese Risiken mit einer sorgfältigen Konfiguration von behoben werden<block ref="f9e1f2ea1a2becbaf82dd54e55a12e6b" prefix=" " category="inline-code"></block> Und<block ref="24d554277b3513bb6cef3f0a336725a9" prefix=" " category="inline-code"></block> Richtlinien. Mit diesen Optionen kann ein Benutzer Richtlinien erstellen, die automatisch den von Snapshots belegten Speicherplatz freigeben oder ein Volume erweitern, um zusätzliche Daten aufzunehmen. Es stehen zahlreiche Optionen zur Verfügung, und die Anforderungen variieren je nach Kunde.</block>
  <block id="6a28738961e6f6e4b57e4dd70c446600" category="inline-link-macro">Dokumentation des Managements von logischem Storage</block>
  <block id="01570cb5a3aec2324ab56e318e1de04d" category="paragraph">Siehe <block ref="e69bd75bdb49183ee90588843edb33f4" category="inline-link-macro-rx"></block> Für eine vollständige Diskussion dieser Funktionen.</block>
  <block id="8cf44a7a390ab582c5010ba430143d4b" category="section-title">LUN Thin Provisioning</block>
  <block id="ba0bdf51bc57bacdd6f3f0bd26b7674c" category="paragraph">Die Effizienz des Thin Provisioning von aktiven LUNs in einer Filesystem-Umgebung kann nach und nach verloren gehen, wenn Daten gelöscht werden. Sofern die gelöschten Daten entweder mit Nullen überschrieben werden oder der Speicherplatz mit TRIM/UNMAP-Rückgewinnung freigegeben wird, belegen die „gelöschten“ Daten immer mehr nicht zugewiesene Leerzeichen im Dateisystem. Darüber hinaus kommt Thin Provisioning für aktive LUNs in vielen Datenbankumgebungen nur eingeschränkt zum Einsatz, da Datendateien zum Zeitpunkt der Erstellung auf ihre volle Größe initialisiert werden.</block>
  <block id="e10d46632bc86306cf4c22633ee930ab" category="paragraph">Eine sorgfältige Planung der LVM-Konfiguration kann die Effizienz steigern und den Bedarf an Storage-Bereitstellung und LUN-Anpassung minimieren. Wenn eine LVM wie Veritas VxVM oder Oracle ASM verwendet wird, werden die zugrunde liegenden LUNs in Extents unterteilt, die nur bei Bedarf verwendet werden. Wenn beispielsweise ein Datensatz bei einer Größe von 2 TB beginnt, jedoch im Laufe der Zeit bis auf 10 TB anwachsen könnte, könnte dieser Datensatz auf 10 TB an LUNs platziert werden, die über Thin Provisioning in einer LVM-Festplattengruppe organisiert sind. Zum Zeitpunkt der Erstellung würden nur 2 TB Speicherplatz belegt und zusätzlichen Speicherplatz beanspruchen, wenn Extents zugewiesen werden, um dem Datenwachstum gerecht zu werden. Dieser Prozess ist sicher, solange der Speicherplatz überwacht wird.</block>
  <block id="66a41fd6fc38c454973e91d92cf0e291" category="section-title">Fraktionale Reservierungen</block>
  <block id="e8a206fe65814e0ea465e32487544751" category="paragraph">Die fraktionale Reserve bezieht sich auf das Verhalten einer LUN in einem Volume in Bezug auf die Platzeffizienz. Wenn die Option<block ref="c1acac5c4332e37ec1f281fcbaf0765a" prefix=" " category="inline-code"></block> Ist auf 100 % festgelegt, können alle Daten im Volume mit jedem Datenmuster 100 % Umsatz verzeichnen, ohne Speicherplatz auf dem Volume zu belegen.</block>
  <block id="a3cd28aef7d0becd57b60187fdc4a24e" category="paragraph">Betrachten Sie beispielsweise eine Datenbank auf einer einzigen 250 GB LUN und einem Volume mit 1 TB. Wenn ein Snapshot erstellt wird, würde sofort eine zusätzliche 250GB an Speicherplatz auf dem Volume reserviert werden, um zu garantieren, dass auf dem Volume aus irgendeinem Grund nicht mehr genügend Speicherplatz verfügbar ist. Die Verwendung von fraktionalen Reserven ist im Allgemeinen aufwändig, da es äußerst unwahrscheinlich ist, dass jedes Byte im Datenbank-Volume überschrieben werden müsste. Es gibt keinen Grund, Platz für ein Ereignis zu reservieren, das nie passiert. Wenn ein Kunde jedoch den Speicherplatzverbrauch in einem Storage-System nicht überwachen kann und sicher sein muss, dass der Platz nie knapp wird, wären für die Nutzung von Snapshots 100 % fraktionale Reservierungen erforderlich.</block>
  <block id="e30fbe8981929fb070a820a213381bab" category="section-title">Komprimierung und Deduplizierung</block>
  <block id="1b6e4e9a2be031edc6f3da1f559ef884" category="paragraph">Komprimierung und Deduplizierung sind beide Formen von Thin Provisioning. Beispielsweise kann ein 50 TB Platzbedarf für Daten auf 30 TB komprimiert werden, was zu Einsparungen von 20 TB führt. Um die Komprimierung nutzen zu können, müssen einige dieser 20 TB für andere Daten verwendet werden. Alternativ muss das Storage-System mit weniger als 50 TB erworben werden. Das Ergebnis sind Speicherung von mehr Daten als technisch auf dem Speichersystem verfügbar ist. Aus Sicht der Daten gibt es 50 TB an Daten, obwohl diese auf den Laufwerken nur 30 TB belegen.</block>
  <block id="dbca4bb791f36eac2c11c32f73f2b4ec" category="paragraph">Es besteht immer die Möglichkeit, dass sich die Komprimierbarkeit eines Datensatzes ändert. Dies würde zu einem erhöhten Verbrauch an echtem Speicherplatz führen. Dieser Anstieg des Verbrauchs bedeutet, dass die Komprimierung wie bei anderen Thin Provisioning-Methoden zur Überwachung und Nutzung gemanagt werden muss<block ref="f9e1f2ea1a2becbaf82dd54e55a12e6b" prefix=" " category="inline-code"></block> Und<block ref="24d554277b3513bb6cef3f0a336725a9" prefix=" " category="inline-code"></block>.</block>
  <block id="ad241666a88b5414e8c2fe6d1cc1edb0" category="paragraph">Die Komprimierung und Deduplizierung werden im Abschnitt Link:efficiency.html ausführlicher behandelt</block>
  <block id="8ecfcadfebb472a089481e8554ebed87" category="section-title">Komprimierung und fraktionale Reservierungen</block>
  <block id="4f8fcc146d2e8e712dcd8c56b1684fcc" category="paragraph">Komprimierung ist eine Form von Thin Provisioning. Fraktionale Reservierungen beeinflussen die Komprimierung. Ein wichtiger Hinweis: Vor der Snapshot-Erstellung wird Speicherplatz reserviert. Normalerweise ist eine fraktionale Reserve nur wichtig, wenn ein Snapshot vorhanden ist. Wenn es keinen Snapshot gibt, ist die fraktionale Reserve nicht wichtig. Dies ist bei der Komprimierung nicht der Fall. Wenn eine LUN auf einem Volume mit Komprimierung erstellt wird, behält ONTAP den Speicherplatz bei, um einen Snapshot aufzunehmen. Dieses Verhalten kann während der Konfiguration verwirrend sein, aber es wird erwartet.</block>
  <block id="e26f8048b4bf60dad827c5a425271361" category="paragraph">Als Beispiel betrachten Sie ein 10GB Volume mit einer 5GB LUN, die bis auf 2,5 GB ohne Snapshots komprimiert wurde. Betrachten wir die beiden folgenden Szenarien:</block>
  <block id="ade18971a2dab7e37335e95d81da0ef1" category="list-text">Die fraktionale Reserve = 100 ergibt eine Auslastung von 7,5 GB</block>
  <block id="1d07b8e7c92488a55301ea201328cf35" category="list-text">Die fraktionale Reserve = 0 ergibt eine Auslastung von 2,5 GB</block>
  <block id="aa410d0e46ec94b6efcf344f0d870c1a" category="paragraph">Das erste Szenario umfasst 2,5 GB Speicherplatzverbrauch für aktuelle Daten und 5 GB Speicherplatz, um 100 % des Umsatzes der Quelle in Erwartung der Snapshot-Nutzung zu berücksichtigen. Das zweite Szenario reserviert keinen zusätzlichen Speicherplatz.</block>
  <block id="e79414ad391b126cc9bd53af1624c8de" category="paragraph">Obwohl diese Situation verwirrend erscheinen mag, ist es unwahrscheinlich, dass sie in der Praxis angetroffen wird. Komprimierung impliziert Thin Provisioning, und Thin Provisioning in einer LUN-Umgebung erfordert nur fraktionale Reservierungen. Es ist immer möglich, dass komprimierte Daten durch eine nicht komprimierbare Funktion überschrieben werden. Aus diesem Grund muss ein Volume für die Komprimierung bereitgestellt werden, um mögliche Einsparungen zu erzielen.</block>
  <block id="499a10b92cb9ca6b3412d4bf5a91a2b0" category="paragraph">*NetApp empfiehlt* die folgenden Reservekonfigurationen:</block>
  <block id="7f26e875cee50c1b3baf71a014043794" category="list-text">Einstellen<block ref="c1acac5c4332e37ec1f281fcbaf0765a" prefix=" " category="inline-code"></block> Auf 0, wenn die grundlegende Kapazitätsüberwachung zusammen mit eingerichtet ist<block ref="f9e1f2ea1a2becbaf82dd54e55a12e6b" prefix=" " category="inline-code"></block> Und<block ref="24d554277b3513bb6cef3f0a336725a9" prefix=" " category="inline-code"></block>.</block>
  <block id="675996bd34ec0d8c134215f5be73fb3a" category="list-text">Einstellen<block ref="c1acac5c4332e37ec1f281fcbaf0765a" prefix=" " category="inline-code"></block> Zu 100, wenn es keine Überwachungsfähigkeit gibt oder wenn es unmöglich ist, unter keinen Umständen Raum abzulassen.</block>
  <block id="8ee38535add58992c14b23a6f7cf8d27" category="doc">LIF-Typen</block>
  <block id="50d034374ef68094a0f6c8e8d06a77af" category="inline-link-macro">Dokumentation zum ONTAP-Netzwerkmanagement</block>
  <block id="fc25025f3f0a2afd42465a55f35c02d0" category="paragraph">Dieser Abschnitt bietet einen Überblick über die wichtigsten LIF-Designprinzipien. Eine ausführlichere Dokumentation finden Sie im <block ref="a3e6361e1a52d384f542a2f2d8bc9bb1" category="inline-link-macro-rx"></block>. Wie andere Aspekte der Datenbankarchitektur hängen die besten Optionen für die Storage Virtual Machine (SVM, in der CLI als vServer bezeichnet) und das Design der logischen Schnittstelle (LIF) stark von den Skalierungsanforderungen und den geschäftlichen Anforderungen ab.</block>
  <block id="be0801f7fb241be642bec73b799d45cb" category="paragraph">Berücksichtigen Sie bei der Entwicklung einer LIF-Strategie die folgenden primären Themen:</block>
  <block id="362c2978dddcf6988ce266d3d60f5beb" category="list-text">*Leistung.* ist die Netzwerkbandbreite ausreichend?</block>
  <block id="cfc88efb72b2c7ea83a4a3d68b760d55" category="list-text">*Ausfallsicherheit.* gibt es Single Points of Failure im Design?</block>
  <block id="af02972fd4dc1e949d800731d9518812" category="list-text">*Verwaltbarkeit.* kann das Netzwerk unterbrechungsfrei skaliert werden?</block>
  <block id="fdcbadc80d2dd31527cc91cf81fb725d" category="paragraph">Diese Themen beziehen sich auf die End-to-End-Lösung, vom Host über die Switches bis zum Speichersystem.</block>
  <block id="f45fe079103703d0b315ff2e339728fd" category="inline-link-macro">ONTAP-Dokumentation zu LIF-Typen</block>
  <block id="cc4583278db25277db9ddcd781cbf992" category="paragraph">Es gibt mehrere LIF-Typen. <block ref="9d27879d9d2bd4f0f081ffed63159522" category="inline-link-macro-rx"></block> Stellen Sie umfassendere Informationen zu diesem Thema bereit, LIFs können jedoch aus funktionaler Sicht in die folgenden Gruppen unterteilt werden:</block>
  <block id="f34a52d788c5a4cf56d7ae8ccb85f8c2" category="list-text">*Cluster- und Node-Management-LIFs.* LIFs, die zum Verwalten des Storage-Clusters verwendet werden.</block>
  <block id="73ac4e00a9ff3caf31e6df13a6df2f78" category="list-text">*SVM-Management-LIFs.* Schnittstellen, die den Zugriff auf eine SVM über die REST-API oder ONTAPI (auch bekannt als ZAPI) für Funktionen wie Snapshot-Erstellung oder Volume-Anpassung erlauben. Produkte wie SnapManager für Oracle (SMO) müssen Zugriff auf eine SVM-Management-LIF haben.</block>
  <block id="b7010e46f4769f638197aa230f448ba0" category="list-text">*Daten-LIFs.* Schnittstellen für FC, iSCSI, NVMe/FC, NVMe/TCP, NFS, oder SMB/CIFS-Daten.</block>
  <block id="1eb4f53fa8ee8f0954514a1b9858bf6b" category="admonition">Eine logische Datenschnittstelle für NFS-Datenverkehr kann durch Änderung der Firewallrichtlinie von auch zum Management verwendet werden<block ref="8d777f385d3dfec8815d20f7496026dc" prefix=" " category="inline-code"></block> Bis<block ref="d724f231a9a7b89757c4394d6622bc47" prefix=" " category="inline-code"></block> Oder eine andere Richtlinie, die HTTP, HTTPS oder SSH erlaubt. Diese Änderung kann die Netzwerkkonfiguration vereinfachen, indem die Konfiguration jedes Hosts für den Zugriff auf die LIF der NFS-Daten und eine separate Management-LIF vermieden wird. Es ist nicht möglich, eine Schnittstelle für iSCSI- und Managementverkehr zu konfigurieren, obwohl beide ein IP-Protokoll verwenden. In iSCSI-Umgebungen ist eine separate Management-LIF erforderlich.</block>
  <block id="85d465743ad38be108b50648ab283d78" category="section-title">Design von SAN LIF</block>
  <block id="8800a54085e1b2987d83537423221cf9" category="paragraph">Das LIF-Design in einer SAN-Umgebung ist aus einem Grund relativ einfach: Multipathing. Alle modernen SAN-Implementierungen ermöglichen es einem Client, über mehrere unabhängige Netzwerkpfade auf Daten zuzugreifen und den optimalen Pfad oder die besten Pfade für den Zugriff auszuwählen. So lässt sich die Performance in Bezug auf LIF-Design einfacher bewältigen, da SAN-Clients automatisch den I/O-Lastausgleich über die besten verfügbaren Pfade durchführen.</block>
  <block id="e33c923a4d6280bf6f2b2a982ff74ee3" category="paragraph">Wenn ein Pfad nicht mehr verfügbar ist, wählt der Client automatisch einen anderen Pfad aus. Das daraus resultierende einfache Design macht SAN LIFs im Allgemeinen einfacher zu managen. Das bedeutet nicht, dass eine SAN-Umgebung immer einfacher zu managen ist, da viele andere Aspekte des SAN-Storage viel komplizierter sind als NFS. Es bedeutet schlichtweg, dass das LIF-Design von SAN einfacher ist.</block>
  <block id="9446a98ad14416153cc4d45ab8b531bf" category="section-title">Leistung</block>
  <block id="141614e246b14131ec01a449d61ed657" category="paragraph">Der wichtigste Aspekt bei der LIF-Performance in einer SAN-Umgebung ist die Bandbreite. In einem ONTAP AFF-Cluster mit zwei Nodes mit zwei 16-GB-FC-Ports pro Node können beispielsweise bis zu 32 GB Bandbreite von jedem Node bereitgestellt werden.</block>
  <block id="02bc0523497de72834c4c7990e32d155" category="section-title">Ausfallsicherheit</block>
  <block id="01b1d8276ca14813ff4804089a9ac082" category="paragraph">SAN LIFs führen keinen Failover auf einem AFF Storage-System durch. Wenn eine SAN-LIF aufgrund eines Controller-Failovers ausfällt, erkennt die Multipathing-Software des Clients den Verlust eines Pfads und leitet den I/O an eine andere LIF um. Bei ASA Storage-Systemen wird für LIFs nach kurzer Verzögerung ein Failover durchgeführt. Die I/O wird jedoch nicht unterbrochen, da auf dem anderen Controller bereits aktive Pfade vorhanden sind. Der Failover-Prozess erfolgt, um den Hostzugriff auf allen definierten Ports wiederherzustellen.</block>
  <block id="b7c94ef25c0629a65f8a1f6ce7014d95" category="section-title">Managebarkeit</block>
  <block id="1325935a6fa0e88cfec45038005f18e3" category="paragraph">Die LIF-Migration ist in einer NFS-Umgebung viel üblicher, da die LIF-Migration häufig mit dem Verschieben von Volumes innerhalb des Clusters verknüpft ist. Wenn Volumes innerhalb des HA-Paars verschoben werden, ist keine Migration einer LIF in eine SAN-Umgebung erforderlich. Der Grund dafür ist, dass ONTAP nach Abschluss der Volume-Verschiebung eine Benachrichtigung über eine Pfadänderung an das SAN sendet, die die SAN-Clients automatisch neu optimieren. Die LIF-Migration mit SAN steht in erster Linie in Verbindung mit größeren Änderungen an physischer Hardware. Wenn beispielsweise ein unterbrechungsfreies Upgrade der Controller erforderlich ist, wird eine SAN LIF auf die neue Hardware migriert. Wenn ein FC-Port defekt ist, kann eine LIF zu einem nicht verwendeten Port migriert werden.</block>
  <block id="dbb887b1373e51dab774976c5a556964" category="section-title">Designempfehlungen</block>
  <block id="076872b2444637e6142c3c6f0f157423" category="paragraph">NetApp gibt die folgenden Empfehlungen:</block>
  <block id="d8d6bca7c981c13479781da85883cfef" category="list-text">Erstellen Sie nicht mehr Pfade, als erforderlich sind. Eine übermäßige Anzahl von Pfaden erschwert das gesamte Management und kann zu Problemen mit dem Pfad-Failover auf einigen Hosts führen. Darüber hinaus weisen einige Hosts unerwartete Pfadeinschränkungen für Konfigurationen wie das Booten von SAN auf.</block>
  <block id="bd662d86fcca370cddf188ff5378fb1b" category="list-text">Nur sehr wenige Konfigurationen sollten mehr als vier Pfade zu einem LUN erfordern. Der Wert von mehr als zwei Nodes, um LUNs bekannt zu machen, ist beschränkt, da das Aggregat, das eine LUN hostet, nicht zugänglich ist, wenn der Node, der Eigentümer der LUN und dessen HA-Partner ausfällt. In solch einem Szenario ist es nicht hilfreich, Pfade auf anderen Nodes als dem primären HA-Paar zu erstellen.</block>
  <block id="8873f044ab7c082f16372e4b8bdc6e03" category="list-text">Obwohl die Anzahl der sichtbaren LUN-Pfade durch Auswählen der in FC-Zonen enthaltenen Ports gemanagt werden kann, ist es im Allgemeinen einfacher, alle potenziellen Zielpunkte in die FC-Zone aufzunehmen und die LUN-Sichtbarkeit auf ONTAP-Ebene zu kontrollieren.</block>
  <block id="0ebc6267761306c4daefb9871a470e4b" category="list-text">In ONTAP 8.3 und höher ist die Funktion für die selektive LUN-Zuordnung (SLM) die Standardeinstellung. Bei SLM wird jede neue LUN automatisch von dem Node bereitgestellt, dem das zugrunde liegende Aggregat und der HA-Partner des Node gehören. Durch diese Anordnung müssen keine Portsätze erstellt oder Zoning konfiguriert werden, um den Zugriff auf den Port zu beschränken. Jede LUN ist mit der Mindestanzahl der Nodes verfügbar, die für eine optimale Performance und Stabilität erforderlich sind.
*Falls eine LUN außerhalb der beiden Controller migriert werden muss, können die zusätzlichen Knoten mit dem hinzugefügt werden<block ref="02d0bbdc14988c85bbd7994723f4dd7f" prefix=" " category="inline-code"></block> Befehl, sodass die LUNs auf den neuen Nodes angekündigt werden. Dadurch werden zusätzliche SAN-Pfade zu den LUNs für die LUN-Migration erstellt. Der Host muss jedoch einen Erkennungsvorgang durchführen, um die neuen Pfade verwenden zu können.</block>
  <block id="cc4b24f288afae5889c6061466dda472" category="list-text">Seien Sie nicht übermäßig besorgt über indirekten Verkehr. Es empfiehlt sich, in einer sehr I/O-intensiven Umgebung, in der jede Mikrosekunde von großer Latenz ist, indirekten Verkehr zu vermeiden, aber der sichtbare Performance-Effekt ist bei typischen Workloads zu vernachlässigen.</block>
  <block id="f54fccb82abaa995eb9f86264f431505" category="section-title">LIF-Design von NFS</block>
  <block id="e68dee93f11ae71aebd7a1e4c2abfc5a" category="paragraph">Im Gegensatz zu SAN-Protokollen kann bei NFS nur bedingt mehrere Pfade zu Daten definiert werden. Die parallelen NFS-Erweiterungen (pNFS) zu NFSv4 beheben diese Einschränkung. Da die ethernet-Geschwindigkeit jedoch 100 GB erreicht hat, ist das Hinzufügen weiterer Pfade selten ein Nutzen.</block>
  <block id="391dc675ec3d853200129b799ed5923e" category="section-title">Performance und Ausfallsicherheit</block>
  <block id="a0bd34f908e3947aa4aba15382354836" category="paragraph">Obwohl die Messung der LIF-Performance in erster Linie dazu dient, die gesamte Bandbreite von allen primären Pfaden zu berechnen, muss die Bestimmung der Performance von NFS LIF genau die Netzwerkkonfiguration durchgeführt werden. Beispielsweise können zwei 10-Gbit-Ports als physische Rohports konfiguriert oder als LACP-Interface-Gruppe (Link Aggregation Control Protocol) konfiguriert werden. Wenn sie als Schnittstellengruppe konfiguriert sind, stehen mehrere Load-Balancing-Richtlinien zur Verfügung, die je nachdem, ob der Datenverkehr geswitcht oder geroutet wird, unterschiedlich funktionieren. Oracle Direct NFS (dNFS) bietet Load-Balancing-Konfigurationen, die derzeit in keinen NFS-Clients des Betriebssystems vorhanden sind.</block>
  <block id="e500ca27c6b92454c989d80e0445c359" category="paragraph">Im Gegensatz zu SAN-Protokollen erfordern NFS-Filesysteme Ausfallsicherheit auf Protokollebene. Beispielsweise wird eine LUN immer mit aktiviertem Multipathing konfiguriert, was bedeutet, dass dem Storage-System mehrere redundante Kanäle zur Verfügung stehen, von denen jeder das FC-Protokoll verwendet. Ein NFS-Dateisystem hingegen hängt von der Verfügbarkeit eines einzelnen TCP/IP-Kanals ab, der nur auf der physischen Ebene geschützt werden kann. Diese Anordnung ist, warum Optionen wie Port-Failover und LACP Port-Aggregation existieren.</block>
  <block id="35926e2ada969ad80fd3b16c0cd7d35a" category="paragraph">In einer NFS-Umgebung werden sowohl Performance als auch Ausfallsicherheit auf der Netzwerkprotokollebene bereitgestellt. Dadurch sind beide Themen miteinander verflochten und müssen gemeinsam diskutiert werden.</block>
  <block id="84f4a5dfaa9613a469cd783c353a186c" category="section-title">Binden Sie LIFs an Portgruppen</block>
  <block id="44bfb87c11d83c1b91c3589f2081e7ca" category="paragraph">Um ein LIF an eine Portgruppe zu binden, ordnen Sie die LIF-IP-Adresse einer Gruppe physischer Ports zu. Die primäre Methode zur Aggregation physischer Ports ist LACP. Die Fehlertoleranz-Funktion von LACP ist ziemlich einfach. Jeder Port in einer LACP-Gruppe wird überwacht und im Falle einer Störung aus der Portgruppe entfernt. Es gibt jedoch viele Missverständnisse darüber, wie LACP in Bezug auf Performance funktioniert:</block>
  <block id="19a43026949fb6ef1017a54cf7c94f9b" category="list-text">Für LACP ist keine Konfiguration auf dem Switch erforderlich, um mit dem Endpunkt übereinstimmen zu können. Beispielsweise kann ONTAP mit IP-basiertem Lastausgleich konfiguriert werden, während ein Switch MAC-basierten Lastausgleich verwenden kann.</block>
  <block id="86501252b34395de5303a65f5e9943e3" category="list-text">Jeder Endpunkt, der eine LACP-Verbindung verwendet, kann den Port für die Paketübertragung unabhängig auswählen, jedoch nicht den für den Empfang verwendeten Port auswählen. Das bedeutet, dass Datenverkehr von ONTAP zu einem bestimmten Ziel an einen bestimmten Port gebunden ist, und der Rückverkehr könnte auf einer anderen Schnittstelle eintreffen. Dies verursacht jedoch keine Probleme.</block>
  <block id="298ca40b99dd3540dcd82ba5537f3f8d" category="list-text">LACP verteilt den Datenverkehr nicht ständig gleichmäßig. In einer großen Umgebung mit vielen NFS-Clients wird normalerweise sogar alle Ports in einer LACP-Aggregation genutzt. Jedoch ist jedes ein NFS-Dateisystem in der Umgebung auf die Bandbreite von nur einem Port beschränkt, nicht die gesamte Aggregation.</block>
  <block id="d071b5ccd1569aace97a0b4d6c0a71ac" category="list-text">Obwohl LACP-Richtlinien für die Robin-Lösung auf ONTAP verfügbar sind, adressieren diese Richtlinien nicht die Verbindung von einem Switch zu einem Host. Beispielsweise ist eine Konfiguration mit einem LACP Trunk mit vier Ports auf einem Host und einem LACP Trunk mit vier Ports auf einem ONTAP immer noch nur in der Lage, ein Filesystem über einen einzelnen Port zu lesen. Obwohl ONTAP Daten über alle vier Ports übertragen kann, sind derzeit keine Switch-Technologien verfügbar, die über alle vier Ports vom Switch an den Host gesendet werden. Es wird nur eine verwendet.</block>
  <block id="6e9e98dfaea1ca7860606f1fc05e414a" category="paragraph">In größeren Umgebungen, die aus vielen Datenbank-Hosts bestehen, ist der geläufigste Ansatz, mithilfe eines IP-Lastausgleichs ein LACP Aggregat mit einer entsprechenden Anzahl von 10 GB (oder schneller) Schnittstellen zu erstellen. Mit diesem Ansatz kann ONTAP sogar die Nutzung aller Ports ermöglichen, sofern genügend Clients vorhanden sind. Der Lastausgleich wird unterbrochen, wenn weniger Clients in der Konfiguration vorhanden sind, da LACP Trunking die Last nicht dynamisch neu verteilt.</block>
  <block id="7815da600ab459d2b05c5792f2271c1a" category="paragraph">Wenn eine Verbindung hergestellt wird, wird der Datenverkehr in eine bestimmte Richtung nur an einem Port platziert. Beispielsweise liest eine Datenbank, die einen vollständigen Tabellenscan gegen ein NFS-Dateisystem durchführt, das über einen LACP-Trunk mit vier Ports verbunden ist, Daten über nur eine Netzwerkkarte (NIC). Wenn sich nur drei Datenbankserver in einer solchen Umgebung befinden, ist es möglich, dass alle drei vom gleichen Port lesen, während die anderen drei Ports inaktiv sind.</block>
  <block id="153f704ea16440133d51b1877af2a657" category="section-title">Binden Sie LIFs an physische Ports</block>
  <block id="70e655aa3c03f840747c5272142b3527" category="paragraph">Das Binden einer LIF an einen physischen Port führt zu einer granulareren Kontrolle der Netzwerkkonfiguration, da eine gegebene IP-Adresse auf einem ONTAP-System jeweils nur mit einem Netzwerk-Port verknüpft ist. Stabilität wird dann durch die Konfiguration von Failover-Gruppen und Failover-Richtlinien erreicht.</block>
  <block id="218f00463f5281b8ead536582c69ac3a" category="section-title">Failover-Richtlinien und Failover-Gruppen</block>
  <block id="0a53c26a1bc4036c84fc3b4b63542744" category="inline-link-macro">ONTAP Netzwerkmanagement-Dokumentation für Failover-Gruppen und Richtlinien</block>
  <block id="f29ae31443947c9782482ee9683dbc0e" category="paragraph">Das Verhalten von LIFs wird während der Netzwerkunterbrechung durch Failover-Richtlinien und Failover-Gruppen gesteuert. Die Konfigurationsoptionen wurden mit den verschiedenen Versionen von ONTAP geändert. Konsultieren Sie die <block ref="96c8cd47b667604fb9991ace7d2eff29" category="inline-link-macro-rx"></block> Finden Sie spezifische Details zur implementierten Version von ONTAP.</block>
  <block id="0f2f345dd1247ae428cee703c1bf1c84" category="paragraph">ONTAP 8.3 und höher ermöglichen das Management von LIF-Failovers basierend auf Broadcast-Domänen. Daher kann ein Administrator alle Ports definieren, die Zugriff auf ein bestimmtes Subnetz haben, und ONTAP erlauben, eine entsprechende Failover-LIF auszuwählen. Einige Kunden verwenden diesen Ansatz durchaus, weist jedoch aufgrund der mangelnden Planbarkeit in einer Storage-Netzwerkumgebung mit hoher Geschwindigkeit Einschränkungen auf. Beispielsweise kann eine Umgebung sowohl 1-Gbit-Ports für routinemäßigen Filesystem-Zugriff als auch 10-Gbit-Ports für Datendatei-I/O. Wenn beide Ports in derselben Broadcast-Domäne vorhanden sind, kann ein LIF-Failover dazu führen, Datendatei-I/O von einem 10-GB-Port auf einen 1-GB-Port zu verschieben.</block>
  <block id="ced0729d57c08312b2b12382f2147d26" category="paragraph">Zusammenfassend lassen sich die folgenden Vorgehensweisen berücksichtigen:</block>
  <block id="57cb6a7ba8acb7faa31cc5219bae83b3" category="list-text">Konfigurieren Sie eine Failover-Gruppe als benutzerdefiniert.</block>
  <block id="b444855eccae552d7fb79bf3d31a4f7b" category="list-text">Füllen Sie die Failover-Gruppe mit Ports am Partner-Controller für Storage Failover (SFO), damit die LIFs beim Storage Failover den Aggregaten folgen. Dadurch wird die Erstellung indirekter Verkehrsströme vermieden.</block>
  <block id="86c48b21d166ed8e440a07e1d4a0b15d" category="list-text">Verwenden Sie Failover-Ports, deren Performance-Merkmale mit der ursprünglichen logischen Schnittstelle übereinstimmen. Beispielsweise sollte eine LIF auf einem einzelnen physischen 10-Gbit-Port eine Failover-Gruppe mit einem einzelnen 10-Gbit-Port enthalten. Ein LACP LIF mit vier Ports sollte ein Failover auf eine andere LACP LIF mit vier Ports durchführen. Diese Ports wären eine Teilmenge der Ports, die in der Broadcast-Domäne definiert sind.</block>
  <block id="3e839a73f7dc1262508f23a89628ca2d" category="list-text">Setzen Sie die Failover-Richtlinie auf nur SFO-Partner. Dadurch wird sichergestellt, dass die LIF während des Failovers dem Aggregat folgt.</block>
  <block id="85e82ce4c9842f978fa774c4fe96b14c" category="section-title">Autom. Rücksetzung</block>
  <block id="3dc8610f78478640e47688101cecbfad" category="paragraph">Stellen Sie die ein<block ref="9f1b7141f09f19c4e33409646aef43cf" prefix=" " category="inline-code"></block> Parameter wie gewünscht. Die meisten Kunden bevorzugen es, diesen Parameter auf zu setzen<block ref="b326b5062b2f0e69046810717534cb09" prefix=" " category="inline-code"></block> Um das LIF auf seinen Home Port zurückzusetzen. In einigen Fällen haben Kunden dies jedoch auf `false `so gesetzt, dass ein unerwartetes Failover untersucht werden kann, bevor eine LIF an ihren Home Port zurückgegeben wird.</block>
  <block id="edf6d4c299bc2890ba63c7eb3ef8b4d2" category="section-title">LIF-Volume-Verhältnis</block>
  <block id="9c75becef8c432a0152a40c7c037a04c" category="paragraph">Ein weit verbreitetes Missverständnis ist, dass es eine 1:1 Beziehung zwischen Volumes und NFS LIFs geben muss. Diese Konfiguration ist zwar erforderlich, um ein Volume ohne zusätzlichen Interconnect-Verkehr an eine beliebige Stelle in einem Cluster zu verschieben, ist jedoch kategorisch keine Anforderung. Der Intercluster-Datenverkehr muss berücksichtigt werden, aber die bloße Anwesenheit von Intercluster-Datenverkehr verursacht keine Probleme. Viele der für ONTAP veröffentlichten Benchmarks sind überwiegend indirekte I/O-Vorgänge</block>
  <block id="2b4ebcd522b07b80d3fd76b301c506e8" category="paragraph">Ein Datenbankprojekt mit einer relativ kleinen Anzahl Performance-kritischer Datenbanken, für die nur insgesamt 40 Volumes benötigt wurden, könnte beispielsweise eine LIF-Strategie für das 1:1 Volume rechtfertigen. Dieses Arrangement würde 40 IP-Adressen erfordern. Jedes Volume könnte dann zusammen mit der zugehörigen LIF an jeden beliebigen Ort im Cluster verschoben werden. Der Datenverkehr würde dann immer direkt erfolgen, wodurch jede Latenzquelle sogar auf Mikrosekunden-Ebene minimiert wird.</block>
  <block id="38bad4911bcdf1117d37eb1195566f8c" category="paragraph">Zählerbeispiel: Eine große, gehostete Umgebung kann durch eine 1:1:1-Beziehung zwischen Kunden und LIFs einfacher gemanagt werden. Im Laufe der Zeit muss ein Volume möglicherweise auf einen anderen Node migriert werden, was zu einem indirekten Traffic führen würde. Der Performance-Effekt sollte jedoch nicht nachweisbar sein, es sei denn, die Netzwerk-Ports auf dem Interconnect-Switch sind voll ausgelastet. Falls Bedenken bestehen, kann eine neue LIF auf zusätzlichen Nodes erstellt werden, und der Host kann im nächsten Wartungsfenster aktualisiert werden, um indirekten Traffic aus der Konfiguration zu entfernen.</block>
  <block id="d75b0d8f723c3e97eaa4ca39630c7420" category="doc">MetroCluster und mehrere Aggregate</block>
  <block id="df5855269b493a27a5565dfd9f2584f0" category="list-text">Unter normalen Bedingungen werden eingehende Schreibvorgänge an einen bestimmten Controller synchron mit seinem Partner gespiegelt. In einer NetApp MetroCluster-Umgebung werden Schreibvorgänge auch auf einem Remote Controller gespiegelt. Bis ein Schreibvorgang auf nicht-flüchtigen Medien an allen Standorten gespeichert wird, wird er für die Host-Applikation nicht bestätigt.</block>
  <block id="05b60db315aa45e1524b7a6ffa242fa8" category="list-text">Das Medium, auf dem die Schreibdaten gespeichert sind, wird als nichtflüchtiger Speicher oder NVMEM bezeichnet. Gelegentlich wird dieser Speicher auch als NVRAM (Nonvolatile Random Access Memory) bezeichnet. Er kann als Schreib-Cache verwendet werden, obwohl er als Journal fungiert. Im normalen Betrieb werden die Daten von NVMEM nicht gelesen, sondern nur zum Schutz der Daten bei einem Software- oder Hardwareausfall verwendet. Wenn die Daten auf die Laufwerke geschrieben werden, werden die Daten vom RAM im System und nicht von NVMEM übertragen.</block>
  <block id="e6dd8b559da6e046f2043043a55faafc" category="list-text">Während eines Übernahmevorgangs übernimmt ein Node in einem Hochverfügbarkeitspaar (HA) den Betrieb seines Partners. Eine Umschaltung ist im Wesentlichen dieselbe, gilt aber für MetroCluster Konfigurationen, bei denen ein Remote Node die Funktionen eines lokalen Node übernimmt.</block>
  <block id="33c0c466972aae7427262e3075a2ed07" category="paragraph">Bei routinemäßigen Wartungsvorgängen sollte ein Storage-Takeover- oder Switchover-Vorgang transparent sein. Anders als bei Änderungen der Netzwerkpfade besteht hier eine potenzielle kurze Betriebsunterbrechung. Networking kann jedoch kompliziert sein und es sind leicht Fehler zu machen. NetApp empfiehlt daher dringend, Takeover- und Switchover-Vorgänge sorgfältig zu testen, bevor das Storage-System in Betrieb geht. Nur so können Sie sicherstellen, dass alle Netzwerkpfade korrekt konfiguriert sind. Prüfen Sie in einer SAN-Umgebung die Ausgabe des Befehls sorgfältig<block ref="41dc2c94e82e1c56ba876085acf5a974" prefix=" " category="inline-code"></block> Um sicherzustellen, dass alle erwarteten primären und sekundären Pfade verfügbar sind.</block>
  <block id="d33ea1ad1493de23aafd480e95fea159" category="paragraph">Bei erzwungener Übernahme oder Umschaltung ist Vorsicht zu beachten. Eine Änderung der Storage-Konfiguration mit diesen Optionen erzwingen, bedeutet, dass der Status des Controllers, dem die Laufwerke gehören, nicht berücksichtigt wird und der alternative Node gewaltsam die Kontrolle über die Laufwerke übernimmt. Ein falscher erzwingen eines Takeover kann zu Datenverlust oder Datenkorruption führen. Das liegt daran, dass durch eine erzwungene Übernahme oder Umschaltung die Inhalte von NVMEM verworfen werden. Nach Abschluss der Übernahme oder Umschaltung bedeutet der Verlust dieser Daten, dass die auf den Laufwerken gespeicherten Daten aus Sicht der Datenbank möglicherweise wieder in einen etwas älteren Zustand zurückgesetzt werden.</block>
  <block id="c226371d96b605ccff84ad23db0069b8" category="paragraph">Eine erzwungene Übernahme mit einem normalen HA-Paar sollte selten erforderlich sein. In fast allen Ausfallszenarien schaltet ein Node ab und informiert den Partner, sodass eine automatische Ausfallsicherung stattfindet. Es gibt einige Edge-Fälle, beispielsweise einen Rolling Failure, bei dem die Verbindung zwischen den Nodes unterbrochen wird und dann ein Controller verloren geht. Dadurch ist eine erzwungene Übernahme erforderlich. In einer solchen Situation geht die Spiegelung zwischen Nodes vor dem Controller-Ausfall verloren. Das bedeutet, dass der verbleibende Controller nicht mehr über eine Kopie der laufenden Schreibvorgänge verfügt. Das Takeover muss anschließend forciert werden, d. h., dass Daten potenziell verloren gehen.</block>
  <block id="418f81f529a577cb711b44adece1376f" category="paragraph">Dieselbe Logik gilt auch für eine MetroCluster-Umschaltung. Unter normalen Bedingungen ist eine Umschaltung nahezu transparent. Bei einem Ausfall kann es jedoch zu einem Verlust der Verbindung zwischen dem noch intakten Standort und dem Notfallstandort kommen. Aus Sicht des verbleibenden Standorts könnte das Problem lediglich eine Unterbrechung der Verbindung zwischen den Standorten sein, wobei der ursprüngliche Standort möglicherweise noch die Daten verarbeitet. Wenn ein Node den Status des primären Controllers nicht überprüfen kann, ist nur eine erzwungene Umschaltung möglich.</block>
  <block id="ae0c16d397348d8f8fd4e56b08b06c7c" category="paragraph">*NetApp empfiehlt* die folgenden Vorsichtsmaßnahmen zu ergreifen:</block>
  <block id="79fd18cb18befbe5c2113757478be193" category="list-text">Seien Sie vorsichtig, damit Sie nicht versehentlich eine Übernahme oder Umschaltung erzwingen. Normalerweise sollte das Erzwingen nicht erforderlich sein, und das Erzwingen der Änderung kann zu Datenverlust führen.</block>
  <block id="26cece11254903c5ba8bfdd8d54ae779" category="list-text">Wenn eine erzwungene Übernahme oder Umschaltung erforderlich ist, stellen Sie sicher, dass die Applikationen heruntergefahren, alle Filesysteme getrennt und die Volume-Gruppen des Logical Volume Manager (LVM) unterschiedlich sind. ASM-Diskgroups müssen abgehängt werden.</block>
  <block id="0b6986eb1285d28a9987ea13adbca358" category="list-text">Sollte eine erzwungene MetroCluster-Umschaltung stattfinden, sollte der ausgefallene Node von allen verbleibenden Storage-Ressourcen abgetrennt werden. Weitere Informationen zur entsprechenden Version von ONTAP finden Sie im MetroCluster-Management- und Disaster-Recovery-Leitfaden.</block>
  <block id="71303adf87737046acd4381c72151278" category="paragraph">MetroCluster ist eine Technologie für die synchrone Replizierung, die bei einer Unterbrechung der Verbindung zum asynchronen Modus wechselt. Dies ist die häufigste Anforderung von Kunden, da durch die garantierte synchrone Replizierung eine Unterbrechung der Standortkonnektivität zu einem vollständigen Stillstand der Datenbank-I/O führt und die Datenbank außer Betrieb genommen wird.</block>
  <block id="cb791a44ee361703eb7594a7932f57de" category="paragraph">Mit MetroCluster synchronisieren sie Aggregate nach der Wiederherstellung der Konnektivität schnell neu. Im Gegensatz zu anderen Storage-Technologien sollte bei MetroCluster nach einem Standortausfall nie eine vollständige Respiegelung erforderlich sein. Es müssen nur Delta-Änderungen versendet werden.</block>
  <block id="c1536091d7c1ca33c9dc4dfa8c0852a2" category="paragraph">Bei Datensätzen, die sich über Aggregate verteilen, besteht das geringe Risiko, dass bei einem rollierenden Disaster-Szenario zusätzliche Schritte zur Daten-Recovery erforderlich wären. Insbesondere, wenn (a) die Verbindung zwischen den Standorten unterbrochen wird, (b) die Konnektivität wiederhergestellt wird, (c) die Aggregate einen Zustand erreichen, in dem einige synchronisiert werden und andere nicht, und dann (d) der primäre Standort verloren geht, ist das Ergebnis ein noch existender Standort, an dem die Aggregate nicht miteinander synchronisiert werden. In diesem Fall werden Teile des Datensatzes miteinander synchronisiert. Ohne Recovery können Applikationen, Datenbanken oder Datastores nicht mehr angezeigt werden. Wenn ein Datensatz über mehrere Aggregate verteilt ist, empfiehlt NetApp dringend, Snapshot-basierte Backups mit einem der vielen verfügbaren Tools einzusetzen, um in diesem ungewöhnlichen Szenario eine schnelle Wiederherstellbarkeit zu überprüfen.</block>
  <block id="a42c87064c284490a38efac4bf0b7f7f" category="paragraph">RAID 4, RAID 5, RAID 6, RAID DP und RAID-TEC nutzen Parität, um sicherzustellen, dass es bei einem Laufwerksausfall zu keinem Datenverlust kommt. Diese RAID-Optionen bieten im Vergleich zur Spiegelung eine viel bessere Speichernutzung, aber die meisten RAID-Implementierungen haben einen Nachteil, der Schreibvorgänge beeinträchtigt. Für den Abschluss eines Schreibvorgangs in anderen RAID-Implementierungen sind möglicherweise mehrere Laufwerkszugriffe erforderlich, um die Paritätsdaten neu zu generieren. Dies ist ein Prozess, der allgemein als RAID-Abzug bezeichnet wird.</block>
  <block id="3cfcf9a3299db75df9aa0e024ebef965" category="paragraph">Bei ONTAP fallen jedoch keine RAID-Einbußen an. Dies liegt an der Integration von NetApp WAFL (Write Anywhere File Layout) mit der RAID-Schicht. Schreibvorgänge werden im RAM zusammengeführt und als vollständiger RAID-Stripe einschließlich der Paritätsgenerierung vorbereitet. ONTAP muss für einen Schreibvorgang keinen Lesevorgang durchführen. Das bedeutet, dass ONTAP und WAFL die RAID-Einbußen vermeiden. Die Performance für latenzkritische Vorgänge, wie die Protokollierung von Wiederherstellungen, wird ohne Behinderung durchgeführt und zufällige Schreibvorgänge von Datendateien verursachen keine RAID-Beeinträchtigungen, da die Parität neu generiert werden muss.</block>
  <block id="5ff9a871332f0f82f38d880b68a9874b" category="paragraph">In Bezug auf statistische Zuverlässigkeit bietet selbst RAID DP besseren Schutz als RAID Mirroring. Das Hauptproblem besteht in der Nachfrage nach Laufwerken während einer RAID-Wiederherstellung. Bei einem gespiegelten RAID-Satz ist das Risiko eines Datenverlusts aufgrund eines Laufwerksausfalls bei der Wiederherstellung an seinen Partner im RAID-Satz deutlich größer als das Risiko eines dreifachen Laufwerksausfalls in einem RAID DP-Satz.</block>
  <block id="12c3fe87fd5a746ce8a7cbe25dc1c25b" category="paragraph">Vor der Ära der Flash-Laufwerke wurde Striping verwendet, um die Performance-Einschränkungen rotierender Laufwerke zu überwinden. Beispiel: Wenn ein Betriebssystem einen Lesevorgang von 1 MB ausführen muss, würde das Lesen dieser 1 MB Daten von einem einzigen Laufwerk viel Festplattenkopf erfordern, der sucht und liest, da die 1 MB langsam übertragen wird. Wenn diese 1 MB Daten über 8 LUNs verteilt wurden, kann das Betriebssystem acht 128K-Lesevorgänge parallel ausführen und die für die 1-MB-Übertragung erforderliche Zeit verringern.</block>
  <block id="e337352c3d57672fd08af8ba709b544f" category="paragraph">Das Striping mit rotierenden Laufwerken war schwieriger, da das I/O-Muster bereits im Vorfeld bekannt sein musste. Wenn das Striping nicht richtig auf die wahren I/O-Muster abgestimmt wurde, können Striping-Konfigurationen die Performance beeinträchtigen. Bei Oracle Datenbanken und insbesondere bei All-Flash-Konfigurationen ist Striping einfacher zu konfigurieren und hat sich nachweislich für eine drastische Verbesserung der Performance bewährt.</block>
  <block id="7025652291dc6872022b0f79a2b2be21" category="paragraph">Logische Volume-Manager wie Oracle ASM Stripe sind standardmäßig aktiviert, aber native OS LVM nicht. Einige von ihnen verbinden mehrere LUNs als verkettete Geräte. Dies führt zu Datendateien, die auf einem und nur einem LUN-Gerät vorhanden sind. Dies verursacht Hotspots. Andere LVM-Implementierungen sind standardmäßig auf verteilte Extents eingestellt. Das ist ähnlich wie Striping, aber es ist gröber. Die LUNs in der Volume-Gruppe werden in große Teile geteilt, die als Extents bezeichnet werden und in der Regel in vielen Megabyte gemessen werden. Die logischen Volumes werden dann über diese Extents verteilt. Das Ergebnis ist ein zufälliger I/O-Vorgang für eine Datei, der auf LUNs verteilt werden sollte. Sequenzielle I/O-Vorgänge sind jedoch nicht so effizient wie möglich.</block>
  <block id="0c2f3b2ec9d90baa0a0a0b6fb673a113" category="paragraph">Die Performance-intensiven Applikations-I/O-Vorgänge erfolgen fast immer entweder (a) in Einheiten der grundlegenden Blockgröße oder (b) in Megabyte.</block>
  <block id="804d5b1f06570b4d242be0c2f0c3392c" category="paragraph">Das primäre Ziel einer Striped-Konfiguration ist es, sicherzustellen, dass Single-File I/O als eine Einheit ausgeführt werden kann. Multiblock-I/O, die eine Größe von 1 MB haben sollte, kann gleichmäßig über alle LUNs im Striped Volume hinweg parallelisiert werden. Das bedeutet, dass die Stripe-Größe nicht kleiner als die Blockgröße der Datenbank sein darf und die Stripe-Größe multipliziert mit der Anzahl der LUNs 1 MB betragen sollte.</block>
  <block id="0598f393baefd05d48b48076cc7df606" category="paragraph">Die folgende Abbildung zeigt drei mögliche Optionen für die Stripe-Größe und Breitenabstimmung. Die Anzahl der LUNs wird ausgewählt, um die oben beschriebenen Performance-Anforderungen zu erfüllen. In allen Fällen beträgt die Gesamtzahl der Daten innerhalb eines einzigen Stripes jedoch 1 MB.</block>
  <block id="9ca503fae9ccd4d6d8e67806b23adfa0" category="paragraph"><block ref="9ca503fae9ccd4d6d8e67806b23adfa0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d36647d06b353fcd6fedc60898e43187" category="summary">ONTAP-Konfiguration</block>
  <block id="0353522b39b87d54d40d3f09ec668851" category="doc">ONTAP-Konfiguration</block>
  <block id="ccaea53c3be76af327e8e6f9c496a3ac" category="paragraph">ONTAP bietet viele Funktionen, die speziell für Applikations- und Datenbank-Workloads konzipiert wurden.</block>
  <block id="8e52de0d4b03d5fe87dc88da09616c7f" category="inline-link-macro">Hier.</block>
  <block id="0940bb4f1fb97b40821b7a3be456f149" category="paragraph">Hier finden Sie einen Überblick über wichtige ONTAP Funktionen, einschließlich Datensicherungsfunktionen, Empfehlungen zur Storage-Effizienz und Disaster Recovery-Optionen <block ref="f7503abce54bbe0e3218519d659c8356" category="inline-link-macro-rx"></block></block>
  <block id="99e4610a4e3d81b01970dbfd92973f0a" category="paragraph">Diese Informationen sind entscheidend für die ordnungsgemäße Architektur und das Management der Applikationsumgebung auf ONTAP Storage-Systemen.</block>
  <block id="9fe343788d08130f46e418bb81928479" category="summary">Übersicht über FabricPool</block>
  <block id="337c62c6b6eb7319bae58701105e889c" category="doc">Tiering</block>
  <block id="cec4b296aaf93974a98a5d3b3f27ff9e" category="paragraph">Um zu verstehen, wie sich FabricPool Tiering auf Applikationen und Datenbanken auswirkt, müssen Sie die Low-Level-FabricPool-Architektur kennen.</block>
  <block id="3493794b3ccb587f71a663f51f4484ef" category="summary">PostgreSQL-Datenbanken auf ONTAP</block>
  <block id="2d3298c651b356a82db5d664ce68e65e" category="doc">Native Datensicherung</block>
  <block id="31c6611c8e0bd237a3ee51db1728a440" category="paragraph">Einer der wichtigsten Aspekte des Storage-Designs ist die Sicherung von PostgreSQL Volumes. Kunden können ihre PostgreSQL-Datenbanken entweder mithilfe des Dump-Ansatzes oder mit Dateisystem-Backups sichern. In diesem Abschnitt werden die verschiedenen Ansätze zur Sicherung einzelner Datenbanken oder des gesamten Clusters erläutert.</block>
  <block id="9f3265914462c64fd02bc50ab4c9ebe9" category="paragraph">Es gibt drei Ansätze für die Sicherung von PostgreSQL-Daten:</block>
  <block id="6b592c7950245a5a9f54d9424e851e97" category="list-text">SQL Server Dump</block>
  <block id="c8b1fc69d12d1da6589e384671c8e82c" category="list-text">Backup auf Filesystem-Ebene</block>
  <block id="3c25062a0babfa1495dd604698707610" category="list-text">Kontinuierliche Archivierung</block>
  <block id="58c132e2be12705408a7456c6183b617" category="paragraph">Die Idee hinter der SQL Server Dump-Methode besteht darin, eine Datei mit SQL Server-Befehlen zu generieren, die, wenn sie an den Server zurückgegeben wird, die Datenbank so neu erstellen kann, wie sie zum Zeitpunkt des Dump war. PostgreSQL stellt die Dienstprogramme zur Verfügung<block ref="5a5149b2817f30cbb3805307f9cadae4" prefix=" " category="inline-code"></block> Und<block ref="0ead269b3d000482b5a44a1ef4e8cd54" prefix=" " category="inline-code"></block> Zur Erstellung von individuellen Backups und Backups auf Cluster-Ebene. Diese Dumps sind logisch und enthalten nicht genügend Informationen, die von WAL Replay verwendet werden können.</block>
  <block id="1d05b80fc6f199681263e063190e8325" category="paragraph">Eine alternative Backup-Strategie ist die Verwendung von Backup auf Dateisystem-Ebene, bei der Administratoren direkt kopieren die Dateien, die PostgreSQL verwendet, um die Daten in der Datenbank zu speichern. Diese Methode erfolgt im Offline-Modus: Die Datenbank oder das Cluster muss heruntergefahren werden. Eine weitere Alternative ist die Verwendung<block ref="35679fc424d9eec0c30f38459fd9b322" prefix=" " category="inline-code"></block> Zum Ausführen von Hot-Streaming-Backups der PostgreSQL-Datenbank.</block>
  <block id="10907e7ac5ab6e5235a23898a2331b31" category="doc">PostgreSQL-Datenbanken auf ONTAP</block>
  <block id="b5f477e959f26421a80e1eebdadbdd71" category="paragraph">PostgreSQL wird mit Varianten wie PostgreSQL, PostgreSQL Plus und EDB Postgres Advanced Server (EPAS) geliefert. PostgreSQL wird typischerweise als Back-End-Datenbank für Multi-Tier-Applikationen implementiert. Es wird von gängigen Middleware-Paketen (wie PHP, Java, Python, Tcl/TK, ODBC, Und JDBC) und war in der Vergangenheit eine beliebte Wahl für Open-Source-Datenbankmanagementsysteme. NetApp ONTAP ist eine ausgezeichnete Wahl für die Ausführung von PostgreSQL-Datenbanken aufgrund seiner Zuverlässigkeit, seiner hohen Performance und seiner effizienten Datenmanagementfunktionen.</block>
  <block id="841a21e58e7c22a71c07b89a4362d2b6" category="admonition">Diese Dokumentation zu ONTAP und der PostgreSQL-Datenbank ersetzt die zuvor veröffentlichte _TR-4770: PostgreSQL-Datenbank unter ONTAP Best Practices._</block>
  <block id="23dc28a190980aa339329235e8b66434" category="paragraph">Mit dem exponentiellen Datenwachstum wird das Datenmanagement für Unternehmen komplexer. Dadurch steigen die Lizenz-, Betriebs-, Support- und Wartungskosten. Zur Senkung der Gesamtbetriebskosten empfiehlt sich der Wechsel von kommerziellen zu Open-Source-Datenbanken mit zuverlässigem, leistungsstarkem Back-End Storage. PostgreSQL ist eine fortschrittliche Open-Source-Datenbank, die in akademischen, kommerziellen und großen Unternehmen weit verbreitet ist. Es kommt mit einem neuen Satz von Funktionen, die Lücken in anderen relationalen Datenbank-Management-Systemen (RDBMSs) zu adressieren.</block>
  <block id="595e7195ec732ff0042e8b03492176cc" category="admonition">NetApp Kunden, die PostgreSQL-Datenbanken in physischen oder virtualisierten Umgebungen verwenden, können von den Best Practices für die erfolgreiche Implementierung und das Management von PostgreSQL-Datenbanken auf ONTAP profitieren. Die Empfehlungen sind allgemein gehalten, sodass sie nicht konfigurationsspezifisch sind. Abhängig von Ihren Geschäftsanforderungen können einige Vorschläge Änderungen erfordern. Sie müssen Ihre Umgebung mit der offiziellen Dokumentation für PostgreSQL, Hypervisoren, Betriebssysteme und ONTAP Storage vergleichen.</block>
  <block id="6c1ea8a6f96c812bdbee4a788f8282dc" category="doc">Anhang A: Host-Konfiguration</block>
  <block id="c3ef6436e8acdba8ced1def7d29a99b8" category="paragraph">Inhalt des Anhangs:</block>
  <block id="873bf9c2fc74dd3fc39aa67a16b51d6a" category="list-text">Überprüfen Sie, ob FC-Hostbusadapter (HBAs) im ESX-Host mit aktualisierten Treibern, Firmware und der korrekten BIOS-Version ausgeführt werden.</block>
  <block id="b6d348f60c7c0e3bb221591b67518d1c" category="list-text">Installieren Sie NetApp Host Utilities auf dem Host, um direkte und indirekte Pfade für eine bestimmte LUN anzuzeigen. Das Kit enthält auch erweiterte Informationen zu den LUN-SVM-Informationen.</block>
  <block id="4a1afd4a3d39c7e385017e01816d721f" category="list-text">Verwenden Sie immer ein Rescan-SCSI-Bus-Skript auf dem Host, um:</block>
  <block id="6d1436a6f6bda3b3ce87df91aaf6fb56" category="list-text">Neue LUNs finden</block>
  <block id="897dc659ee2dd9f0dd17af82c47259bd" category="list-text">Verwerfen Sie veraltete LUNs</block>
  <block id="ecef9cf88b8cf100d1a489f3acdd4732" category="list-text">Aktualisieren Sie neue Pfade zu LUNs</block>
  <block id="c7b133bd977e02fc973a2df60786e7a8" category="list-text">Um bei Pfadausfall mehrere Routen zum Speicher einzurichten, installieren und konfigurieren Sie Multipathing-Software auf dem Host-Betriebssystem.</block>
  <block id="3617da17b3368e5730bf10cdacf54a18" category="list-text">Wenn Sie keine Multipathing-Software verwenden, sollten Sie jede LUN auf einen einzelnen Pfad beschränken.</block>
  <block id="6dff2f8361cdca0bbb6cfa1d162de499" category="list-text">Der Linux-Kernel ermöglicht eine Low-Level-Kontrolle über die Planung von E/A-Vorgängen, um Geräte zu blockieren. Die Standardwerte in Linux-Versionen können erheblich variieren. Im Allgemeinen zeigen NetApp Kunden und interne Tests bessere Ergebnisse mit NoOps-Scheduler für Datenbanken. Sie sollten Benchmarking durchführen, um festzustellen, welche I/O-Planer für Ihren Anwendungsfall optimal sind.</block>
  <block id="9147e5e61a7b9260dec09f3a6eb3e5be" category="doc">Snapshots</block>
  <block id="0b9d99167191c5d9ad23ca07bc6a9b38" category="paragraph">Snapshot-basierte Backups mit PostgreSQL erfordern die Konfiguration von Snapshots für Datendateien, WAL-Dateien und archivierte WAL-Dateien, um eine vollständige oder zeitpunktgenaue Recovery zu ermöglichen.</block>
  <block id="8c6a53edc4449a4cc3983d47ecffa851" category="paragraph">Bei PostgreSQL-Datenbanken liegt die durchschnittliche Backup-Zeit mit Snapshots im Bereich von wenigen Sekunden bis zu wenigen Minuten. Diese Backup-Geschwindigkeit ist 60 bis 100 Mal schneller als<block ref="35679fc424d9eec0c30f38459fd9b322" prefix=" " category="inline-code"></block> Und anderen Filesystem-basierten Backup-Ansätzen.</block>
  <block id="c798632224ae09152f66f60e0edc757e" category="paragraph">Snapshots auf NetApp Storage können sowohl ausfallkonsistent als auch applikationskonsistent sein. Ein Crash-konsistenter Snapshot wird auf dem Storage erstellt, ohne die Datenbank stillzustehen. Während sich die Datenbank im Backup-Modus befindet, wird ein applikationskonsistenter Snapshot erstellt. NetApp sorgt außerdem dafür, dass nachfolgende Snapshots dauerhaft inkrementelle Backups sind, um die Storage-Einsparungen und die Netzwerkeffizienz zu erhöhen.</block>
  <block id="d0e369216eeac8de66e915909364970a" category="paragraph">Da Snapshots schnell sind und die System-Performance nicht beeinträchtigen, können Sie mehrere Snapshots täglich planen, anstatt wie bei anderen Streaming-Backup-Technologien täglich ein einziges Backup zu erstellen. Wenn ein Wiederherstellungs- und Wiederherstellungsvorgang erforderlich ist, verringert sich die Systemausfallzeit um zwei wichtige Funktionen:</block>
  <block id="316eb8adba4d16a34c92eaf9db381b9e" category="list-text">Dank der NetApp SnapRestore Datenwiederherstellungs-Technologie erfolgt die Wiederherstellung in Sekundenschnelle.</block>
  <block id="c128c475c12703e37685edd6db8144bc" category="list-text">Durch aggressive Recovery Point Objectives (RPOs) müssen weniger Datenbankprotokolle angewendet werden und auch die Recovery wird beschleunigt.</block>
  <block id="9b9f26085ff7149d4dbb916b1db0f121" category="paragraph">Für das Backup von PostgreSQL müssen Sie sicherstellen, dass die Datenvolumes gleichzeitig mit (Consistency Group) WAL und den archivierten Protokollen geschützt sind. Stellen Sie beim Kopieren von WAL-Dateien mit der Snapshot-Technologie sicher, dass Sie ausgeführt werden<block ref="a3b8c8ee15ba60bfb2b999195d2b4e7d" prefix=" " category="inline-code"></block> Um alle WAL-Einträge zu löschen, die archiviert werden müssen. Wenn Sie die WAL-Einträge während der Wiederherstellung löschen, müssen Sie nur die Datenbank anhalten, das vorhandene Datenverzeichnis aufheben oder löschen und einen SnapRestore-Vorgang auf dem Speicher ausführen. Nachdem die Wiederherstellung abgeschlossen ist, können Sie das System mounten und in den aktuellen Status zurückversetzen. Für Point-in-Time Recovery können Sie WAL wiederherstellen und Protokolle archivieren. PostgreSQL entscheidet dann über den konsistentesten Punkt und stellt ihn automatisch wieder her.</block>
  <block id="8e8d6187572eace409fee5bf2dbb7cf9" category="paragraph">Konsistenzgruppen sind in ONTAP eine Funktion, die ebenfalls empfohlen werden, wenn mehrere Volumes in eine einzelne Instanz oder in eine Datenbank mit mehreren Tablespaces gemountet sind. Ein Snapshot einer Konsistenzgruppe stellt sicher, dass alle Volumes gruppiert und geschützt sind. Eine Konsistenzgruppe kann über den ONTAP System Manager effizient gemanagt werden und Sie können sie sogar klonen, um eine Instanzkopie einer Datenbank zu Test- oder Entwicklungszwecken zu erstellen.</block>
  <block id="55ca4b30c6f7c3ef975a6d1e1fb222a2" category="inline-link-macro">Übersicht über NetApp Konsistenzgruppen</block>
  <block id="69dd5879aee425e37fdd5796a8e06a56" category="paragraph">Weitere Informationen zu Konsistenzgruppen finden Sie im <block ref="112c5744a39904facdbc5fab385d9fe1" category="inline-link-macro-rx"></block>.</block>
  <block id="7e7397a7b79323762c61941fc0e6b5f9" category="doc">Datensicherung</block>
  <block id="04e7487d479314b6bdfdca58a245d899" category="paragraph">Indexschutz</block>
  <block id="90b0d8da95f7f5935481bc7e648c111e" category="summary">PostgreSQL Tablespaces</block>
  <block id="16a49d0bc0249ef3dd42949589a0ed4e" category="doc">Tablespaces</block>
  <block id="d6d544de56c329d9f68bb176c6245e7c" category="paragraph">Bei der Initialisierung des Datenbank-Clusters werden automatisch zwei Tablespaces erstellt.</block>
  <block id="6df924905e21856e4e8b8f936767cdd6" category="paragraph">Der<block ref="bd676cbef0d168a62a062c8709af1824" prefix=" " category="inline-code"></block> Tablespace wird für freigegebene Systemkataloge verwendet. Der<block ref="3224684b8e7208962a73daeb0bb24110" prefix=" " category="inline-code"></block> Tablespace ist der Standard-Tablespace der Datenbanken temple1 und template0. Wenn die Partition oder das Volume, auf der das Cluster initialisiert wurde, nicht mehr genügend Speicherplatz hat und nicht erweitert werden kann, kann ein Tablespace auf einer anderen Partition erstellt und verwendet werden, bis das System neu konfiguriert werden kann.</block>
  <block id="364c9d7b9593277eee9477befaf9f66b" category="paragraph">Ein stark genutzter Index kann auf einer schnellen, hochverfügbaren Festplatte wie einem Solid-State-Gerät platziert werden. Darüber hinaus kann eine Tabelle mit archivierten Daten, die selten verwendet oder nicht Performance-kritisch sind, auf einem kostengünstigeren, langsameren Festplattensystem wie SAS- oder SATA-Laufwerken gespeichert werden.</block>
  <block id="9bfe8d8e1117bd1d4b8597220e3f166e" category="paragraph">Tablespaces sind Bestandteil des Datenbank-Clusters und können nicht als eigenständige Erfassung von Datendateien behandelt werden. Sie sind von Metadaten im Hauptdatenverzeichnis abhängig und können daher nicht an einen anderen Datenbankcluster angeschlossen oder einzeln gesichert werden. Wenn Sie einen Tablespace verlieren (durch Dateilöschung, Festplattenfehler usw.), kann der Datenbankcluster möglicherweise unlesbar werden oder nicht mehr starten. Wenn ein Tablespace auf einem temporären Dateisystem wie einer RAM-Festplatte platziert wird, besteht die Gefahr, dass der gesamte Cluster zuverlässig ist.</block>
  <block id="7d9573b1ed3543ec6ea42c81830dc27c" category="paragraph">Nach der Erstellung kann ein Tablespace aus jeder beliebigen Datenbank verwendet werden, wenn der anfordernde Benutzer über ausreichende Berechtigungen verfügt. PostgreSQL verwendet symbolische Links, um die Implementierung von Tablespaces zu vereinfachen. PostgreSQL fügt dem eine Zeile hinzu<block ref="4a926dc6e7549c49a13755513af41e67" prefix=" " category="inline-code"></block> Tabelle (eine clusterwide-Tabelle) und weist dieser Zeile eine neue Objektkennung (OID) zu. Schließlich verwendet der Server die OID, um einen symbolischen Link zwischen Ihrem Cluster und dem angegebenen Verzeichnis zu erstellen. Das Verzeichnis<block ref="8e3da386e945c59fb1e1cd1d7a47697c" prefix=" " category="inline-code"></block> Enthält symbolische Links, die auf jeden nicht integrierten Tablespace verweisen, der im Cluster definiert ist.</block>
  <block id="249fd7d68098688fab42436eed51be7d" category="doc">Datenbankkonfiguration</block>
  <block id="8daf26b2c72dd18a89fa89a6b1aa988d" category="paragraph">Es gibt mehrere PostgreSQL-Tuning-Konfigurationen, die die Performance verbessern können.</block>
  <block id="abb3dae412afe5c801e9ab90de71675b" category="paragraph">Die am häufigsten verwendeten Parameter sind:</block>
  <block id="bfdf741f4acb3dfee6e87075b535610e" category="list-text"><block ref="39d79378db03fed7c5ba62efba38e327" prefix="" category="inline-code"></block>: Die maximale Anzahl von Datenbankverbindungen, die gleichzeitig verfügbar sind. Verwenden Sie diesen Parameter, um den Austausch auf Festplatte zu beschränken und die Leistung zu unterbinden. Je nach Anwendungsanforderung können Sie diesen Parameter auch für die Einstellungen des Verbindungspools anpassen.</block>
  <block id="9625e1a6f5d1f695fd1c72401afaa07e" category="list-text"><block ref="904d399f43708a8a5b6d10c1ee3f8356" prefix="" category="inline-code"></block>: Die einfachste Methode zur Verbesserung der Leistung Ihres Datenbankservers. Die Standardeinstellung ist niedrig für die meisten modernen Hardware. Sie wird während der Bereitstellung auf ca. 25 % des verfügbaren RAM auf dem System eingestellt. Diese Parametereinstellung hängt davon ab, wie sie mit bestimmten Datenbankinstanzen funktioniert; Sie müssen die Werte möglicherweise durch Versuch und Fehler erhöhen oder verringern. Bei einer hohen Einstellung wird die Performance jedoch wahrscheinlich beeinträchtigt.</block>
  <block id="d1960c56572383fc401fec3f0b767cf9" category="list-text"><block ref="5edeed59821790d8bec6d32da26bca4c" prefix="" category="inline-code"></block>: Dieser Wert teilt PostgreSQL's Optimizer mit, wie viel Speicher PostgreSQL für das Caching von Daten zur Verfügung hat und hilft bei der Bestimmung, ob ein Index verwendet werden soll. Ein größerer Wert erhöht die Wahrscheinlichkeit, einen Index zu verwenden. Dieser Parameter sollte auf die Größe des zugewiesenen Speichers eingestellt werden<block ref="e15ed0f69e5c2475450b97691d6a2cee" prefix=" " category="inline-code"></block> Und die Menge an verfügbarem BS-Cache. Dieser Wert liegt häufig bei mehr als 50 % des gesamten Systemspeichers.</block>
  <block id="508df54f84fc7abb00f3a92937ca3506" category="list-text"><block ref="1edef4d43b06d4deb28010505df5724d" prefix="" category="inline-code"></block>: Dieser Parameter steuert die Speichermenge, die in Sort-Operationen und Hash-Tabellen verwendet werden soll. Wenn Sie eine starke Sortierung in Ihrer Anwendung ausführen, müssen Sie möglicherweise den Speicherplatz erhöhen, aber seien Sie vorsichtig. Es handelt sich nicht um einen systemweiten Parameter, sondern um einen pro-Operation-Parameter. Wenn eine komplexe Abfrage mehrere Sortieroperationen enthält, verwendet sie mehrere Work_mem-Speichereinheiten, und mehrere Back-Ends könnten dies gleichzeitig tun. Diese Abfrage kann oft dazu führen, dass Ihr Datenbankserver ausgetauscht wird, wenn der Wert zu groß ist. Diese Option wurde zuvor in älteren PostgreSQL-Versionen als sort_mem bezeichnet.</block>
  <block id="59d9770060aecba84c7e8ed849b5653d" category="list-text"><block ref="65768448b4f275b95af20a317c7355a9" prefix="" category="inline-code"></block>: Dieser Parameter legt fest, ob alle WAL-Seiten mit fsync() synchronisiert werden sollen, bevor eine Transaktion durchgeführt wird. Wenn Sie sie deaktivieren, kann die Schreibleistung manchmal verbessert werden, und wenn Sie sie einschalten, erhöht sich der Schutz vor dem Risiko von Beschädigungen, wenn das System abstürzt.</block>
  <block id="625a65dd6cef83bac66319bde3894899" category="list-text"><block ref="ff5a06a39dd6824f30a778a51cf7ea69" prefix="" category="inline-code"></block>: Der Checkpoint-Prozess überträgt die Daten auf die Festplatte. Dies beinhaltet viele Lese-/Schreibvorgänge auf der Festplatte. Der Wert wird in Sekunden festgelegt, und niedrigere Werte verringern die Absturzwiederherstellungszeit, und höhere Werte können die Belastung der Systemressourcen verringern, indem die Checkpoint-Anrufe reduziert werden. Legen Sie je nach Wichtigkeit der Anwendung, Auslastung und Verfügbarkeit der Datenbank den Wert von Checkpoint_Timeout fest.</block>
  <block id="309b1036c45e7ad490448925dc4f9597" category="list-text"><block ref="6a5c0586429891e84e05d6ab15088405" prefix="" category="inline-code"></block> Und<block ref="9080796d32078fea7d191100eab64f92" prefix=" " category="inline-code"></block>: Diese Optionen werden zusammen verwendet, um die Leistung zu verbessern, indem mehrere Transaktionen, die auf einmal begehen, ausgeschrieben werden. Wenn mehrere commit_Geschwister-Objekte aktiv sind, sobald Ihre Transaktion abgeschlossen ist, wartet der Server auf commit_delay Mikrosekunden, um zu versuchen, mehrere Transaktionen gleichzeitig zu begehen.</block>
  <block id="8d5137ce002c6328c2b5f4f328662e1d" category="list-text"><block ref="fa4ca2cd95c20a44171f964fb8f5fdb9" prefix="" category="inline-code"></block>: Konfigurieren Sie die optimale Anzahl von Arbeitern für Prozesse. Max_Parallel_Workers entspricht der Anzahl der verfügbaren CPUs. Je nach Anwendungsdesign erfordern Abfragen möglicherweise weniger Mitarbeiter für parallele Vorgänge. Es ist besser, den Wert für beide Parameter gleich zu halten, aber den Wert nach dem Testen anzupassen.</block>
  <block id="c8736e7ca19e9096796c624f3030dae5" category="list-text"><block ref="8dda85a5feb6de66d8f5f9a4cbdb0754" prefix="" category="inline-code"></block>: Dieser Wert steuert die Art und Weise, wie PostgreSQL nicht-sequentielle Datenträger liest. Ein höherer Wert bedeutet, dass PostgreSQL eher einen sequenziellen Scan anstelle eines Indexscans verwendet, was darauf hinweist, dass Ihr Server über schnelle Festplatten verfügt.Ändern Sie diese Einstellung, nachdem Sie andere Optionen wie planbasierte Optimierung, Staubsaugen, Indexieren auf Abfragen oder Schema überprüft haben.</block>
  <block id="17edf3863f12b7d9480b3336a9fca773" category="list-text"><block ref="709989c844c22473cb8406550423d39a" prefix="" category="inline-code"></block>: Dieser Parameter legt die Anzahl der gleichzeitigen Festplatten-I/O-Operationen fest, die PostgreSQL gleichzeitig auszuführen versucht. Wenn Sie diesen Wert erhöhen, erhöht sich die Anzahl der I/O-Vorgänge, die jede einzelne PostgreSQL-Sitzung parallel initiieren möchte. Der zulässige Bereich ist 1 bis 1,000 oder Null, um die Ausgabe asynchroner I/O-Anfragen zu deaktivieren. Derzeit wirkt sich diese Einstellung nur auf Bitmap-Heap-Scans aus. Solid State Drives (SSDs) und anderer speicherbasierter Storage (NVMe) können oft zahlreiche gleichzeitige Anforderungen verarbeiten, sodass der beste Nutzen aus Hunderten von Laufwerken zu ziehen ist.</block>
  <block id="82b38edb10ad73f9645c5d65e73a659b" category="paragraph">Eine vollständige Liste der PostgreSQL-Konfigurationsparameter finden Sie in der PostgreSQL-Dokumentation.</block>
  <block id="402fbc243dbef50cd5c8e57ccbdd92f5" category="section-title">TOAST</block>
  <block id="0d2b62abb26bd0b4109f5bc967250933" category="paragraph">TOAST steht für die Oversized-Attribute Storage-Technik. PostgreSQL verwendet eine feste Seitengröße (üblicherweise 8 KB) und erlaubt nicht, dass Tupel mehrere Seiten umfassen. Daher ist es nicht möglich, große Feldwerte direkt zu speichern. Wenn Sie versuchen, eine Zeile zu speichern, die diese Größe überschreitet, bricht TOAST die Daten großer Spalten in kleinere „Stücke“ und speichert sie in einem TOAST Tisch.</block>
  <block id="3f11f21bdc22c3c955c3f0fca39e9bc0" category="paragraph">Die großen Werte der getoasteten Attribute werden nur dann herausgezogen (wenn sie überhaupt ausgewählt sind), wenn der Ergebnissatz an den Client gesendet wird. Die Tabelle selbst ist viel kleiner und kann mehr Zeilen in den gemeinsam genutzten Puffer-Cache passen als ohne Out-of-Line Storage (TOAST).</block>
  <block id="9a311ef6dad816cb7a15c0ab41920ad8" category="section-title">VAKUUM</block>
  <block id="385e23b8ebe64dfd0005f6846cc8e85e" category="paragraph">Im normalen PostgreSQL-Betrieb werden Tupel, die durch eine Aktualisierung gelöscht oder veraltet gemacht werden, nicht physisch aus ihrer Tabelle entfernt; sie bleiben vorhanden, bis VAKUUM ausgeführt wird. Daher müssen Sie regelmäßig VAKUUM betreiben, insbesondere auf häufig aktualisierten Tabellen. Der belegte Speicherplatz muss dann zur Wiederverwendung durch neue Zeilen zurückgewonnen werden, um einen Ausfall von Festplattenspeicher zu vermeiden. Er gibt jedoch nicht den Speicherplatz an das Betriebssystem zurück.</block>
  <block id="db81319c35b48ed94867775a9a1ce1d7" category="paragraph">Der freie Platz innerhalb einer Seite ist nicht fragmentiert. VACUUM schreibt den gesamten Block neu, verpackt die restlichen Zeilen und hinterlässt einen einzigen zusammenhängenden Block freien Speicherplatz auf einer Seite.</block>
  <block id="8a5c17164c9920590fc057ee01f2fcb3" category="paragraph">Dagegen verdichtet VACUUM FULL Tabellen aktiv, indem eine völlig neue Version der Tabellendatei ohne Totraum geschrieben wird. Diese Aktion minimiert die Größe des Tisches, kann aber lange dauern. Außerdem wird zusätzlicher Speicherplatz für die neue Kopie der Tabelle benötigt, bis der Vorgang abgeschlossen ist. Ziel des routinemäßigen VAKUUMS ist es, die VOLLE VAKUUMAKTIVITÄT zu vermeiden. Bei diesem Prozess werden nicht nur Tabellen auf der Mindestgröße gespeichert, sondern auch der Festplattenspeicherplatz weiterhin gleichmäßig genutzt.</block>
  <block id="d3213224909897cac25fe1359e587293" category="summary">PostgreSQL-Initialisierung</block>
  <block id="61bcd96a2c1f8026527cbf2019d6e9a4" category="doc">Initialisierung</block>
  <block id="f4f9dac58f7c47e819293af5f2dd1177" category="paragraph">Sie erstellen mithilfe von ein neues Datenbankcluster<block ref="abc91e782cd3950bfa31202aff74ca69" prefix=" " category="inline-code"></block> Programm. An<block ref="abc91e782cd3950bfa31202aff74ca69" prefix=" " category="inline-code"></block> Skript erstellt die Datendateien, Systemtabellen und Vorlagendatenbanken (template0 und template 1), die den Cluster definieren.</block>
  <block id="b668460552732302350bbb840d57931c" category="paragraph">Die Vorlagendatenbank stellt eine Bestandsdatenbank dar. Es enthält Definitionen für Systemtabellen, Standardansichten, Funktionen und Datentypen.<block ref="3865cf98fe802a965570b4a10a1d894b" prefix=" " category="inline-code"></block> Fungiert als Argument für den<block ref="abc91e782cd3950bfa31202aff74ca69" prefix=" " category="inline-code"></block> Skript, das den Speicherort des Datenbank-Clusters angibt.</block>
  <block id="8fcd14822a5b94d212898fe3e006526e" category="paragraph">Alle Datenbankobjekte in PostgreSQL werden intern von den jeweiligen OIDs verwaltet. Tabellen und Indizes werden auch von einzelnen OIDs verwaltet. Die Beziehungen zwischen Datenbankobjekten und ihren jeweiligen OIDs werden je nach Objekttyp in entsprechenden Systemkatalogtabellen gespeichert. OIDs von Datenbanken und Heap-Tabellen werden beispielsweise in gespeichert<block ref="d0fcebb608269edbd5d67486884ebed7" prefix=" " category="inline-code"></block> Und `pg_class. Sie können die OIDs durch Abfragen auf dem PostgreSQL-Client ermitteln.</block>
  <block id="d0e97e34fe92edd2facd0f7377b6340b" category="paragraph">Jede Datenbank verfügt über eigene einzelne Tabellen und Indexdateien, die auf 1 GB beschränkt sind. Jede Tabelle hat zwei zugehörige Dateien, die jeweils mit dem Suffix versehen sind<block ref="7b9b00c45b01f7b7c6d3a3c8ba2e9275" prefix=" " category="inline-code"></block> Und<block ref="a1d869a79e2f43693a6a416fcbdc2724" prefix=" " category="inline-code"></block>. Sie werden als freie Raumkarte und Sichtbarkeitskarte bezeichnet. Diese Dateien speichern die Informationen über die freie Speicherkapazität und haben Sichtbarkeit auf jeder Seite in der Tabellendatei. Indizes verfügen nur über individuelle freie Speicherplatzkarten und haben keine Sichtbarkeits-Karten.</block>
  <block id="048a7ed79caf84bb5c725efc5f474911" category="paragraph">Der<block ref="c28f4f32219f5ff99fb4b116980b8549" prefix=" " category="inline-code"></block> Das Verzeichnis enthält die Write-Ahead-Protokolle. Mit Write-Ahead-Protokollen werden die Zuverlässigkeit und Performance der Datenbank verbessert. Immer wenn Sie eine Zeile in einer Tabelle aktualisieren, schreibt PostgreSQL die Änderung zuerst in das Write-Ahead-Protokoll und schreibt später die Änderungen auf die eigentlichen Datenseiten auf eine Festplatte. Der<block ref="f7223cfaa9416056a91e259e326ac5cf" prefix=" " category="inline-code"></block> Das Verzeichnis enthält normalerweise mehrere Dateien, aber initdb erstellt nur die erste. Zusätzliche Dateien werden bei Bedarf hinzugefügt. Jede xlog-Datei ist 16 MB lang.</block>
  <block id="2bd2440a8b5fed6660918b5f10f685bb" category="doc">Dateisysteme</block>
  <block id="81d00501c34ba5f161f685a99dce0d13" category="paragraph">PostgreSQL kann auf NFS- oder SAN-Dateisystemen gehostet werden.</block>
  <block id="789a6c7dd865d16eb1df122bcc5c9a3a" category="admonition">*NetApp empfiehlt* NFSv4.1 zu verwenden, wenn NFSv4-Funktionen erforderlich sind. Es gibt einige funktionale Verbesserungen am NFSv4-Protokoll in NFSv4.1, die die Ausfallsicherheit in bestimmten Edge-Fällen verbessern.</block>
  <block id="36772d6dfc6e102eff552ffad6b98690" category="paragraph">Verwenden Sie beim Mounten eines NFS-Dateisystems die folgende Mount-Option:</block>
  <block id="8e86e0aee135afb67c6a1d3d6e0f3306" category="inline-link-macro">NFS-Übertragungsgrößen</block>
  <block id="8952190775a545f4f8fdf241a9359455" category="paragraph">Informationen zur Verbesserung der NFS-Performance finden Sie unter <block ref="4e8f03f35a599a194f36d03d2b8495dd" category="inline-link-macro-rx"></block>.</block>
  <block id="d84b41126744795c4ee82f7b256e7234" category="inline-link-macro">FC SAN</block>
  <block id="b69b3938a2935a6c5ad8e3f696efd637" category="paragraph">Anleitungen zur SAN-Konfiguration und wichtige Details zu LVM-Striping und LUN-Anzahl finden Sie unter <block ref="588ec6ef762c46d35337665cf518bf6a" category="inline-link-macro-rx"></block>.</block>
  <block id="2c8c2171fc87c96e58fb40d8714f85cf" category="doc">PostgreSQL Architektur</block>
  <block id="ee62b4420d426c21a46d892ac084872a" category="paragraph">PostgreSQL ist ein RDBMS, das auf Client- und Serverarchitektur basiert. Eine PostgreSQL-Instanz wird als Datenbank-Cluster bezeichnet, bei dem es sich um eine Sammlung von Datenbanken und nicht um eine Sammlung von Servern handelt.</block>
  <block id="89c30c326e106773af32af40255b92a8" category="inline-image-macro">Fehler: Grafik nicht gefunden</block>
  <block id="54c2dd41fd1ad3efa25e80bee0bae549" category="paragraph">In einer PostgreSQL-Datenbank gibt es drei Hauptelemente: Den Postmaster, das Frontend (Client) und das Backend Der Client sendet Anfragen an den Postmaster mit Informationen wie IP-Protokoll und zu welcher Datenbank eine Verbindung hergestellt werden soll. Der Postmaster authentifiziert die Verbindung und leitet sie zur weiteren Kommunikation an den Back-End-Prozess weiter. Der Back-End-Prozess führt die Abfrage aus und sendet Ergebnisse direkt an das Frontend (Client).</block>
  <block id="9f96e07bbaf7c0237047d6d0f95301a8" category="paragraph">Eine PostgreSQL-Instanz basiert auf einem Multiprocess-Modell statt auf einem Multithread-Modell. Es gibt mehrere Prozesse für verschiedene Jobs, und jeder Prozess hat seine eigene Funktionalität. Zu den wichtigsten Prozessen gehören der Clientprozess, der WAL Writer-Prozess, der Background Writer-Prozess und der Checkpointer-Prozess:</block>
  <block id="6aebf901bd4be26a765c56e4133b3798" category="list-text">Wenn ein Client-Prozess (Vordergrund) Lese- oder Schreibanforderungen an die PostgreSQL-Instanz sendet, werden keine Daten direkt auf die Festplatte geschrieben oder gelesen. Zuerst werden die Daten in gemeinsam genutzten Puffern und WAL-Puffern (Write-Ahead Logging) gepuffert.</block>
  <block id="458239ee6c634dc5fef96f9dfab275f0" category="list-text">Ein WAL-Schreibprozess manipuliert den Inhalt der gemeinsam genutzten Puffer und WAL-Puffer, um in die WAL-Protokolle zu schreiben. WAL-Protokolle sind in der Regel Transaktionsprotokolle von PostgreSQL und werden sequenziell geschrieben. Um die Reaktionszeit aus der Datenbank zu verbessern, schreibt PostgreSQL zunächst in die Transaktionsprotokolle und bestätigt den Client.</block>
  <block id="9ec2999256fe568cd596b42e7da2cc39" category="list-text">Um die Datenbank in einen konsistenten Zustand zu versetzen, überprüft der Background Writer-Prozess den gemeinsam genutzten Puffer regelmäßig auf fehlerhafte Seiten. Anschließend überträgt es die Daten auf die Datendateien, die auf NetApp Volumes oder LUNs gespeichert sind.</block>
  <block id="5c852dd8ba7215c01dfde8e98f6c46c6" category="list-text">Der Checkpointer-Prozess läuft auch periodisch (seltener als der Hintergrundprozess) und verhindert jegliche Änderung der Puffer. Er signalisiert dem WAL Writer-Prozess, den Checkpoint-Datensatz zu schreiben und an das Ende der WAL-Protokolle zu löschen, die auf der NetApp-Festplatte gespeichert sind. Er signalisiert auch, dass der Background Writer-Prozess alle fehlerhaften Seiten auf die Festplatte schreibt und auf diese schreibt.</block>
  <block id="0a7b1215fd0b9621d4d7300f88b2906c" category="doc">Datensicherungssoftware</block>
  <block id="e265011e47d11db43ee112fd2fdc9d5b" category="paragraph">Das NetApp SnapCenter Plug-in für die PostgreSQL Datenbank bietet in Kombination mit Snapshot und NetApp FlexClone Technologien folgende Vorteile:</block>
  <block id="4dcdaba06a92b8fecfdc823643a71723" category="list-text">Schnelles Backup und Restore:</block>
  <block id="aee746a577a1baebdc33197fb5f3a279" category="list-text">Platzsparende Klone:</block>
  <block id="b96bb0cd2ebc0389b6670602ac80d983" category="list-text">Aufbau eines schnellen und effektiven Disaster Recovery-Systems</block>
  <block id="9e060ad00fced94f2616dd71fbc49f76" category="paragraph">Unter den folgenden Umständen bevorzugen Sie die Premium-Backup-Partner von NetApp, z. B. Veeam Software und CommVault:</block>
  <block id="0ee17b3b55ea2b0af3d90985bc347775" category="list-text">Management von Workloads in heterogener Umgebung</block>
  <block id="88fbde7bbe0274fbe9e7ce01c563d03c" category="list-text">Speichern von Backups in der Cloud oder auf Tape zur langfristigen Aufbewahrung</block>
  <block id="445e3e0cce7f959696dde65b3be27843" category="list-text">Unterstützung für eine Vielzahl von Betriebssystemversionen und -Typen</block>
  <block id="21c5d67cc22beaf7d7c9c84c8deaabbe" category="paragraph">SnapCenter Plugin für PostgreSQL ist Community-unterstütztes Plugin und das Setup und die Dokumentation ist auf NetApp Automation Store verfügbar. Mit SnapCenter können Anwender Datenbanken sichern sowie Daten Remote klonen und wiederherstellen.</block>
  <block id="7d334ca369e4a752ec91b1503183f0ed" category="summary">Lösungen für SAP HANA und AnyDB</block>
  <block id="1ac73696f4529e3901b0d4e5430365cb" category="doc">SAP HANA und SAP mit AnyDB</block>
  <block id="2c1b27a986b5e37a810d61f72b23ee4b" category="paragraph">Best Practices für die Konfiguration, Verwaltung und Automatisierung von SAP-Lösungen finden Sie auf der Seite NetApp SAP-Lösungen.</block>
  <block id="6c92285fa6d3e827b198d120ea3ac674" category="inline-link-macro">Hier</block>
  <block id="ee1e67308b27672a8f54eace4c615a98" category="paragraph">Klicken Sie auf <block ref="c95e4a3e1de9e00fefc4bf8a7ce42893" category="inline-link-macro-rx"></block> Für mehr.</block>
  <block id="beb3ca55ed0a53a38a2b97540b05d6e4" category="summary">Microsoft SQL Server auf ONTAP</block>
  <block id="7636ae91f443b605f05bed59d7d57a02" category="doc">Disaster Recovery für Microsoft SQL Server</block>
  <block id="810304d54e0a61663cfc457b0894037b" category="paragraph">NetApp bietet verschiedene Ansätze zur Verbesserung der Datenverfügbarkeit bei Hardware-, Software- oder Standortausfällen.</block>
  <block id="44665451998410d7d5e3e61e1785d112" category="paragraph">NetApp bietet Technologien wie MetroCluster, SnapMirror Business Continuity (SM-BC) , SnapMirror. Sie finden eine Beschreibung dieser Funktionen <block ref="08de3f734af11bdee4de0329d4acad67" category="inline-link-macro-rx"></block>.</block>
  <block id="9c1e9d82d3220658621f72dca978adb0" category="section-title">NetApp SnapMirror</block>
  <block id="46983273062fdc8ce8561a9ce89cdc5b" category="paragraph">NetApp SnapMirror bietet eine schnelle und flexible Enterprise-Lösung zum Spiegeln oder Replizieren von Daten über LANs und WANs. Die SnapMirror Technologie überträgt nach dem ersten Basistransfer nur geänderte 4-KB-Datenblöcke zum Ziel, wodurch die Anforderungen an die Netzwerkbandbreite erheblich gesenkt werden. SnapMirror bietet asynchrone Replizierung auf Volume-Ebene, die auf einem konfigurierten Update-Intervall für die Replizierung basiert.
Nachfolgend finden Sie Empfehlungen für SnapMirror für SQL Server:</block>
  <block id="5f3bfe8f92842bdc2f9455d4102f2531" category="list-text">Bei Verwendung von CIFS muss die Ziel-SVM Mitglied derselben Active Directory-Domäne sein, der die Quell-SVM angehört, damit die in NAS-Dateien gespeicherten Zugriffssteuerungslisten (Access Control Lists, ACLs) während der Wiederherstellung nach einem Notfall nicht beschädigt werden.</block>
  <block id="e0fd410ebdc68e7ca628bbca66b63ff4" category="list-text">Die Verwendung von Ziel-Volume-Namen, die mit den Namen des Quell-Volume übereinstimmen, ist nicht erforderlich, kann jedoch das Mounten von Ziel-Volumes in das Ziel einfacher gestalten. Wenn CIFS verwendet wird, müssen Sie den Ziel-NAS-Namespace in Pfaden und Verzeichnisstruktur mit dem Quell-Namespace identisch machen.</block>
  <block id="14b01fb6bdbebef1f8a00c7f84926307" category="list-text">Aus Konsistenzgründen sollten Sie die SnapMirror Aktualisierung nicht von den Controllern planen. Aktivieren Sie jedoch das SnapMirror Update von SnapCenter, um SnapMirror zu aktualisieren, nachdem ein vollständiger oder ein Protokoll-Backup abgeschlossen wurde.</block>
  <block id="18c6a681ea46e1ed394e092461bb53ef" category="list-text">Verteilen Sie Volumes, die SQL Server-Daten enthalten, auf verschiedene Nodes im Cluster, damit alle Clusterknoten SnapMirror-Replikationsaktivitäten gemeinsam nutzen können. Diese Verteilung optimiert die Nutzung von Knotenressourcen.</block>
  <block id="0a01e6837f5c691536f0b6cbdd0232ec" category="inline-link-macro">TR-4015: SnapMirror Konfigurations- und Best Practices-Leitfaden für ONTAP 9</block>
  <block id="1cca1a3fad8c6dd7e2dadbd2aa08bf07" category="paragraph">Weitere Informationen zu SnapMirror finden Sie unter <block ref="64b916f792bad525a069a243c092b62e" category="inline-link-macro-rx"></block>.</block>
  <block id="3d4b417d78ff0ef4c84f0c043de24b10" category="doc">Datenbanksicherheit</block>
  <block id="555119357ec4acedae2d155a0c65df5a" category="paragraph">Die Sicherung der Datenbank hat immer Priorität, und DBA und Organisation erzwingen Absicherungsprüfpunkte, um nur Benutzern den Zugriff auf Server und Datenbank zu erlauben. Vom regelmäßigen Patching des Servers über die Konfiguration der Firewall bis hin zum Entfernen von generischem Gast- oder öffentlichem Zugriff und der Gewährung minimaler Berechtigungen für eingeschränkte Benutzer zur Ausführung von Anwendungen oder zum Ausführen von Ad-hoc-Berichtsabfragen gehören alle zum Schutz des Unternehmens-Ecosystems.</block>
  <block id="3f0ff45bcce968caef3a216a79681533" category="paragraph">In immer größeren Fällen von Ransomware oder internen Bedrohungen müssen Geschäftsdaten und Backups geschützt werden und müssen nach böswilligen Angriffen eine schnelle Wiederherstellung in konsistenter Reihenfolge ermöglichen. Angreifer können immer noch Wege finden, Daten zu entführen.
ONTAP bietet eine Vielzahl an Funktionen zur Sicherung von Daten auf NAS und SAN.</block>
  <block id="8b64c006213e96766bdb598b57396083" category="paragraph">ONTAP ermöglicht die Sicherung flexibler Volumes auf einem SnapLock Enterprise oder einem SnapLock Compliance Volume, indem eine SnapMirror Beziehung zwischen FlexVol Volume als Quelle und SnapLock Volume als Ziel erstellt wird.Snapshot Kopien, die auf einem sekundären Storage gesichert werden, werden mithilfe der SnapLock Technologie vor Änderungen oder Löschungen geschützt, bevor das Aufbewahrungsdatum erreicht wird.Dies ist basiert Sie gilt für die SnapMirror Richtlinie, die mit einer Beziehung verknüpft ist, bei der die Anzahl der Snapshot Kopien für ein bestimmtes snapmirror-Label definiert ist, das auf dem SnapLock Ziel-Volume aufbewahrt wird. die Wiederherstellung eines Snapshots mit LUN-Daten kann auf einem nicht-SnapLock Volume über den Wiederherstellungsvorgang von snapmirror durchgeführt werden. In ONTAP 9.13.1 kann eine FlexClone Kopie erstellt werden, indem der SnapLock-Typ als nicht-snaplock angegeben wird. Weitere Informationen zu SnapLock finden Sie unter <block ref="ef172f6fa5e7e0d1ce81bd97ee5f82e3" category="inline-link-macro-rx"></block>.</block>
  <block id="ccad2a7107c9ef5d1565c269187f32ef" category="paragraph"><block ref="ccad2a7107c9ef5d1565c269187f32ef" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0b6dbdd1b25ffa8aa9efcccb98bb3fbe" category="paragraph">Manipulationssichere Snapshot Kopien oder Sperrung der Snapshot-Kopie: Snapshot-Kopie ist schnelle Möglichkeit, Datenbank zu schützen und wiederherzustellen. Ein Angreifer kann Snapshot-Kopien löschen. Dies könnte die letzte Option zum Wiederherstellen einer Datenbank im Fall von Datenbeschädigungen sein. Durch die Aktivierung manipulationssicherer Snapshot Kopien wird die Snapshot Kopie auf dem primären oder sekundären ONTAP System gesperrt, um zu verhindern, dass Administratoren oder nicht vertrauenswürdige Administratoren Snapshots für einen bestimmten Zeitraum löschen. Die manipulationssichere Snapshot Kopie ist ab ONTAP 9.12.1 verfügbar und erfordert die SnapLock Lizenz und die Initialisierung der Compliance-Uhr.</block>
  <block id="310ba850db6109a11c606bdc5224be97" category="paragraph">ONTAP verfügt über eine Funktion zur Verifizierung durch mehrere Administratoren. Dies bedeutet, dass kein einzelner Administrator über die vollständige Berechtigung verfügt, Snapshot Kopien zu löschen oder Volumes zu ändern. Dies bietet zusätzliche Sicherheit, um zu vermeiden, dass Volumes oder Snapshot Kopien von nicht vertrauenswürdigen Administratoren erneut manipuliert werden.</block>
  <block id="77641f4a3e4406855e878235cbd89b87" category="doc">CPU-Konfiguration</block>
  <block id="a51adad5719779145ac252822e328611" category="section-title">Hyperthreading</block>
  <block id="fe520b79816bad6a21fbebcb205c7ca9" category="paragraph">Hyperthreading ist Intels proprietäre Implementierung für simultanes Multithreading (SMT), die die Parallelisierung von Berechnungen (Multitasking) auf x86-Mikroprozessoren verbessert.</block>
  <block id="005f484c2235e04f39d2e69256147281" category="paragraph">Hardware, die Hyperthreading verwendet, ermöglicht die Darstellung der logischen hyperthread-CPUs als physische CPUs für das Betriebssystem. SQL Server erkennt dann die physischen CPUs, die das Betriebssystem darstellt, und kann so die Hyper-Threading-Prozessoren verwenden.</block>
  <block id="673c216e20d1cf8827f347c01dace664" category="paragraph">Der Nachteil hierbei ist, dass jede SQL Server-Version ihre eigenen Einschränkungen hinsichtlich der Rechenleistung hat, die sie verwenden kann. Weitere Informationen finden Sie unter Kapazitätsgrenzen nach Edition von SQL Server berechnen.</block>
  <block id="932a9271c08db114962ce3791480f371" category="paragraph">Bei der Lizenzierung von SQL Server gibt es zwei wichtige Denkschulen. Die erste wird als Server + Client Access License (CAL)-Modell bezeichnet; die zweite ist das pro Prozessor-Core-Modell. Obwohl Sie mit der Server + CAL-Strategie auf alle in SQL Server verfügbaren Produktfunktionen zugreifen können, gibt es eine Hardwaregrenze von 20 CPU-Kernen pro Sockel. Selbst wenn Sie SQL Server Enterprise Edition + CAL für einen Server mit mehr als 20 CPU-Kernen pro Socket verwenden, kann die Anwendung nicht alle diese Kerne gleichzeitig auf dieser Instanz verwenden. Abbildung zeigt die SQL Server-Protokollmeldung nach dem Start, die die Durchsetzung des Kernlimits anzeigt.</block>
  <block id="d06fce44fdcf20791141e7585205a477" category="section-title">Protokolleinträge geben an, wie viele Kerne nach dem Start von SQL Server verwendet werden.</block>
  <block id="f172c98eb1173f29e1d98efffb0e63f9" category="paragraph"><block ref="f172c98eb1173f29e1d98efffb0e63f9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cf0e2551e639758cc3c4d82df655eccd" category="inline-link-macro">SQL Server 2022: Ihre moderne Datenplattform</block>
  <block id="809c9e1f6ce0bc82bf42fae361c6f43e" category="paragraph">Um alle CPUs zu verwenden, sollten Sie daher die Prozessorkern-Lizenz verwenden. Weitere Informationen zur SQL Server-Lizenzierung finden Sie unter <block ref="457abfaf1083b1cbfc49f2783069c6cd" category="inline-link-macro-rx"></block>.</block>
  <block id="cb8d56a3511d402b7355db8502a54c5a" category="section-title">CPU-Affinität</block>
  <block id="884be48d06a17be095fb51de089dfc89" category="paragraph">Es ist unwahrscheinlich, dass Sie jemals die Standardeinstellungen für die Prozessoraffinität ändern müssen, es sei denn, Sie stoßen auf Leistungsprobleme, aber es lohnt sich immer noch zu verstehen, was sie sind und wie sie funktionieren.</block>
  <block id="74f896768ee487acfd4c42370c202bed" category="paragraph">SQL Server unterstützt die Prozessoraffinität durch zwei Optionen:</block>
  <block id="cb315fb2b62c836ba51357d46f2e8c3f" category="list-text">CPU-Affinitätsmaske</block>
  <block id="cb00a2408ea648cf85edfd7dbb23fbe0" category="list-text">Affinity-E/A-Maske</block>
  <block id="14ad08466dec6635067b988a82e91a8e" category="paragraph">SQL Server verwendet alle CPUs, die über das Betriebssystem verfügbar sind (wenn die Prozessorkern-Lizenz gewählt wird). Es erstellt Scheduler auf allen CPUs, um die Ressourcen für jeden gegebenen Workload optimal zu nutzen. Beim Multitasking kann das Betriebssystem oder andere Anwendungen auf dem Server die Prozess-Threads von einem Prozessor zum anderen wechseln. SQL Server ist eine ressourcenintensive Applikation und daher kann die Performance in diesem Fall beeinträchtigt werden. Um den Effekt zu minimieren, können Sie die Prozessoren so konfigurieren, dass die gesamte SQL Server-Last an eine vorgewählte Prozessorgruppe weitergeleitet wird. Dies wird durch die CPU Affinitätsmaske erreicht.</block>
  <block id="28a51b601de21080b76fe2d8b2ec8101" category="paragraph">Die Affinity I/O-Maskenoption bindet SQL Server-Festplatten-I/O an eine Teilmenge von CPUs. In SQL Server-OLTP-Umgebungen kann diese Erweiterung die Performance von SQL Server-Threads steigern, die I/O-Vorgänge ausgeben.</block>
  <block id="49e103832576f4486179df8868372d17" category="section-title">Max. Parallelitätsgrad (MAXDOP)</block>
  <block id="f7e9f8e341a301aec4560db108b93020" category="paragraph">Standardmäßig verwendet SQL Server während der Abfrageausführung alle verfügbaren CPUs (wenn die Prozessorkernlizenz gewählt wurde).</block>
  <block id="9bdcdbe52ea41cf96b314b7b7671bd2a" category="paragraph">Obwohl dies ideal für große Abfragen ist, kann es zu Leistungsproblemen und zur Begrenzung der Parallelität kommen. Ein besserer Ansatz besteht darin, die Parallelität auf die Anzahl der physischen Kerne in einem einzelnen CPU-Socket zu beschränken. Beispiel: Auf einem Server mit zwei physischen CPU-Sockeln mit 12 Kernen pro Socket, unabhängig von Hyperthreading, sollte MAXDOP auf 12 gesetzt werden. MAXDOP kann nicht festlegen, welche CPU verwendet werden soll. Stattdessen beschränkt es die Anzahl der CPUs, die von einer einzelnen Batch-Abfrage verwendet werden können.</block>
  <block id="1a6b79859b80796a108bd348f98856f6" category="admonition">*NetApp empfiehlt* für DSS wie Data Warehouses, beginnen Sie mit dieser Einstellung bei 50 oder so und stimmen Sie ggf. auf oder ab. Stellen Sie sicher, dass Sie die kritischen Abfragen in Ihrer Anwendung messen und gegebenenfalls anpassen.</block>
  <block id="a99f7ebb3b0f5b0ecea93ed586b2a17d" category="section-title">Max. Worker-Threads</block>
  <block id="aff27140f50a549b1331add8d5025f7e" category="paragraph">Die Option Max. Worker-Threads hilft, die Leistung zu optimieren, wenn eine große Anzahl von Clients mit SQL Server verbunden ist.</block>
  <block id="aefc7f2ee96effbbbe49e6ece6d2f72a" category="paragraph">Normalerweise wird für jede Abfrageanforderung ein separater Betriebssystemthread erstellt. Wenn Hunderte von gleichzeitigen Verbindungen zu SQL Server hergestellt werden, verbraucht ein Thread pro Abfrage große Mengen an Systemressourcen. Die Option Max Worker Threads verbessert die Leistung, indem SQL Server in die Lage versetzt wird, einen Pool von Worker-Threads zu erstellen, um eine größere Anzahl von Abfrage-Anforderungen zu bedienen.</block>
  <block id="decd79137325e1efbc7b994f946ea24f" category="paragraph">Der Standardwert ist 0, wodurch SQL Server die Anzahl der Worker-Threads beim Start automatisch konfigurieren kann. Dies funktioniert für die meisten Systeme. Max Worker-Threads sind eine erweiterte Option und sollten nicht ohne Unterstützung durch einen erfahrenen Datenbankadministrator (DBA) geändert werden.</block>
  <block id="030a270970f70c1bd91d3689b6f95f3f" category="inline-link-macro">Konfigurieren Sie die Option Max Worker Threads Server Configuration</block>
  <block id="2a0c648df721b9bc2643d59c4a3a310a" category="paragraph">Wann sollten Sie SQL Server so konfigurieren, dass mehr Worker-Threads verwendet werden? Wenn die durchschnittliche Länge der Arbeitswarteschlange für jeden Scheduler über 1 liegt, können Sie vom Hinzufügen weiterer Threads zum System profitieren, jedoch nur, wenn die Last nicht CPU-gebunden ist oder andere schwere Wartezeiten auftritt. Wenn einer dieser Vorgänge stattfindet, sind weitere Threads nicht hilfreich, da sie schließlich auf andere Systemengpässe warten müssen. Weitere Informationen zu max. Worker-Threads finden Sie unter <block ref="77c391df5f9f06cdf367c2a7314ce351" category="inline-link-macro-rx"></block>.</block>
  <block id="67028b81f2fa3e41f3a791718fec0fc7" category="paragraph"><block ref="67028b81f2fa3e41f3a791718fec0fc7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="29d04e616d2293c4c7538dd6226feac5" category="section-title">Konfigurieren von max Worker-Threads mit SQL Server Management Studio</block>
  <block id="5962130d833e0408cf58a87e342bc1f9" category="doc">Microsoft SQL Server tempdb-Dateien</block>
  <block id="625156cc6cef9a3c56b1b535579bd2c9" category="paragraph">NetApp empfiehlt, tempdb-Dateien proaktiv auf ihre volle Größe aufzublähen, um eine Festplattenfragmentierung zu vermeiden.</block>
  <block id="ca75041d415f4dafabb49b7f06b634ed" category="paragraph">Seitenkonflikte können auf den Seiten der lobal Allocation Map (GAM), der Shared Global Allocation Map (SGAM) oder der Page Free Space (PFS) auftreten, wenn SQL Server auf spezielle Systemseiten schreiben muss, um neue Objekte zuzuweisen. Verriegelungen schützen (sperren) diese Seiten im Speicher. In einer stark ausgelasteten SQL Server-Instanz kann es lange dauern, bis ein Latch auf einer Systemseite in tempdb abgerufen wird. Dies führt zu längeren Abfragezeiten und wird als Latch Contention bezeichnet. Lesen Sie die folgenden Best Practices für das Erstellen von tempdb-Datendateien:</block>
  <block id="44dbc82801d84781083ed9e23b63be00" category="list-text">Für &lt; oder = bis 8 Kerne: Tempdb-Datendateien = Anzahl der Kerne</block>
  <block id="6203fcdbdad10bb603fd00edd2f0fcf5" category="list-text">Für &gt; 8 Kerne: 8 tempdb-Datendateien</block>
  <block id="b9f341e4fb0e6b384aa7ec0b5c33f964" category="paragraph">Mit dem folgenden Beispielskript wird tempdb geändert, indem acht tempdb-Dateien erstellt und tempdb auf den Mount-Punkt verschoben wird<block ref="ae6fbe62f3ddc46fa9a9885244d23675" prefix=" " category="inline-code"></block> Für SQL Server 2012 und höher.</block>
  <block id="0424163d6b24f29436021dfd7072863b" category="paragraph">Ab SQL Server 2016 wird die Anzahl der für das Betriebssystem sichtbaren CPU-Kerne während der Installation automatisch erkannt. Auf Basis dieser Anzahl berechnet und konfiguriert SQL Server die Anzahl der für eine optimale Performance erforderlichen tempdb-Dateien.</block>
  <block id="1c5b37437282a3648dde78afd914e452" category="doc">Microsoft SQL Server – Übersicht</block>
  <block id="9aa5016539f88d8f1972a16ce9babd34" category="paragraph">SQL Server bildet die Grundlage der Microsoft Datenplattform. Es bietet geschäftskritische Performance mit in-Memory-Technologien und schnelleren Einblick in alle Daten – lokal und in der Cloud.</block>
  <block id="93561e0df88dabbfc4999f97e0030525" category="admonition">Diese Dokumentation ersetzt die zuvor veröffentlichten technischen Berichte _TR-4590: Best Practice Guide for Microsoft SQL Server with ONTAP_</block>
  <block id="8133a02d7327679696821fb31b105177" category="paragraph">Microsoft SQL Server baut auf den geschäftskritischen Funktionen früherer Versionen auf und bietet für geschäftskritische Applikationen eine herausragende Performance, Verfügbarkeit und Verwaltbarkeit. Das Storage-System ist ein entscheidender Faktor für die Gesamt-Performance einer SQL Server Datenbank. NetApp bietet verschiedene Produkte für eine SQL Server Datenbank, die Performance der Enterprise-Klasse bietet und gleichzeitig erstklassige Tools für das Management Ihrer Umgebung bereitstellt.</block>
  <block id="0bdfc026961d516d3d473152b4b6a87e" category="section-title">Zweck und Umfang</block>
  <block id="d0554e23b25bb82082a0cd9eaf810d0f" category="paragraph">Dieser Abschnitt enthält Best Practices und Überlegungen zum Design für die Implementierung von SQL Server auf NetApp Storage-Systemen mit NetApp ONTAP Software mit dem Ziel einer effektiven und effizienten Storage-Implementierung sowie einer umfassenden Planung der Datensicherung und Datenhaltung. Dieser Leitfaden beschränkt sich auf technische Designrichtlinien basierend auf den Designprinzipien und bevorzugten Standards, die NetApp für die Storage-Infrastruktur bei der Implementierung von SQL Server empfiehlt. Die End-to-End-Implementierung ist nicht im Umfang dieses Berichts enthalten.</block>
  <block id="cf4cab9c6fd24025b34dfcae06e9b6fc" category="paragraph">Anhand der in diesem Leitfaden beschriebenen Best Practices und Empfehlungen können SQL Server-Architekten und NetApp Storage-Administratoren eine hochverfügbare und einfach zu managende SQL Server-Umgebung erstellen und strenge SLAs einhalten. NetApp geht davon aus, dass der Leser über die folgenden Kenntnisse verfügt:</block>
  <block id="9801f873fe2232da0de3cbab00483bfb" category="list-text">NetApp ONTAP Software</block>
  <block id="3b5b2ca12603a36517ce602ffe47361c" category="list-text">NetApp SnapCenter als Backup-Software, einschließlich:</block>
  <block id="36a92a010308100e1efc10d9eb98c369" category="list-text">SnapCenter Plug-in für Microsoft Windows</block>
  <block id="ec51578d7d8f930329548bf3d00d7038" category="list-text">SnapCenter Plug-in für SQL Server</block>
  <block id="a6d698a68f555339f6e91957f636ad69" category="list-text">Architektur und Administration von Microsoft SQL Server</block>
  <block id="697ea025ecb303d4f40d1bf3a8b4bde0" category="inline-link-macro">NetApp Interoperabilitäts-Matrix-Tool (IMT)</block>
  <block id="c02eaaaf0eed9e51c3a9e1e9ae8b9147" category="paragraph">Informationen zur Konfigurationskompatibilität im gesamten NetApp Stack finden Sie im <block ref="ea0e6fe442c1f7a042a8853ffcc2b382" category="inline-link-macro-rx"></block>.</block>
  <block id="fbd4c4f9516af91c6c3cb5fa35fb5720" category="doc">Überlegungen zum Microsoft SQL Server-Storage</block>
  <block id="8c2a9e7195a263b5d79d397f5c6a9f68" category="paragraph">Die Kombination aus NetApp Storage-Lösungen und Microsoft SQL Server ermöglicht die Erstellung von Datenbank-Storage-Designs der Enterprise-Klasse, die den anspruchsvollsten Applikationsanforderungen von heute gerecht werden.</block>
  <block id="8136e237a15b0f72e5d7a60392225d17" category="paragraph">Um beide Technologien zu optimieren, ist es wichtig, das SQL Server-I/O-Muster und die Merkmale zu verstehen. Ein gut geplantes Storage-Layout für eine SQL Server Datenbank unterstützt die Performance von SQL Server und das Management der SQL Server Infrastruktur. Ein gutes Storage-Layout ermöglicht außerdem eine erfolgreiche Erstimplementierung und ein reibungsloses Wachstum der Umgebung im Laufe der Zeit, während das Unternehmen wächst.</block>
  <block id="3da07c62fca4dd242f7ffcfcf72998be" category="section-title">Datenspeicher Design</block>
  <block id="9e45010900186b3cbbe04f954a6f3562" category="paragraph">Für SQL Server-Datenbanken, die keine Backups mit SnapCenter durchführen, empfiehlt Microsoft, die Daten und Log-Dateien auf separaten Laufwerken zu platzieren. Bei Anwendungen, die gleichzeitig Daten aktualisieren und anfordern, ist die Protokolldatei schreibintensiv und die Datendatei (je nach Anwendung) ist Lese-/schreibintensiv. Für den Datenabruf wird die Protokolldatei nicht benötigt. Daher können Datenanfragen aus der Datendatei auf dem eigenen Laufwerk bearbeitet werden.</block>
  <block id="df018ea4abdb71f91802ea1d4fb0fb37" category="inline-link-macro">Platzieren Sie Daten- und Protokolldateien auf separaten Laufwerken</block>
  <block id="f2f25c68d67c561be1926b4b06e676b0" category="paragraph">Wenn Sie eine neue Datenbank erstellen, empfiehlt Microsoft, getrennte Laufwerke für die Daten und Protokolle anzugeben. Um Dateien nach der Datenbankerstellung zu verschieben, muss die Datenbank offline geschaltet werden. Weitere Empfehlungen von Microsoft finden Sie unter <block ref="04fab8828edf0d2e95eff3c4f124b372" category="inline-link-macro-rx"></block>.</block>
  <block id="d5350d8759b1ec84607e47908809058e" category="section-title">Aggregate</block>
  <block id="b8212b86fca1dcaeb0438529a03212c3" category="paragraph">Aggregate sind die primären Storage-Container für NetApp Storage-Konfigurationen und enthalten eine oder mehrere RAID-Gruppen, die sowohl Daten- als auch Parity-Festplatten bestehen. NetApp hat verschiedene I/O-Workload-Merkmalstests mit gemeinsam genutzten und dedizierten Aggregaten mit getrennten Datendateien und Transaktions-Log-Dateien durchgeführt. Die Tests zeigen, dass ein großes Aggregat mit mehr RAID-Gruppen und Spindeln die Storage Performance optimiert und verbessert und Administratoren aus zwei Gründen einfacher zu managen sind:</block>
  <block id="5f9196be7c85ebe3a38375ace1f3a345" category="list-text">Ein großes Aggregat macht die I/O-Fähigkeiten aller Spindeln für alle Dateien verfügbar.</block>
  <block id="77f1d6b9cbcaf3663f6bdd19a821e773" category="list-text">Ein großes Aggregat ermöglicht die effizienteste Nutzung von Festplattenspeicher.</block>
  <block id="63d9962fabe500361986d05317bd65a5" category="paragraph">Platzieren Sie für Hochverfügbarkeit (HA) das sekundäre synchrone Replikat der SQL Server Always On Availability Group auf einer separaten Storage Virtual Machine (SVM) im Aggregat. Platzieren Sie zum Zweck der Disaster Recovery das asynchrone Replikat in einem Aggregat, das Teil eines separaten Storage-Clusters am DR-Standort ist, und Inhalte werden mithilfe der NetApp SnapMirror Technologie repliziert. NetApp empfiehlt eine Verfügbarkeit von mindestens 10 % freien Speicherplatz in einem Aggregat zugunsten der optimalen Storage-Performance.</block>
  <block id="c6f01c78bfe0a0a495cb5d3ed77824a9" category="section-title">Volumes</block>
  <block id="5ec65e803efce0f0779c59e4df9b2a71" category="paragraph">NetApp FlexVol Volumes werden erstellt und befinden sich in den Aggregaten. Zahlreiche Volumes können in einem einzigen Aggregat erstellt werden. Jedes Volume kann ohne Ausfallzeit für die Benutzer erweitert, verkleinert oder zwischen Aggregaten verschoben werden.</block>
  <block id="17fce39141e6fa457c789ce2c3239b0c" category="section-title">Überlegungen zum Volume-Design</block>
  <block id="d1c9fdbcdbb8521971decf35c6d1c0c8" category="paragraph">Bevor Sie ein Datenbank-Volume-Design erstellen, ist es wichtig zu wissen, wie das I/O-Muster und die Merkmale von SQL Server je nach Workload und Backup- und Recovery-Anforderungen variieren. Beachten Sie die folgenden NetApp Empfehlungen für flexible Volumes:</block>
  <block id="570f1006846b0d45ff44b4332b9b4d14" category="list-text">Verwenden Sie flexible Volumes, um SQL Server-Datenbankdateien zu speichern und die gemeinsame Nutzung von Volumes zwischen Hosts zu vermeiden.</block>
  <block id="674343739e297abb52c536a453ebaad0" category="list-text">Verwenden Sie NTFS-Bereitstellungspunkte anstelle von Laufwerksbuchstaben, um die Beschränkung auf 26 Laufwerksbuchstaben in Windows zu überschreiten. Bei der Verwendung von Volume-Mount-Punkten wird generell empfohlen, dem Volume-Label den gleichen Namen wie dem Mount-Punkt zu geben.</block>
  <block id="d5fe4f7f1c47df1ec78c926d21498f73" category="list-text">Konfigurieren Sie bei Bedarf eine Richtlinie für die automatische Größenanpassung von Volumes, um Speicherplatzbelegung zu verhindern. 17 Best Practice Guide für Microsoft SQL Server mit ONTAP © 2022 NetApp, Inc Alle Rechte vorbehalten.</block>
  <block id="fdb3a973962ea77cf56d76e12cff8c7d" category="list-text">Aktivieren Sie die Optimierung für Lesezugriffe auf dem Volume, wenn das I/O-Profil der SQL Server-Datenbank aus überwiegend großen sequenziellen Lesezugriffen besteht, beispielsweise mit System-Workloads zur Entscheidungsunterstützung. Die Optimierung der Lesezugriffe optimiert die Blöcke, um eine bessere Performance zu erzielen.</block>
  <block id="3a9320cf27fb328f77ec6153273784d5" category="list-text">Wenn Sie SQL Server auf einer SMB-Freigabe installieren, stellen Sie sicher, dass Unicode auf den SMB/CIFS-Volumes zum Erstellen von Ordnern aktiviert ist.</block>
  <block id="08a6901e4e7b04d6170563bc57864093" category="list-text">Setzen Sie den Wert der Reserve von NetApp Snapshot Kopien im Volume auf null, um die Überwachung aus betrieblicher Sicht zu vereinfachen.</block>
  <block id="156ce9adf6c474183396aa3cfb8f92f1" category="list-text">Deaktivieren Sie Zeitpläne und Aufbewahrungsrichtlinien für Storage Snapshot™ Kopien. Stattdessen können Sie SnapCenter verwenden, um Snapshot Kopien der SQL Server-Daten-Volumes zu koordinieren.</block>
  <block id="f2e00c12259a4bb11608f2a12fc8014a" category="list-text">Platzieren Sie die SQL Server Systemdatenbanken auf einem dedizierten Volume oder einer VMDK.</block>
  <block id="4176288dbc134524f79476ba4e57e3aa" category="list-text">Tempdb ist eine Systemdatenbank, die von SQL Server als temporärer Arbeitsbereich verwendet wird, insbesondere für I/O-intensive DBCC-CHECKDB-Vorgänge. Platzieren Sie diese Datenbank daher auf einem dedizierten Volume mit einem separaten Satz von Spindeln. In großen Umgebungen, in denen die Volume-Anzahl eine Herausforderung ist, können Sie tempdb in weniger Volumes konsolidieren und im gleichen Volume wie andere Systemdatenbanken nach einer sorgfältigen Planung speichern. Datenschutz für tempdb hat keine hohe Priorität, da diese Datenbank bei jedem Neustart von SQL Server neu erstellt wird.</block>
  <block id="57eda1aa66778bf3c77caa0294652ba8" category="list-text">Platzieren Sie Benutzerdatendateien (.mdf) auf separaten Volumes, da es sich um Workloads mit zufälligen Lese-/Schreibzugriffen handelt. Es ist üblich, Transaktions-Log-Backups häufiger zu erstellen als Datenbank-Backups. Legen Sie aus diesem Grund Transaktions-Log-Dateien (.ldf) auf ein separates Volume oder VMDK aus den Datendateien, so dass für jede Datei unabhängige Backup-Zeitpläne erstellt werden können. Durch diese Trennung werden auch die I/O-Vorgänge bei sequenziellen Schreibvorgängen aus den I/O-Vorgängen für zufällige Lese-/Schreibzugriffe von Datendateien isoliert und die SQL Server Performance deutlich verbessert.</block>
  <block id="b26e74ed6e2892c7e2bb95e414d460c6" category="section-title">LUN</block>
  <block id="b703a2ceaabee81dd9dfcfb3a4b738ee" category="list-text">Stellen Sie sicher, dass sich die Benutzerdatenbankdateien und das Protokollverzeichnis für das Protokoll-Backup auf separaten Volumes befinden, damit die Aufbewahrungsrichtlinie Snapshots bei Verwendung der SnapVault-Technologie nicht überschreibt.</block>
  <block id="152bb9192ea87919eda3b4f97fd4e1bf" category="list-text">Stellen Sie sicher, dass sich SQL Server-Datenbanken auf LUNs befinden, die von LUNs getrennt sind, die keine Datenbankdateien enthalten, z. B. Dateien für die Volltextsuche.</block>
  <block id="e2faf723544ceb1ea01ba41cef2d633a" category="list-text">Wenn sekundäre Datenbankdateien (als Teil einer Dateigruppe) auf separate Volumes platziert werden, wird die Performance der SQL Server Datenbank verbessert. Diese Trennung ist nur gültig, wenn die mdf-Datei der Datenbank ihre LUN nicht mit anderen mdf-Dateien teilt.</block>
  <block id="ae72f885471636cbfd0dbe902ddf24e1" category="list-text">Wenn Sie LUNs mit DiskManager oder anderen Werkzeugen erstellen, stellen Sie sicher, dass die Größe der Zuordnungseinheit beim Formatieren der LUNs auf 64K für Partitionen festgelegt ist.</block>
  <block id="ac4782a9243acaaff52164f9e47417d5" category="inline-link-macro">Microsoft Windows und natives MPIO unter den Best Practices von ONTAP für modernes SAN</block>
  <block id="934e206705ddafc720e4a8f25a4acded" category="list-text">Siehe <block ref="95506eaa4fca841adc20747ae4650d10" category="inline-link-macro-rx"></block> So wenden Sie Multipathing-Unterstützung unter Windows auf iSCSI-Geräte in den MPIO-Eigenschaften an.</block>
  <block id="31a8d85b6a44cffc2c7dfc6387696f31" category="section-title">Protokollverzeichnis</block>
  <block id="973781a026becacffaae9fd5fd5c2b7b" category="paragraph">Das Protokollverzeichnis wird in SQL Server angegeben, um die Backup-Daten des Transaktionsprotokolls auf Hostebene zu speichern. Wenn Sie SnapCenter zum Sichern von Protokolldateien verwenden, muss für jeden von SnapCenter verwendeten SQL Server-Host ein Hostprotokollverzeichnis konfiguriert sein, um Protokollsicherungen durchzuführen. Bei SnapCenter gibt es ein Datenbank-Repository, sodass Metadaten, die mit Backup-, Restore- oder Klonvorgängen verbunden sind, in einem zentralen Datenbank-Repository gespeichert werden.</block>
  <block id="29766ed5967263787fface0a4ad3396f" category="paragraph">Die Größe des Host-Log-Verzeichnisses wird wie folgt berechnet:
Größe des Host-Log-Verzeichnisses = ( (maximale DB-LDF-Größe x tägliche Log-Änderungsrate %) x (Snapshot-Aufbewahrung) ÷ (1 - LUN Overhead-Speicherplatz %)
Die Formel zur Größenbestimmung des Host-Protokollverzeichnisses nimmt einen LUN Overhead von 10 % an</block>
  <block id="31333b887781902e13c263570523ddc1" category="paragraph">Platzieren Sie das Protokollverzeichnis auf einem dedizierten Volume oder LUN. Die Datenmenge im Host-Log-Verzeichnis hängt von der Größe der Backups und der Anzahl der Tage ab, die Backups aufbewahrt werden. SnapCenter erlaubt nur ein Host-Protokollverzeichnis pro SQL Server-Host. Sie können die Host-Protokollverzeichnisse unter SnapCenter --&gt; Host --&gt; Configure Plug-in konfigurieren.</block>
  <block id="e815059019027c04aa969a50787d5b34" category="paragraph">*NetApp empfiehlt* für ein Host-Log-Verzeichnis:</block>
  <block id="07ae4edb1ccfbfe1f5da6006c95ee4a9" category="list-text">Stellen Sie sicher, dass das Host-Protokollverzeichnis nicht von anderen Datentypen gemeinsam genutzt wird, die möglicherweise die Backup-Snapshot-Daten beschädigen können.</block>
  <block id="991bd1f492a593453f65c2a23c1f1612" category="list-text">Platzieren Sie keine Benutzerdatenbanken oder Systemdatenbanken auf einer LUN, die Bereitstellungspunkte hostet.</block>
  <block id="bdfdf6f1492d7a7beac0bce2c4109f95" category="list-text">Erstellen Sie das Host-Log-Verzeichnis auf dem dedizierten FlexVol Volume, auf das SnapCenter Transaktionsprotokolle kopiert.</block>
  <block id="7b01578e73f5081fecdcc6dedf28aa3c" category="list-text">Migrieren Sie Datenbanken mithilfe von SnapCenter-Assistenten in NetApp Storage, damit die Datenbanken an gültigen Speicherorten gespeichert werden und so erfolgreiche SnapCenter-Backup- und -Restore-Vorgänge ermöglichen. Beachten Sie, dass der Migrationsprozess für den Fall von Unterbrechungen verantwortlich ist und dazu führen kann, dass die Datenbanken offline gehen, während die Migration durchgeführt wird.</block>
  <block id="b2d0e2f60ee139155b728ef6933efe7c" category="list-text">Die folgenden Bedingungen müssen für Failover-Cluster-Instanzen (FCIs) von SQL Server gelten:</block>
  <block id="863fda0972208e1e15d0c4a16d6915af" category="list-text">Wenn Sie eine Failover-Cluster-Instanz verwenden, muss das Host-Log-Verzeichnis LUN eine Cluster-Festplattenressource in derselben Cluster-Gruppe sein wie die SQL Server-Instanz, die SnapCenter gesichert wird.</block>
  <block id="ddb1104e1e71caabad3e7639c7675af8" category="list-text">Wenn Sie eine Failover-Cluster-Instanz verwenden, müssen Benutzerdatenbanken auf gemeinsam genutzte LUNs platziert werden, bei denen es sich um physische Festplatten-Cluster-Ressourcen handelt, die der Cluster-Gruppe zugewiesen sind, die der SQL Server-Instanz zugeordnet ist.</block>
  <block id="bca5f9a18696e080113088282fe481de" category="doc">Microsoft SQL Server-Speicherkonfiguration</block>
  <block id="02578ec0e8ce2fbef37ca792fd20c289" category="section-title">Max. Serverspeicher</block>
  <block id="81dbc262a15fc545920141998ddd1c17" category="paragraph">Mit der Option „Max. Serverspeicher“ wird die maximale Speichergröße festgelegt, die die SQL Server-Instanz verwenden kann.</block>
  <block id="c9fa383209ffc05f20049101298fec96" category="paragraph">Sie wird in der Regel verwendet, wenn mehrere Anwendungen auf demselben Server ausgeführt werden, auf dem SQL Server ausgeführt wird, und Sie sicherstellen möchten, dass diese Anwendungen über genügend Arbeitsspeicher verfügen, um ordnungsgemäß zu funktionieren.</block>
  <block id="1ceeb5f5f18aefbc39e34d0d3c7b7e1c" category="paragraph">Einige Anwendungen verwenden nur den verfügbaren Speicher, wenn sie starten, und fordern nicht mehr an, selbst wenn nötig. Hier kommt die maximale Serverspeichereinstellung ins Spiel.</block>
  <block id="6e345f11e9b2856a7ac40d6cf283606b" category="paragraph">Auf einem SQL Server-Cluster mit mehreren SQL Server-Instanzen könnte jede Instanz mit Ressourcen konkurrieren. Durch die Festlegung einer Speichergrenze für jede SQL Server-Instanz kann eine optimale Performance für jede Instanz gewährleistet werden.</block>
  <block id="318b34a3511a1be6d179a73303da2077" category="admonition">*NetApp empfiehlt*, mindestens 4 GB bis 6 GB RAM für das Betriebssystem zu belassen, um Leistungsprobleme zu vermeiden.</block>
  <block id="bc34e8cb14e602c11eab57e5d4131989" category="paragraph"><block ref="bc34e8cb14e602c11eab57e5d4131989" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cd151dbdf946ad6bd27e1d55ea1cd029" category="section-title">Anpassen des minimalen und maximalen Serverspeichers mit SQL Server Management Studio</block>
  <block id="2e0d4de7d927936246f5537ba48015d2" category="paragraph">Die Verwendung von SQL Server Management Studio zur Anpassung des minimalen oder maximalen Serverspeichers erfordert einen Neustart des SQL Server-Dienstes. Sie können den Serverspeicher mithilfe von Transact SQL (T-SQL) mit diesem Code anpassen:</block>
  <block id="998c5e632fa0f987c20c182fc9322f67" category="section-title">Uneinheitlicher Speicherzugriff</block>
  <block id="d92030bf70ac1cf1da30ce4c9ab2bbf6" category="paragraph">NUMA (Ununiform Memory Access) ist eine Methode zur Optimierung des Speicherzugriffs, die dazu beiträgt, die Prozessorgeschwindigkeit zu erhöhen, ohne die Last auf den Prozessorbus zu erhöhen.</block>
  <block id="6ef102e61df24a50b0119558432f5623" category="paragraph">Wenn NUMA auf dem Server konfiguriert ist, auf dem SQL Server installiert ist, ist keine zusätzliche Konfiguration erforderlich, da SQL Server NUMA-fähig ist und auf NUMA-Hardware eine gute Performance erzielt.</block>
  <block id="b3b5cd113ed637ebe6cb28eab322307a" category="section-title">Index Speicher erstellen</block>
  <block id="8e7c0153e4b7aa851a5a62683c378d1c" category="paragraph">Die Option Index create Memory ist eine weitere erweiterte Option, die Sie normalerweise nicht ändern sollten.</block>
  <block id="631c6718cc62ad33b6e3b3b48d754569" category="paragraph">Er steuert die maximale RAM-Größe, die ursprünglich für die Erstellung von Indizes zugewiesen wurde. Der Standardwert für diese Option ist 0, was bedeutet, dass sie von SQL Server automatisch verwaltet wird. Wenn Sie jedoch Schwierigkeiten beim Erstellen von Indizes haben, sollten Sie den Wert dieser Option erhöhen.</block>
  <block id="8c91aa3f5264c57bd2d2e66bd70f2ad1" category="section-title">Min. Arbeitsspeicher pro Abfrage</block>
  <block id="027d5a3eabe88aa0ab705b9c4a2fe096" category="paragraph">Wenn eine Abfrage ausgeführt wird, versucht SQL Server, die optimale Speichermenge für die effiziente Ausführung zuzuweisen.</block>
  <block id="4c7836a7e63c3ecb3f6860ec19643561" category="paragraph">Standardmäßig weist die Einstellung Min. Arbeitsspeicher pro Abfrage &gt; oder = bis 1024 KB für jede auszulaufende Abfrage zu. Es empfiehlt sich, diese Einstellung auf den Standardwert 0 zu belassen, damit SQL Server die für Indexerstellung zugewiesene Speichermenge dynamisch verwalten kann. Wenn SQL Server jedoch über mehr RAM verfügt, als für eine effiziente Ausführung erforderlich ist, kann die Leistung einiger Abfragen erhöht werden, wenn Sie diese Einstellung erhöhen. Solange also auf dem Server, der nicht von SQL Server verwendet wird, Speicher verfügbar ist, können andere Anwendungen oder das Betriebssystem diese Einstellung erhöhen, was die gesamte SQL Server-Leistung verbessern kann. Wenn kein freier Speicher verfügbar ist, kann eine Erhöhung dieser Einstellung die Gesamtleistung beeinträchtigen.</block>
  <block id="280cb8402bda4f652caf7bab6f9d2c6d" category="paragraph"><block ref="280cb8402bda4f652caf7bab6f9d2c6d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d2a88da9a0fcc96168f8f051909d5599" category="section-title">Pufferpool-Erweiterungen</block>
  <block id="11a3fdcfeb0715eaf26e855034f6ab9a" category="paragraph">Die Pufferpool-Erweiterung ermöglicht die nahtlose Integration einer NVRAM-Erweiterung in den Puffer-Pool der Datenbank-Engine und sorgt so für eine deutliche Steigerung des I/O-Durchsatzes.</block>
  <block id="c722da593d2f37b2c1ffc91a10c03dad" category="paragraph">Die Pufferpool-Erweiterung ist nicht in jeder SQL Server-Edition verfügbar. Es ist nur mit den 64-Bit-Editionen SQL Server Standard, Business Intelligence und Enterprise verfügbar.</block>
  <block id="df07548a7c164cbe93b68c4cbebbdcf8" category="paragraph">Die Funktion zur Erweiterung des Puffer-Pools erweitert den Cache des Puffers auf nicht-flüchtigen Storage (in der Regel SSDs). Durch die Erweiterung kann der Puffer-Pool einen größeren Datenbank-Arbeitsdatensatz aufnehmen. So wird der Ausruf von I/O zwischen dem RAM und den SSDs erzwungen und kleine zufällige I/O-Vorgänge werden von mechanischen Festplatten auf SSDs ausgelagert. Aufgrund der geringeren Latenz und besseren zufälligen I/O-Performance von SSDs verbessert die Pufferpool-Erweiterung den I/O-Durchsatz erheblich.</block>
  <block id="54af95ef673718e2f8bf1cc873d8b3ce" category="paragraph">Die Funktion zur Erweiterung des Puffer-Pools bietet folgende Vorteile:</block>
  <block id="2c250b49dc6705e6d219cf2bf8d50bc5" category="list-text">Erhöhter Durchsatz von zufälligen I/O-Operationen</block>
  <block id="93dce890e8c62b3a651edb9098201e58" category="list-text">Geringere I/O-Latenz</block>
  <block id="d7e49f79c1b78c9ead1e9541d2160307" category="list-text">Erhöhter Transaktionsdurchsatz</block>
  <block id="6643befb3c9dc2fbb68fe1107fe24842" category="list-text">Verbesserte Lese-Performance mit einem größeren hybriden Puffer-Pool</block>
  <block id="6609220b8670ffd627a3663b3beef46b" category="list-text">Eine Caching-Architektur, die die Vorteile eines vorhandenen und künftig kostengünstigen Speichers nutzt</block>
  <block id="471bda18bb94c589b421edccb0e402fe" category="paragraph">*NetApp empfiehlt*, die Pufferpool-Erweiterungen so zu konfigurieren:</block>
  <block id="12810c53d2afa05bd2a75aa3c0c55592" category="list-text">Stellen Sie sicher, dass eine SSD-gestützte LUN (wie NetApp AFF) dem SQL Server-Host angezeigt wird, damit diese als Zielfestplatte zur Pufferpool-Erweiterung verwendet werden kann.</block>
  <block id="824cfa1576a82f89ee0af13fb9f086dc" category="list-text">Die Erweiterungsdatei muss die gleiche Größe wie oder größer als der Pufferpool haben.</block>
  <block id="c7e0d87e723625072015431887edf349" category="paragraph">Das folgende Beispiel zeigt einen T-SQL-Befehl zum Einrichten einer Pufferpool-Erweiterung von 32 GB.</block>
  <block id="7ef20d2374bc8b734222e4ec2f0f3643" category="doc">ONTAP Storage-Effizienz mit Microsoft SQL Server</block>
  <block id="e5bc122522e9ae1409590d9944ec4421" category="paragraph">Storage-Effizienz bezieht sich auf die Fähigkeit, SQL Server-Daten so zu speichern und zu managen, dass der Speicherplatz auf ein Minimum beschränkt wird und die Gesamt-Performance des Systems kaum oder gar nicht beeinträchtigt wird.</block>
  <block id="c2a147b6be5d033c4eb55813488dbcc1" category="inline-link-macro">Empfehlungen zur Bereitstellung</block>
  <block id="ff824cee2c3b7ec7f7581d5dc93d1444" category="paragraph">Storage-Effizienz ist eine Kombination aus RAID, Bereitstellung (Gesamtlayout und Auslastung), Spiegelung und anderen Datensicherungstechnologien. Mit NetApp Technologien wie Snapshot Kopien, Thin Provisioning und FlexClone lassen sich Kostenvorteile erzielen, indem vorhandener Storage in der Infrastruktur optimiert und künftige Storage-Ausgaben verschoben oder vermieden werden. Je öfter Sie diese Technologien kombinieren, desto größer sind die Einsparungen. Weitere Informationen finden Sie unter <block ref="b5384d52b6e3305a2c57340dbe087476" category="inline-link-macro-rx"></block></block>
  <block id="6a10562f7a321860904cbd17167319df" category="inline-link-macro">Best Practices für Effizienz</block>
  <block id="5c7e263278e678895b97dc11f2a3cc36" category="paragraph">Storage-Komprimierung, Data-Compaction und Deduplizierung sind weitere Storage-Effizienzoptionen, die eine höhere logische Datenmenge für die gegebene Menge an physischem Storage erzielen. Weitere Informationen finden Sie unter <block ref="2f4d6c4cfae5ce39369594d1e1758c5d" category="inline-link-macro-rx"></block>.</block>
  <block id="2d3c9d6f03cd640c224f5daf9c2352b0" category="paragraph">SQL Server verfügt auch über eine Funktion zur Komprimierung und zum effizienten Management von Daten. SQL Server unterstützt derzeit zwei Arten der Datenkomprimierung: Row Compression und Page Compression.</block>
  <block id="181341700086c5e2f2259774b2aaa59c" category="inline-link-macro">Implementierung Der Seitenkomprimierung</block>
  <block id="46c6aaf21d639d23d4f297a1f6922d9a" category="paragraph">Durch die Zeilenkomprimierung wird das Datenspeicherformat geändert. So werden beispielsweise ganze Zahlen und Dezimalzahlen anstelle des nativen Formats mit fester Länge in das Format mit variabler Länge geändert. Außerdem werden Zeichenketten mit fester Länge durch das Entfernen von Leerzeichen in das Format mit variabler Länge geändert. Die Seitenkomprimierung implementiert die Zeilenkomprimierung und zwei weitere Komprimierungsstrategien (Prefix-Komprimierung und Wörterbuchkomprimierung). Weitere Details zur Seitenkomprimierung finden Sie unter <block ref="88eab602b149fe360da37498ad5cdeae" category="inline-link-macro-rx"></block>.</block>
  <block id="0d629ff07f9214182fa91977089ff029" category="paragraph">Die Datenkomprimierung wird derzeit in den Enterprise-, Developer- und Evaluation-Editionen von SQL Server 2008 und höher unterstützt. Obwohl die Komprimierung von der Datenbank selbst durchgeführt werden kann, ist dies in einer SQL Server Umgebung nur selten der Fall.</block>
  <block id="c6757fbc56df4ba20f0ef165aeb214d0" category="paragraph">Hier sind die Empfehlungen für die Verwaltung von Speicherplatz für SQL Server-Datendateien</block>
  <block id="46344e63db1ea2128cc47543b10a0f96" category="list-text">Verwenden Sie Thin Provisioning in SQL Server-Umgebungen, um die Speicherplatzauslastung zu verbessern und bei Einsatz der Speicherplatzgarantiefunktion den gesamten Storage-Bedarf zu senken.</block>
  <block id="924e1b131d6b3a2846efd1a81de8eac1" category="list-text">Verwenden Sie Autogrow für die meisten gängigen Implementierungskonfigurationen, da der Storage-Administrator nur die Speicherplatznutzung im Aggregat überwachen muss.</block>
  <block id="13a233d96ce19e7530391105360d749b" category="list-text">Es empfiehlt sich, die Deduplizierung auf Volumes mit SQL Server-Datendateien nicht zu aktivieren, es sei denn, das Volume enthält bekanntermaßen mehrere Kopien derselben Daten, wie beispielsweise das Wiederherstellen von Datenbanken aus Backups auf einem einzelnen Volume.</block>
  <block id="752d71c042ef775879f6db705ccf6b31" category="section-title">Speicherplatzrückgewinnung</block>
  <block id="89f8656e4e33094d6011ef9aaa8fa8de" category="paragraph">Die Rückgewinnung von ungenutztem Speicherplatz in einer LUN kann regelmäßig gestartet werden. Bei SnapCenter können Sie den folgenden PowerShell Befehl verwenden, um die Rückgewinnung von ungenutztem Speicherplatz zu starten.</block>
  <block id="aa864feb1e600aa376e91ac119da387b" category="paragraph">Wenn Sie die Speicherplatzrückgewinnung durchführen müssen, sollte dieser Prozess in Zeiten geringer Aktivität ausgeführt werden, da er anfangs Hostzyklen beansprucht.</block>
  <block id="a356c94dff23a233551ff221e74a144d" category="summary">Microsoft SQL Server Datensicherung mit ONTAP</block>
  <block id="731c00fe6475fb22aece82ffa9d74ef3" category="paragraph">Die Sicherung von Datenbanken ist für jedes Unternehmen von großer Bedeutung. Da die Datenmenge und Anzahl der Datenbanken zugenommen haben, ist die Einhaltung der Recovery Time Objective (RTO) und der Recovery Point Objective (RPO) von großer Bedeutung.</block>
  <block id="5cf56e0e8b1ff5cffb383d58615265e0" category="paragraph">Der wichtigste Faktor bei Datenbank-Backups ist die Nutzung der NetApp Snapshot Technologie. Die Planung der Datensicherung mit ONTAP wird erörtert <block ref="8f339e5651f846037d94f72580710268" category="inline-link-macro-rx"></block>. Ein applikationskonsistentes Backup und Datenbank-Layout sind weitere wichtige Kriterien für die Einhaltung von RTO und RPO, die von NetApp SnapCenter orchestriert werden können.</block>
  <block id="5c014f8939a89da0166a347a0237cf4f" category="section-title">SnapCenter</block>
  <block id="2ddb1872f6c378e74cb7269e9de4c4e5" category="paragraph">SnapCenter ist die NetApp Datensicherungssoftware für Enterprise-Applikationen.SQL Server Datenbanken lassen sich mit dem Plug-in für SQL Server und dem Plug-in für Microsoft Windows schnell und einfach mit NetApp SnapCenter Software sichern.</block>
  <block id="bdc6c0cf646d837838203c2980eba84a" category="paragraph">Diese Produkte ermöglichen applikationskonsistente Backups, automatisiertes Klonen sowie Restores und Recoverys von SQL Server Datenbanken, Instanzen oder Verfügbarkeitsgruppen.</block>
  <block id="2450e19674db2a865555d3c04563e647" category="admonition">*NetApp empfiehlt* SnapCenter zum Erstellen von Snapshot Kopien zu verwenden.</block>
  <block id="1567bc0803275089d7cbc1ffc468158c" category="inline-link-macro">TR-4714: Best Practice Guide für SQL Server mit NetApp SnapCenter</block>
  <block id="17f58c1b5cb5feb5dcaf49ca87298c00" category="paragraph">Weitere Informationen zum SQL Server-Plug-in für SnapCenter finden Sie unter <block ref="c94de7812b9bc9ed76b3c4005974958d" category="inline-link-macro-rx"></block>.</block>
  <block id="91a7baba41dc4b5f958101b261cf179b" category="section-title">Datenbanken mit T-SQL-Snapshots werden gesichert</block>
  <block id="e158e137ead13fd14e064b875e45df20" category="paragraph">In SQL Server 2022 hat Microsoft T-SQL Snapshots eingeführt. Diese bieten einen integrierten Vorteil als die herkömmliche Methode, die vom Datenbankadministrator nicht einfach verwendet wurde. Durch die Nutzung der ONTAP REST-APIs können Sie Befehle zu Snapshot-Volumes aufrufen.</block>
  <block id="02e19b2989ebddca9ad3778807bdc426" category="paragraph">Im Folgenden finden Sie ein Beispiel für einen Backup-Workflow:</block>
  <block id="17884d5a1cfc06145e718a49c8d6ac66" category="list-text">Eine Datenbank mit dem Befehl „ALTER“ einfrieren – damit die Möglichkeit besteht, einen konsistenten Snapshot auf dem zugrunde liegenden Speicher zu erstellen. Danach können Sie die Datenbank auftauen und den Snapshot mit dem BACKUP-Befehl aufzeichnen.</block>
  <block id="bd03301405e4dd8f2460ff1788765ac4" category="list-text">Führen Sie Snapshots mehrerer Datenbanken auf den Speichervolumes gleichzeitig mit den neuen Befehlen BACKUP-GRUPPE und BACKUP-SERVER durch.</block>
  <block id="a3b19be7df3ddff7295558d9934cd9b6" category="list-text">Führen Sie VOLLSTÄNDIGE Backups oder COPY_ONLY VOLLSTÄNDIGE Backups durch. Diese Backups werden auch in msdb aufgezeichnet.</block>
  <block id="e2d06152222f63515f4b83229cb5444c" category="list-text">Durchführung einer zeitpunktgenauen Recovery mithilfe von Protokoll-Backups, die mit dem normalen Streaming-Ansatz nach dem VOLLSTÄNDIGEN Snapshot-Backup erstellt wurden. Streaming Differential Backups werden auf Wunsch auch unterstützt.</block>
  <block id="a7a2496066febda8d325e0964e434481" category="inline-link-macro">Microsoft-Dokumentation zu den T-SQL-Snapshots</block>
  <block id="bf06f3f95c5b653499bb4ac53ba44c95" category="paragraph">Weitere Informationen finden Sie unter <block ref="2ba8392a398067f6d2e5f6e4167e9d00" category="inline-link-macro-rx"></block>.</block>
  <block id="450eb6d84ec721a20f17b7778b24b457" category="doc">Microsoft SQL Server-Workloads</block>
  <block id="764e07fc8f1f5e2d1b9fc63f83b88cbd" category="paragraph">Die SQL Server Datenbankplattform kann zahlreiche Applikationen unterstützen.</block>
  <block id="25343e3363b414e89943f5a4e46f51ad" category="paragraph">Vor der Bereitstellung von SQL Server müssen Sie die Anforderungen an die Datenbank-Workloads der Anwendungen kennen, die von Ihren SQL Server-Instanzen unterstützt werden. Jede Applikation hat unterschiedliche Anforderungen an Kapazität, Performance und Verfügbarkeit. Daher sollte jede Datenbank für eine optimale Unterstützung dieser Anforderungen entworfen werden. Viele Unternehmen klassifizieren Datenbanken in mehrere Management-Tiers unter Verwendung von Anwendungsanforderungen zur Definition von SLAs. SQL Server-Workloads können wie folgt beschrieben werden:</block>
  <block id="c6a1c5843ff7b078079edf24beeea746" category="list-text">OLTP-Datenbanken sind oft auch die kritischsten Datenbanken eines Unternehmens. Diese Datenbanken stehen in der Regel kundenorientierten Applikationen gegenüber und werden als unverzichtbar für die Kernprozesse des Unternehmens angesehen. Für geschäftskritische OLTP-Datenbanken und die von ihnen unterstützten Applikationen gibt es oft SLAs, die ein hohes Maß an Performance erfordern und mit hohen Anforderungen an Performance-Verschlechterung und Verfügbarkeit verbunden sind. Sie können auch Kandidaten für „Always On“-Failover-Cluster oder „Always On“-Verfügbarkeitsgruppen sein. Der I/O-Mix dieser Datenbanktypen ist in der Regel durch 75 bis 90 % zufällige Lesevorgänge und 25 bis 10 % Schreibzugriffe gekennzeichnet.</block>
  <block id="96d864d235bcd68e1ef22c2c49aef352" category="list-text">Datenbanken des Decision Support System (DSS) können auch als Data Warehouses bezeichnet werden. Diese Datenbanken sind in vielen Unternehmen, die auf Analysen für ihr Geschäft vertrauen, geschäftskritisch. Diese Datenbanken sind sensibel für die CPU-Auslastung und Lesevorgänge von der Festplatte, wenn Abfragen ausgeführt werden. In vielen Unternehmen sind DSS-Datenbanken zum Monats-, Quartals- und Jahresende am wichtigsten Dieser Workload verfügt in der Regel über eine I/O-Kombination mit 100 % Lesevorgängen.</block>
  <block id="da02a82356735ded82f6661108abe7ef" category="section-title">Benchmarking</block>
  <block id="b9a9b34816c2e5ebaecb45f376b52bc3" category="paragraph">Der Transaction Process Council (TPC) ist ein gemeinnütziges Unternehmen, das gegründet wurde, um Transaktionsverarbeitung und Datenbank-Benchmarks zu definieren und objektive, überprüfbare TPC-Leistungsdaten an die Branche weiterzugeben. TPC Tests simulieren komplette Computing-Umgebungen, in denen eine Benutzerpopulation Transaktionen anhand von Datenbanken ausführt.</block>
  <block id="427af860f9733f0c5427a1408195bb2b" category="cell">Workload-Typ</block>
  <block id="54861efdd06fc309e1c9a420feff98eb" category="cell">Szenario</block>
  <block id="b130fcf8f0704ab887b72883b1eda2fa" category="cell">Lese-/Schreibverhältnis (Prozentsätze)</block>
  <block id="3edb9cc3b98f151feb21dbde6323e82a" category="cell">OLTP</block>
  <block id="69e16af975a283d07a422bdbcc70aa33" category="cell">TPC-C</block>
  <block id="b1e04731135df8a16c5318612ec8654e" category="cell">~75/25</block>
  <block id="106ff1baff5c32dc414f262e0a710c54" category="cell">TPC-E</block>
  <block id="48e219d97cf4619f212471bafd4215ec" category="cell">~90/10</block>
  <block id="e71f0182ed04206cb78bd7ceb2d9f4f3" category="cell">DSS</block>
  <block id="5788057170990ecf5e4d921f2853c2ae" category="cell">TPC-H</block>
  <block id="492d66c3da61bdb9c69261aa1aa6f5f9" category="cell">~100/0</block>
  <block id="0737ef89fbed16c79fadf3568aad6ba0" category="inline-link-macro">HammerDB.com</block>
  <block id="45e5ae4569fb8a91cd5513654f31b764" category="paragraph">Obwohl verschiedene Optionen zur Workload-Generierung verfügbar sind, konzentrieren wir uns in der Regel auf die Messung der Performance von SQL Server Datenbanken bei der Verarbeitung transaktionaler Workloads. Wir verwenden die TPC-E Tools von Microsoft oder TPC-H mit HammerDB (<block ref="af66be8e0834614cdd62ca4f34bc61ec" category="inline-link-macro-rx"></block>^). Die detaillierten Anweisungen zur Verwendung dieser spezifischen Benchmarks liegen außerhalb des Rahmens dieses Dokuments.</block>
  <block id="1b1b4c822e9c1b28b845dcc038fec08e" category="doc">Microsoft SQL Server Datenbankdateien und Dateigruppen</block>
  <block id="381c0738613a6b6a27d1c14f223e99ba" category="paragraph">Eine SQL Server-Datenbank ist eine Sammlung von Objekten, mit denen Sie Daten speichern und bearbeiten können.</block>
  <block id="5306de2e4bff067a10c1c9b5aafe5920" category="paragraph">Theoretisch unterstützt SQL Server (64-Bit) 32,767 Datenbanken pro Instanz und 524.272 TB Datenbankgröße, obwohl die typische Installation normalerweise über mehrere Datenbanken verfügt. Die Anzahl der Datenbanken, die SQL Server verarbeiten kann, hängt jedoch von der Last und der Hardware ab. Es ist nicht ungewöhnlich, dass SQL Server Instanzen Dutzende, Hunderte oder sogar Tausende kleine Datenbanken hosten.</block>
  <block id="9a3f42cec243006996ab4580d3ce5d56" category="paragraph">Jede Datenbank besteht aus einer oder mehreren Datendateien und einer oder mehreren Transaktions-Log-Dateien. Das Transaktionsprotokoll speichert die Informationen über Datenbanktransaktionen und alle von jeder Sitzung vorgenommenen Datenänderungen. Jedes Mal, wenn die Daten geändert werden, speichert SQL Server genügend Informationen im Transaktionsprotokoll, um die Aktion rückgängig zu machen (Rollback) oder zu wiederholen (Replay). Ein SQL Server-Transaktionsprotokoll ist ein integraler Bestandteil des Rufs von SQL Server für Datenintegrität und Robustheit. Das Transaktionsprotokoll ist für die Atomizität, Konsistenz, Isolation und Strapazierfähigkeit (ACID) von SQL Server von entscheidender Bedeutung. SQL Server schreibt in das Transaktionsprotokoll, sobald eine Änderung an der Datenseite erfolgt. Jede DML-Anweisung (Data Manipulation Language) (z. B. SELECT, Insert, Update oder delete) ist eine vollständige Transaktion, und das Transaktionsprotokoll stellt sicher, dass der gesamte Set-basierte Vorgang durchgeführt wird, um die Atomizität der Transaktion sicherzustellen.</block>
  <block id="cbe6958e46fbab53cdbdb9deb2d75938" category="paragraph">Jede Datenbank verfügt über eine primäre Datendatei, die standardmäßig über die Erweiterung .mdf verfügt. Darüber hinaus kann jede Datenbank sekundäre Datenbankdateien enthalten. Diese Dateien haben standardmäßig .ndf-Erweiterungen.</block>
  <block id="811b578b6dfbb4a4ca16ba0c0911e3df" category="paragraph">Alle Datenbankdateien werden in Dateigruppen gruppiert. Eine Dateigruppe ist die logische Einheit, die die Datenbankverwaltung vereinfacht. Sie ermöglichen die Trennung zwischen einer logischen Objektplatzierung und physischen Datenbankdateien. Wenn Sie die Tabellen für Datenbankobjekte erstellen, geben Sie an, in welcher Dateigruppe sie platziert werden sollen, ohne sich um die zugrunde liegende Datendateikonfiguration zu sorgen.</block>
  <block id="cd2f60511a1a153b21b89b7c5c3ca326" category="paragraph"><block ref="cd2f60511a1a153b21b89b7c5c3ca326" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3717596742d438a1c8e77b0aeb58fcec" category="paragraph">Die Fähigkeit, mehrere Datendateien innerhalb der Dateigruppe zu speichern, ermöglicht es Ihnen, die Last auf verschiedene Speichergeräte zu verteilen, wodurch die I/O-Performance des Systems verbessert wird. Der Kontrast für die Transaktionsprotokollanmeldung profitiert nicht von den mehreren Dateien, da SQL Server in sequenzieller Weise in das Transaktionsprotokoll schreibt.</block>
  <block id="c136ffb510a6a465d338ab0affc16641" category="paragraph">Die Trennung zwischen der Platzierung logischer Objekte in den Dateigruppen und physischen Datenbankdateien ermöglicht es Ihnen, das Layout von Datenbankdateien zu optimieren und so das Storage-Subsystem optimal zu nutzen. Beispielsweise können unabhängige Softwareanbieter (ISVs), die ihre Produkte bei unterschiedlichen Kunden implementieren, die Anzahl der Datenbankdateien basierend auf der zugrunde liegenden I/O-Konfiguration und der erwarteten Datenmenge während der Implementierungsphase anpassen. Diese Änderungen sind für die Anwendungsentwickler transparent, die die Datenbankobjekte in den Dateigruppen statt in Datenbankdateien platzieren.</block>
  <block id="3ac46c2f04dec9d215efbe44d307a020" category="admonition">*NetApp empfiehlt* die Verwendung der primären Dateigruppe für alles andere als Systemobjekte zu vermeiden. Das Erstellen einer separaten Dateigruppe oder einer Gruppe von Dateigruppen für die Benutzerobjekte vereinfacht die Datenbankverwaltung und Disaster Recovery, insbesondere bei großen Datenbanken.</block>
  <block id="e3fc56c012a5d0c9f92dff9b49bcc80d" category="paragraph">Sie können die ursprüngliche Dateigröße und die automatischen Wachstumsparameter angeben, wenn Sie die Datenbank erstellen oder neue Dateien zu einer vorhandenen Datenbank hinzufügen. SQL Server verwendet einen proportionalen Füllalgorithmus bei der Auswahl der Datendatei, in die Daten geschrieben werden sollen. Es schreibt eine Datenmenge proportional zum verfügbaren freien Speicherplatz in den Dateien. Je mehr Speicherplatz in der Datei verfügbar ist, desto mehr Schreibvorgänge werden verarbeitet.</block>
  <block id="91d249de86b62102d6324849de2360fe" category="admonition">*NetApp empfiehlt*, dass alle Dateien in der einzelnen Dateigruppe die gleiche Anfangsgröße und die gleichen Autogrowth-Parameter haben, wobei die Grow-Größe in Megabyte und nicht in Prozentsätzen definiert ist. Dies hilft dem proportionalen Füllalgorithmus, Schreibaktivitäten gleichmäßig über Datendateien hinweg auszugleichen.</block>
  <block id="a39d73055b8dbbe112e749e7c3ededb8" category="paragraph">Jedes Mal, wenn SQL Server die Dateien vergrößert, füllt es neu zugewiesenen Speicherplatz in den Dateien mit Nullen. Dieser Prozess blockiert alle Sitzungen, die in die entsprechende Datei geschrieben werden müssen, oder generiert im Falle eines Wachstums des Transaktionsprotokolls Transaktionsprotokolle.</block>
  <block id="54db492ee9e4d356cc8722d1f4126f77" category="paragraph">SQL Server löscht das Transaktionsprotokoll immer auf Null, und dieses Verhalten kann nicht geändert werden. Sie können jedoch festlegen, ob Datendateien auf Null gesetzt werden, indem Sie die sofortige Dateiinitialisierung aktivieren oder deaktivieren. Durch die sofortige Dateiinitialisierung wird das Wachstum von Datendateien beschleunigt und der Zeitaufwand für die Erstellung oder Wiederherstellung der Datenbank verringert.</block>
  <block id="92208bd4d9c6fec3f7c1dedeca62e135" category="paragraph">Mit der sofortigen Dateiinitialisierung ist ein kleines Sicherheitsrisiko verbunden. Wenn diese Option aktiviert ist, können nicht zugewiesene Teile der Datendatei Informationen aus zuvor gelöschten Betriebssystemdateien enthalten. Datenbankadministratoren können solche Daten prüfen.</block>
  <block id="2b222ad4000e6e966783fd7bc480180e" category="paragraph">Sie können die sofortige Dateiinitialisierung aktivieren, indem Sie dem SQL Server-Startkonto die Berechtigung SA_MANAGE_VOLUME_NAME, auch bekannt als „Perform Volume Maintenance Task“, hinzufügen. Sie können dies unter der Anwendung zur Verwaltung lokaler Sicherheitsrichtlinien (secpol.msc) tun, wie in der folgenden Abbildung dargestellt. Öffnen Sie die Eigenschaften für die Berechtigung zum Ausführen von Volume-Wartungsaufgaben und fügen Sie das SQL Server-Startkonto zur Liste der Benutzer dort hinzu.</block>
  <block id="f5127c997811da26d32c454a19000117" category="paragraph"><block ref="f5127c997811da26d32c454a19000117" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c622e0142ed854a10f98fcaa8b3487f8" category="paragraph">Um zu überprüfen, ob die Berechtigung aktiviert ist, können Sie den Code aus dem folgenden Beispiel verwenden. Dieser Code setzt zwei Trace-Flags, die SQL Server zwingen, zusätzliche Informationen in das Fehlerprotokoll zu schreiben, eine kleine Datenbank zu erstellen und den Inhalt des Protokolls zu lesen.</block>
  <block id="eba8c32bde087b29aaa1fe0d3bb32ef3" category="paragraph">Wenn die sofortige Dateiinitialisierung nicht aktiviert ist, zeigt das SQL Server-Fehlerprotokoll an, dass SQL Server die mdf-Datendatei zusätzlich zum Nullsetzen der ldf-Protokolldatei auf Null setzt, wie im folgenden Beispiel gezeigt. Wenn die sofortige Dateiinitialisierung aktiviert ist, wird nur das Nullsetzen der Protokolldatei angezeigt.</block>
  <block id="b38fa7baf9ceb53ef15ca3677d3cdfa5" category="paragraph"><block ref="b38fa7baf9ceb53ef15ca3677d3cdfa5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cf346325be0652c6b6e9a04b9352bda3" category="paragraph">Die Wartungsaufgabe zum Ausführen von Volumes wird in SQL Server 2016 vereinfacht und später während des Installationsprozesses als Option bereitgestellt. In dieser Abbildung wird die Option angezeigt, dem SQL Server-Datenbank-Engine-Service die Berechtigung zum Ausführen der Volume-Wartungsaufgabe zu gewähren.</block>
  <block id="aea48caa289e2e488286fae0515eb9d9" category="paragraph"><block ref="aea48caa289e2e488286fae0515eb9d9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="638b283700120d26a838f9cb56fca59d" category="paragraph">Eine weitere wichtige Datenbankoption, die die Größe der Datenbankdateien steuert, ist Autoshrink. Wenn diese Option aktiviert ist, verkleinert SQL Server die Datenbankdateien regelmäßig, reduziert deren Größe und gibt Speicherplatz für das Betriebssystem frei. Dieser Vorgang ist ressourcenintensiv und nur selten sinnvoll, da die Datenbankdateien nach einiger Zeit wieder wachsen, wenn neue Daten in das System gelangen. Autoshrink darf in der Datenbank niemals aktiviert werden.</block>
  <block id="3b6c913908f5844ccb31a4d3775cb34e" category="doc">Gemeinsame Instanz von Microsoft SQL Server und dedizierte Instanzen</block>
  <block id="8b58192b54b5dc25444ace0536a34893" category="paragraph">Wenn eine Anwendung über viele Schemas und gespeicherte Prozeduren verfügt, kann dies möglicherweise andere Apps beeinträchtigen, die eine SQL Server-Instanz gemeinsam nutzen.</block>
  <block id="0f85d9701e2ca305652e98c4181097e4" category="paragraph">Instanzressourcen können möglicherweise geteilt oder gesperrt werden, was wiederum zu Performance-Problemen bei anderen Anwendungen führt, bei denen Datenbanken auf der gemeinsam genutzten SQL Server-Instanz gehostet werden.</block>
  <block id="37fbf1be337695452699ab9df948aa25" category="paragraph">Die Fehlerbehebung bei Performance-Problemen kann kompliziert sein, da Sie herausfinden müssen, welche Instanz die eigentliche Ursache ist. Diese Frage wird gegen die Kosten von Betriebssystemlizenzen und SQL Server-Lizenzen abgewogen. Wenn die Applikations-Performance oberste Priorität hat, ist eine dedizierte Instanz sehr empfehlenswert.</block>
  <block id="c840abede1d1bcf78e7b3e30048c08b1" category="paragraph">Microsoft lizenziert SQL Server pro Kern auf Serverebene und nicht pro Instanz. Aus diesem Grund sind Datenbankadministratoren versucht, so viele SQL Server-Instanzen zu installieren, wie der Server verarbeiten kann, um Lizenzierungskosten zu sparen, was später zu größeren Performanceproblemen führen kann.</block>
  <block id="8a77155b45f0f2313c8ebf3d755463e5" category="admonition">*NetApp empfiehlt*, wenn möglich dedizierte SQL Server-Instanzen zu wählen, um optimale Leistung zu erzielen.</block>
  <block id="df7423789cebcf51de121abdae4181c3" category="summary">ONTAP- und Enterprise-Applikationen</block>
  <block id="6e1c62c6c9ec560b6b6cf47a8a8c83f8" category="summary">Oracle auf ONTAP unter Solaris</block>
  <block id="eaf36c98b91893b7f79bd5184a23d377" category="doc">Solaris</block>
  <block id="fb04d97697a77a89d0c3f5c09cd9ba47" category="paragraph">Konfigurationsthemen für das Solaris-Betriebssystem.</block>
  <block id="eefc332f1bd0a0aa81d0ce222989294f" category="section-title">Solaris NFS-Mount-Optionen</block>
  <block id="3e484486d582145f6d93ca5f8c71e228" category="paragraph">In der folgenden Tabelle sind die Solaris NFS-Mount-Optionen für eine einzelne Instanz aufgeführt.</block>
  <block id="6622c14ce91b6b9683505626a5eebdd2" category="cell">Dateityp</block>
  <block id="f18f8a29d3e2281d374f43c78cf8f0f1" category="cell">Mount-Optionen</block>
  <block id="a45543a64530673135f37ff8f9e95e69" category="cell">AdR-Startseite</block>
  <block id="93a02670f814a2df6c830194a7244ea9" category="cell"><block ref="623bbf58c0b2f552d891a1c276bcc3bc" prefix="" category="inline-code"></block></block>
  <block id="80d52d74fd5c383b43f91575d569b42c" category="cell">Steuerdateien
Datendateien
Wiederherstellungsprotokolle</block>
  <block id="73cf9d3814b8678439c37316096219b1" category="cell"><block ref="4c899c62e1ffeb12078476828bb54351" prefix="" category="inline-code"></block></block>
  <block id="72d33cb5c8b7ff5f7fd6a894094b0697" category="cell"><block ref="e1f651debac4f720c13ae930ff3ca14a" prefix="" category="inline-code"></block></block>
  <block id="3f490427e0bf55dc5c837e7b0d4c651c" category="cell"><block ref="b9ce73264210e6d0faa4115ce7525610" prefix="" category="inline-code"></block></block>
  <block id="b00b0ab6e8494db1a230bf3da7f42fd6" category="paragraph">Die Verwendung von<block ref="545e1db0caafaa47ef37ce893c8fb92c" prefix=" " category="inline-code"></block> Hat sich in Kundenumgebungen nachweislich für eine drastische Performance-Steigerung bewährt, da die mit dem Erwerb und Freigeben von Sperren des Storage-Systems verbundene Latenz beseitigt wurde. Verwenden Sie diese Option sorgfältig in Umgebungen, in denen zahlreiche Server für die Bereitstellung derselben Dateisysteme konfiguriert sind und Oracle für das Mounten dieser Datenbanken konfiguriert ist. Dies ist zwar eine äußerst ungewöhnliche Konfiguration, wird jedoch von wenigen Kunden verwendet. Wenn eine Instanz versehentlich ein zweites Mal gestartet wird, kann es zu Datenbeschädigungen kommen, weil Oracle die Sperrdateien auf dem fremden Server nicht erkennen kann. NFS-Sperren bieten sonst keinen Schutz, wie in NFS-Version 3 sind sie nur beratend.</block>
  <block id="f480015b57b289b7dad1473ee5c55216" category="paragraph">Weil die<block ref="545e1db0caafaa47ef37ce893c8fb92c" prefix=" " category="inline-code"></block> Und<block ref="6698a391ee8befa0ca4646a86a1bbd66" prefix=" " category="inline-code"></block> Parameter schließen sich gegenseitig aus, es ist wichtig, dass<block ref="b6a2b868e8bebfc19497b406a12a1071" prefix=" " category="inline-code"></block> Befindet sich im<block ref="b6bd7c570605affc5b50bbd3e436f0c0" prefix=" " category="inline-code"></block> So speichern<block ref="6887bae4cda2d09a283a165c5be3f2b8" prefix=" " category="inline-code"></block> Verwendet wird. Ohne diesen Parameter wird Puffer-Caching des Host-Betriebssystems verwendet und die Performance kann beeinträchtigt werden.</block>
  <block id="5171d5dfdc21b0941b921796638c10a9" category="paragraph">In der folgenden Tabelle sind die Mount-Optionen für Solaris NFS RAC aufgeführt.</block>
  <block id="38e4e10abf410c92cd13e9cb4d54ae35" category="cell"><block ref="41a82b9bd64cb001f8913a34614b00d1" prefix="" category="inline-code"></block></block>
  <block id="e72cc50c204d77a1e47f0dcc8ad28a56" category="cell">Kontrolldateien
Datendateien
Wiederherstellungsprotokolle</block>
  <block id="98ee9e91a49f27abbd9dc831afa9fae5" category="cell"><block ref="f3a0fd4a197a2eae60d2ef904e5366f1" prefix="" category="inline-code"></block></block>
  <block id="f93eecf9c582d76d4e14292dc34c79f8" category="cell">CRS/Abstimmung</block>
  <block id="42c82995de255264e2a8690c3149c16a" category="cell">Dediziert<block ref="e1f651debac4f720c13ae930ff3ca14a" prefix=" " category="inline-code"></block></block>
  <block id="b71e04a676ec52e65edb52c138f2ad98" category="cell"><block ref="ac15a7c050732bc5169b6c17ce30f859" prefix="" category="inline-code"></block></block>
  <block id="273f714e976e2a709a6abe18d34e4b61" category="cell">Freigegeben<block ref="e1f651debac4f720c13ae930ff3ca14a" prefix=" " category="inline-code"></block></block>
  <block id="2052aa052eee25e077178cd737b68f47" category="cell"><block ref="18f533bce293643d1004086db883dd03" prefix="" category="inline-code"></block></block>
  <block id="e9d3beba8b6a40da6f8074236ca3ddbc" category="paragraph">Der Hauptunterschied zwischen Single-Instance- und RAC-Mount-Optionen ist das Hinzufügen von<block ref="79fea224ffd9e8111e4e87cab732464b" prefix=" " category="inline-code"></block> Und<block ref="6698a391ee8befa0ca4646a86a1bbd66" prefix=" " category="inline-code"></block> Zu den Mount-Optionen. Durch diese Ergänzung wird das Caching des Host-Betriebssystems deaktiviert, wodurch alle Instanzen im RAC Cluster eine konsistente Ansicht des Status der Daten haben. Obwohl Sie den verwenden<block ref="b6bd7c570605affc5b50bbd3e436f0c0" prefix=" " category="inline-code"></block> Parameter<block ref="b6a2b868e8bebfc19497b406a12a1071" prefix=" " category="inline-code"></block> Hat die gleiche Wirkung wie die Deaktivierung des Host-Caching, ist es weiterhin erforderlich, zu verwenden<block ref="79fea224ffd9e8111e4e87cab732464b" prefix=" " category="inline-code"></block> Und<block ref="6698a391ee8befa0ca4646a86a1bbd66" prefix=" " category="inline-code"></block>.</block>
  <block id="983c4ff0cb78851d95be06277152653f" category="paragraph">Der Grund<block ref="3504e2b0e7c968444314433be465518d" prefix=" " category="inline-code"></block> Ist für die gemeinsame Nutzung erforderlich<block ref="e1f651debac4f720c13ae930ff3ca14a" prefix=" " category="inline-code"></block> Die Bereitstellung soll die Konsistenz von Dateien wie Oracle-Passwortdateien und SPfiles erleichtern. Wenn jede Instanz in einem RAC-Cluster über einen dedizierten verfügt<block ref="e1f651debac4f720c13ae930ff3ca14a" prefix=" " category="inline-code"></block>, Dieser Parameter ist nicht erforderlich.</block>
  <block id="5a11994cffaa4d0a9c8594d2223e3e96" category="section-title">Solaris UFS-Mount-Optionen</block>
  <block id="130c5ffb786e38c2e6648fd53593681a" category="paragraph">NetApp empfiehlt nachdrücklich die Verwendung der Mount-Option für die Protokollierung, damit die Datenintegrität im Fall eines Solaris Host-Absturzes oder der Unterbrechung der FC-Konnektivität erhalten bleibt. Die Mount-Option für die Protokollierung behält außerdem die Benutzerfreundlichkeit von Snapshot Backups bei.</block>
  <block id="516f7006de2e9b1f7f871d961db4a1ca" category="section-title">Solaris ZFS</block>
  <block id="a92c2c52c7360246c6da2b1169e0fa50" category="paragraph">Solaris ZFS muss sorgfältig installiert und konfiguriert werden, um eine optimale Leistung zu erzielen.</block>
  <block id="c9208a3ad95d5ce3d9e2ba1839426251" category="section-title">Mvektor</block>
  <block id="c54b9977f43cf2f9a1aa7cb0de8fec22" category="paragraph">Solaris 11 beinhaltete eine Änderung bei der Verarbeitung großer I/O-Vorgänge, die zu schwerwiegenden Leistungsproblemen auf SAN-Speicher-Arrays führen können. Das Problem wird ausführlich im NetApp-Fehlerbericht 630173 „Solaris 11 ZFS Performance Regression“ dokumentiert. „Die Lösung besteht darin, einen OS-Parameter mit dem Namen zu ändern<block ref="954f82599f7db0212a28fd448e03bdf3" prefix=" " category="inline-code"></block>.</block>
  <block id="17e692fa261653b11634297d15070637" category="paragraph">Führen Sie den folgenden Befehl als root aus:</block>
  <block id="bc7e9b3c34345bf9ebe88467d6714f1b" category="paragraph">Wenn unerwartete Probleme durch diese Änderung auftreten, kann sie einfach rückgängig gemacht werden, indem der folgende Befehl als Root ausgeführt wird:</block>
  <block id="6ff9f4444ac481652f4412b5e1623846" category="section-title">Kernel</block>
  <block id="78d06f587305b9e5481c8cf660693a61" category="paragraph">Eine zuverlässige ZFS-Performance erfordert einen Solaris-Kernel, der gegen Probleme bei der LUN-Ausrichtung gepatcht ist. Der Fix wurde mit Patch 147440-19 in Solaris 10 und SRU 10.5 für Solaris 11 eingeführt. Verwenden Sie nur Solaris 10 und höher mit ZFS.</block>
  <block id="db8880d80ab20f2f01a010e5c454f7fb" category="section-title">LUN-Konfiguration</block>
  <block id="3b296d65c0c37979abe39ac7f6d8e1d8" category="paragraph">Führen Sie zum Konfigurieren einer LUN die folgenden Schritte aus:</block>
  <block id="3bdc2a5622b76404f8b0ce2fc774e69a" category="list-text">Erstellen Sie eine LUN des Typs<block ref="7bee0477f82303aa43de5d78f7b9cb05" prefix=" " category="inline-code"></block>.</block>
  <block id="c06f6c6685c06bb821295b3a6d5e580c" category="list-text">Installieren Sie das entsprechende Host Utility Kit (HUK), das vom angegeben wird <block ref="b5b16f3cdb0eb25a282348ba54f8c677" category="inline-link-macro-rx"></block>.</block>
  <block id="33db73c9b3936cb8eaae825d3101f60c" category="inline-link-macro">Aktuellste Dokumentation</block>
  <block id="c8646086dca29c1d978ab285faa93709" category="list-text">Befolgen Sie die Anweisungen im HUK genau wie beschrieben. Die grundlegenden Schritte sind unten beschrieben, beziehen Sie sich jedoch auf <block ref="33574dfffc2cb6d01be0edb6738c51bb" category="inline-link-macro-rx"></block> Für das richtige Verfahren.</block>
  <block id="6c06455cad171d61eac3593147bd71d6" category="list-text">Führen Sie die aus<block ref="3062dc928daa4d85f6e34b6dea110a00" prefix=" " category="inline-code"></block> Dienstprogramm zum Aktualisieren des<block ref="d5416d340f5bec1fcb3addb6ae7d059e" prefix=" " category="inline-code"></block> Datei: Dadurch können die SCSI-Laufwerke ONTAP-LUNs korrekt erkennen.</block>
  <block id="7ec6668202fa9a677238143b0445102f" category="list-text">Befolgen Sie die Anweisungen des<block ref="3062dc928daa4d85f6e34b6dea110a00" prefix=" " category="inline-code"></block> Dienstprogramm zur Aktivierung von Multipath Input/Output (MPIO).</block>
  <block id="b53abe6c0013125abea171427b351ccc" category="list-text">Neustart. Dieser Schritt ist erforderlich, damit alle Änderungen im gesamten System erkannt werden.</block>
  <block id="b88caedbe9708683eed783eb534ae5f6" category="list-text">Partitionieren Sie die LUNs und stellen Sie sicher, dass sie ordnungsgemäß ausgerichtet sind. Anweisungen zum direkten Testen und Bestätigen der Ausrichtung finden Sie in Anhang B „Überprüfung der WAFL-Ausrichtung“.</block>
  <block id="a0c1c26e783204cf713b2e1f0823aab3" category="section-title">Zpools</block>
  <block id="c81b8fe4a368c32102406e65fc41a227" category="inline-link-macro">LUN-Konfiguration</block>
  <block id="c49c7ca1707a6d27b04d804b2b5dfeb3" category="paragraph">Ein zpool sollte erst nach den Schritten im erstellt werden <block ref="255d6439b7182d422c7625a86084578a" category="inline-link-macro-rx"></block> Durchgeführt werden. Wenn das Verfahren nicht korrekt durchgeführt wird, kann es durch die I/O-Ausrichtung zu einer ernsthaften Verschlechterung der Performance kommen. Eine optimale Performance auf ONTAP erfordert, dass der I/O an einer 4-KB-Grenze auf einem Laufwerk ausgerichtet ist. Die auf einem zpool erstellten Dateisysteme verwenden eine effektive Blockgröße, die über einen Parameter mit dem Namen gesteuert wird<block ref="81df978a8e3da4bee74b135548f390f3" prefix=" " category="inline-code"></block>, Die durch Ausführen des Befehls angezeigt werden kann<block ref="1615297782a0dff59b20451e2ca97ea7" prefix=" " category="inline-code"></block>.</block>
  <block id="869dc3a8daf591c7f33e5bb32a4a63c9" category="paragraph">Der Wert von<block ref="81df978a8e3da4bee74b135548f390f3" prefix=" " category="inline-code"></block> Der Standardwert ist 9. Dies bedeutet 2^9 oder 512 Byte. Für eine optimale Leistung, die<block ref="81df978a8e3da4bee74b135548f390f3" prefix=" " category="inline-code"></block> Wert muss 12 (2^12=4K) sein. Dieser Wert wird zum Zeitpunkt der Erstellung des zpool gesetzt und kann nicht geändert werden, was bedeutet, dass Daten in zpools mit<block ref="81df978a8e3da4bee74b135548f390f3" prefix=" " category="inline-code"></block> Andere als 12 sollten durch Kopieren der Daten in einen neu erstellten zpool migriert werden.</block>
  <block id="6a00a2262e030c2656588743cb031710" category="paragraph">Überprüfen Sie nach dem Erstellen eines zpool den Wert von<block ref="81df978a8e3da4bee74b135548f390f3" prefix=" " category="inline-code"></block> Bevor Sie fortfahren. Wenn der Wert nicht 12 lautet, wurden die LUNs nicht richtig erkannt. Zerstören Sie den zpool, überprüfen Sie, ob alle Schritte in der entsprechenden Host Utilities Dokumentation korrekt ausgeführt wurden, und erstellen Sie den zpool neu.</block>
  <block id="15ec722ce3f6694d12f89aeb5b621941" category="section-title">Zpools und Solaris LDOMs</block>
  <block id="8826ef54a7d108df25ed6921b5129cb6" category="paragraph">Solaris LDOMs stellen eine zusätzliche Anforderung dar, um sicherzustellen, dass die I/O-Ausrichtung korrekt ist. Obwohl eine LUN möglicherweise ordnungsgemäß als 4K-Gerät erkannt wird, erbt ein virtuelles vdsk-Gerät auf einem LDOM die Konfiguration nicht von der I/O-Domäne. Die vdsk auf Basis dieser LUN wird standardmäßig auf einen 512-Byte-Block zurückgesetzt.</block>
  <block id="9a984f24f825e4f0bca1f36e11acbca9" category="paragraph">Eine zusätzliche Konfigurationsdatei ist erforderlich. Zunächst müssen die einzelnen LDOMs für Oracle Bug 15824910 gepatcht werden, um die zusätzlichen Konfigurationsoptionen zu aktivieren. Dieser Patch wurde in alle derzeit verwendeten Versionen von Solaris portiert. Sobald das LDOM gepatcht ist, kann es wie folgt konfiguriert werden:</block>
  <block id="e0f306ab540315b015db849b1ae9099e" category="list-text">Identifizieren Sie die LUN oder LUNs, die in dem neuen zpool verwendet werden sollen. In diesem Beispiel handelt es sich um das c2d1-Gerät.</block>
  <block id="f469046d419183a7be08ed5a13d2c65e" category="list-text">Rufen Sie die vdc-Instanz der Geräte ab, die für einen ZFS-Pool verwendet werden sollen:</block>
  <block id="bcaa63dcd5db76bffd8b867e8720a272" category="list-text">Bearbeiten<block ref="ebceeaa7b6ce5abf6c8de7177255fef5" prefix=" " category="inline-code"></block>:</block>
  <block id="ec960a08b4666fe258b6e005064378ab" category="paragraph">Dies bedeutet, dass Geräteinstanz 1 eine Blockgröße von 4096 zugewiesen wird.</block>
  <block id="3df4cdc476a0c3a5a930597e9d8da84c" category="paragraph">Nehmen wir als weiteres Beispiel an, dass die vdsk-Instanzen 1 bis 6 für eine 4-KB-Blockgröße und konfiguriert sein müssen<block ref="74a491ed941b00d0c9909d488eee67bf" prefix=" " category="inline-code"></block> Lautet wie folgt:</block>
  <block id="dfed6d8974f03c5b31f20c9c5c2bbe66" category="list-text">Das Finale<block ref="3328fba80b08b36663ffae0684f6c578" prefix=" " category="inline-code"></block> Die Datei sollte Folgendes enthalten:</block>
  <block id="764a2caff05993fc0d3eff5de7b225e9" category="cell">Achtung</block>
  <block id="5c442834a7707cc96719e468c87b2ff6" category="cell">Das LDOM muss neu gestartet werden, nachdem vdc.conf konfiguriert und vdsk erstellt wurde. Dieser Schritt kann nicht vermieden werden. Die Änderung der Blockgröße wird nur nach einem Neustart wirksam. Fahren Sie mit der Konfiguration von zpool fort und stellen Sie sicher, dass der Ashift wie zuvor beschrieben richtig auf 12 eingestellt ist.</block>
  <block id="2138e0b461ac7e557539bb0b33bde81a" category="section-title">ZFS-Absichtsprotokoll (ZIL)</block>
  <block id="5477cebfd480a13008afdd16bea2b3f9" category="paragraph">Im Allgemeinen gibt es keinen Grund, das ZFS Intent Log (ZIL) auf einem anderen Gerät zu finden. Das Protokoll kann Speicherplatz mit dem Hauptpool teilen. Die primäre Verwendung eines separaten ZIL ist, wenn physische Laufwerke verwendet werden, denen die Schreib-Cache-Funktionen in modernen Speicher-Arrays fehlen.</block>
  <block id="26a004aeb043de19f767bd7daa39cf2f" category="section-title">Logbias</block>
  <block id="07fff183bc4c01bf9bbb21a48b389845" category="paragraph">Stellen Sie die ein<block ref="26a004aeb043de19f767bd7daa39cf2f" prefix=" " category="inline-code"></block> Parameter auf ZFS-Dateisystemen, auf denen Oracle-Daten gehostet werden.</block>
  <block id="ac01fbc5e98d6450f3b565d0617f4a55" category="paragraph">Die Verwendung dieses Parameters verringert die Gesamtschreibebenen. Unter den Standardeinstellungen werden geschriebene Daten zuerst an das ZIL und dann an den Hauptspeicherpool übertragen. Dieser Ansatz eignet sich für eine Konfiguration mit einer einfachen Laufwerkskonfiguration, die ein SSD-basiertes ZIL-Gerät und rotierende Medien für den Hauptspeicherpool umfasst. Dies liegt daran, dass eine Übertragung in einer einzelnen I/O-Transaktion auf den Medien mit der niedrigsten verfügbaren Latenz ausgeführt werden kann.</block>
  <block id="c6cc0f147c42f124079d7fc1a0761886" category="paragraph">Bei Verwendung eines modernen Storage Array mit eigener Caching-Funktion ist dieser Ansatz in der Regel nicht erforderlich. In seltenen Fällen ist es wünschenswert, einen Schreibvorgang mit einer einzigen Transaktion in das Protokoll übertragen zu können, z. B. bei einem Workload, der aus hochkonzentrierten, latenzempfindlichen zufälligen Schreibvorgängen besteht. Die Form der Write Amplification hat Folgen, da die protokollierten Daten schließlich in den Haupt-Storage Pool geschrieben werden, wodurch die Schreibaktivität verdoppelt wird.</block>
  <block id="92b9531657a4ce6a31c623d889a2c55d" category="section-title">Direkter I/O</block>
  <block id="387f4a4c250ed7a5003f3f6a19abfd1f" category="paragraph">Viele Applikationen, darunter auch Oracle Produkte, können den Host-Puffer-Cache umgehen, indem sie direkten I/O aktivieren Diese Strategie funktioniert bei ZFS-Dateisystemen nicht wie erwartet. Obwohl der Host-Puffer-Cache umgangen wird, speichert ZFS selbst weiterhin Daten im Cache. Dies kann zu irreführenden Ergebnissen führen, wenn Tools wie fio oder sio für Performance-Tests verwendet werden, da schwer vorherzusagen ist, ob I/O das Storage-System erreicht oder ob es lokal im BS zwischengespeichert wird. Diese Aktion macht es auch sehr schwierig, solche synthetischen Tests zu verwenden, um ZFS-Leistung mit anderen Dateisystemen zu vergleichen. In der Praxis gibt es bei echten Benutzer-Workloads kaum bis keine Unterschiede in der Filesystem-Performance.</block>
  <block id="ec79b30d56e7bae54aa7efedccc47e93" category="section-title">Mehrere zpools</block>
  <block id="f5aa5b31f0536ddcdb748ae360d91358" category="paragraph">Snapshot-basierte Backups, Wiederherstellungen, Klone und Archivierung von ZFS-basierten Daten müssen auf der Ebene von zpool durchgeführt werden und erfordern in der Regel mehrere zpools. Ein zpool ist analog zu einer LVM-Plattengruppe und sollte mit denselben Regeln konfiguriert werden. Beispielsweise ist eine Datenbank wahrscheinlich am besten mit den Datendateien in ausgelegt<block ref="f1fb162e58045170396a0ac29d648fa5" prefix=" " category="inline-code"></block> Und die Archivprotokolle, Kontrolldateien und Wiederherstellungsprotokolle befinden sich auf<block ref="92073f03d18c8eaec3eb5e0908210e1a" prefix=" " category="inline-code"></block>. Dieser Ansatz ermöglicht ein Standard-Hot Backup, bei dem sich die Datenbank im Hot Backup-Modus befindet, gefolgt von einem Snapshot von<block ref="f1fb162e58045170396a0ac29d648fa5" prefix=" " category="inline-code"></block>. Die Datenbank wird dann aus dem Hot Backup-Modus entfernt, das Protokollarchiv wird erzwungen und ein Snapshot von<block ref="92073f03d18c8eaec3eb5e0908210e1a" prefix=" " category="inline-code"></block> Wird erstellt. Ein Wiederherstellungsvorgang erfordert das Abhängen der zfs-Dateisysteme und den vollständigen Offlining des zpool nach einer SnapRestore-Wiederherstellung. Der zpool kann dann wieder online gebracht werden und die Datenbank wiederhergestellt werden.</block>
  <block id="f1110589be196c2310808482067fce1b" category="section-title">Filesystemio_options</block>
  <block id="c271ff9f255f2d215054d508448781a3" category="paragraph">Der Oracle-Parameter<block ref="f1110589be196c2310808482067fce1b" prefix=" " category="inline-code"></block> Funktioniert anders mit ZFS. Wenn<block ref="aef8f91b1e026cc1bb55e8b08c491d35" prefix=" " category="inline-code"></block> Oder<block ref="6887bae4cda2d09a283a165c5be3f2b8" prefix=" " category="inline-code"></block> Wird verwendet, Schreibvorgänge sind synchron und umgehen den BS-Puffer-Cache, aber Lesevorgänge werden von ZFS gepuffert. Diese Aktion führt zu Schwierigkeiten bei der Performance-Analyse, da I/O manchmal vom ZFS-Cache abgefangen und gewartet wird. Dadurch werden die Speicherlatenz und der gesamte I/O geringer als möglicherweise angezeigt.</block>
  <block id="22a7d37643562540ddbda52f511fb1fe" category="summary">Oracle auf ONTAP mit HP-UX</block>
  <block id="b1fd823d262032e04291313f72be9452" category="doc">HP-UX ERHÄLTLICH</block>
  <block id="5be7e182308e16aee80978c6a5ebe02b" category="paragraph">Konfigurationsthemen für das HP-UX-Betriebssystem.</block>
  <block id="8ec258cd0b6ab050fc478a415a20f2e9" category="section-title">HP-UX NFS Mount-Optionen</block>
  <block id="7c5876d5737071c64af78562fe375386" category="paragraph">In der folgenden Tabelle sind die HP-UX-NFS-Mount-Optionen für eine einzelne Instanz aufgeführt.</block>
  <block id="9c9fb3cc18a83e4e46165b5c3d4ce8ef" category="cell">Kontrolldateien
Datendateien
Wiederherstellungsprotokolle</block>
  <block id="55b835c747261995c0e1022d234e286d" category="cell"><block ref="fa8766c679857b7d589983df0ab5bcf4" prefix="" category="inline-code"></block></block>
  <block id="189dbd39cabd57c5d2e51714d9a5b85b" category="paragraph">In der folgenden Tabelle sind die HP-UX-NFS-Mount-Optionen für RAC aufgeführt.</block>
  <block id="fa9da3a6a7ef8986a94c7395577c322f" category="cell"><block ref="8b080dc74532d24847a6163dcc34d93f" prefix="" category="inline-code"></block></block>
  <block id="add42ff64fa5b57e5abeab49d154a9d9" category="cell"><block ref="acdef4af05a9f0c43f72b7c600f04d62" prefix="" category="inline-code"></block></block>
  <block id="c88a7b7f83f761f7fc2979815d210140" category="cell"><block ref="d29d7b7ed8c19a99fe17fd7f3d07ea7b" prefix="" category="inline-code"></block></block>
  <block id="af8831a1b8129b099114c3237a61db88" category="paragraph">Der Hauptunterschied zwischen Single-Instance- und RAC-Mount-Optionen ist das Hinzufügen von<block ref="79fea224ffd9e8111e4e87cab732464b" prefix=" " category="inline-code"></block> Und<block ref="6698a391ee8befa0ca4646a86a1bbd66" prefix=" " category="inline-code"></block> Zu den Mount-Optionen. Durch diese Ergänzung wird das Caching des Host-Betriebssystems deaktiviert, wodurch alle Instanzen im RAC Cluster eine konsistente Ansicht des Status der Daten haben. Obwohl Sie den verwenden<block ref="b6bd7c570605affc5b50bbd3e436f0c0" prefix=" " category="inline-code"></block> Parameter<block ref="b6a2b868e8bebfc19497b406a12a1071" prefix=" " category="inline-code"></block> Hat die gleiche Wirkung wie die Deaktivierung des Host-Caching, ist es weiterhin erforderlich, zu verwenden<block ref="79fea224ffd9e8111e4e87cab732464b" prefix=" " category="inline-code"></block> Und<block ref="6698a391ee8befa0ca4646a86a1bbd66" prefix=" " category="inline-code"></block>.</block>
  <block id="b865c6aba24c3f61595471aab993d27c" category="paragraph">Der Grund<block ref="79fea224ffd9e8111e4e87cab732464b" prefix=" " category="inline-code"></block> Ist für die gemeinsame Nutzung erforderlich<block ref="e1f651debac4f720c13ae930ff3ca14a" prefix=" " category="inline-code"></block> Die Bereitstellung soll die Konsistenz von Dateien wie Oracle-Passwortdateien und SPfiles erleichtern. Wenn jede Instanz in einem RAC-Cluster über einen dedizierten verfügt<block ref="e1f651debac4f720c13ae930ff3ca14a" prefix=" " category="inline-code"></block>, Dieser Parameter ist nicht erforderlich.</block>
  <block id="898311d838a2fa2fa41b4b52a63a7f1d" category="section-title">HP-UX VxFS-Mount-Optionen</block>
  <block id="85b4a3d44370909d395ab8af28ff4927" category="paragraph">Verwenden Sie die folgenden Mount-Optionen für Dateisysteme, auf denen Oracle-Binärdateien gehostet werden:</block>
  <block id="6630bbc9a901be0d038b2c39e2faf65d" category="paragraph">Verwenden Sie die folgenden Mount-Optionen für Dateisysteme mit Datendateien, Wiederherstellungsprotokollen, Archivprotokollen und Steuerdateien, bei denen die Version von HP-UX keine gleichzeitigen I/O unterstützt:</block>
  <block id="ed37730e0f28a631768a396e7898e197" category="paragraph">Wenn gleichzeitige I/O-Vorgänge unterstützt werden (VxFS 5.0.1 und höher oder mit der ServiceGuard Storage Management Suite), verwenden Sie diese Mount-Optionen für Dateisysteme, die Datendateien, Wiederherstellungsprotokolle, Archivprotokolle und Steuerdateien enthalten:</block>
  <block id="f51ddb98d92e83609db075add5fba4d8" category="admonition">Der Parameter<block ref="d3cc759510a3aba837fc8efeb2e24b91" prefix=" " category="inline-code"></block> Insbesondere in VxFS-Umgebungen kritisch ist. Oracle empfiehlt, dass dieser Parameter in Oracle 10g R1 und höher nicht festgelegt wird, sofern nicht ausdrücklich anders angegeben. Der Standardwert bei einer Oracle 8 KB Blockgröße ist 128. Wenn der Wert dieses Parameters auf 16 oder weniger erzwungen wird, entfernen Sie den<block ref="a6b02283cba560dcfdea44af66ec792c" prefix=" " category="inline-code"></block> Mount-Option, da dadurch die sequenzielle I/O-Performance beeinträchtigt werden kann. Dieser Schritt schädigt andere Aspekte der Leistung und sollte nur erfolgen, wenn der Wert von<block ref="d3cc759510a3aba837fc8efeb2e24b91" prefix=" " category="inline-code"></block> Muss vom Standardwert geändert werden.</block>
  <block id="ca3fa25943498edb0ee62d0ea286bb7a" category="summary">Oracle unter ONTAP mit Linux und ASMlib/ASM Filtertreiber</block>
  <block id="d7e9c72be485a5a848f1f7cd15a9a5ba" category="doc">ASMlib- und ASM-Filtertreiber</block>
  <block id="5802d9527a43305e9e1c903bc6b5a721" category="paragraph">Spezifische Konfigurationsthemen für das Linux-Betriebssystem unter Verwendung von AFD und ASMlib</block>
  <block id="2681013be5b0a9063a7ef0a8fe4d31da" category="section-title">ASMlib-Blockgrößen</block>
  <block id="1943673cc25055e93f0129f2baa8f499" category="paragraph">ASMlib ist eine optionale ASM-Managementbibliothek und zugehörige Dienstprogramme. Sein primärer Wert ist die Fähigkeit, eine LUN oder eine NFS-basierte Datei als ASM-Ressource mit einem für den Benutzer lesbaren Label zu stempeln.</block>
  <block id="51713fdb873939c9c333273947776b8e" category="paragraph">Aktuelle Versionen von ASMlib erkennen einen LUN-Parameter namens Logical Blocks per Physical Block Exponent (LBPPBE). Dieser Wert wurde erst vor kurzem vom ONTAP SCSI-Ziel gemeldet. Es gibt jetzt einen Wert zurück, der angibt, dass eine 4-KB-Blockgröße bevorzugt wird. Dies ist keine Definition der Blockgröße, aber es ist ein Hinweis für jede Anwendung, die LBPPBE verwendet, dass I/OS einer bestimmten Größe effizienter verarbeitet werden könnten. ASMlib interpretiert LBPPBE jedoch als Blockgröße und stempelt den ASM-Header dauerhaft, wenn das ASM-Gerät erstellt wird.</block>
  <block id="65242d5b49071240043eeef598415104" category="paragraph">Dieser Prozess kann auf verschiedene Weise Probleme mit Upgrades und Migrationen verursachen, die auf die Unfähigkeit basieren, ASMlib-Geräte mit unterschiedlichen Blockgrößen in derselben ASM-Diskgruppe zu mischen.</block>
  <block id="ea884eec0628302adc731211dc4e2cc7" category="paragraph">Beispielsweise haben ältere Arrays im Allgemeinen einen LBPPBE-Wert von 0 gemeldet oder diesen Wert überhaupt nicht gemeldet. ASMlib interpretiert dies als 512-Byte-Blockgröße. Neuere Arrays weisen daher eine 4-KB-Blockgröße auf. Es ist nicht möglich, sowohl 512-Byte- als auch 4-KB-Geräte in derselben ASM-Diskgruppe zu mischen. Dies würde verhindern, dass ein Benutzer die Größe der ASM-Diskgruppe mit LUNs aus zwei Arrays vergrößert oder ASM als Migrationstool nutzt. In anderen Fällen erlaubt RMAN möglicherweise nicht das Kopieren von Dateien zwischen einer ASM-Diskgruppe mit einer Blockgröße von 512 Byte und einer ASM-Diskgruppe mit einer Blockgröße von 4 KB.</block>
  <block id="f17ff15b23b87f35906ece98842a080f" category="paragraph">Die bevorzugte Lösung ist das Patchen von ASMlib. Die Oracle-Fehler-ID lautet 13999609, und der Patch ist in oracleasm-Support-2.1.8-1 und höher vorhanden. Mit diesem Patch kann der Benutzer den Parameter festlegen<block ref="442e2026c8afecc4611b52331b5d0d56" prefix=" " category="inline-code"></block> Bis<block ref="b326b5062b2f0e69046810717534cb09" prefix=" " category="inline-code"></block> Im<block ref="92a59ba9a0643a344be2d72cfd504181" prefix=" " category="inline-code"></block> Konfigurationsdatei Dadurch wird die Verwendung des LBPPBE-Parameters durch ASMlib blockiert, was bedeutet, dass LUNs auf dem neuen Array nun als 512-Byte-Blockgeräte erkannt werden.</block>
  <block id="f140ff6b2b71e70e551e39dacb9561ef" category="admonition">Die Option ändert nicht die Blockgröße von LUNs, die zuvor von ASMlib gestempelt wurden. Wenn beispielsweise eine ASM-Datenträgergruppe mit 512-Byte-Blöcken zu einem neuen Speichersystem migriert werden muss, das einen 4-KB-Block meldet, dann ist die Option<block ref="442e2026c8afecc4611b52331b5d0d56" prefix=" " category="inline-code"></block> Muss festgelegt werden, bevor die neuen LUNs mit ASMlib gestempelt werden.  Wenn Geräte bereits durch Oracleasm gestempelt wurden, müssen sie neu formatiert werden, bevor sie mit einer neuen Blockgröße neu aufgestempelt werden. Zuerst, dekonstruieren Sie das Gerät mit<block ref="41bd8c47b8e640da7bdb5c7dc995d435" prefix=" " category="inline-code"></block>, Und löschen Sie dann die ersten 1GB des Geräts mit<block ref="85c2e94baaf4d9c084e19d290907596e" prefix=" " category="inline-code"></block>. Wenn das Gerät zuvor partitioniert worden war, verwenden Sie schließlich die<block ref="9a287d63dabd6fbcbbe1b12344bfe922" prefix=" " category="inline-code"></block> Befehl, um veraltete Partitionen zu entfernen oder einfach das Betriebssystem neu zu starten.</block>
  <block id="75ad83418241561186f96dfed5229aaa" category="paragraph">Wenn ASMlib nicht gepatcht werden kann, kann ASMlib aus der Konfiguration entfernt werden. Diese Änderung führt zu Unterbrechungen und erfordert das Entstempeln von ASM-Festplatten und die Sicherstellung, dass die<block ref="0802edf7303a95bdecde832bbbe3a89c" prefix=" " category="inline-code"></block> Parameter ist korrekt eingestellt. Diese Änderung erfordert jedoch nicht die Migration der Daten.</block>
  <block id="ad9ac4c6d7ed2e11bdcf8c693658a482" category="section-title">Blockgrößen des ASM-Filterlaufwerks (AFD)</block>
  <block id="de59cd97a61c9f9964a35d2cd8b05c88" category="paragraph">AFD ist eine optionale ASM-Managementbibliothek, die zum Ersatz für ASMlib wird. Aus Sicht des Speichers ist es ASMlib sehr ähnlich, aber es enthält zusätzliche Funktionen wie die Möglichkeit, nicht-Oracle-I/O zu blockieren, um die Wahrscheinlichkeit von Benutzer- oder Anwendungsfehlern zu verringern, die Daten beschädigen könnten.</block>
  <block id="36dc27685773851e52f035f82e3deba2" category="section-title">Blockgrößen des Geräts</block>
  <block id="1ef92cf7e561e179d6079cc937b2778a" category="paragraph">Wie ASMlib liest auch AFD den LUN-Parameter Logical Blocks per Physical Block Exponent (LBPPBE) und verwendet standardmäßig die physische Blockgröße, nicht die logische Blockgröße.</block>
  <block id="b95ce6c503801cb15f2f9c0773c58f00" category="paragraph">Dies kann zu einem Problem führen, wenn AFD zu einer bestehenden Konfiguration hinzugefügt wird, bei der die ASM-Geräte bereits als 512-Byte-Blockgeräte formatiert sind. Der AFD-Treiber erkennt die LUN als 4K-Gerät und die Diskrepanz zwischen dem ASM-Label und dem physischen Gerät würde den Zugriff verhindern. Ebenso wären Migrationen betroffen, da es nicht möglich ist, sowohl 512-Byte- als auch 4-KB-Geräte in derselben ASM-Diskgruppe zu mischen. Dies würde verhindern, dass ein Benutzer die Größe der ASM-Diskgruppe mit LUNs aus zwei Arrays vergrößert oder ASM als Migrationstool nutzt. In anderen Fällen erlaubt RMAN möglicherweise nicht das Kopieren von Dateien zwischen einer ASM-Diskgruppe mit einer Blockgröße von 512 Byte und einer ASM-Diskgruppe mit einer Blockgröße von 4 KB.</block>
  <block id="7ef45d3a7c5fff234bf42bdf549b8339" category="paragraph">Die Lösung ist einfach: AFD enthält einen Parameter, mit dem gesteuert werden kann, ob logische oder physische Blockgrößen verwendet werden. Dies ist ein globaler Parameter, der alle Geräte im System betrifft. Um die Verwendung der logischen Blockgröße durch AFD zu erzwingen, legen Sie fest<block ref="722fc896569f3d455bb5ef8f5b8c3703" prefix=" " category="inline-code"></block> Im<block ref="dcd5fd81543c5e08e927c54e89acdd40" prefix=" " category="inline-code"></block> Datei:</block>
  <block id="47b0d7fc4c27720c4fc326722edad27c" category="section-title">Multipath-Übertragungsgrößen</block>
  <block id="7c329811bcc7bb2f50005da5a3aff250" category="paragraph">Durch die jüngsten linux-Kernel-Änderungen werden E/A-Größenbeschränkungen an Multipath-Geräte durchgesetzt, und AFD hält diese Einschränkungen nicht ein. Die I/OS werden dann abgelehnt, was dazu führt, dass der LUN-Pfad offline geschaltet wird. Dies führt dazu, dass Oracle Grid nicht installiert, ASM konfiguriert oder eine Datenbank nicht erstellt werden kann.</block>
  <block id="926e4b7a2822a39a07f61474b92e9d8c" category="paragraph">Die Lösung besteht darin, die maximale Übertragungslänge in der Datei multipath.conf für ONTAP-LUNs manuell anzugeben:</block>
  <block id="3d0c741146f1e8e31bc7d07128ca6e0a" category="admonition">Auch wenn derzeit keine Probleme vorliegen, sollte dieser Parameter eingestellt werden, wenn AFD verwendet wird, um sicherzustellen, dass ein künftiges linux-Upgrade nicht unerwartet Probleme verursacht.</block>
  <block id="72247c591c444399f3d42dffa31b644e" category="summary">Oracle auf ONTAP unter Nutzung von AIX</block>
  <block id="23802d94b756cf69028557bea156ab1a" category="doc">IBM AIX</block>
  <block id="5b8d4d99cdcb494ca636eb065004b165" category="paragraph">Konfigurationsthemen für das IBM AIX-Betriebssystem.</block>
  <block id="d99ae60d37a12f766bc2a1f1c228fb4f" category="section-title">Gleichzeitige I/O-Vorgänge</block>
  <block id="0f3eb508f611e203aeffa91d5753648a" category="paragraph">Um eine optimale Leistung auf IBM AIX zu erzielen, muss gleichzeitig I/O verwendet werden Ohne gleichzeitige I/O-Vorgänge sind Performance-Einschränkungen wahrscheinlich, weil AIX serialisierte, atomare I/O-Vorgänge durchführt, was einen beträchtlichen Overhead nach sich zieht.</block>
  <block id="ecdc41fc6a2adf7e41e7277e12eeb805" category="paragraph">Ursprünglich hat NetApp die Verwendung von empfohlen<block ref="4482571a249db31b3abed938e4567a15" prefix=" " category="inline-code"></block> Mount-Option, um die Verwendung von gleichzeitigen I/O-Vorgängen auf dem Dateisystem zu erzwingen. Dieser Prozess hatte jedoch Nachteile und ist nicht mehr erforderlich. Seit der Einführung von AIX 5.2 und Oracle 10gR1 kann Oracle auf AIX einzelne Dateien für gleichzeitige I/O-Vorgänge öffnen, anstatt gleichzeitige I/O-Vorgänge auf dem gesamten Dateisystem zu erzwingen.</block>
  <block id="445b433b62b675f0ca0bda7acb56d41b" category="paragraph">Die beste Methode für die Aktivierung gleichzeitiger I/O ist, die festzulegen<block ref="b6bd7c570605affc5b50bbd3e436f0c0" prefix=" " category="inline-code"></block> Parameter<block ref="f1110589be196c2310808482067fce1b" prefix=" " category="inline-code"></block> Bis<block ref="aef8f91b1e026cc1bb55e8b08c491d35" prefix=" " category="inline-code"></block>. Auf diese Weise kann Oracle spezifische Dateien zur Verwendung mit gleichzeitigen I/O-Vorgängen öffnen</block>
  <block id="6206c23a0282b18352573158f9a8f9b3" category="paragraph">Wird Verwendet<block ref="4482571a249db31b3abed938e4567a15" prefix=" " category="inline-code"></block> Als Mount-Option erzwingt die Verwendung von gleichzeitigen I/O-Vorgängen, was negative Auswirkungen haben kann. Das Erzwingen von gleichzeitigen I/O-Vorgängen deaktiviert beispielsweise das Vorauslesen auf Dateisystemen, was die Performance für I/O-Vorgänge beeinträchtigen kann, die außerhalb der Oracle-Datenbanksoftware auftreten, z. B. das Kopieren von Dateien und das Durchführen von Bandsicherungen. Darüber hinaus sind Produkte wie Oracle GoldenGate und SAP BR*Tools nicht mit der Verwendung des kompatibel<block ref="4482571a249db31b3abed938e4567a15" prefix=" " category="inline-code"></block> Mount-Option mit bestimmten Versionen von Oracle.</block>
  <block id="770cb9a1e9321ca3012ecbb9ec65c422" category="list-text">Verwenden Sie das nicht<block ref="4482571a249db31b3abed938e4567a15" prefix=" " category="inline-code"></block> Mount-Option auf Filesystem-Ebene. Aktivieren Sie stattdessen Concurrent I/O über<block ref="b6a2b868e8bebfc19497b406a12a1071" prefix=" " category="inline-code"></block>.</block>
  <block id="872080b7d5ec5585776f1426fb157842" category="list-text">Verwenden Sie nur das<block ref="4482571a249db31b3abed938e4567a15" prefix=" " category="inline-code"></block> Die Mount-Option sollte aktiviert werden, wenn keine Einstellung möglich ist<block ref="b6a2b868e8bebfc19497b406a12a1071" prefix=" " category="inline-code"></block>.</block>
  <block id="0c5d86482201f32acb30cd2f7de3048f" category="section-title">Mount-Optionen für AIX NFS</block>
  <block id="1ce07cafb2507c98c8b96ad5f35fb66a" category="paragraph">In der folgenden Tabelle sind die AIX NFS-Mount-Optionen für Oracle Single-Instance-Datenbanken aufgeführt.</block>
  <block id="9a8f040dae3f0f15b337fe69a85239c0" category="cell"><block ref="86d38d6e2b36f6557e583e005e23d258" prefix="" category="inline-code"></block></block>
  <block id="d45a1a2afa30c30042b28f028fe75953" category="cell"><block ref="915be14765d6133923d803e1221f1513" prefix="" category="inline-code"></block></block>
  <block id="b74f5956b4bcda2de3c82ee97e192ab6" category="paragraph">In der folgenden Tabelle sind die AIX-NFS-Mount-Optionen für RAC aufgeführt.</block>
  <block id="b547b55ba7f2a20602494777c5426eba" category="cell"><block ref="7e879bda961bd5b7d64d2ef4f5fb7869" prefix="" category="inline-code"></block></block>
  <block id="875abb256654bd3f6da7abcb1bd92f27" category="cell"><block ref="f93eecf9c582d76d4e14292dc34c79f8" prefix="" category="inline-code"></block></block>
  <block id="3ed8fb68917b28af138fb74ccde62e80" category="cell"><block ref="415e8eb8b9fc05cb48e633d31fd04944" prefix="" category="inline-code"></block></block>
  <block id="8102775fe4080f632332ab8d3312311a" category="paragraph">Der Hauptunterschied zwischen Single-Instance- und RAC-Mount-Optionen ist das Hinzufügen von<block ref="79fea224ffd9e8111e4e87cab732464b" prefix=" " category="inline-code"></block> Zu den Mount-Optionen. Durch diese Ergänzung wird das Caching des Host-Betriebssystems deaktiviert, wodurch alle Instanzen im RAC Cluster eine konsistente Ansicht des Status der Daten haben.</block>
  <block id="1e3f10dfa324520cb7261c0da5bf6ec7" category="paragraph">Obwohl Sie den verwenden<block ref="4482571a249db31b3abed938e4567a15" prefix=" " category="inline-code"></block> Mount-Option und der<block ref="b6bd7c570605affc5b50bbd3e436f0c0" prefix=" " category="inline-code"></block> Parameter<block ref="b6a2b868e8bebfc19497b406a12a1071" prefix=" " category="inline-code"></block> Hat die gleiche Wirkung wie die Deaktivierung des Host-Caching, ist es weiterhin erforderlich, zu verwenden<block ref="79fea224ffd9e8111e4e87cab732464b" prefix=" " category="inline-code"></block>.<block ref="79fea224ffd9e8111e4e87cab732464b" prefix=" " category="inline-code"></block> Ist für die gemeinsame Nutzung erforderlich<block ref="e1f651debac4f720c13ae930ff3ca14a" prefix=" " category="inline-code"></block> Bereitstellung, um die Konsistenz von Dateien wie Oracle-Passwortdateien und zu erleichtern<block ref="1737629d60b511cf45957529a8f046e2" prefix=" " category="inline-code"></block> Parameterdateien. Wenn jede Instanz in einem RAC-Cluster über einen dedizierten verfügt<block ref="e1f651debac4f720c13ae930ff3ca14a" prefix=" " category="inline-code"></block>, Dann ist dieser Parameter nicht erforderlich.</block>
  <block id="5365dd1a92461c9e6cf65017c4a11647" category="section-title">Mount-Optionen für AIX jfs/jfs2</block>
  <block id="d7a578263480a2003f05c459a8961298" category="paragraph">In der folgenden Tabelle sind die AIX jfs/jfs2-Mount-Optionen aufgeführt.</block>
  <block id="0aabf727ab0a83c5f5d078e8b18445e0" category="cell">Standardwerte</block>
  <block id="e1f651debac4f720c13ae930ff3ca14a" category="cell">ORACLE_HOME</block>
  <block id="27a7ffa293f5a4d2a5bb54354486dece" category="paragraph">Vor der Verwendung von AIX<block ref="b7cc91287fc99a8937a55e79376c6f54" prefix=" " category="inline-code"></block> Geräte in jeder Umgebung, einschließlich Datenbanken, überprüfen Sie den Parameter<block ref="9d51746070ef554ad4e93a16de4aed0f" prefix=" " category="inline-code"></block>. Dieser Parameter entspricht nicht der HBA-Warteschlangentiefe, sondern bezieht sich auf die SCSI-Warteschlangentiefe der einzelnen<block ref="66ad66c6ace8456eae4ca6807552e54b" prefix=" " category="inline-code"></block> Ist möglicherweise zu niedrig für eine gute Leistung. Die Prüfung hat ergeben, dass der optimale Wert 64 ist.</block>
  <block id="6e1dee25b21d0005970053df9e9384ba" category="summary">Oracle auf ONTAP unter Microsoft Windows</block>
  <block id="bb79f96acbff544ded541446c9c7c894" category="doc">Microsoft Windows</block>
  <block id="44959b8c12de9e1107621ee8c0337463" category="paragraph">Spezifische Konfigurationsthemen für das Microsoft Windows-Betriebssystem.</block>
  <block id="14ce2582c2080a7f08fe9249f6565f40" category="paragraph">Oracle unterstützt den Einsatz von Microsoft Windows mit dem direkten NFS-Client. Diese Funktion eröffnet neue Möglichkeiten für das Management von NFS. Hierzu zählen beispielsweise die Möglichkeit, Dateien über verschiedene Umgebungen hinweg anzuzeigen, Volumes dynamisch zu skalieren und das kostengünstigere IP-Protokoll zu nutzen. Informationen zur Installation und Konfiguration einer Datenbank unter Microsoft Windows unter Verwendung von DNFS finden Sie in der offiziellen Oracle-Dokumentation. Es gibt keine speziellen Best Practices.</block>
  <block id="f854b764258138b512f30be71e1c7908" category="paragraph">Stellen Sie für eine optimale Komprimierungseffizienz sicher, dass das NTFS-Dateisystem eine Zuweisungseinheit mit 8 KB oder mehr verwendet. Die Verwendung einer 4-KB-Zuweisungseinheit, die im Allgemeinen die Standardeinstellung ist, wirkt sich negativ auf die Komprimierungseffizienz aus.</block>
  <block id="140def8362bd2cf6a999328e25572cfd" category="summary">Oracle auf ONTAP unter Linux</block>
  <block id="edc9f0a5a5d57797bf68e37364743831" category="doc">Linux</block>
  <block id="dfc95ed5e895617bbd0d4b1a8bfba8ca" category="paragraph">Konfigurationsthemen für das Linux-Betriebssystem.</block>
  <block id="5ecd4a6f4aedfdd45cce80a18b1a7942" category="section-title">Slot-Tabellen</block>
  <block id="cb0b01337e8f6bf9d06b70a95f74501e" category="paragraph">Die NFS-Performance unter Linux hängt von einem Parameter namens ab<block ref="453f2cc2326f82af1053f4aa4b75400b" prefix=" " category="inline-code"></block>. Siehe <block ref="77039a327377cbf65e33c7c5d3766672" category="inline-link-macro-rx"></block> Für kritische Informationen.</block>
  <block id="2518e65e64213437c921c39a097db167" category="section-title">Mount-Optionen für Linux NFS</block>
  <block id="29cd2e6d4fc96e749c4a0e622cad7f50" category="paragraph">In der folgenden Tabelle sind die Linux-NFS-Mount-Optionen für eine einzelne Instanz aufgeführt.</block>
  <block id="9fafd031075cede0e8a5a796ec45fbff" category="paragraph">In der folgenden Tabelle sind die Linux-NFS-Mount-Optionen für RAC aufgeführt.</block>
  <block id="f16135915fe2ca5c3b0d660acc0325d3" category="cell"><block ref="4c927b3193f1cd00c7cfd3ac2e7ba8ea" prefix="" category="inline-code"></block></block>
  <block id="fc1ea13514277ff14dc705f62c31c0fc" category="cell"><block ref="4d0511346ac74044d79c9bc297d59b09" prefix="" category="inline-code"></block></block>
  <block id="13c64659680c0bc3603209997cc22225" category="cell">CRS/Abstimmung</block>
  <block id="672c5eef2603018159295408f761324b" category="cell"><block ref="26b20bdf0b0e7d3ddef3749a70c17932" prefix="" category="inline-code"></block></block>
  <block id="f7085c7dc406f5b44813ac43c18b80c0" category="paragraph">Der Hauptunterschied zwischen Single-Instance- und RAC-Mount-Optionen ist das Hinzufügen von<block ref="3504e2b0e7c968444314433be465518d" prefix=" " category="inline-code"></block> Zu den Mount-Optionen. Durch diese Ergänzung wird das Caching des Host-Betriebssystems deaktiviert, wodurch alle Instanzen im RAC Cluster eine konsistente Ansicht des Status der Daten haben. Obwohl Sie den verwenden<block ref="b6bd7c570605affc5b50bbd3e436f0c0" prefix=" " category="inline-code"></block> Parameter<block ref="b6a2b868e8bebfc19497b406a12a1071" prefix=" " category="inline-code"></block> Hat die gleiche Wirkung wie die Deaktivierung des Host-Caching, ist es weiterhin erforderlich, zu verwenden<block ref="3504e2b0e7c968444314433be465518d" prefix=" " category="inline-code"></block>.</block>
  <block id="d2537738f34705bc9d100925252c0102" category="paragraph">Der Grund<block ref="3504e2b0e7c968444314433be465518d" prefix=" " category="inline-code"></block> Ist für die gemeinsame Nutzung erforderlich<block ref="e1f651debac4f720c13ae930ff3ca14a" prefix=" " category="inline-code"></block> Die Bereitstellung soll die Konsistenz von Dateien wie den Oracle-Passwortdateien und den SPfiles erleichtern. Wenn jede Instanz in einem RAC-Cluster über einen dedizierten verfügt<block ref="e1f651debac4f720c13ae930ff3ca14a" prefix=" " category="inline-code"></block>, Dann ist dieser Parameter nicht erforderlich.</block>
  <block id="5084019c1051a9937b5ff77568ce579b" category="paragraph">Im Allgemeinen sollten nicht-Datenbankdateien mit denselben Optionen gemountet werden, die für Datendateien mit einer einzigen Instanz verwendet werden, obwohl bestimmte Applikationen unterschiedliche Anforderungen haben können. Vermeiden Sie die Montageoptionen<block ref="79fea224ffd9e8111e4e87cab732464b" prefix=" " category="inline-code"></block> Und<block ref="3504e2b0e7c968444314433be465518d" prefix=" " category="inline-code"></block> Wenn möglich, da diese Optionen das Vorauslesen und Puffern auf Dateisystemebene deaktivieren. Dies kann zu schwerwiegenden Leistungsproblemen bei Prozessen wie Extraktion, Übersetzung und Laden führen.</block>
  <block id="243de27c01fea05cc58186d2e5ad1ce5" category="section-title">ACCESS und GETATTR</block>
  <block id="59dcf78e97c197a0f240067da57a248f" category="paragraph">Einige Kunden bemerken, dass ein extrem hohes Maß an anderen IOPS wie ACCESS und GETATTR ihre Workloads dominieren kann. In Extremfällen können Vorgänge wie Lese- und Schreibvorgänge bis zu 10 % des Gesamtbetrags ausmachen. Dies ist ein normales Verhalten bei jeder Datenbank, die die Verwendung einschließt<block ref="3504e2b0e7c968444314433be465518d" prefix=" " category="inline-code"></block> Und/oder<block ref="79fea224ffd9e8111e4e87cab732464b" prefix=" " category="inline-code"></block> Unter Linux, weil diese Optionen dazu führen, dass das Linux-Betriebssystem ständig Datei-Metadaten aus dem Speichersystem neu lädt. Vorgänge wie ACCESS und GETATTR sind Vorgänge mit geringen Auswirkungen, die aus dem ONTAP Cache in einer Datenbankumgebung bedient werden. Sie sollten nicht als echte IOPS-Werte wie Lese- und Schreibvorgänge betrachtet werden, die einen echten Bedarf an Storage-Systemen verursachen. Diese anderen IOPS erzeugen jedoch eine gewisse Last, insbesondere in RAC-Umgebungen. Um diesem Problem zu begegnen, aktivieren Sie DNFS, wodurch der Puffercache des Betriebssystems umgangen wird und unnötige Metadatenvorgänge vermieden werden.</block>
  <block id="041f371e212c70407e145ae9f752a8b4" category="section-title">Linux Direct NFS</block>
  <block id="dd2f3f344f14ae5daf12cb0a817a72e0" category="paragraph">Eine zusätzliche Mount-Option, genannt<block ref="4740c034d97ca90a96b8050082816605" prefix=" " category="inline-code"></block>, Ist erforderlich, wenn (a) DNFS aktiviert ist und (b) ein Quell-Volume mehr als einmal auf einem einzelnen Server (c) mit einem verschachtelten NFS-Mount gemountet wird. Diese Konfiguration ist hauptsächlich in Umgebungen zu finden, die SAP-Anwendungen unterstützen. Beispielsweise könnte ein einzelnes Volume auf einem NetApp System über ein Verzeichnis verfügen, das sich in befindet<block ref="9f9f4ccb1fc3afcbfe0cc3f5eac4332c" prefix=" " category="inline-code"></block> Und eine Sekunde bei<block ref="ac2f9bbcd397d8f6b39e6713658051ea" prefix=" " category="inline-code"></block>. Wenn<block ref="9f9f4ccb1fc3afcbfe0cc3f5eac4332c" prefix=" " category="inline-code"></block> Ist bei montiert<block ref="9ad16912cc0ba54a259b1a15d233c264" prefix=" " category="inline-code"></block> Und<block ref="ac2f9bbcd397d8f6b39e6713658051ea" prefix=" " category="inline-code"></block> Ist bei montiert<block ref="1da707b60c3b55bd01cb7df7c171a368" prefix=" " category="inline-code"></block>Das Ergebnis sind verschachtelte NFS-Mounts, die von der gleichen Quelle stammen.</block>
  <block id="b06ff38483faff2d17d8de1fc966848e" category="paragraph">Das Betriebssystem kann erkennen, dass<block ref="9ad16912cc0ba54a259b1a15d233c264" prefix=" " category="inline-code"></block> Und<block ref="1da707b60c3b55bd01cb7df7c171a368" prefix=" " category="inline-code"></block> Befinden sich auf demselben Volume, bei dem es sich um das gleiche Quelldateisystem handelt. Das Betriebssystem verwendet dann dasselbe Geräte-Handle für den Zugriff auf die Daten. Dadurch wird die Verwendung von OS Caching und bestimmten anderen Vorgängen verbessert, es beeinträchtigt jedoch DNFS. Wenn DNFS auf eine Datei zugreifen muss, z. B. auf<block ref="1737629d60b511cf45957529a8f046e2" prefix=" " category="inline-code"></block>, Ein<block ref="1da707b60c3b55bd01cb7df7c171a368" prefix=" " category="inline-code"></block>Es könnte irrtümlich versuchen, den falschen Pfad zu den Daten zu verwenden. Das Ergebnis ist ein I/O-Vorgang, der fehlgeschlagen ist. Fügen Sie in diesen Konfigurationen den hinzu<block ref="4740c034d97ca90a96b8050082816605" prefix=" " category="inline-code"></block> Mount-Option für jedes NFS-Dateisystem, das ein Quell-FlexVol-Volume mit einem anderen NFS-Dateisystem auf diesem Host gemeinsam nutzt. Dies zwingt das Linux-Betriebssystem, einem unabhängigen Device Handle für dieses Dateisystem zuzuweisen.</block>
  <block id="14dd7af30f62ec838445a1e167d2aff6" category="section-title">Linux Direct NFS und Oracle RAC</block>
  <block id="c6a209e4ad702c6424efb7d63d76feca" category="paragraph">Die Verwendung von DNFS bietet besondere Leistungsvorteile für Oracle RAC auf dem Linux-Betriebssystem, da Linux keine Methode zur Erzwang direkter I/O-Vorgänge bietet, die für die Kohärenz über die Knoten mit RAC erforderlich ist. Als Workaround benötigt Linux die Verwendung von<block ref="3504e2b0e7c968444314433be465518d" prefix=" " category="inline-code"></block> Mount-Option, die dazu führt, dass Dateidaten sofort aus dem OS-Cache ablaufen. Diese Option zwingt den Linux NFS Client wiederum, Attributdaten ständig neu zu lesen, was die Latenz schädigt und die Belastung des Storage Controllers erhöht.</block>
  <block id="3070cb366c38db327b0cf057d63792c1" category="paragraph">Durch die Aktivierung von DNFS wird der Host-NFS-Client umgangen und dieser Schaden wird vermieden. Mehrere Kunden haben bei der Aktivierung von DNFS deutliche Performance-Steigerungen bei RAC Clustern und deutliche geringere ONTAP-Lasten (insbesondere im Hinblick auf andere IOPS) gemeldet.</block>
  <block id="e97ab7f94d503bbec4b013b5b77118c6" category="section-title">Linux Direct NFS- und oranfstab-Datei</block>
  <block id="f63255b70940d25581e0cf5f81dd6cd6" category="paragraph">Bei der Verwendung von DNFS unter Linux mit der Multipathing-Option müssen mehrere Subnetze verwendet werden. Auf anderen Betriebssystemen können mehrere DNFS-Kanäle mithilfe des eingerichtet werden<block ref="54b4c4075463b2e02cd69f5cd139b5b2" prefix=" " category="inline-code"></block> Und<block ref="bbf52a1a57a4eaa83512cab68fd52b70" prefix=" " category="inline-code"></block> Optionen zum Konfigurieren mehrerer DNFS-Kanäle in einem einzigen Subnetz. Dies funktioniert jedoch unter Linux nicht richtig, und es können unerwartete Leistungsprobleme auftreten. Bei Linux muss sich jeder für den DNFS-Verkehr verwendete NIC in einem anderen Subnetz befinden.</block>
  <block id="6c5cf31ca1af553b1f4a9b99e3cb054c" category="section-title">I/O-Planer</block>
  <block id="49bb1f5f4810e5f3d32dac84bd96005d" category="paragraph">Der Linux-Kernel ermöglicht eine Steuerung auf niedriger Ebene über die Art und Weise, wie I/O-Vorgänge zum Blockieren von Geräten geplant werden. Die Standardeinstellungen auf verschiedenen Linux-Distribution variieren erheblich. Tests zeigen, dass Deadline in der Regel die besten Ergebnisse bietet, aber gelegentlich NOOP war etwas besser. Der Unterschied in der Performance ist minimal, aber testen Sie beide Optionen, wenn es erforderlich ist, um die maximal mögliche Performance aus einer Datenbankkonfiguration zu extrahieren. CFQ ist in vielen Konfigurationen der Standard und hat bei Datenbank-Workloads erhebliche Performance-Probleme gezeigt.</block>
  <block id="38f25b8840d56fc601af1024115764b2" category="paragraph">Anweisungen zur Konfiguration des I/O-Planers finden Sie in der entsprechenden Dokumentation des Linux-Anbieters.</block>
  <block id="4150162ad42bffea7bb903b4c7a4ffd9" category="section-title">Multipathing</block>
  <block id="305482bf1c318f0a9a04f94987db06b2" category="paragraph">Einige Kunden sind während der Netzwerkunterbrechung auf Abstürze gestoßen, weil der Multipath-Daemon auf ihrem System nicht ausgeführt wurde. Bei aktuellen Versionen von Linux können der Installationsprozess des Betriebssystems und des Multipathing-Daemons diese Betriebssysteme für dieses Problem anfällig machen. Die Pakete sind ordnungsgemäß installiert, aber nach einem Neustart nicht für den automatischen Start konfiguriert.</block>
  <block id="6fb0bf499bef576f56e0fd6360eba0a6" category="paragraph">Die Standardeinstellung für den Multipath-Daemon unter RHEL5.5 kann beispielsweise wie folgt angezeigt werden:</block>
  <block id="31026ba0b77cbe4c9d44ed6afc859ed6" category="paragraph">Dies kann mit den folgenden Befehlen korrigiert werden:</block>
  <block id="c759a9b7e4db09da8a25fb73d256f6b7" category="section-title">ASM Spiegelung</block>
  <block id="f2f41836b42c08199948378b4a4a6e26" category="paragraph">ASM-Spiegelung erfordert möglicherweise Änderungen an den Linux Multipath-Einstellungen, damit ASM ein Problem erkennen und zu einer alternativen Ausfallgruppe wechseln kann. Die meisten ASM-Konfigurationen auf ONTAP verwenden externe Redundanz. Das bedeutet, dass Datensicherung durch das externe Array bereitgestellt wird und ASM keine Daten spiegelt. Einige Standorte verwenden ASM mit normaler Redundanz, um normalerweise zwei-Wege-Spiegelung über verschiedene Standorte hinweg bereitzustellen.</block>
  <block id="25f47751ccd5df99e3c25a8eb2a21fc5" category="inline-link-macro">NetApp Host Utilities-Dokumentation</block>
  <block id="066a79b72a430b074cdc0476b67bbde3" category="paragraph">Die Linux-Einstellungen, die im angezeigt werden <block ref="210658f6fe0d0061c73c19a9a6b263d1" category="inline-link-macro-rx"></block> Schließen Sie Multipath-Parameter ein, die zu unbestimmter I/O-Warteschlange führen Dies bedeutet, dass ein I/O auf einem LUN-Gerät ohne aktive Pfade so lange wartet, wie es für den I/O-Abschluss erforderlich ist. Dies ist in der Regel wünschenswert, da Linux-Hosts so lange warten, bis die Änderungen des SAN-Pfads abgeschlossen sind, FC-Switches neu gestartet werden oder ein Storage-System einen Failover abschließt.</block>
  <block id="184ea23c04f24d03fc0123bc6eb30de2" category="paragraph">Dieses unbegrenzte Warteschlangenverhalten verursacht ein Problem mit der ASM-Spiegelung, da ASM einen I/O-Fehler empfangen muss, damit er I/O auf einer alternativen LUN erneut versuchen kann.</block>
  <block id="5616945ee545765b51d3fe1871cff4ec" category="paragraph">Legen Sie die folgenden Parameter in Linux fest<block ref="9ac80d53ede05256c28cf9e043eb423c" prefix=" " category="inline-code"></block> Datei für ASM-LUNs, die mit ASM-Spiegelung verwendet werden:</block>
  <block id="49af3bbe0c557480960d217b217502ff" category="paragraph">Mit diesen Einstellungen wird ein Timeout von 120 Sekunden für ASM-Geräte erstellt. Das Timeout wird als berechnet<block ref="e2f0125c5971e1ce714f86f145386ee3" prefix=" " category="inline-code"></block> *<block ref="9434de34302b4f40887a7277cf35a8fc" prefix=" " category="inline-code"></block> Sekunden lang. Der genaue Wert muss unter Umständen angepasst werden, aber ein Timeout von 120 Sekunden sollte für die meisten Anwendungen ausreichen. Insbesondere sollten in 120 Sekunden eine Controller-Übernahme oder -Rückgabe möglich sein, ohne dass ein I/O-Fehler auftritt, der dazu führen würde, dass die Fehlergruppe offline geschaltet wird.</block>
  <block id="dbff1dc161f3f1d61258259b3a0b549c" category="paragraph">A niedriger<block ref="9434de34302b4f40887a7277cf35a8fc" prefix=" " category="inline-code"></block> Value kann die für ASM erforderliche Zeit zum Wechsel zu einer alternativen Ausfallgruppe verkürzen. Dies erhöht jedoch auch das Risiko eines unerwünschten Failovers während Wartungsaktivitäten wie beispielsweise einem Controller-Takeover. Das Risiko kann durch eine sorgfältige Überwachung des ASM-Spiegelungsstatus verringert werden. Wenn ein unerwünschtes Failover auftritt, können die Spiegelungen schnell neu synchronisiert werden, wenn die Resynchronisierung relativ schnell durchgeführt wird. Weitere Informationen finden Sie in der Oracle-Dokumentation zu ASM Fast Mirror Resync für die verwendete Version der Oracle-Software.</block>
  <block id="ec0b68df6b5a0fdd6d73ac710b9684da" category="section-title">Mount-Optionen für Linux xfs, ext3 und ext4</block>
  <block id="278230e4238d02fcb49850454e7d79e0" category="admonition">*NetApp empfiehlt* die Verwendung der Standard-Mount-Optionen.</block>
  <block id="17361a1d111a3ff3a45b20c3a1efa11b" category="summary">Oracle- und TCP/IP- sowie ethernet-Konfiguration.</block>
  <block id="fe586387f0871fa578f77ac2e26e624a" category="doc">TCP/IP- und Ethernet-Konfiguration für Oracle Database</block>
  <block id="02a5a4d50c5112bb31ff9c94f5b47ce9" category="paragraph">Viele Kunden von Oracle auf ONTAP verwenden ethernet, das Netzwerkprotokoll von NFS, iSCSI, NVMe/TCP sowie insbesondere die Cloud.</block>
  <block id="8a1870adbe8a237106c32d72660a9c42" category="summary">Design der logischen Schnittstelle für Oracle-Datenbanken</block>
  <block id="f46a94d438563c03413adfec27c6bfda" category="paragraph">Oracle Datenbanken benötigen Zugriff auf den Storage. Logische Schnittstellen (LIFs) sind die Netzwerk-Rohrleitungen, die eine Storage Virtual Machine (SVM) mit dem Netzwerk und damit der Datenbank verbinden. Ein angemessenes LIF-Design ist erforderlich, um sicherzustellen, dass für jeden Datenbank-Workload ausreichend Bandbreite vorhanden ist. Das Failover führt nicht zu einem Verlust von Storage-Services.</block>
  <block id="f445528d334d486a14570735705e2223" category="summary">FC-Netzwerkkonfiguration für Oracle-Datenbanken</block>
  <block id="ee955933387c00b282dcfda69005517f" category="doc">FC-Konfiguration für Oracle</block>
  <block id="92cdde4ecc529b9f9379ed2bdb6aae34" category="paragraph">Bei der Konfiguration von FC SAN für Oracle-Datenbanken geht es in erster Linie um die Umsetzung der täglichen SAN Best Practices.</block>
  <block id="953369199e3a71ad1ad58bc7d5ad2d9f" category="summary">NetApp ONTAP ist eine leistungsstarke Datenmanagementplattform mit nativen Funktionen, die u. a. sofortige Backup-, Restore- und Klonfunktionen, Effizienzfunktionen wie Inline-Komprimierung, unterbrechungsfreie Hardware-Upgrades und die Möglichkeit zum Import einer LUN aus einem fremden Storage Array umfasst.</block>
  <block id="9eaca569c6f5ca3388f5613da3aa008c" category="doc">Oracle-Datenbanken auf ONTAP</block>
  <block id="528b35962f1679204260ddef6800eece" category="paragraph">ONTAP wurde für Oracle Datenbanken entwickelt. Seit Jahrzehnten ist ONTAP für die speziellen Anforderungen relationaler Datenbank-I/O optimiert. Es wurden mehrere ONTAP-Funktionen speziell dafür entwickelt, die Anforderungen von Oracle Datenbanken zu bedienen – und sogar auf Wunsch von Oracle Inc. Selbst.</block>
  <block id="c9f8ef2db64ce19b15d2cc98fbd3d24c" category="admonition">Diese Dokumentation ersetzt die zuvor veröffentlichten technischen Berichte _TR-3633: Oracle Databases on ONTAP; TR-4591: Oracle Data Protection: Backup, Recovery, Replizierung; TR-4592: Oracle on MetroCluster; und TR-4534: Migration von Oracle Databases to NetApp Storage Systems_</block>
  <block id="b42ad0517ef7394f97178fb9e1de8d78" category="paragraph">Neben den vielfältigen Möglichkeiten, die ONTAP für eine Datenbankumgebung bietet, gibt es auch zahlreiche Benutzeranforderungen, darunter Datenbankgröße, Performance-Anforderungen und Datensicherung. Bekannte Implementierungen von NetApp Storage umfassen alles von einer virtualisierten Umgebung mit ca. 6,000 Datenbanken unter VMware ESX bis hin zu einem Data Warehouse mit einer einzigen Instanz, das derzeit eine Größe von 996 TB aufweist und weiter wächst. Aus diesem Grund gibt es nur wenige klare Best Practices für die Konfiguration einer Oracle Datenbank auf NetApp Storage.</block>
  <block id="7bf0493f27e81fe4c3740e773e137a48" category="paragraph">Die Anforderungen für den Betrieb einer Oracle Database auf NetApp Storage werden auf zweierlei Weise erfüllt. Erstens, wenn eine klare Best Practice besteht, wird sie ausdrücklich genannt. Im Allgemeinen werden viele Designüberlegungen erläutert, die von den Architekten von Oracle-Speicherlösungen auf der Grundlage ihrer spezifischen Geschäftsanforderungen berücksichtigt werden müssen.</block>
  <block id="633d94718c25247da5772ed6f2b244c9" category="summary">Einführung in die Oracle Storage-Migration</block>
  <block id="6ca08c212e9ec987ce485fd9c7705eff" category="doc">Migration von Oracle-Datenbanken auf NetApp-Speichersysteme</block>
  <block id="9e099143017b5d9ff9c117de4ac659d7" category="paragraph">Die Nutzung der Leistungsfähigkeit einer neuen Storage-Plattform erfordert zwingend die Speicherung der Daten in dem neuen Storage-System.</block>
  <block id="08beeb11d62fd51ef2742eae3ee3719f" category="admonition">Diese Dokumentation ersetzt den bereits veröffentlichten technischen Bericht _TR-4534: Migration von Oracle-Datenbanken zu NetApp-Speichersystemen_</block>
  <block id="5f2a4190824fd64be3c8cabeb7dc62ff" category="paragraph">Im Falle eines neuen Datenbankprojekts ist dies kein Problem, da die Datenbank- und Anwendungsumgebungen eingerichtet sind. Die Migration stellt Unternehmen jedoch vor besondere Herausforderungen, was die Unterbrechung des Geschäftsbetriebs, den für den Abschluss der Migration erforderlichen Zeitaufwand, die erforderlichen Fachkompetenzen und die Risikominimierung angeht.</block>
  <block id="a83f1ca5ad00b39773d9e6a26b0e70b2" category="section-title">Skripte</block>
  <block id="08293bec81c296b61f4a751175d9caa7" category="paragraph">In dieser Dokumentation sind Beispielskripte enthalten. Diese Skripte bieten Beispielmethoden zur Automatisierung verschiedener Aspekte der Migration, um das Risiko von Benutzerfehlern zu verringern. Die Skripte können die Gesamtanforderungen an die für eine Migration verantwortlichen IT-Mitarbeiter verringern und den Gesamtprozess beschleunigen. Diese Skripte stammen alle aus Migrationsprojekten, die von NetApp Professional Services und NetApp-Partnern durchgeführt werden. Beispiele für deren Verwendung sind in dieser Dokumentation aufgeführt.</block>
  <block id="b3978e376e381abd116a2ae7938d8a9c" category="summary">FLI Umstellung - Oracle</block>
  <block id="c28b52826242c7cdffe5f3ae1e917f61" category="paragraph">Aufgrund der Notwendigkeit, die FC-Netzwerkkonfiguration zu ändern, sind Unterbrechungen beim Import fremder LUNs unvermeidbar. Die Unterbrechung muss jedoch nicht viel länger dauern als die Zeit, die für den Neustart der Datenbankumgebung und die Aktualisierung des FC-Zoning für die Umstellung der Host-FC-Konnektivität von der fremden LUN auf ONTAP erforderlich ist.</block>
  <block id="a2248459756ffc1877beb9b39c77668b" category="paragraph">Dieser Prozess lässt sich wie folgt zusammenfassen:</block>
  <block id="c9f77905e39abbada6c73a7a3d5f51f8" category="list-text">Legen Sie alle LUN-Aktivitäten auf den fremden LUNs still.</block>
  <block id="cff6e7c6c4f8dd7e57a0286f28712c58" category="list-text">Umleiten von Host-FC-Verbindungen zum neuen ONTAP-System</block>
  <block id="9fea842823b73e1eb32307ab325f170e" category="list-text">Starten Sie den Importvorgang.</block>
  <block id="df814ea2bf92d4f18e72a648e93103a2" category="list-text">Ermitteln Sie die LUNs neu.</block>
  <block id="030a5009bbe6fb141ca5863ab6c59464" category="list-text">Starten Sie die Datenbank neu.</block>
  <block id="f3bb22d18791c042e889671ad1963239" category="paragraph">Sie müssen nicht warten, bis der Migrationsprozess abgeschlossen ist. Sobald die Migration einer bestimmten LUN beginnt, ist sie auf ONTAP verfügbar und kann Daten bereitstellen, während der Datenkopievorgang fortgesetzt wird. Alle Lesevorgänge werden an die fremde LUN weitergeleitet, und alle Schreibvorgänge werden synchron auf beide Arrays geschrieben. Der Kopiervorgang läuft sehr schnell ab und der Overhead bei der Umleitung des FC-Datenverkehrs ist minimal. Die Auswirkungen auf die Performance sollten daher kurzlebig und minimal sein. Wenn Bedenken bestehen, können Sie den Neustart der Umgebung verzögern, bis der Migrationsprozess abgeschlossen ist und die Importbeziehungen gelöscht wurden.</block>
  <block id="b19e17ab765f91aa0bc0e7152f13779f" category="section-title">Datenbank herunterfahren</block>
  <block id="2869cd69e0fec20ba28a42e74afef158" category="paragraph">Der erste Schritt bei der Stilllegung der Umgebung in diesem Beispiel ist das Herunterfahren der Datenbank.</block>
  <block id="e20dab0880a91f5da2ea05170177576d" category="section-title">Netzdienste herunterfahren</block>
  <block id="89c458e5176d6caf0690f1e61ecb0620" category="paragraph">Zu den migrierten SAN-basierten Dateisystemen gehören auch die Oracle ASM-Services. Um die zugrunde liegenden LUNs stilllegen zu können, müssen die Dateisysteme getrennt werden. Dies bedeutet wiederum, dass alle Prozesse mit offenen Dateien auf diesem Dateisystem angehalten werden.</block>
  <block id="49f05bf7da4eacfa4c80bb987443eb5a" category="section-title">Entfernen Sie Dateisysteme</block>
  <block id="c5a09ac3ff0bb25c97951c7b7f815cd0" category="paragraph">Wenn alle Prozesse heruntergefahren werden, ist der umount-Vorgang erfolgreich. Wenn die Berechtigung verweigert wird, muss es einen Prozess mit einer Sperre auf dem Dateisystem geben. Der<block ref="ace112f9725b6fa0b702e6b3970b2102" prefix=" " category="inline-code"></block> Der Befehl kann bei der Identifizierung dieser Prozesse helfen.</block>
  <block id="765e13ffc3361a9fd6c6088b2603ffbf" category="section-title">Deaktivieren Sie Volume-Gruppen</block>
  <block id="907e5f35f70dc2f5e4b67da56381bdf4" category="paragraph">Nachdem alle Dateisysteme in einer bestimmten Volume-Gruppe getrennt wurden, kann die Volume-Gruppe deaktiviert werden.</block>
  <block id="ad80f935ccd133a802189e3c2f4421d7" category="section-title">Änderungen am FC-Netzwerk</block>
  <block id="a497da6790d9ab4bb5cce3d04b0efd2e" category="paragraph">Die FC-Zonen können jetzt aktualisiert werden, um den gesamten Zugriff vom Host auf das fremde Array zu entfernen und den Zugriff auf ONTAP zu ermöglichen.</block>
  <block id="3ef31115a10790468ad841ec2cdf566f" category="section-title">Importvorgang starten</block>
  <block id="5bc309ef1913ddc70534a0a7135ba938" category="paragraph">Um die LUN-Importprozesse zu starten, führen Sie den aus<block ref="76ffc50817aa4cd6214aa0061339fdf6" prefix=" " category="inline-code"></block> Befehl.</block>
  <block id="0a10f1ad4a0b45d384c5771ec0906c4c" category="section-title">Überwachen Sie den Importfortschritt</block>
  <block id="9a3a7545f4a7407ec022c4b2271e0c34" category="paragraph">Der Importvorgang kann mit dem überwacht werden<block ref="1ab15ef2c245a4434fcea3cc3149f4f4" prefix=" " category="inline-code"></block> Befehl. Wie unten dargestellt, läuft der Import aller 20 LUNs, was bedeutet, dass die Daten jetzt über ONTAP zugänglich sind, obwohl der Kopiervorgang noch fortschreitet.</block>
  <block id="d36f98c8a305e33483232e7b5cd90c49" category="inline-link-macro">Import fremder LUNs – Abschluss</block>
  <block id="24a74765303a8fc0e4b1e7afbb8e2205" category="paragraph">Wenn Sie einen Offline-Prozess benötigen, verzögern Sie die Neuermittlung oder den Neustart von Diensten bis zum<block ref="1ab15ef2c245a4434fcea3cc3149f4f4" prefix=" " category="inline-code"></block> Befehl zeigt an, dass die gesamte Migration erfolgreich und abgeschlossen ist. Anschließend können Sie den Migrationsprozess wie unter beschrieben abschließen <block ref="5b0017122426f8734e0358273adc6802" category="inline-link-macro-rx"></block>.</block>
  <block id="a9c97f84ee4958d39ed989b3da7ed0ba" category="paragraph">Wenn Sie eine Online-Migration benötigen, fahren Sie mit der Neuerkennung der LUNs in ihrem neuen Zuhause fort, und führen Sie die Dienste aus.</block>
  <block id="d0369936c6fe8c292874e3bc647893b8" category="section-title">Nach SCSI-Geräteänderungen suchen</block>
  <block id="6d338faddede649cab4c5b498e8e4379" category="paragraph">In den meisten Fällen besteht die einfachste Möglichkeit, neue LUNs neu zu ermitteln, darin, den Host neu zu starten. Dadurch werden alte veraltete Geräte automatisch entfernt, alle neuen LUNs ordnungsgemäß erkannt und verbundene Geräte wie Multipathing-Geräte erstellt. Das Beispiel zeigt einen vollständig online-Prozess zu Demonstrationszwecken.</block>
  <block id="3b493a859f19779c1f7db7d1951785ee" category="paragraph">Achtung: Bevor Sie einen Host neu starten, stellen Sie sicher, dass alle Einträge in sind<block ref="816a3ef77b62ade41c3f936c958aa555" prefix=" " category="inline-code"></block> Diese Referenz migrierte SAN-Ressourcen werden kommentiert. Wenn dies nicht durchgeführt wird und Probleme mit dem LUN-Zugriff auftreten, wird das OS möglicherweise nicht gebootet. Diese Situation beschädigt Daten nicht. Es kann jedoch sehr unbequem sein, in den Rettungsmodus oder einen ähnlichen Modus zu starten und die zu korrigieren<block ref="816a3ef77b62ade41c3f936c958aa555" prefix=" " category="inline-code"></block> Damit das OS gebootet werden kann, um die Fehlerbehebung zu ermöglichen.</block>
  <block id="9d7b16568eb7edb80492b49cb02d7663" category="paragraph">Die LUNs auf der in diesem Beispiel verwendeten Linux-Version können erneut mit dem gescannt werden<block ref="b6f75508bf2af141e9de6f862662661e" prefix=" " category="inline-code"></block> Befehl. Wenn der Befehl erfolgreich war, sollte jeder LUN-Pfad in der Ausgabe angezeigt werden. Die Ausgabe kann schwer zu interpretieren sein, wenn die Zoning- und igroup-Konfiguration korrekt war, sollten viele LUNs scheinen, die eine enthalten<block ref="971c047750d8e3b03c71d24020b3816f" prefix=" " category="inline-code"></block> Anbieterzeichenfolge.</block>
  <block id="3384aa7c090758ad18028832967b143f" category="section-title">Überprüfen Sie auf Multipath-Geräte</block>
  <block id="07a39d42e6d8cc61e0a880e43b83e2a3" category="paragraph">Der LUN-Erkennungsprozess löst auch die Wiederherstellung von Multipath-Geräten aus, der Linux-Multipathing-Treiber hat jedoch bekanntermaßen gelegentlich Probleme. Die Ausgabe von<block ref="eeb30d005cab1d8c69785a3cd5818f55" prefix=" " category="inline-code"></block> Sollte überprüft werden, um sicherzustellen, dass die Ausgabe wie erwartet aussieht. Die folgende Ausgabe zeigt beispielsweise Multipath-Geräte, die mit einem verknüpft sind<block ref="971c047750d8e3b03c71d24020b3816f" prefix=" " category="inline-code"></block> Anbieterzeichenfolge. Jedes Gerät verfügt über vier Pfade, wobei zwei mit einer Priorität von 50 und zwei mit einer Priorität von 10. Obwohl die genaue Ausgabe mit verschiedenen Versionen von Linux variieren kann, sieht diese Ausgabe wie erwartet aus.</block>
  <block id="efd921479c3d57448954050760c568ca" category="admonition">Überprüfen Sie anhand der Dokumentation der Host-Dienstprogramme die Version von Linux, die Sie verwenden<block ref="dd5ff67ba72768d33f75e645aa2b8e56" prefix=" " category="inline-code"></block> Die Einstellungen sind korrekt.</block>
  <block id="28751dc1e914a778d11ca0e69613690b" category="section-title">Reaktivieren Sie die LVM-Volume-Gruppe</block>
  <block id="a66a38e4056f28a310ef6d1fa8bbcc77" category="paragraph">Wenn die LVM-LUNs ordnungsgemäß erkannt wurden, wird das angezeigt<block ref="5239f542d8edbc4b528b1f362153c0c7" prefix=" " category="inline-code"></block> Befehl sollte erfolgreich sein. Dies ist ein gutes Beispiel für den Nutzen eines logischen Volume-Managers. Eine Änderung des WWN einer LUN oder auch einer Seriennummer ist unwichtig, da die Metadaten der Volume-Gruppe auf die LUN selbst geschrieben werden.</block>
  <block id="1d374f8de5ba1b82ab4407b8c6efbd0d" category="paragraph">Das Betriebssystem hat die LUNs gescannt und eine kleine Menge an auf die LUN geschriebenen Daten ermittelt, die sie als physisches Volume des identifizieren<block ref="83b7788c8e4de444d6cd4c69978eaf32" prefix=" " category="inline-code"></block>. Anschließend wurden alle erforderlichen Geräte erstellt. Sie müssen nur die Volume-Gruppe erneut aktivieren.</block>
  <block id="1f0285a57b2357507c3b77ce5130b548" category="section-title">Dateisysteme neu einbinden</block>
  <block id="a9047d68dc7e99f553b71590cff301d6" category="paragraph">Nachdem die Volume-Gruppe wieder aktiviert wurde, können die Dateisysteme mit allen ursprünglichen Daten gemountet werden. Wie bereits erwähnt, sind die Dateisysteme voll funktionsfähig, selbst wenn die Datenreplikation in der Back-Gruppe weiterhin aktiv ist.</block>
  <block id="a787d65e2525ac6bc3a6328efe383b5c" category="section-title">Neuscannen für ASM-Geräte</block>
  <block id="a25bb20f07ed95a633f623678855e8dc" category="paragraph">Die ASMlib-Geräte sollten beim erneuten Scannen der SCSI-Geräte neu erkannt worden sein. Die Wiedererkennung kann online überprüft werden, indem ASMlib neu gestartet und anschließend die Datenträger gescannt werden.</block>
  <block id="37fb12a52b4a5371c12209e89e09b04f" category="admonition">Dieser Schritt ist nur für ASM-Konfigurationen relevant, in denen ASMlib verwendet wird.</block>
  <block id="6de48f39063d81d53fd0ff3e9938af13" category="paragraph">Achtung: Wenn ASMlib nicht verwendet wird, ist die<block ref="9c9f766701f811ef6f170c7a3453c53f" prefix=" " category="inline-code"></block> Geräte sollten automatisch neu erstellt worden sein. Die Berechtigungen sind jedoch möglicherweise nicht korrekt. Sie müssen spezielle Berechtigungen für die zugrunde liegenden Geräte für ASM festlegen, wenn ASMlib nicht vorhanden ist. Dies wird in der Regel durch spezielle Einträge in entweder der erreicht<block ref="dd5ff67ba72768d33f75e645aa2b8e56" prefix=" " category="inline-code"></block> Oder<block ref="ab775c875d5f89d991a670444dd32ad2" prefix=" " category="inline-code"></block> Regeln oder möglicherweise in beiden Regelsätzen. Diese Dateien müssen möglicherweise aktualisiert werden, um Änderungen in der Umgebung in Bezug auf WWNs oder Seriennummern widerzuspiegeln, um sicherzustellen, dass die ASM-Geräte weiterhin über die richtigen Berechtigungen verfügen.</block>
  <block id="08b33d6af4ec78f99dbbc3533589aafc" category="paragraph">In diesem Beispiel werden beim Neustart von ASMlib und beim Scannen nach Festplatten die gleichen 10 ASM-LUNs wie in der ursprünglichen Umgebung angezeigt.</block>
  <block id="17c4ae76000d9a79a56195071665af32" category="section-title">Starten Sie die Grid-Services neu</block>
  <block id="e8c3dc00e15826e3b77a2d41d7fde92a" category="paragraph">Da die LVM- und ASM-Geräte jetzt online und verfügbar sind, können die Grid-Dienste neu gestartet werden.</block>
  <block id="934317e45581988a01f54761705ca58a" category="section-title">Datenbank neu starten</block>
  <block id="41475a737e947d73c674b90e78e246a0" category="paragraph">Nach dem Neustart der Netzdienste kann die Datenbank gestartet werden. Möglicherweise müssen Sie einige Minuten warten, bis die ASM-Dienste vollständig verfügbar sind, bevor Sie versuchen, die Datenbank zu starten.</block>
  <block id="0b986cf2a434b03b097578ad444e72f0" category="summary">Abschließen einer FLI-Umstellung – Oracle</block>
  <block id="24bd7d2a01571aa270c81d8d9f8370e9" category="doc">FLI-Abschluss – Oracle</block>
  <block id="b171714b39ad4102aced4daceef8c678" category="paragraph">Aus Host-Sicht ist die Migration abgeschlossen, aber I/O wird weiterhin vom fremden Array bedient, bis die Importbeziehungen gelöscht werden.</block>
  <block id="f708d001227724fa0a8a3d57aacedb1a" category="paragraph">Bevor Sie die Beziehungen löschen, müssen Sie bestätigen, dass der Migrationsprozess für alle LUNs abgeschlossen ist.</block>
  <block id="85cf20229bc9008553794abdaed507f5" category="section-title">Importbeziehungen löschen</block>
  <block id="b23ec325eb9c6278cb36e4c45c2c3499" category="paragraph">Löschen Sie nach Abschluss des Migrationsprozesses die Migrationsbeziehung. Anschließend wird die I/O ausschließlich von den Laufwerken auf ONTAP bedient.</block>
  <block id="40b98b0023a7eea7c432c29e3c44ba7d" category="section-title">Registrierung ausländischer LUNs aufheben</block>
  <block id="5ccc14ae93ba94bd4183439a9f80f6c8" category="paragraph">Ändern Sie schließlich die Festplatte, um die zu entfernen<block ref="96ea0e5f46787e93e2970a086b47fdb6" prefix=" " category="inline-code"></block> Bezeichnung.</block>
  <block id="875bb561ba851d301052704e0ffb70f4" category="summary">Oracle-Migration über Protokollversand</block>
  <block id="e0f9c3b73fe5700df95f30eb98ca4034" category="doc">Oracle-Protokollversand</block>
  <block id="8e42b5809657e127c7e2d24f30bc493e" category="paragraph">Ziel bei einer Migration mit Protokollversand ist, eine Kopie der ursprünglichen Datendateien an einem neuen Standort zu erstellen und anschließend eine Methode für den Versand von Änderungen in die neue Umgebung zu definieren.</block>
  <block id="599df5f564506c95624dd78b0b75eeac" category="paragraph">Nach der Einrichtung können Protokollversand und -Wiedergabe automatisiert werden, um die Replikatdatenbank weitgehend mit der Quelle synchron zu halten. So kann beispielsweise ein Cron-Job so geplant werden, dass (a) die letzten Protokolle an den neuen Speicherort kopiert und (b) alle 15 Minuten erneut wiedergegeben werden. Dadurch sind zum Zeitpunkt der Umstellung nur minimale Unterbrechungen möglich, da maximal 15 Minuten Archiv-Logs wieder eingespielt werden müssen.</block>
  <block id="41bec1b4ddc17b3367c68a025c0ddfb9" category="paragraph">Das unten abgebildete Verfahren ist außerdem im Wesentlichen eine Datenbankklonoperation. Die gezeigte Logik ähnelt der Engine in NetApp SnapManager für Oracle (SMO) und dem NetApp SnapCenter Oracle Plug-in. Einige Kunden haben das in Skripten oder WFA Workflows angezeigte Verfahren für individuelle Klonvorgänge verwendet. Dieses Verfahren ist zwar mehr manuell als SMO oder SnapCenter, es wird jedoch immer noch ohne Skripte erstellt und die Datenmanagement-APIs in ONTAP vereinfachen den Prozess weiter.</block>
  <block id="f0616883a5ca70aa97676de436a7fb9e" category="section-title">Protokollversand – Dateisystem an Dateisystem</block>
  <block id="8f922b64f0bc64f6bba1d555a61ee3bb" category="paragraph">Dieses Beispiel zeigt die Migration einer Datenbank namens WAFFLE von einem gewöhnlichen Dateisystem zu einem anderen gewöhnlichen Dateisystem auf einem anderen Server. Es veranschaulicht auch die Verwendung von SnapMirror zum Erstellen einer schnellen Kopie der Datendateien, aber dies ist kein integraler Bestandteil des gesamten Verfahrens.</block>
  <block id="60100e1b826a4b972fc113c391f932e7" category="section-title">Erstellen Sie eine Datenbanksicherung</block>
  <block id="80cf34e10dcfbc5e76c6b2f845f2708d" category="paragraph">Der erste Schritt besteht darin, ein Datenbank-Backup zu erstellen. Insbesondere erfordert dieses Verfahren eine Reihe von Datendateien, die für die Wiedergabe des Archivprotokolls verwendet werden können.</block>
  <block id="0ba29c6a1afacf586b03a26162c72274" category="section-title">Umgebung</block>
  <block id="82f9b672d88793b2ca5716b2a5427056" category="paragraph">In diesem Beispiel befindet sich die Quelldatenbank auf einem ONTAP-System. Die einfachste Methode zum Erstellen eines Backups einer Datenbank ist die Verwendung einer Snapshot-Kopie. Die Datenbank wird für einige Sekunden in den Hot Backup-Modus versetzt, während ein<block ref="252ce13e6c150af4d3e7eea5fca266bc" prefix=" " category="inline-code"></block> Der Vorgang wird auf dem Volume ausgeführt, auf dem die Datendateien gehostet werden.</block>
  <block id="1fd3a22cf15d1e18a6507f539346c40d" category="paragraph">Das Ergebnis ist eine Snapshot-Kopie auf der Festplatte, die als aufgerufen wird<block ref="a8b3bc9f12cd194b80d404c30e9015ee" prefix=" " category="inline-code"></block> Die ein Image der Datendateien enthält, während sie sich im Hot Backup-Modus befinden. Wenn die Daten in dieser Snapshot-Kopie zusammen mit den entsprechenden Archivprotokollen konsistent sind, können sie als Grundlage für Wiederherstellungen oder Klone verwendet werden. In diesem Fall wird sie auf den neuen Server repliziert.</block>
  <block id="744a73803cdac4a5067725ca5814a2cf" category="section-title">Wiederherstellung in neuer Umgebung</block>
  <block id="46228bb2ce31b0d397faad2b805e8a37" category="paragraph">Das Backup muss nun in der neuen Umgebung wiederhergestellt werden. Dies kann auf verschiedene Arten erfolgen, z. B. Oracle RMAN, Wiederherstellung über eine Backup-Applikation wie NetBackup oder ein einfacher Kopiervorgang von Datendateien, die im Hot-Backup-Modus platziert wurden.</block>
  <block id="ca7da361ad92f677545e12dd462c6e39" category="paragraph">In diesem Beispiel wird SnapMirror verwendet, um die Snapshot-Kopie namens „HotBackup“ an einen neuen Speicherort zu replizieren.</block>
  <block id="1f255556546f1fdfb53692e41f35eb6c" category="list-text">Erstellen Sie ein neues Volume für den Empfang der Snapshot-Daten. Initialisieren Sie die Spiegelung von<block ref="937e9fa808ccfe9a4f6b004a2a7caada" prefix=" " category="inline-code"></block> Bis<block ref="96f9dacb3cb1b1f6f9b4ad02992a1a0e" prefix=" " category="inline-code"></block>.</block>
  <block id="5b1944ec8c0ed933e5b2ea2e3e5fa76e" category="list-text">Nachdem der Status von SnapMirror festgelegt wurde und Sie angeben, dass die Synchronisierung abgeschlossen ist, aktualisieren Sie die Spiegelung speziell auf der Grundlage des gewünschten Snapshots.</block>
  <block id="f4d90c6c29b1f76ab9c87a9996c9751e" category="list-text">Die erfolgreiche Synchronisierung kann durch Anzeigen des überprüft werden<block ref="31952c255e722053d4cc3f82921e95db" prefix=" " category="inline-code"></block> Feld auf der Spiegelungslautstärke.</block>
  <block id="0934c3fcad3065c2a479125e4a80b259" category="list-text">Der Spiegel kann dann gebrochen werden.</block>
  <block id="fcf1f505b94151a36eba8e1563e7176f" category="list-text">Mounten Sie das neue Dateisystem.bei blockbasierten Dateisystemen variieren die genauen Verfahren je nach der verwendeten LVM. FC-Zoning oder iSCSI-Verbindungen müssen konfiguriert werden. Nachdem die Verbindung zu den LUNs hergestellt wurde, Befehle wie Linux<block ref="302c49bbd5bcda5463eb5130804effc1" prefix=" " category="inline-code"></block> Möglicherweise muss ermittelt werden, welche Volume-Gruppen oder LUNs ordnungsgemäß konfiguriert werden müssen, damit sie von ASM erkannt werden können.</block>
  <block id="20c4d1d4163c2463cf15ff7df6424459" category="paragraph">In diesem Beispiel wird ein einfaches NFS-Dateisystem verwendet. Dieses Dateisystem kann direkt gemountet werden.</block>
  <block id="b2dd88a1f03a5fb4c2e3c0d46f425161" category="section-title">Erstellen Sie eine Vorlage für die Erstellung von Steuerdateien</block>
  <block id="1c30e11140f1d0a1093bedee34eef1e4" category="paragraph">Als nächstes müssen Sie eine controlfile-Vorlage erstellen. Der<block ref="3177841b2335a6640ea3054199830f1c" prefix=" " category="inline-code"></block> Befehl erstellt Textbefehle, um eine Steuerdatei neu zu erstellen. Diese Funktion kann unter bestimmten Umständen hilfreich sein, um eine Datenbank aus einem Backup wiederherzustellen. Sie wird häufig bei Skripten verwendet, die Aufgaben wie das Klonen von Datenbanken ausführen.</block>
  <block id="3f51d58ec72b9d36cb5e0636525130b5" category="list-text">Die Ausgabe des folgenden Befehls wird verwendet, um die Steuerdateien für die migrierte Datenbank neu zu erstellen.</block>
  <block id="cb395c3bf18fd427287caecc9b28058a" category="list-text">Nachdem die Steuerdateien erstellt wurden, kopieren Sie die Datei auf den neuen Server.</block>
  <block id="cf5c9046a3617a19c0ccc24e4cf54a33" category="section-title">Parameterdatei sichern</block>
  <block id="0d1d1a7db58f3f93ec977733f4909f5d" category="paragraph">In der neuen Umgebung ist auch eine Parameterdatei erforderlich. Die einfachste Methode ist, aus dem aktuellen spfile oder pfile ein pfile zu erstellen. In diesem Beispiel verwendet die Quelldatenbank eine spfile.</block>
  <block id="051a634cb1e9a53dbf139214e1d24001" category="section-title">Oratab-Eintrag erstellen</block>
  <block id="2dabc26c8b55d44e25a184ba2624eed0" category="paragraph">Die Erstellung eines Oratab-Eintrags ist für das ordnungsgemäße Funktionieren von Dienstprogrammen wie oraenv erforderlich. Führen Sie den folgenden Schritt aus, um einen Oratab-Eintrag zu erstellen.</block>
  <block id="87ef75141d237e3b44e8310aad8fcf19" category="section-title">Verzeichnisstruktur vorbereiten</block>
  <block id="12f833c44c11e6bbd970cc126bce2bcb" category="paragraph">Wenn die benötigten Verzeichnisse noch nicht vorhanden waren, müssen Sie sie erstellen, oder der Datenbankstartvorgang schlägt fehl. Um die Verzeichnisstruktur vorzubereiten, müssen Sie die folgenden Mindestanforderungen erfüllen.</block>
  <block id="60225c364a012796a6d886e8cf4ec486" category="section-title">Aktualisierung der Parameterdatei</block>
  <block id="e36ee2d9a95a6b672917862d714af383" category="list-text">Um die Parameterdatei auf den neuen Server zu kopieren, führen Sie die folgenden Befehle aus. Der Standardspeicherort ist der<block ref="45c7302d9c2e8745b3a2bff0f992b6df" prefix=" " category="inline-code"></block> Verzeichnis. In diesem Fall kann die pfile überall platziert werden. Sie wird nur als Zwischenschritt im Migrationsprozess genutzt.</block>
  <block id="d437a40a59905247cfb39cf9dc9da256" category="list-text">Bearbeiten Sie die Datei nach Bedarf. Wenn sich beispielsweise der Speicherort des Archivprotokolls geändert hat, muss das pfile entsprechend dem neuen Speicherort geändert werden. In diesem Beispiel werden nur die Steuerdateien verschoben, zum Teil, um sie zwischen Protokoll- und Datendateisystemen zu verteilen.</block>
  <block id="55cc35656c3d28c1b3267c246b397521" category="list-text">Nachdem die Bearbeitungen abgeschlossen sind, erstellen Sie auf Basis dieses pfile ein spfile.</block>
  <block id="a833a03e6af0b969524dcccb8f296f1c" category="section-title">Erstellen Sie Steuerdateien neu</block>
  <block id="74a636ee3a009f08cd5623dc8066dd09" category="paragraph">In einem vorherigen Schritt wird die Ausgabe von angezeigt<block ref="3177841b2335a6640ea3054199830f1c" prefix=" " category="inline-code"></block> Wurde auf den neuen Server kopiert. Der spezifische Teil des erforderlichen Ausgangs ist der<block ref="0ca1fba455d799b9a1cc2440b9ba7043" prefix=" " category="inline-code"></block> Befehl. Diese Informationen finden Sie in der Datei unter dem markierten Abschnitt<block ref="9fb76d62be749cec8bdd06f46c77bf5b" prefix=" " category="inline-code"></block>. Es beginnt mit der Linie<block ref="13ac20c4a96b2ecfd703e831ad722907" prefix=" " category="inline-code"></block> Und sollte das Wort enthalten<block ref="c3c62948f78a7ccaabb9ef2eea80a895" prefix=" " category="inline-code"></block>. Er endet mit dem Semikolon (; ).</block>
  <block id="bf4b2a006646a8e77166a2a596425074" category="list-text">In diesem Beispiel liest die Datei wie folgt.</block>
  <block id="a9a27c002ec883341220e267712250a7" category="list-text">Bearbeiten Sie dieses Skript wie gewünscht, um den neuen Speicherort der verschiedenen Dateien anzuzeigen. Beispielsweise können bestimmte Datendateien, von denen bekannt ist, dass sie eine hohe I/O-Last unterstützen, auf ein Filesystem auf einer hochperformanten Storage-Ebene umgeleitet werden. In anderen Fällen könnten die Änderungen lediglich aus Administratorgründen vorgenommen werden, wie z. B. die Isolierung der Datendateien einer bestimmten PDB in dedizierten Volumes.</block>
  <block id="2540fb1670d4f9ee8a704a7eb8d748fe" category="list-text">In diesem Beispiel ist der<block ref="b86df74c6982de8dec7509d039294d7a" prefix=" " category="inline-code"></block> Stanza bleibt unverändert, aber die Redo-Logs werden an einen neuen Speicherort in verschoben<block ref="96bb85ed0fe822778c4e5a821e991ad8" prefix=" " category="inline-code"></block> Statt Speicherplatz für Archivprotokolle freizugeben<block ref="0e62afc91abe157ef67895cca0a7f912" prefix=" " category="inline-code"></block>.</block>
  <block id="8d47ad079859f2976fdc7ebf742f768d" category="paragraph">Wenn Dateien falsch platziert oder Parameter falsch konfiguriert sind, werden Fehler generiert, die angeben, was repariert werden muss. Die Datenbank ist gemountet, aber noch nicht geöffnet und kann nicht geöffnet werden, da die verwendeten Datendateien noch als Hot Backup-Modus markiert sind. Um die Datenbankkonsistenz zu gewährleisten, müssen zunächst Archivprotokolle angewendet werden.</block>
  <block id="6b7c2d588ac708b58f7ac889090608f6" category="section-title">Erste Protokollreplizierung</block>
  <block id="2db2d3d6001a06d1a027904fa66bc78c" category="paragraph">Es ist mindestens ein Protokollantwort erforderlich, um die Datendateien konsistent zu gestalten. Es stehen zahlreiche Optionen zur Wiedergabe von Protokollen zur Verfügung. In einigen Fällen kann der ursprüngliche Speicherort des Archivprotokolls auf dem ursprünglichen Server über NFS freigegeben werden, und die Protokollantwort kann direkt erfolgen. In anderen Fällen müssen die Archivprotokolle kopiert werden.</block>
  <block id="5c394e6951584d114c6706d0768e30d7" category="paragraph">Zum Beispiel, eine einfache<block ref="8a444a43bdf534c0c6338bb7809659b3" prefix=" " category="inline-code"></block> Der Vorgang kann alle aktuellen Protokolle vom Quellserver auf den Migrationsserver kopieren:</block>
  <block id="5fdb3158ed28dd3aa90b94556476b781" category="section-title">Erste Protokollwiedergabe</block>
  <block id="c2f93ef52583f81f0eba05a39483e2d8" category="paragraph">Nachdem sich die Dateien im Archiv-Log-Speicherort befinden, können sie mit dem Befehl wiedergegeben werden<block ref="5fea768eb2d353716ca623ae58ce382c" prefix=" " category="inline-code"></block> Gefolgt von der Antwort<block ref="e1f2d5134ed2543d38a0de9751cf75d9" prefix=" " category="inline-code"></block> Um alle verfügbaren Protokolle automatisch wiederzugeben.</block>
  <block id="f30a45a22256018185c5d235292e4d5e" category="paragraph">Die endgültige Antwort des Archivprotokolls meldet einen Fehler. Dies ist jedoch normal. Das Protokoll zeigt das an<block ref="a84f4f3da79386c29ab6dfa560af786e" prefix=" " category="inline-code"></block> Ich habe eine bestimmte Protokolldatei gesucht und sie nicht gefunden. Der Grund dafür ist höchstwahrscheinlich, dass die Protokolldatei noch nicht existiert.</block>
  <block id="80bea8a60412cace54760b223b2d799e" category="paragraph">Wenn die Quelldatenbank vor dem Kopieren von Archivprotokollen heruntergefahren werden kann, muss dieser Schritt nur einmal durchgeführt werden. Die Archivprotokolle werden kopiert und eingespielt. Anschließend kann der Prozess direkt zum Umstellungsprozess fortgesetzt werden, der die kritischen Wiederherstellungsprotokolle repliziert.</block>
  <block id="1e334141582a9dcb581c9b34ef2df071" category="section-title">Inkrementelle Protokollreplikation und -Wiedergabe</block>
  <block id="5fd2b0bf662c2b1ebdc677ea888536ce" category="paragraph">In den meisten Fällen erfolgt die Migration nicht sofort. Es kann Tage oder sogar Wochen bis zum Abschluss des Migrationsprozesses dauern. Das bedeutet, dass die Protokolle kontinuierlich an die Replikatdatenbank gesendet und erneut eingespielt werden müssen. Bei Ankunft der Umstellung müssen daher nur minimale Daten übertragen und erneut eingespielt werden.</block>
  <block id="0c56d82ec6857bcef5475899b9f7b5cc" category="paragraph">Dies kann auf viele Arten per Skript gesteuert werden, aber eine der beliebtesten Methoden ist die Verwendung von rsync, einem gemeinsamen Dateireplikationsdienstprogramm. Die sicherste Methode, dieses Dienstprogramm zu verwenden, ist es als Daemon zu konfigurieren. Beispiel: Der<block ref="b31375af035ed8a698a803a491084f61" prefix=" " category="inline-code"></block> Die folgende Datei zeigt, wie eine Ressource mit dem Namen erstellt wird<block ref="260e23541ff372b9bc53b4bd3c0c38ba" prefix=" " category="inline-code"></block> Der Zugriff erfolgt mit Oracle-Benutzeranmeldeinformationen und ist zugeordnet<block ref="488a4921a81e36fca411e6f13cefbbf2" prefix=" " category="inline-code"></block>. Am wichtigsten ist jedoch, dass die Ressource schreibgeschützt ist, wodurch die Produktionsdaten gelesen, aber nicht verändert werden können.</block>
  <block id="eabf1b424989b2c7113ba3a538079afa" category="paragraph">Mit dem folgenden Befehl wird das Archivprotokollziel des neuen Servers mit der rsync-Ressource synchronisiert<block ref="260e23541ff372b9bc53b4bd3c0c38ba" prefix=" " category="inline-code"></block> Auf dem ursprünglichen Server. Der<block ref="e358efa489f58062f10dd7316b65649e" prefix=" " category="inline-code"></block> Argument in<block ref="293e33723231f0504effabb52b054a31" prefix=" " category="inline-code"></block> Führt dazu, dass die Dateiliste anhand des Zeitstempels verglichen wird und nur neue Dateien kopiert werden. Dieser Prozess bietet eine inkrementelle Aktualisierung des neuen Servers. Dieser Befehl kann auch in cron so geplant werden, dass er regelmäßig ausgeführt wird.</block>
  <block id="c775c44069da13c8f7ee5c5116e76e36" category="inline-link-macro">Protokolle in der Datenbank wiedergeben</block>
  <block id="c3bf9b2ef3e3ae2ae6a02f7f77cfcbc6" category="paragraph">Nachdem die Protokolle empfangen wurden, müssen sie erneut abgespielt werden. Frühere Beispiele zeigen die Verwendung von sqlplus zum manuellen Ausführen<block ref="5fea768eb2d353716ca623ae58ce382c" prefix=" " category="inline-code"></block>Ein Prozess, der leicht automatisiert werden kann. Das hier abgebildete Beispiel verwendet das in beschriebene Skript <block ref="3e57a2099043fa40c58f1e0d4eed995d" category="inline-link-macro-rx"></block>. Die Skripte akzeptieren ein Argument, das die Datenbank angibt, die einen Wiedergabevorgang erfordert. Damit kann dasselbe Skript bei einer Migration mit mehreren Datenbanken verwendet werden.</block>
  <block id="4ea2a6c39b10b3e3076f976f58a861d1" category="section-title">Umstellung</block>
  <block id="5de3f1ba0bbef459baa93f04f63b9ea1" category="paragraph">Wenn Sie bereit sind, in die neue Umgebung zu schneiden, müssen Sie eine abschließende Synchronisierung durchführen, die sowohl Archivprotokolle als auch Redo-Protokolle enthält. Wenn der ursprüngliche Speicherort des Wiederherstellungsprotokolls nicht bereits bekannt ist, kann er wie folgt identifiziert werden:</block>
  <block id="677f005cc0f8be0f891df5af72fb5688" category="list-text">Fahren Sie die Quelldatenbank herunter.</block>
  <block id="41b182875e12de118d17b3432cca93fa" category="list-text">Führen Sie eine abschließende Synchronisierung der Archivprotokolle auf dem neuen Server mit der gewünschten Methode durch.</block>
  <block id="37d6d9420cef8230249e7691315f0e13" category="list-text">Die Wiederherstellungsprotokolle der Quelle müssen auf den neuen Server kopiert werden. In diesem Beispiel wurden die Wiederherstellungsprotokolle in ein neues Verzeichnis unter verschoben<block ref="96bb85ed0fe822778c4e5a821e991ad8" prefix=" " category="inline-code"></block>.</block>
  <block id="d0a5f1380bd67b0d0fd3bc72f22d88f2" category="list-text">In dieser Phase enthält die neue Datenbankumgebung alle Dateien, die als Quelle erforderlich sind. Die Archivprotokolle müssen ein letztes Mal wiedergegeben werden.</block>
  <block id="c2721157205b2d2e96c656c45ca72992" category="list-text">Nach Abschluss müssen die Wiederherstellungsprotokolle erneut wiedergegeben werden. Wenn die Meldung angezeigt wird<block ref="975df7a5099101ffbe47981cd1d37c2c" prefix=" " category="inline-code"></block> Wird zurückgegeben, der Prozess ist erfolgreich und die Datenbanken sind synchronisiert und können geöffnet werden.</block>
  <block id="6acab27c5f334c66f06f3f74bc62d6d8" category="section-title">Protokollversand: ASM an Dateisystem</block>
  <block id="a67ffcc8b155bb909a6f8c5d5ba2f334" category="paragraph">In diesem Beispiel wird die Verwendung von Oracle RMAN zur Migration einer Datenbank demonstriert. Es ähnelt dem vorherigen Beispiel des Dateisystems zum Protokollversand des Dateisystems, aber die Dateien auf ASM sind für den Host nicht sichtbar. Die einzigen Optionen für die Migration von Daten auf ASM-Geräten sind entweder die Verlagerung der ASM-LUN oder die Durchführung der Kopiervorgänge mithilfe von Oracle RMAN.</block>
  <block id="1c51600a778919f7f3abb5b25175220a" category="paragraph">Auch wenn RMAN für das Kopieren von Dateien aus Oracle ASM erforderlich ist, ist die Verwendung von RMAN nicht auf ASM beschränkt. Mit RMAN können beliebige Storage-Typen zu beliebigen anderen Storage-Typen migriert werden.</block>
  <block id="2cb6a5bfc4a76f651d496cddc685e078" category="paragraph">Dieses Beispiel zeigt die Verlagerung einer Datenbank namens PANCAKE aus dem ASM-Speicher in ein normales Dateisystem, das sich auf einem anderen Server in Pfaden befindet<block ref="f006bf17b06c884c47190c4225d3215a" prefix=" " category="inline-code"></block> Und<block ref="0e62afc91abe157ef67895cca0a7f912" prefix=" " category="inline-code"></block>.</block>
  <block id="d1d789c37f1c96d0a5de07798c14fcc5" category="paragraph">Im ersten Schritt wird ein Backup der Datenbank erstellt, die auf einen alternativen Server migriert werden soll. Da die Quelle Oracle ASM verwendet, muss RMAN verwendet werden. Ein einfaches RMAN-Backup kann wie folgt durchgeführt werden. Diese Methode erstellt ein getaggtes Backup, das später im Verfahren von RMAN leicht identifiziert werden kann.</block>
  <block id="ed927706d8abc2bbf3a5a8bc55e1e562" category="paragraph">Der erste Befehl definiert den Zieltyp für das Backup und den zu verwendenden Speicherort. Die zweite initiiert nur die Sicherung der Datendateien.</block>
  <block id="db85d05166dd65559ae5f426b51198e6" category="section-title">Sicherungscontrolfile</block>
  <block id="a0b95d36955723a82dde7bbe40b6ccb9" category="paragraph">Im weiteren Verlauf des Verfahrens wird eine Sicherungscontrolfile benötigt<block ref="08de2bfcc2d52d5bc4f3f2dcb97558ad" prefix=" " category="inline-code"></block> Betrieb.</block>
  <block id="76ff543de72e62217293a1d0ceade0aa" category="paragraph">In der neuen Umgebung ist auch eine Parameterdatei erforderlich. Die einfachste Methode ist, aus dem aktuellen spfile oder pfile ein pfile zu erstellen. In diesem Beispiel verwendet die Quelldatenbank eine spfile.</block>
  <block id="d28f3a5b77909b45c50e6c711bef8b60" category="section-title">Skript zum Umbenennen der ASM-Datei</block>
  <block id="c242730c760d895368557f78141ff8b1" category="paragraph">Mehrere aktuell in den Steuerdateien definierte Dateispeicherorte ändern sich, wenn die Datenbank verschoben wird. Mit dem folgenden Skript wird ein RMAN-Skript erstellt, um den Prozess zu vereinfachen. Dieses Beispiel zeigt eine Datenbank mit einer sehr kleinen Anzahl von Datendateien, aber in der Regel enthalten Datenbanken Hunderte oder gar Tausende von Datendateien.</block>
  <block id="359b84bcf7447a77b212e844aeaa9d89" category="inline-link-macro">Namenskonvertierung von ASM in Dateisystem</block>
  <block id="374a1a0facd7c604ac09ed0dca6efb3e" category="paragraph">Dieses Skript finden Sie in <block ref="288325982fd7bee6cf9eb66ad33f6f7a" category="inline-link-macro-rx"></block> Und es tut zwei Dinge.</block>
  <block id="42787fdca1cf792241ce03151ec7dbd3" category="paragraph">Zuerst erstellt es einen Parameter, um die Speicherort des Wiederherstellungsprotokolls neu zu definieren<block ref="0f2d7ef9b967c2d9fb1ad5aa5e9eb688" prefix=" " category="inline-code"></block>. Es handelt sich im Wesentlichen um eine Liste von abwechselnden Feldern. Das erste Feld ist der Speicherort eines aktuellen Wiederherstellungsprotokolls und das zweite Feld ist der Speicherort auf dem neuen Server. Das Muster wird dann wiederholt.</block>
  <block id="cf444fd96c87609516f0ad8212f41b01" category="paragraph">Die zweite Funktion ist die Bereitstellung einer Vorlage für die Umbenennung von Datendateien. Das Skript führt eine Schleife durch die Datendateien durch, ruft den Namen und die Dateinummer ab und formatiert sie als RMAN-Skript. Dann macht es das gleiche mit den temporären Dateien. Das Ergebnis ist ein einfaches rman-Skript, das nach Bedarf bearbeitet werden kann, um sicherzustellen, dass die Dateien an dem gewünschten Speicherort wiederhergestellt werden.</block>
  <block id="50614366822786a4f2ee3a5065543634" category="paragraph">Erfassen Sie die Ausgabe dieses Bildschirms. Der<block ref="0f2d7ef9b967c2d9fb1ad5aa5e9eb688" prefix=" " category="inline-code"></block> Der Parameter wird wie unten beschrieben in pfile platziert. Die RMAN-Datendatei umbenennen und das doppelte Skript müssen entsprechend bearbeitet werden, um die Datendateien an den gewünschten Speicherorten zu platzieren. In diesem Beispiel werden sie alle in platziert<block ref="36c3572e381980ee1f1343988ae4a955" prefix=" " category="inline-code"></block>.</block>
  <block id="e60cd818b9f7ae02a73d8b3a6ea0a809" category="paragraph">Die Skripte sind fast fertig zur Ausführung, aber zuerst muss die Verzeichnisstruktur vorhanden sein. Wenn die benötigten Verzeichnisse nicht bereits vorhanden sind, müssen sie erstellt werden, oder der Datenbankstartvorgang schlägt fehl. Das folgende Beispiel gibt die Mindestanforderungen wieder.</block>
  <block id="2f2eed2ed14ba876a017aa9ea9515724" category="paragraph">Der folgende Befehl ist für Dienstprogramme wie oraenv erforderlich, um ordnungsgemäß zu funktionieren.</block>
  <block id="f34a9f7c077457a54f8838b55b9fc025" category="section-title">Parameteraktualisierungen</block>
  <block id="fd5c3a935e7374f8b1577e73e85ef375" category="paragraph">Die gespeicherte pfile muss aktualisiert werden, um alle Pfadänderungen auf dem neuen Server widerzuspiegeln. Die Änderungen des Datendateipfads werden durch das RMAN-Duplizierungsskript geändert, und fast alle Datenbanken erfordern Änderungen am<block ref="d98137bd230dac4372cf20a2e7839463" prefix=" " category="inline-code"></block> Und<block ref="2d205df7ae2efff1576140524b40b93c" prefix=" " category="inline-code"></block> Parameter. Es können auch Prüfdateipositionen vorhanden sein, die geändert werden müssen, und Parameter wie<block ref="40f8833ae28ec69bcc89eb0eba090fe4" prefix=" " category="inline-code"></block> Ist außerhalb von ASM möglicherweise nicht relevant. Ein erfahrener DBA sollte die vorgeschlagenen Änderungen sorgfältig prüfen, bevor er fortfahren kann.</block>
  <block id="b581dd429e9b4c24127b8940ca8e4346" category="paragraph">In diesem Beispiel sind die wichtigsten Änderungen die Speicherorte der Steuerdatei, das Protokollarchivziel und das Hinzufügen des<block ref="0f2d7ef9b967c2d9fb1ad5aa5e9eb688" prefix=" " category="inline-code"></block> Parameter.</block>
  <block id="bbba1f65801697ba3abd94d90c83ba71" category="paragraph">Nachdem die neuen Parameter bestätigt wurden, müssen die Parameter wirksam werden. Es gibt mehrere Optionen, aber die meisten Kunden erstellen ein Spfile basierend auf dem Text pfile.</block>
  <block id="3a17a12678d74dabb1032aaf373166d8" category="section-title">Startbezeichnung</block>
  <block id="a9dc570a0b3161e69edc31f3545cbf22" category="paragraph">Der letzte Schritt vor dem Replizieren der Datenbank ist, die Datenbankprozesse zu laden, aber nicht die Dateien zu mounten. In diesem Schritt können Probleme mit dem spfile offensichtlich werden. Wenn der<block ref="357eedab214bb515c5622e275bc19cdb" prefix=" " category="inline-code"></block> Befehl schlägt aufgrund eines Parameterfehlers fehl, es ist einfach herunterzufahren, die pfile-Vorlage zu korrigieren, sie als spfile neu zu laden und es erneut zu versuchen.</block>
  <block id="0257eff4bf9bf0cb483f2544fd42f109" category="section-title">Duplizieren Sie die Datenbank</block>
  <block id="4632b675c558eda129fe6da4fbbae2b2" category="paragraph">Die Wiederherstellung des vorherigen RMAN-Backups am neuen Speicherort nimmt mehr Zeit in Anspruch als andere Schritte in diesem Prozess. Die Datenbank muss ohne Änderung der Datenbank-ID (DBID) oder Zurücksetzen der Protokolle dupliziert werden. Dadurch wird verhindert, dass Protokolle angewendet werden, was ein erforderlicher Schritt zur vollständigen Synchronisierung der Kopien ist.</block>
  <block id="06206ea0cdea741420d9f7619503db89" category="paragraph">Stellen Sie mit RMAN als AUX eine Verbindung zur Datenbank her, und geben Sie den Befehl Duplicate Database aus, indem Sie das in einem vorherigen Schritt erstellte Skript verwenden.</block>
  <block id="5ae45dfed3c4aff7fe4fd6a7e3606cb0" category="paragraph">Sie müssen die Änderungen nun von der Quelldatenbank an einen neuen Speicherort senden. Dies kann eine Kombination von Schritten erfordern. Die einfachste Methode wäre, RMAN auf der Quelldatenbank zu haben, um Archivprotokolle auf eine freigegebene Netzwerkverbindung zu schreiben. Wenn ein freigegebener Speicherort nicht verfügbar ist, verwenden Sie RMAN zum Schreiben auf ein lokales Dateisystem und anschließend rcp oder rsync zum Kopieren der Dateien.</block>
  <block id="e355807335e5f05930a748afe1c3b23d" category="paragraph">In diesem Beispiel ist der<block ref="45987b06d5eae35fc3e3487749a9ba27" prefix=" " category="inline-code"></block> Verzeichnis ist eine NFS-Freigabe, die sowohl für die ursprüngliche als auch für die migrierte Datenbank verfügbar ist.</block>
  <block id="49fffa356bcd041918ce24ef714f3f72" category="paragraph">Ein wichtiges Thema ist hier die<block ref="6761e3b36547cd115b3966fcbc7192b2" prefix=" " category="inline-code"></block> Klausel. Das Festplattenformat des Backups ist<block ref="9ae0f22d9fa2eac270499e74092af364" prefix=" " category="inline-code"></block>, Das bedeutet, dass Sie das Format der Thread-Nummer, Sequenznummer und Aktivierungs-ID für die Datenbank verwenden müssen. Obwohl die Buchstaben unterschiedlich sind, entspricht dies der<block ref="03e92f2c3a8cae5315f0e42bf6acf436" prefix=" " category="inline-code"></block> Parameter in pfile. Mit diesem Parameter werden auch Archivprotokolle im Format Thread-Nummer, Sequenznummer und Aktivierungs-ID angegeben. Das Endergebnis ist, dass die Protokolldatei-Backups auf der Quelle eine Benennungskonvention verwenden, die von der Datenbank erwartet wird. Dadurch werden z. B. Operationen wie die<block ref="81168dbef15af03d02c51a7447378e76" prefix=" " category="inline-code"></block> Viel einfacher, weil sqlplus richtig vorwegnimmt die Namen der Archiv-Protokolle wiedergegeben werden.</block>
  <block id="76d77393c7ffc6b0a0edd47ad09afe4d" category="paragraph">Nachdem sich die Dateien im Archiv-Log-Speicherort befinden, können sie mit dem Befehl wiedergegeben werden<block ref="5fea768eb2d353716ca623ae58ce382c" prefix=" " category="inline-code"></block> Gefolgt von der Antwort<block ref="e1f2d5134ed2543d38a0de9751cf75d9" prefix=" " category="inline-code"></block> Um alle verfügbaren Protokolle automatisch wiederzugeben. Die Parameterdatei leitet derzeit Archivprotokolle an<block ref="e421a42fc6f604fcc78707336ed222b9" prefix=" " category="inline-code"></block>, Aber dies stimmt nicht mit dem Speicherort überein, an dem RMAN zum Speichern von Protokollen verwendet wurde. Der Speicherort kann vor der Wiederherstellung der Datenbank wie folgt vorübergehend umgeleitet werden.</block>
  <block id="0a96a4559ad3ab8c616a12a207e8daca" category="paragraph">Die endgültige Antwort des Archivprotokolls meldet einen Fehler. Dies ist jedoch normal. Der Fehler zeigt an, dass sqlplus eine bestimmte Protokolldatei gesucht und nicht gefunden hat. Der Grund dafür ist sehr wahrscheinlich, dass die Protokolldatei noch nicht existiert.</block>
  <block id="e2a234d3299b9e66f0756db00c9ee8c7" category="paragraph">In den meisten Fällen erfolgt die Migration nicht sofort. Es kann Tage oder sogar Wochen bis zum Abschluss des Migrationsprozesses dauern. Das bedeutet, dass die Protokolle kontinuierlich an die Replikatdatenbank gesendet und wieder eingespielt werden müssen. So ist sichergestellt, dass bei der Umstellung nur minimale Daten übertragen und eingespielt werden müssen.</block>
  <block id="247e1695519da78866726a4dcb2c5252" category="paragraph">Dieser Prozess kann einfach per Skript ausgeführt werden. Beispielsweise kann der folgende Befehl für die ursprüngliche Datenbank geplant werden, um sicherzustellen, dass der für den Protokollversand verwendete Speicherort fortlaufend aktualisiert wird.</block>
  <block id="3ce19ecb7c874f75b9a46e29abe2012e" category="inline-link-macro">Wiedergabe von Protokollen in der Standby-Datenbank</block>
  <block id="469d3082a0f3ad08223ba8fe69bf9311" category="paragraph">Nachdem die Protokolle empfangen wurden, müssen sie erneut abgespielt werden. Frühere Beispiele zeigten die Verwendung von sqlplus zum manuellen Ausführen<block ref="5fea768eb2d353716ca623ae58ce382c" prefix=" " category="inline-code"></block>, Die leicht automatisiert werden kann. Das hier abgebildete Beispiel verwendet das in beschriebene Skript <block ref="7c7730292e0135c86626e1771f7f02ec" category="inline-link-macro-rx"></block>. Das Skript akzeptiert ein Argument, das die Datenbank angibt, für die eine Wiedergabeoperation erforderlich ist. Bei diesem Prozess kann dasselbe Skript für eine Migration mit mehreren Datenbanken verwendet werden.</block>
  <block id="15d3442f7626bb62f4b255c7ed5c5098" category="paragraph">Wenn Sie bereit sind, in die neue Umgebung zu schneiden, müssen Sie eine abschließende Synchronisierung durchführen. Bei der Arbeit mit normalen Dateisystemen ist es leicht sicherzustellen, dass die migrierte Datenbank zu 100 % mit dem Original synchronisiert wird, da die ursprünglichen Wiederherstellungsprotokolle kopiert und wiedergegeben werden. Es gibt keinen guten Weg, dies mit ASM zu tun. Nur die Archivprotokolle können einfach wiederaufgenommen werden. Um sicherzustellen, dass keine Daten verloren gehen, muss das endgültige Herunterfahren der ursprünglichen Datenbank sorgfältig durchgeführt werden.</block>
  <block id="f9952f2469fbec5fc9dca180322ff9ee" category="list-text">Zunächst muss die Datenbank stillgelegt werden, um sicherzustellen, dass keine Änderungen vorgenommen werden. Diese Stilllegung kann die Deaktivierung geplanter Vorgänge, das Herunterfahren von Listenern und/oder das Herunterfahren von Anwendungen umfassen.</block>
  <block id="58fd1c52efcde7151ac264a8f67b14ff" category="list-text">Nach diesem Schritt erstellen die meisten DBAs eine Dummy-Tabelle, die als Marker für das Herunterfahren dient.</block>
  <block id="442da9ab2cced82a6cbdd112be285bcf" category="list-text">Erzwingen Sie eine Protokollarchivierung, um sicherzustellen, dass die Erstellung der Dummy-Tabelle in den Archivprotokollen aufgezeichnet wird. Führen Sie dazu die folgenden Befehle aus:</block>
  <block id="83fce8a41250d6af49205f9659468351" category="list-text">Führen Sie die folgenden Befehle aus, um die letzten Archivprotokolle zu kopieren. Die Datenbank muss verfügbar, aber nicht geöffnet sein.</block>
  <block id="1b0e887c1394d4617c2a5243da19e44e" category="list-text">Um die Archivprotokolle zu kopieren, führen Sie die folgenden Befehle aus:</block>
  <block id="86a7e05acb17098c514dd570b9220302" category="list-text">Geben Sie abschließend die restlichen Archivprotokolle auf dem neuen Server wieder.</block>
  <block id="a430882deb5403e7b4b8061dec17cc80" category="list-text">In dieser Phase sollten Sie alle Daten replizieren. Die Datenbank kann von einer Standby-Datenbank in eine aktive Betriebsdatenbank konvertiert und dann geöffnet werden.</block>
  <block id="077c7bcbf9a94bb62aecadc85045886e" category="list-text">Bestätigen Sie das Vorhandensein der Dummy-Tabelle und legen Sie sie dann ab.</block>
  <block id="6130a27b8ec8ccf18e06bb3389b0fbbd" category="section-title">Unterbrechungsfreie Migration von Wiederherstellungsprotokollen</block>
  <block id="26c294f993888218237d5f9306bfcfc4" category="paragraph">Es gibt Zeiten, in denen eine Datenbank insgesamt korrekt organisiert ist, mit Ausnahme der Wiederherstellungsprotokolle. Dies kann aus vielen Gründen geschehen, von denen die häufigste im Zusammenhang mit Snapshots steht. Produkte wie SnapManager für Oracle, SnapCenter und das Storage Management Framework NetApp Snap Creator ermöglichen eine nahezu sofortige Wiederherstellung einer Datenbank, jedoch nur, wenn Sie den Zustand der Daten-File-Volumes zurücksetzen. Wenn Redo-Logs Speicherplatz mit den Datendateien teilen, kann Reversion nicht sicher ausgeführt werden, da es zur Zerstörung der Redo-Protokolle führen würde, was wahrscheinlich Datenverlust bedeutet. Daher müssen die Redo-Logs verschoben werden.</block>
  <block id="2c56f5081b94b926c93c40f4c935a44a" category="paragraph">Dieses Verfahren ist einfach und unterbrechungsfrei.</block>
  <block id="2986f9fe7ed4aab5aaa64c2ee9fe4841" category="section-title">Aktuelle Konfiguration des Wiederherstellungsprotokolls</block>
  <block id="dd786d22c88a5f1fe0c10cfec58c1b44" category="list-text">Ermitteln Sie die Anzahl der Redo-Log-Gruppen und deren jeweilige Gruppennummern.</block>
  <block id="3cd0f7a32a4f5ee026702f8125f3dda7" category="list-text">Geben Sie die Größe der Wiederherstellungsprotokolle ein.</block>
  <block id="7c2f6ada37d59f2be0bc1a3ead80f77c" category="section-title">Erstellen Sie neue Protokolle</block>
  <block id="106b215e5d87fb1256e47932f2ebf9cf" category="list-text">Erstellen Sie für jedes Redo-Protokoll eine neue Gruppe mit einer passenden Größe und Anzahl von Mitgliedern.</block>
  <block id="0851b65f20b98420968e488fc3c0085e" category="list-text">Überprüfen Sie die neue Konfiguration.</block>
  <block id="cbccec9e0905e0b7f5cd630a3fa12f64" category="section-title">Alte Protokolle ablegen</block>
  <block id="00f63618719701ddae7fc2ff1d406ec2" category="list-text">Löschen Sie die alten Protokolle (Gruppen 1, 2 und 3).</block>
  <block id="f00c8361a8acc818247282bb6420a8c1" category="list-text">Wenn ein Fehler auftritt, der verhindert, dass Sie ein aktives Protokoll ablegen, erzwingen Sie einen Wechsel zum nächsten Protokoll, um die Sperre freizugeben und einen globalen Kontrollpunkt zu erzwingen. Siehe folgendes Beispiel für diesen Prozess. Der Versuch, die Logfile-Gruppe 2, die sich am alten Speicherort befand, zu löschen, wurde abgelehnt, da noch aktive Daten in dieser Logdatei vorhanden waren.</block>
  <block id="5d49a93437a42d2926c8be7eb3c7a56f" category="list-text">Eine Protokollarchivierung, gefolgt von einem Kontrollpunkt, ermöglicht es Ihnen, die Protokolldatei zu löschen.</block>
  <block id="e3898c187d7edf64fc8e4d4e409fd244" category="list-text">Löschen Sie anschließend die Protokolle aus dem Dateisystem. Sie sollten diesen Vorgang mit äußerster Sorgfalt durchführen.</block>
  <block id="eb290dfcb2d35cffcb49a22fd05168b5" category="summary">Planung der Oracle-Migration</block>
  <block id="4e0761b3f22b38640f0d2291420d26f6" category="doc">Iracle-Migrationsplanung</block>
  <block id="dacc2a633e9981c9f91e43ac6b59e889" category="paragraph">Die Oracle-Datenmigration kann auf einer der drei Ebenen erfolgen: Der Datenbank, dem Host oder dem Storage Array.</block>
  <block id="5153193d50d4c628312db2d5bc0132ed" category="paragraph">Die Unterschiede liegen darin, welche Komponente der Gesamtlösung für das Verschieben von Daten verantwortlich ist: Die Datenbank, das Host-Betriebssystem oder das Speichersystem.</block>
  <block id="cc3e73ae592a355b9beb405232d08fe2" category="paragraph">Die Abbildung unten zeigt ein Beispiel für die Migrationsebenen und den Datenfluss. Bei einer Migration auf Datenbankebene werden die Daten vom ursprünglichen Storage-System über die Host- und Datenbankschichten in die neue Umgebung verschoben. Die Migration auf Host-Ebene ist ähnlich, aber die Daten durchlaufen nicht die Applikationsebene und werden stattdessen mithilfe von Host-Prozessen an den neuen Speicherort geschrieben. Und schließlich ist bei der Migration auf Storage-Ebene ein Array wie ein NetApp FAS System für die Datenverschiebung verantwortlich.</block>
  <block id="204415652114bfb773b51cd76c8c692e" category="paragraph"><block ref="204415652114bfb773b51cd76c8c692e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b059e0e23ffaa8fbd97f681942ce0018" category="paragraph">Eine Migration auf Datenbankebene bezieht sich im Allgemeinen auf die Verwendung von Oracle-Protokollversand über eine Standby-Datenbank, um eine Migration auf der Oracle-Ebene durchzuführen. Migrationen auf Host-Ebene werden mithilfe der nativen Funktionen der Konfiguration des Host-Betriebssystems durchgeführt. Diese Konfiguration umfasst Dateikopiervorgänge mit Befehlen wie CP, tar und Oracle Recovery Manager (RMAN) oder mit einem Logical Volume Manager (LVM) zur Verlagerung der zugrunde liegenden Bytes eines Dateisystems. Oracle Automatic Storage Management (ASM) wird als Funktion auf Hostebene kategorisiert, da sie unter der Ebene der Datenbankanwendung ausgeführt wird. ASM tritt an die Stelle des üblichen Logical Volume Managers auf einem Host. Und schließlich können Daten auf Storage-Array-Ebene migriert werden, d. h. unter der Ebene des Betriebssystems.</block>
  <block id="228d9e0418aa12bae73676a5743558db" category="section-title">Überlegungen zur Planung</block>
  <block id="ce7eea640cd6ee20e55cbe868f4026e9" category="paragraph">Die beste Option für die Migration hängt von einer Kombination verschiedener Faktoren ab: Vom Umfang der zu migrierenden Umgebung, der Notwendigkeit, Ausfallzeiten zu vermeiden, und dem für die Migration erforderlichen Gesamtaufwand. Große Datenbanken erfordern offensichtlich mehr Zeit und Aufwand für die Migration, aber die Komplexität einer solchen Migration ist minimal. Kleine Datenbanken können schnell migriert werden. Wenn jedoch Tausende migriert werden müssen, kann das Ausmaß des Aufwands zu Komplikationen führen. Und je größer die Datenbank ist, desto wahrscheinlicher ist sie, dass sie geschäftskritisch ist. Dies führt dazu, dass Ausfallzeiten minimiert werden müssen, während gleichzeitig ein Back-Out-Pfad beibehalten wird.</block>
  <block id="d4b9b19593598d98059aae44d6a7bbe1" category="paragraph">Im Folgenden werden einige Überlegungen zur Planung einer Migrationsstrategie erörtert.</block>
  <block id="931c6f2c99380fbd899e3eaa31e97d98" category="section-title">Datengröße</block>
  <block id="64e4d570abeebacf6bdcb19dfb73fcae" category="paragraph">Die Größe der zu migrierenden Datenbanken wirkt sich natürlich auf die Migrationsplanung aus. Die Größe wirkt sich jedoch nicht unbedingt auf die Umstellungszeit aus. Wenn große Datenmengen migriert werden müssen, kommt es in erster Linie auf die Bandbreite an. Kopiervorgänge werden in der Regel mit effizienten sequenziellen I/O-Vorgängen ausgeführt Gehen Sie bei Kopiervorgängen von einer Auslastung der verfügbaren Netzwerkbandbreite von 50 % aus. Ein 8-GB-FC-Port kann theoretisch etwa 800 Mbit/s übertragen. Bei einer Auslastung von 50 % kann eine Datenbank mit einer Geschwindigkeit von etwa 400 Mbps kopiert werden. Somit kann eine 10-TB-Datenbank innerhalb von etwa sieben Stunden kopiert werden.</block>
  <block id="84a80a048e7abc027dd6bdce55fda9d2" category="inline-link-macro">Online-Datendatei verschieben</block>
  <block id="96220ddfb388df1ec5c630828316520f" category="paragraph">Eine Migration über größere Entfernungen erfordert in der Regel einen kreativen Ansatz, wie der Protokollversand-Prozess in erläutert <block ref="3a18b1903dadc58123e7db364a89a706" category="inline-link-macro-rx"></block>. IP-Netzwerke über große Entfernungen verfügen selten überall in der Nähe von LAN- oder SAN-Geschwindigkeiten über eine entsprechende Bandbreite. In einem Fall unterstützte NetApp die Fernmigration einer 220 TB großen Datenbank mit sehr hohen Archiv- Log-Generierungsraten. Der gewählte Ansatz für die Datenübertragung war der tägliche Versand von Bändern, da diese Methode die maximal mögliche Bandbreite bot.</block>
  <block id="1c169b76761527b28040655a783e50a2" category="section-title">Anzahl der Datenbanken</block>
  <block id="da3770c5d6d1215e9f2524b9d7b7c3c5" category="paragraph">In vielen Fällen liegt das Problem beim Verschieben großer Datenmengen nicht in der Datengröße, sondern in der Komplexität der Konfiguration, die die Datenbank unterstützt. Wenn man einfach nur weiß, dass 50 TB Datenbanken migriert werden müssen, reicht das nicht aus. Dabei kann es sich um eine einzelne 50 TB große geschäftskritische Datenbank, eine Sammlung von 4, 000 älteren Datenbanken oder eine Kombination aus Produktions- und nicht produktiven Daten handeln. In manchen Fällen besteht ein Großteil der Daten aus Klonen einer Quelldatenbank. Diese Klone müssen überhaupt nicht migriert werden, da sie einfach wiederhergestellt werden können. Dies gilt insbesondere dann, wenn die neue Architektur die Nutzung von NetApp FlexClone Volumes ermöglicht.</block>
  <block id="a1739e745a7544d2432b2b990a715817" category="paragraph">Für die Migrationsplanung müssen Sie verstehen, wie viele Datenbanken im Umfang enthalten sind und wie sie priorisiert werden müssen. Mit zunehmender Anzahl an Datenbanken ist die bevorzugte Migrationsoption in der Regel im Stack immer geringer. So kann zum Beispiel das Kopieren einer einzelnen Datenbank mit RMAN problemlos und bei einem kurzen Ausfall durchgeführt werden. Dies ist die Replizierung auf Host-Ebene.</block>
  <block id="284723d6a05b50ace5e5b96c761d03ac" category="paragraph">Wenn es 50 Datenbanken gibt, kann es einfacher sein, die Einrichtung einer neuen Dateisystemstruktur zu vermeiden, um eine RMAN-Kopie zu erhalten und stattdessen die Daten an die Stelle zu verschieben. Dies kann durch hostbasierte LVM-Migration erfolgen, um Daten von alten LUNs auf neue LUNs zu verschieben. Dadurch wird die Verantwortung vom Datenbankadministratorteam (DBA) an das Betriebssystemteam übertragen und die Daten werden in Bezug auf die Datenbank transparent migriert. Die Dateisystemkonfiguration ist unverändert.</block>
  <block id="8e734da04d394519001f47f723341e9d" category="paragraph">Wenn schließlich 500 Datenbanken von 200 Servern migriert werden müssen, können speicherbasierte Optionen wie die ONTAP Funktion zum Importieren fremder LUNs (Foreign LUN Import, FLI) verwendet werden, um eine direkte Migration der LUNs durchzuführen.</block>
  <block id="39f43935349622951e0f392c83b6e736" category="section-title">Anforderungen neu architekturgerecht</block>
  <block id="50f1558a3f9d47464b5d57f9d9d0f9d1" category="paragraph">In der Regel muss das Layout einer Datenbankdatei verändert werden, um die Funktionen des neuen Storage Array nutzen zu können. Dies ist jedoch nicht immer der Fall. Die Funktionen der EF-Series All-Flash-Arrays richten sich beispielsweise primär an SAN-Performance und SAN-Zuverlässigkeit. In den meisten Fällen können Datenbanken auf ein EF-Series Array migriert werden, ohne dass dabei besondere Überlegungen zum Datenlayout angestellt werden müssen. Die einzigen Anforderungen sind hohe IOPS, niedrige Latenz und robuste Zuverlässigkeit. Wenngleich es Best Practices für Faktoren wie RAID-Konfiguration oder Dynamic Disk Pools gibt, sind für EF-Series Projekte kaum nennenswerte Änderungen an der gesamten Storage-Architektur erforderlich, um diese Funktionen nutzen zu können.</block>
  <block id="0e2c78f7e9948e19ccb1bf2e1b7f0faf" category="paragraph">Im Gegensatz dazu erfordert die Migration zu ONTAP in der Regel eine stärkere Berücksichtigung des Datenbanklayouts, um sicherzustellen, dass die endgültige Konfiguration den größtmöglichen Nutzen erzielt. ONTAP bietet für eine Datenbankumgebung bereits viele Funktionen ohne besondere Architekturanstrengungen. Am wichtigsten ist jedoch die Möglichkeit einer unterbrechungsfreien Migration auf neue Hardware, wenn die aktuelle Hardware das Ende ihres Lebenszyklus erreicht. Generell gilt: Eine Migration zu ONTAP ist die letzte Migration, die Sie durchführen müssen. Nachfolgende Hardware Upgrades werden durchgeführt und die Daten werden unterbrechungsfrei auf neue Medien migriert.</block>
  <block id="ad93bd21d59f2286385dc519fd7e39fb" category="paragraph">Bei einigen Planungen sind noch mehr Vorteile verfügbar. Die wichtigsten Überlegungen beziehen sich auf die Verwendung von Snapshots. Snapshots bilden die Grundlage für nahezu sofortige Backups, Restores und Klonvorgänge. Ein Beispiel für die Leistung von Snapshots ist der größte bekannte Einsatz bei einer einzigen Datenbank mit 996 TB, die auf ca. 250 LUNs auf 6 Controllern ausgeführt wird. Diese Datenbank kann innerhalb von 2 Minuten gesichert, innerhalb von 2 Minuten wiederhergestellt und innerhalb von 15 Minuten geklont werden. Zu den weiteren Vorteilen zählen die Möglichkeit, Daten im Cluster als Reaktion auf Workload-Änderungen zu verschieben, sowie die Anwendung von Quality-of-Service-Kontrollen (QoS), um in einer Umgebung mit mehreren Datenbanken eine gute und konsistente Performance zu erreichen.</block>
  <block id="6b48ce64da84423ce167ffb72f5f9a8b" category="inline-link-macro">Oracle-Migrationsverfahren – Überblick</block>
  <block id="1311d3b592e4da5950e91965dac1d593" category="paragraph">Technologien wie QoS-Steuerung, Datenverlagerung, Snapshots und Klonen arbeiten in nahezu jeder Konfiguration. Allerdings ist einige Überlegungen im Allgemeinen erforderlich, um die Vorteile zu maximieren. In einigen Fällen können Änderungen am Design von Datenbank-Storage-Layouts erforderlich sein, um die Investitionen in das neue Speicher-Array zu maximieren. Solche Designänderungen können sich auf die Migrationsstrategie auswirken, da Host- oder Storage-basierte Migrationen das ursprüngliche Datenlayout replizieren. Weitere Schritte sind möglicherweise erforderlich, um die Migration abzuschließen und ein für ONTAP optimiertes Daten-Layout zu liefern. Die in dargestellten Verfahren <block ref="d4d5600aaaced44e203002ec1910822d" category="inline-link-macro-rx"></block> Und später zeigen einige der Methoden, um nicht nur eine Datenbank zu migrieren, sondern sie mit minimalem Aufwand in das optimale finale Layout zu migrieren.</block>
  <block id="1fd9b0a8321228b5b8ad4be85e71cf64" category="section-title">Umstellungszeit</block>
  <block id="95b9194d9f06f6f70febc87c071f3050" category="paragraph">Der maximal zulässige Service-Ausfall während der Umstellung sollte ermittelt werden. Es ist ein häufiger Fehler anzunehmen, dass der gesamte Migrationsprozess zu Störungen führt. Viele Aufgaben können vor Beginn von Serviceunterbrechungen durchgeführt werden. Viele Optionen ermöglichen den Abschluss der Migration ohne Unterbrechungen oder Ausfälle. Auch wenn Unterbrechungen unvermeidbar sind, müssen Sie dennoch den maximal zulässigen Serviceausfall definieren, da die Dauer der Umstellungszeit von Prozedur zu Prozedur variiert.</block>
  <block id="2671d3330eac790e8b14ba2a9cecd70b" category="paragraph">Das Kopieren einer 10-TB-Datenbank dauert beispielsweise in der Regel ungefähr sieben Stunden. Wenn das Unternehmen einen Ausfall von sieben Stunden zulassen muss, ist Dateikopien eine einfache und sichere Möglichkeit für die Migration. Wenn fünf Stunden nicht akzeptabel sind, lässt sich ein einfacher Protokollversand-Prozess wie (siehe) <block ref="d746c73310b8111ae91d5cedb4066344" category="inline-link-macro-rx"></block>) Kann mit minimalem Aufwand eingerichtet werden, um die Umstellungszeit auf etwa 15 Minuten zu reduzieren. Während dieser Zeit kann ein Datenbankadministrator den Prozess abschließen. Wenn 15 Minuten nicht akzeptabel sind, kann der endgültige Umstellungsprozess durch Skripting automatisiert werden, um die Umstellungszeit auf wenige Minuten zu verkürzen. Sie können eine Migration jederzeit beschleunigen, doch dies kostet Zeit und Aufwand. Die Umstellungszeitziele sollten darauf basieren, was für das Unternehmen akzeptabel ist.</block>
  <block id="9cfeaf56d2fc41c2695a69adf260c3f8" category="section-title">Rückweg</block>
  <block id="f493e16f7e2caba820eba88a1c5f82d8" category="paragraph">Keine Migration ist völlig risikolos. Auch wenn die Technik einwandfrei funktioniert, besteht immer die Möglichkeit eines Anwenderfehlers. Das mit einem ausgewählten Migrationspfad verbundene Risiko muss neben den Folgen einer fehlgeschlagenen Migration berücksichtigt werden. Die transparente Online-Storage-Migrationsfunktion von Oracle ASM ist beispielsweise eines der wichtigsten Merkmale, und diese Methode ist eine der zuverlässigsten. Mit dieser Methode werden die Daten jedoch irreversibel kopiert. In dem sehr unwahrscheinlichen Fall, dass ein Problem mit ASM auftritt, gibt es keinen einfachen Rückweg. Die einzige Option besteht darin, entweder die ursprüngliche Umgebung wiederherzustellen oder die Migration mit ASM zurück zu den ursprünglichen LUNs rückgängig zu machen. Das Risiko kann durch ein Backup vom Typ Snapshot auf dem ursprünglichen Storage-System minimiert, aber nicht sogar ganz beseitigt werden, vorausgesetzt, das System ist in der Lage, einen solchen Vorgang auszuführen.</block>
  <block id="1886f1ab01daa4511ce537d1af675427" category="section-title">Probe</block>
  <block id="dd5dac65febd7071311b1ae3be1eca90" category="paragraph">Einige Migrationsverfahren müssen vor der Ausführung vollständig überprüft werden. Eine Migration und eine Generalprobe des Umstellungsprozesses ist eine häufige Anfrage bei geschäftskritischen Datenbanken, bei denen die Migration erfolgreich sein und die Downtime minimiert werden muss. Zudem gehören auch die Anwenderakzeptanztests häufig zu den Aufgaben nach der Migration, und das gesamte System kann erst nach Abschluss der Tests in die Produktionsumgebung zurückgeführt werden.</block>
  <block id="7d06b32cdd06d27f7c62fb110d831e60" category="paragraph">Wenn es Bedarf an Proben gibt, können verschiedene ONTAP Funktionen den Prozess wesentlich vereinfachen. Snapshots können insbesondere eine Testumgebung zurücksetzen und schnell mehrere platzsparende Kopien einer Datenbankumgebung erstellen.</block>
  <block id="440a667261bd94f099ef4dde5caf024f" category="summary">Migration einzelner Oracle Datendateien</block>
  <block id="727bb4db430517995ca651c4f57b0c9f" category="doc">Datendatei verschieben</block>
  <block id="fade70b277397e039e100bf0faa98d8e" category="paragraph">Einzelne Oracle Datendateien können mit einem einzigen Befehl verschoben werden.</block>
  <block id="50c3d56e93d52f122bab9de1f2b35780" category="paragraph">Mit dem folgenden Befehl wird beispielsweise die Datendatei IOPST.dbf aus dem Dateisystem verschoben<block ref="87941c54be03c9785752ea54ac9a2dd4" prefix=" " category="inline-code"></block> Zu Dateisystem<block ref="eff8b2f7c4da1cf002bdea257a43fd10" prefix=" " category="inline-code"></block>.</block>
  <block id="53784088a62519d581c3dac4640c41b5" category="paragraph">Das Verschieben einer Datendatei mit dieser Methode kann langsam sein, sollte jedoch normalerweise nicht genügend I/O produzieren, um die täglichen Datenbank-Workloads zu beeinträchtigen. Im Gegensatz dazu kann die Migration über die ASM-Ausbalancierung viel schneller ablaufen, doch dies geschieht auf Kosten der Verlangsamung der gesamten Datenbank, während die Daten verschoben werden.</block>
  <block id="f92065612dfd409585ca08d95cc7a4dc" category="paragraph">Die zum Verschieben von Datendateien erforderliche Zeit kann einfach gemessen werden, indem eine Test-Datendatei erstellt und dann verschoben wird. Die verstrichene Zeit für den Vorgang wird in den Sitzungsdaten mit den folgenden Kosten aufgezeichnet:</block>
  <block id="78fb69ccdf01155db62828d0bc182b84" category="paragraph">In diesem Beispiel handelte es sich bei der verschobenen Datei um die Datendatei 8, deren Größe 21 GB betrug und die Migration ca. 6 Minuten in Anspruch nahm. Der erforderliche Zeitaufwand hängt natürlich von den Funktionen des Storage-Systems, des Storage-Netzwerks und der gesamten Datenbankaktivität zum Zeitpunkt der Migration ab.</block>
  <block id="593b763e01de37a327966ee1abb3f8a2" category="summary">Oracle-Migration mit dem Host-seitigen Storage Stack</block>
  <block id="174f3246d5f9cdf330404cb6158e67e2" category="doc">Oracle Host-Datenkopie</block>
  <block id="3dc2d5f8d7209bb75e8d67aed68bc5ed" category="paragraph">Wie bei der Migration auf Datenbankebene bietet auch die Migration auf Hostebene einen vom Storage-Anbieter unabhängigen Ansatz.</block>
  <block id="1686ceaaa0d8fb4f9a8adb5e717b029c" category="paragraph">Mit anderen Worten, manchmal "einfach die Dateien kopieren" ist die beste Option.</block>
  <block id="d5732a4ab4c633ceb871cebdbf9ae34f" category="paragraph">Obwohl dieser Low-Tech-Ansatz zu einfach erscheint, bietet er doch erhebliche Vorteile, da keine spezielle Software erforderlich ist und die Originaldaten während des Prozesses sicher unberührt bleiben. Die primäre Einschränkung besteht darin, dass eine Datenmigration auf Dateikopien einen unterbrechungsfreien Prozess darstellt, da die Datenbank vor Beginn des Kopiervorgangs heruntergefahren werden muss. Es gibt keine gute Möglichkeit, Änderungen innerhalb einer Datei zu synchronisieren, so dass die Dateien vollständig stillgelegt werden müssen, bevor das Kopieren beginnt.</block>
  <block id="706e7514bb30a289d7ce786a1a5c2ca0" category="paragraph">Wenn das für einen Kopiervorgang erforderliche Herunterfahren nicht wünschenswert ist, ist die nächstbeste Host-basierte Option die Nutzung eines Logical Volume Managers (LVM). Es gibt viele LVM-Optionen, einschließlich Oracle ASM, alle mit ähnlichen Funktionen, aber auch mit einigen Einschränkungen, die berücksichtigt werden müssen. In den meisten Fällen lässt sich die Migration ohne Ausfallzeit und Unterbrechung durchführen.</block>
  <block id="f58e97ac8406ca3e8f0bb7a019a81985" category="section-title">Dateisystem wird kopiert</block>
  <block id="a08ab728e75c63a41ce7571cb781cda2" category="paragraph">Der Nutzen einer einfachen Kopieroperation sollte nicht unterschätzt werden. Dieser Vorgang erfordert während des Kopierprozesses Ausfallzeiten, ist jedoch äußerst zuverlässig und erfordert keine besondere Expertise in Bezug auf Betriebssysteme, Datenbanken oder Speichersysteme. Darüber hinaus ist es sehr sicher, weil es die ursprünglichen Daten nicht beeinträchtigt. In der Regel ändert ein Systemadministrator die Quelldateisysteme, die schreibgeschützt gemountet werden, und startet dann einen Server neu, um zu gewährleisten, dass die aktuellen Daten nicht beschädigt werden können. Der Kopiervorgang kann mithilfe eines Skripts durchgeführt werden, um sicherzustellen, dass er so schnell wie möglich ohne das Risiko eines Benutzerfehlers ausgeführt wird. Da der I/O-Typ eine einfache, sequenzielle Datenübertragung ist, ist er eine äußerst effiziente Bandbreitennutzung.</block>
  <block id="ba0bd93801872993ce832352dd03b56a" category="paragraph">Das folgende Beispiel zeigt eine Möglichkeit für eine sichere und schnelle Migration.</block>
  <block id="d8cb8bcd239bbe7a2a488c1d68dbe420" category="paragraph">Die zu migrierende Umgebung ist wie folgt:</block>
  <block id="3ffbdefc66ad1d1e707c1d6820afbdc0" category="list-text">Aktuelle Dateisysteme</block>
  <block id="bdc9e98c6b17bb14a7bce916054413ba" category="list-text">Neue Filesysteme</block>
  <block id="3b878279a04dc47d60932cb294d96259" category="section-title">Überblick</block>
  <block id="e76912cd513cc8cbcabc2735b524e814" category="paragraph">Die Datenbank kann von einem Datenbankadministrator migriert werden, indem er die Datenbank herunterfährt und die Dateien kopiert. Der Prozess kann jedoch problemlos Skripte erstellen, wenn viele Datenbanken migriert werden müssen oder die Ausfallzeit minimiert werden muss. Die Verwendung von Skripten verringert zudem das Risiko von Benutzerfehlern.</block>
  <block id="d21aae9692f3b1d4e53fd73131414b93" category="paragraph">Die Beispielskripte automatisieren die folgenden Vorgänge:</block>
  <block id="66909ae9d06bad444f5a059b8ee2cd41" category="list-text">Die Datenbank wird heruntergefahren</block>
  <block id="ae737f3f8c04ccbefa99b2bbf87dccc2" category="list-text">Konvertieren der vorhandenen Dateisysteme in einen schreibgeschützten Zustand</block>
  <block id="1dd90b7b28cbd03687df6538c66ff494" category="list-text">Kopieren aller Daten von der Quelle auf Zieldateisysteme, wobei alle Dateiberechtigungen erhalten bleiben</block>
  <block id="741341be7809d7f5765b2352e6ab0aab" category="list-text">Heben Sie das Mounten der alten und neuen Dateisysteme auf</block>
  <block id="7465bc030ca3fe236bcf3ecdf8aaebe4" category="list-text">Erneutes Mounten der neuen Dateisysteme in denselben Pfaden wie die vorherigen Dateisysteme</block>
  <block id="8c4271e6faf2cea4cfc8e5b7108d8ee9" category="section-title">Verfahren</block>
  <block id="b273f8d4284bd1f58cfbafe8065af9fa" category="list-text">Fahren Sie die Datenbank herunter.</block>
  <block id="67eadd4b70772835f318e6d3027e4308" category="inline-link-macro">Dateisystem in schreibgeschützt konvertieren</block>
  <block id="474aae6515223cc3ba71074c9d5abcae" category="list-text">Konvertieren Sie die Dateisysteme in schreibgeschützt. Dies ist mit einem Skript schneller möglich, wie in dargestellt <block ref="2d6e37849c641071fe1cf71ac348d28c" category="inline-link-macro-rx"></block>.</block>
  <block id="4879ec77723fce4974f8ae2a7f87121a" category="list-text">Vergewissern Sie sich, dass die Dateisysteme jetzt schreibgeschützt sind.</block>
  <block id="c91e7f5dba3c873d0978f4892bf8b3f2" category="list-text">Synchronisieren Sie Dateisysteminhalte mit dem<block ref="89a4551b0f29c1a652648b1cb8747021" prefix=" " category="inline-code"></block> Befehl.</block>
  <block id="91e702884985853b8a7091ed5f2beceb" category="inline-link-macro">Ersetzen Sie Das Dateisystem</block>
  <block id="ea27cab9fe7b891870e0ce59aa34e853" category="list-text">Heben Sie die Bereitstellung der alten Dateisysteme auf, und verschieben Sie die kopierten Daten. Dies ist mit einem Skript schneller möglich, wie in dargestellt <block ref="fa3b775593af4f3de8972aced258710d" category="inline-link-macro-rx"></block>.</block>
  <block id="5fe2431acb45422c46eadf66a93851af" category="list-text">Vergewissern Sie sich, dass die neuen Dateisysteme in der Position sind.</block>
  <block id="2d53403ab873059f92ad884eb271e8dc" category="list-text">Starten Sie die Datenbank.</block>
  <block id="40351c33ab81b8b374a20fd292057481" category="section-title">Vollständig automatisierte Umstellung</block>
  <block id="3f70361470a11fb351c83257cd7aa63e" category="paragraph">Dieses Beispielskript akzeptiert Argumente der Datenbank-SID gefolgt von gemeinsam getrennten Paaren von Dateisystemen. Für das oben abgebildete Beispiel wird der Befehl wie folgt ausgegeben:</block>
  <block id="5cddd7b314b7ae819e2cfcac85021426" category="paragraph">Wenn das Beispielskript ausgeführt wird, wird die folgende Sequenz ausgeführt. Er wird beendet, wenn in einem beliebigen Schritt ein Fehler auftritt:</block>
  <block id="43d4fce7952ee09c0c8df60a17f5ea56" category="list-text">Konvertieren Sie die aktuellen Dateisysteme in den schreibgeschützten Status.</block>
  <block id="9d53d62d1e6dc69460f47c83e6c1919d" category="list-text">Verwenden Sie jedes durch Kommas getrennte Paar von Dateisystemargumenten, und synchronisieren Sie das erste Dateisystem mit dem zweiten.</block>
  <block id="39ff0e6dfa9915344ec96f9e78a27267" category="list-text">Entfernen Sie die früheren Dateisysteme.</block>
  <block id="e220fa2a2806386a64e9860f27372e43" category="list-text">Aktualisieren Sie die<block ref="816a3ef77b62ade41c3f936c958aa555" prefix=" " category="inline-code"></block> Datei wie folgt:</block>
  <block id="232c2c4ddd45fc028ae13b58251c5f7e" category="list-text">Erstellen Sie ein Backup bei<block ref="9eb56e72a6bb8350a1453c2762d14178" prefix=" " category="inline-code"></block>.</block>
  <block id="d5082ae73767550813688202df21bc4d" category="list-text">Kommentieren Sie die vorherigen Einträge für die vorherigen und neuen Dateisysteme.</block>
  <block id="b8793b424d1738f1e00e545379867b0d" category="list-text">Erstellen Sie einen neuen Eintrag für das neue Dateisystem, das den alten Bereitstellungspunkt verwendet.</block>
  <block id="29478980f354caa483bc0cfb827c7251" category="list-text">Mounten Sie die Dateisysteme.</block>
  <block id="a0ec0d8bede7d9d58172084de7d5ce53" category="paragraph">Der folgende Text enthält ein Ausführungsbeispiel für dieses Skript:</block>
  <block id="350265a378d2cb1183cd51d56f0e5843" category="section-title">Oracle ASM SPFile- und Passthwd-Migration</block>
  <block id="f37bc722651f2fd86ba4da87f947c4db" category="paragraph">Eine Schwierigkeit beim Abschluss der ASM-Migration sind die ASM-spezifische SPFile- und die Passwort-Datei. Standardmäßig werden diese kritischen Metadatendateien auf der ersten definierten ASM-Laufwerksgruppe erstellt. Wenn eine bestimmte ASM-Datenträgergruppe evakuiert und entfernt werden muss, müssen die SPFile- und Passwortdatei, die diese ASM-Instanz regelt, verschoben werden.</block>
  <block id="88e2a97e52f9854b59ce63e74c4b0cac" category="paragraph">Ein weiterer Anwendungsfall, in dem diese Dateien eventuell verschoben werden müssen, ist die Implementierung von Datenbankmanagement-Software wie beispielsweise SnapManager für Oracle oder dem SnapCenter Oracle Plug-in. Eine der Funktionen dieser Produkte besteht darin, eine Datenbank schnell wiederherzustellen, indem der Zustand der ASM-LUNs, die die Datendateien hosten, zurückgesetzt wird. Um dies zu tun, muss die ASM-Laufwerksgruppe offline geschaltet werden, bevor eine Wiederherstellung durchgeführt werden kann. Dies ist kein Problem, solange die Datendateien einer Datenbank in einer dedizierten ASM-Datenträgergruppe isoliert sind.</block>
  <block id="24de04443b6bdae76336fcab04ae946c" category="paragraph">Wenn diese Datenträgergruppe auch die ASM-Datei spfile/passwd enthält, kann die Datenträgergruppe nur offline geschaltet werden, wenn die gesamte ASM-Instanz heruntergefahren wird. Dies ist ein disruptiver Prozess, was bedeutet, dass die Datei spfile/passwd verschoben werden muss.</block>
  <block id="a6221bf4332cc966c69066295a843480" category="list-text">Datenbank-SID = TOAST</block>
  <block id="0af0da2831407b8130e7f2fabdfab87d" category="list-text">Aktuelle Datendateien auf<block ref="c097579d8cb34b312d396304e0b8f487" prefix=" " category="inline-code"></block></block>
  <block id="24aa2824a0b52b46b301afdb3af9336f" category="list-text">Aktuelle Logfiles und Controlfiles auf<block ref="ad6062251d172504e3b3bed3a8256a5a" prefix=" " category="inline-code"></block></block>
  <block id="bb6de9ea84381f7d01fdd038f104e4ae" category="list-text">Neue ASM-Laufwerksgruppen als eingerichtet<block ref="cb2eb5386826561ac7895f1c878e4252" prefix=" " category="inline-code"></block> Und<block ref="5e20ccf28224fc0cc564f9825c208dbd" prefix=" " category="inline-code"></block></block>
  <block id="8b14bd9d310bf8b211c19645576201e3" category="section-title">Speicherorte für ASM-SPfile/passwd-Dateien</block>
  <block id="7c7d8dd5d09a73f06678562b66dcdc68" category="paragraph">Die Verlagerung dieser Dateien kann ohne Unterbrechungen erfolgen. Aus Sicherheitsgründen empfiehlt NetApp jedoch, die Datenbankumgebung herunterzufahren, damit Sie sicher sein können, dass die Dateien verschoben wurden und die Konfiguration ordnungsgemäß aktualisiert wird. Dieses Verfahren muss wiederholt werden, wenn mehrere ASM-Instanzen auf einem Server vorhanden sind.</block>
  <block id="3666b74ddcf77306328ac5d6db94fecd" category="section-title">Ermitteln Sie ASM-Instanzen</block>
  <block id="9d19a85576af8e1b3dbd78e343a2b022" category="paragraph">Ermitteln Sie die ASM-Instanzen anhand der in aufgezeichneten Daten<block ref="9da4474b569071bcb2ece1d0bdfe7560" prefix=" " category="inline-code"></block> Datei: Die ASM-Instanzen werden durch ein +-Symbol gekennzeichnet.</block>
  <block id="3fe2dd8cf6f82ac15544fd96f9b59b28" category="paragraph">Auf diesem Server befindet sich eine ASM-Instanz namens +ASM.</block>
  <block id="35a557b0490d5a93931025eaaf712cac" category="section-title">Stellen Sie sicher, dass alle Datenbanken heruntergefahren werden</block>
  <block id="e6b0819ae1eca7d408a097efc2fbf2cf" category="paragraph">Der einzige sichtbare smon-Prozess sollte der sman für die verwendete ASM-Instanz sein. Ein weiterer smon-Prozess zeigt an, dass eine Datenbank noch läuft.</block>
  <block id="97639c779a60f010af01997e2363f4eb" category="paragraph">Der einzige smon-Prozess ist die ASM-Instanz selbst. Das bedeutet, dass keine anderen Datenbanken ausgeführt werden und ohne das Risiko einer Störung der Datenbankvorgänge sicher fortgesetzt werden kann.</block>
  <block id="a8d157790e55d19378ddbbdfeb675ef8" category="section-title">Suchen Sie Dateien</block>
  <block id="12d8c982eb4072e31ac4bfe375193160" category="paragraph">Ermitteln Sie den aktuellen Speicherort der ASM-Datei und der Passwortdatei mithilfe des<block ref="e258dbf5114b4df07f0d9e72deb386f2" prefix=" " category="inline-code"></block> Und<block ref="bb41cdf6c9bb75ee17856f938070f23d" prefix=" " category="inline-code"></block> Befehle.</block>
  <block id="bebe64e9d0d4ae3d44b4dfb3583e0109" category="paragraph">Beide Dateien befinden sich an der Basis des<block ref="c097579d8cb34b312d396304e0b8f487" prefix=" " category="inline-code"></block> Festplattengruppe.</block>
  <block id="558f28628ba8ab4cb8420949524832d3" category="section-title">Dateien kopieren</block>
  <block id="c0c2c850cb11c5bb52abbd55a9578e54" category="paragraph">Kopieren Sie die Dateien mit dem in die neue ASM-Datenträgergruppe<block ref="c0baea639672c84505e661b9e369c68a" prefix=" " category="inline-code"></block> Und<block ref="c7adee97d05083a7b65e4b6953045177" prefix=" " category="inline-code"></block> Befehle. Wenn die neue Laufwerksgruppe vor kurzem erstellt wurde und derzeit leer ist, muss sie möglicherweise zuerst gemountet werden.</block>
  <block id="3ed2faf3e1299edd7d92d6c4064f1579" category="paragraph">Die Dateien wurden nun von kopiert<block ref="c097579d8cb34b312d396304e0b8f487" prefix=" " category="inline-code"></block> Bis<block ref="cb2eb5386826561ac7895f1c878e4252" prefix=" " category="inline-code"></block>.</block>
  <block id="1dba5fc559232a8dae45d9f88ed36030" category="section-title">ASM-Instanz aktualisieren</block>
  <block id="1fe2cc6cf436a4bcc6bdc41f947a416a" category="paragraph">Die ASM-Instanz muss jetzt aktualisiert werden, um die Standortänderung widerzuspiegeln. Der<block ref="c8b1affa9ec15d0c0e79347905e75d3e" prefix=" " category="inline-code"></block> Und<block ref="73fb08020d8535b4123a8968c596038c" prefix=" " category="inline-code"></block> Befehle aktualisieren die zum Starten der ASM-Datenträgergruppe erforderlichen ASM-Metadaten.</block>
  <block id="626759f91a0458b0c068cce8a05a6468" category="section-title">Aktivieren Sie ASM mit aktualisierten Dateien</block>
  <block id="69f08287c6faa04381e5a05f4087abe1" category="paragraph">Zu diesem Zeitpunkt verwendet die ASM-Instanz weiterhin die früheren Speicherorte dieser Dateien. Die Instanz muss neu gestartet werden, um ein erneutes Lesen der Dateien von ihren neuen Speicherorten zu erzwingen und Sperren für die vorherigen Dateien freizugeben.</block>
  <block id="5505cf0c514193b89221f1cef3004c58" category="section-title">Entfernen Sie alte spfile- und Passwortdateien</block>
  <block id="8f2d3ac58be7a91f51d7ce9ffa04e397" category="paragraph">Wenn der Vorgang erfolgreich durchgeführt wurde, sind die vorherigen Dateien nicht mehr gesperrt und können jetzt entfernt werden.</block>
  <block id="cfca2b2eb0d694e70904ec82f5d1c34e" category="section-title">Kopie von Oracle ASM zu ASM</block>
  <block id="12632d520b8d9518b5622ac00dc764a8" category="paragraph">Oracle ASM ist im Grunde ein schlankes kombiniertes Volume-Manager- und Dateisystem. Da das Dateisystem nicht sofort sichtbar ist, muss RMAN für Kopiervorgänge verwendet werden. Ein auf Kopien basierender Migrationsprozess ist zwar sicher und einfach, kann jedoch mit Unterbrechungen verbunden sein. Die Unterbrechung kann minimiert, aber nicht vollständig beseitigt werden.</block>
  <block id="152106ebb2aaa94cc87657d353331189" category="paragraph">Wenn Sie eine unterbrechungsfreie Migration einer ASM-basierten Datenbank wünschen, empfiehlt es sich, die ASM-Fähigkeit zu nutzen, um ASM-Extents auf neue LUNs auszugleichen, während die alten LUNs gelöscht werden. Dies ist im Allgemeinen sicher und unterbrechungsfrei, bietet aber keinen Ausweg. Wenn Funktions- oder Leistungsprobleme auftreten, besteht die einzige Möglichkeit darin, die Daten zurück zur Quelle zu migrieren.</block>
  <block id="81fe23a1ac3b2bb348e579b2c5b0f5d5" category="paragraph">Dieses Risiko kann vermieden werden, indem die Datenbank an den neuen Speicherort kopiert wird, anstatt Daten zu verschieben, sodass die Originaldaten nicht geändert werden. Die Datenbank kann vor der Inbetriebnahme vollständig an ihrem neuen Standort getestet werden, und die ursprüngliche Datenbank steht als Fallback-Option zur Verfügung, wenn Probleme gefunden werden.</block>
  <block id="3028182db088e823770b3d02aa0eac9e" category="paragraph">Dieses Verfahren ist eine von vielen Optionen, die RMAN einbeziehen. Er ermöglicht einen zweistufigen Prozess, bei dem das erste Backup erstellt und später durch die Protokollwiedergabe synchronisiert wird. Dieser Prozess sollte die Downtime minimieren, da die Datenbank betriebsbereit bleibt und während der ersten Basiskopie Daten bereitgestellt werden können.</block>
  <block id="634f50a6c6f112c46150a301d749dbcb" category="section-title">Datenbank kopieren</block>
  <block id="5f0bd85dd65afab1472713e8e034fff7" category="paragraph">Oracle RMAN erstellt eine vollständige Kopie der Quelldatenbank der Ebene 0, die sich derzeit in der ASM-Datenträgergruppe befindet<block ref="c097579d8cb34b312d396304e0b8f487" prefix=" " category="inline-code"></block> An den neuen Standort am<block ref="cb2eb5386826561ac7895f1c878e4252" prefix=" " category="inline-code"></block>.</block>
  <block id="b51dc519efad4b151a05682b68f4b182" category="section-title">Schalter für Archivprotokoll erzwingen</block>
  <block id="10793485747151dfa2eaddb0854c84b2" category="paragraph">Sie müssen einen Schalter für das Archivprotokoll erzwingen, um sicherzustellen, dass die Archivprotokolle alle Daten enthalten, die erforderlich sind, um die Kopie vollständig konsistent zu machen. Ohne diesen Befehl können Schlüsseldaten in den Wiederherstellungsprotokollen weiterhin vorhanden sein.</block>
  <block id="c55a88a6b8fdc5972d4e2a4924f93dbf" category="section-title">Quelldatenbank herunterfahren</block>
  <block id="9ec82bff06c706f42a8170befdd6cf39" category="paragraph">Die Unterbrechung beginnt in diesem Schritt, weil die Datenbank heruntergefahren und in einen schreibgeschützten Modus mit eingeschränktem Zugriff versetzt wird. Um die Quelldatenbank herunterzufahren, führen Sie die folgenden Befehle aus:</block>
  <block id="6ecf02e1343e82cf0cd95d7303346ff1" category="section-title">Backup von Controlfile</block>
  <block id="e7bc82f6d1381df55ace121dc02368e6" category="paragraph">Sie müssen die controlfile sichern, falls Sie die Migration abbrechen und zum ursprünglichen Speicherort zurückkehren müssen. Eine Kopie der Backup-Steuerdatei ist nicht 100% erforderlich, aber es macht den Prozess des Rücksetzens der Datenbank-Speicherorte zurück an den ursprünglichen Speicherort einfacher.</block>
  <block id="4e7a51f2c1ee60c69cd719d415f5e87a" category="paragraph">Der aktuelle spfile enthält Verweise auf die Steuerdateien an ihren aktuellen Speicherorten innerhalb der alten ASM-Datenträgergruppe. Es muss bearbeitet werden, was leicht durch das Bearbeiten einer Zwischenversion von pfile erfolgt.</block>
  <block id="253e30479f86461bc79f2fca58ee4cb1" category="section-title">Aktualisieren Sie pfile</block>
  <block id="35db8a54b9c7581f0f77b059233cc61b" category="paragraph">Aktualisieren Sie alle Parameter, die sich auf alte ASM-Datenträgergruppen beziehen, um die neuen Namen der ASM-Datenträgergruppen wiederzugeben. Speichern Sie dann die aktualisierte Datei pfile. Stellen Sie sicher, dass die<block ref="5fa1d01559c04dcdb3ba05775712b1ab" prefix=" " category="inline-code"></block> Parameter sind vorhanden.</block>
  <block id="bb607fbd46f48c3a4080ecda83288b69" category="paragraph">Im folgenden Beispiel werden die Verweise auf angezeigt<block ref="c097579d8cb34b312d396304e0b8f487" prefix=" " category="inline-code"></block> Die in geändert wurden<block ref="cb2eb5386826561ac7895f1c878e4252" prefix=" " category="inline-code"></block> Sind gelb markiert. Zwei wichtige Parameter sind die<block ref="5fa1d01559c04dcdb3ba05775712b1ab" prefix=" " category="inline-code"></block> Parameter, die neue Dateien am richtigen Speicherort erstellen.</block>
  <block id="5275e85db4d606621d8f074e44b95748" category="section-title">Init.ora-Datei aktualisieren</block>
  <block id="17a2b5d1af48f7f8d1511d5372896f7a" category="paragraph">Die meisten ASM-basierten Datenbanken verwenden einen<block ref="b6bd7c570605affc5b50bbd3e436f0c0" prefix=" " category="inline-code"></block> Datei befindet sich im<block ref="45c7302d9c2e8745b3a2bff0f992b6df" prefix=" " category="inline-code"></block> Verzeichnis, das einen Punkt auf das Spfile auf der ASM-Datenträgergruppe darstellt. Diese Datei muss an einen Speicherort auf der neuen ASM-Datenträgergruppe umgeleitet werden.</block>
  <block id="6ad274256421918b584abff3b9446b09" category="paragraph">Ändern Sie diese Datei wie folgt:</block>
  <block id="b6638505615764c377e2cf2585993fd0" category="section-title">Wiederherstellung der Parameterdatei</block>
  <block id="52b21c2e6103a3b8d888a4185e21a787" category="paragraph">Der spfile kann nun mit den Daten in der bearbeiteten pfile gefüllt werden.</block>
  <block id="37f4738eddd35e77d15af55a40e1ab1c" category="section-title">Starten Sie die Datenbank, um neue spfile zu verwenden</block>
  <block id="79f8a930424fe3b21dc30a72791171d4" category="paragraph">Starten Sie die Datenbank, um sicherzustellen, dass sie jetzt den neu erstellten spfile verwendet und dass alle weiteren Änderungen an den Systemparametern korrekt aufgezeichnet werden.</block>
  <block id="231ef0ea12d142611eeea2fdfad67114" category="section-title">Kontrolldatei wiederherstellen</block>
  <block id="33cdbbeabc7f2c647f20b3f8b924307f" category="paragraph">Die von RMAN erstellte Backup-Controldatei kann auch direkt an dem im neuen spfile angegebenen Speicherort wiederhergestellt werden.</block>
  <block id="ce656b7f351ebdc7c599aff6a99e0f2a" category="paragraph">Mounten Sie die Datenbank und überprüfen Sie die Verwendung der neuen Steuerdatei.</block>
  <block id="fda1e79fe400519496075b7e2871092a" category="section-title">Protokollwiedergabe</block>
  <block id="daaec4441f16b5bac11476d4582a296c" category="paragraph">Die Datenbank verwendet derzeit die Datendateien am alten Speicherort. Bevor die Kopie verwendet werden kann, müssen sie synchronisiert werden. Die Zeit während des ersten Kopiervorgangs ist verstrichen, und die Änderungen wurden hauptsächlich in den Archivprotokollen protokolliert. Diese Änderungen werden wie folgt repliziert:</block>
  <block id="fca6726270a94f51cab3142509d32919" category="list-text">Führen Sie ein inkrementelles RMAN-Backup durch, das die Archivprotokolle enthält.</block>
  <block id="8b8a5667b011b5f37163ff4da1004343" category="list-text">Wiederholen Sie das Protokoll.</block>
  <block id="a9a62e70841c4d06dd16306a85700d36" category="section-title">Aktivierung</block>
  <block id="8fecb0145484a35b1d9d5926c945ca30" category="paragraph">Die wiederhergestellte Steuerdatei verweist weiterhin auf die Datendateien am ursprünglichen Speicherort und enthält auch die Pfadinformationen für die kopierten Datendateien.</block>
  <block id="f590db5fdc10f6942f7cd173c0bb578b" category="list-text">Um die aktiven Datendateien zu ändern, führen Sie den aus<block ref="7705ebb59373d0b1dfc71d86ef726f93" prefix=" " category="inline-code"></block> Befehl.</block>
  <block id="2c5c2b5174eafe321358329636e80f5e" category="paragraph">Die aktiven Datendateien sind nun die kopierten Datendateien, aber es können immer noch Änderungen in den letzten Redo-Protokollen enthalten sein.</block>
  <block id="fe83c5826bec1aa20e26802fa94a4a0f" category="list-text">Um alle verbleibenden Protokolle wiederzugeben, führen Sie den aus<block ref="81168dbef15af03d02c51a7447378e76" prefix=" " category="inline-code"></block> Befehl. Wenn die Meldung angezeigt wird<block ref="cef3519da39a73834e89a18ca91951f1" prefix=" " category="inline-code"></block> Wird angezeigt, der Prozess war erfolgreich.</block>
  <block id="15434ad90ad32205a804fe96f265b91d" category="paragraph">Bei diesem Vorgang wurde nur der Speicherort der normalen Datendateien geändert. Die temporären Datendateien müssen umbenannt werden, müssen aber nicht kopiert werden, da sie nur temporär sind. Die Datenbank ist derzeit nicht verfügbar, sodass es keine aktiven Daten in den temporären Datendateien gibt.</block>
  <block id="2a7c5560f8e4ad220c853666c46eb051" category="list-text">Um die temporären Datendateien zu verschieben, geben Sie zuerst ihren Speicherort an.</block>
  <block id="10b2632cf9c3bf6568b36f6a37e627c2" category="list-text">Verschieben Sie temporäre Datendateien mithilfe eines RMAN-Befehls, der den neuen Namen für jede Datendatei festlegt. Bei Oracle Managed Files (OMF) ist der vollständige Name nicht erforderlich; die ASM-Datenträgergruppe reicht aus. Wenn die Datenbank geöffnet wird, verknüpft OMF mit dem entsprechenden Speicherort in der ASM-Datenträgergruppe. Um Dateien zu verschieben, führen Sie die folgenden Befehle aus:</block>
  <block id="2c592b1e2841899b280deafe27eeefbf" category="section-title">Migration des Wiederherstellungsprotokolls</block>
  <block id="3f53598059c3bf11ff505ad9dc0d6776" category="paragraph">Der Migrationsprozess ist fast abgeschlossen, aber die Wiederherstellungsprotokolle befinden sich immer noch in der ursprünglichen ASM-Laufwerksgruppe. Wiederherstellungsprotokolle können nicht direkt verschoben werden. Stattdessen wird ein neuer Satz von Wiederherstellungsprotokollen erstellt und der Konfiguration hinzugefügt, gefolgt von einem Drop der alten Protokolle.</block>
  <block id="d54f1c98a924385411a8488657b21dad" category="list-text">Erstellen Sie für jedes Redo-Protokoll eine neue Gruppe mit einer passenden Konfiguration. Wenn Sie OMF nicht verwenden, müssen Sie den vollständigen Pfad angeben. Dies ist auch ein Beispiel, das den verwendet<block ref="c9655c773db3ebd5871fbe76c0e38a52" prefix=" " category="inline-code"></block> Parameter. Wie bereits gezeigt, wurde dieser Parameter auf +NEWLOGS gesetzt. Mit dieser Konfiguration können Sie die folgenden Befehle verwenden, um neue Online-Protokolle zu erstellen, ohne einen Dateispeicherort oder sogar eine bestimmte ASM-Datenträgergruppe angeben zu müssen.</block>
  <block id="3e0c7c8ee841e9919343fe45e3e04f2d" category="list-text">Öffnen Sie die Datenbank.</block>
  <block id="7e4b38db083a404d0d628bdb1ad83311" category="list-text">Die alten Protokolle ablegen.</block>
  <block id="37e48dd687a01e58ed329feebebf3198" category="list-text">Wenn ein Fehler auftritt, der verhindert, dass Sie ein aktives Protokoll ablegen, erzwingen Sie einen Wechsel zum nächsten Protokoll, um die Sperre freizugeben und einen globalen Kontrollpunkt zu erzwingen. Ein Beispiel ist unten dargestellt. Der Versuch, die Logfile-Gruppe 3, die sich am alten Speicherort befand, zu löschen, wurde abgelehnt, da noch aktive Daten in dieser Logdatei vorhanden waren. Eine Protokollarchivierung nach einem Kontrollpunkt ermöglicht das Löschen der Protokolldatei.</block>
  <block id="79d08abfbe5fd73dc85c55cd20ad4974" category="list-text">Überprüfen Sie die Umgebung, um sicherzustellen, dass alle standortbasierten Parameter aktualisiert werden.</block>
  <block id="799f5ce04f1d9cad4455676b2fd908d9" category="list-text">Im folgenden Skript wird erläutert, wie dieser Prozess vereinfacht werden kann:</block>
  <block id="9867dfc0eee2725f24f86d8114c356a0" category="list-text">Wenn die ASM-Datenträgergruppen vollständig evakuiert wurden, können sie jetzt mit abgehängt werden<block ref="ae709dc3414219bf2c9c8abc9ff6c67a" prefix=" " category="inline-code"></block>. In vielen Fällen sind jedoch die Dateien, die zu anderen Datenbanken oder der ASM-Datei spfile/passwd gehören, noch vorhanden.</block>
  <block id="49f8dc5754bd205ea0da17521cb89a1f" category="section-title">Kopie von Oracle ASM auf das Dateisystem</block>
  <block id="0f5b1767a58e43cb548226e94441dc07" category="paragraph">Das Verfahren zum Kopieren von Oracle ASM in ein Dateisystem ähnelt dem Verfahren zum Kopieren von ASM zu ASM mit ähnlichen Vorteilen und Einschränkungen. Der Hauptunterschied ist die Syntax der verschiedenen Befehle und Konfigurationsparameter bei der Verwendung eines sichtbaren Dateisystems im Gegensatz zu einer ASM-Datenträgergruppe.</block>
  <block id="b533404c568b600f9fceddeac9253964" category="paragraph">Oracle RMAN wird verwendet, um eine (vollständige) Kopie der Quelldatenbank zu erstellen, die sich derzeit in der ASM-Datenträgergruppe befindet<block ref="c097579d8cb34b312d396304e0b8f487" prefix=" " category="inline-code"></block> An den neuen Standort am<block ref="f006bf17b06c884c47190c4225d3215a" prefix=" " category="inline-code"></block>.</block>
  <block id="f78b0ab71e2863c28dbe331056451135" category="paragraph">Der Wechsel des Archivprotokolls muss erzwungen werden, um sicherzustellen, dass die Archivprotokolle alle erforderlichen Daten enthalten, damit die Kopie vollständig konsistent ist. Ohne diesen Befehl können Schlüsseldaten in den Wiederherstellungsprotokollen weiterhin vorhanden sein. Um einen Archivprotokollschalter zu erzwingen, führen Sie den folgenden Befehl aus:</block>
  <block id="c37c761fc28428b9ead4533aba9ee148" category="paragraph">Die Unterbrechung beginnt in diesem Schritt, weil die Datenbank heruntergefahren und in einen schreibgeschützten Modus mit eingeschränktem Zugriff versetzt wird. Um die Quelldatenbank herunterzufahren, führen Sie die folgenden Befehle aus:</block>
  <block id="3abd8870d8a333edcaec6a1082520c67" category="paragraph">Sichern Sie controlfiles, falls Sie die Migration abbrechen und zum ursprünglichen Speicherort zurückkehren müssen. Eine Kopie der Backup-Steuerdatei ist nicht 100% erforderlich, aber es macht den Prozess des Rücksetzens der Datenbank-Speicherorte zurück an den ursprünglichen Speicherort einfacher.</block>
  <block id="38825215f02e25ca63ff64387b01c1c2" category="paragraph">Alle Parameter, die sich auf alte ASM-Datenträgergruppen beziehen, sollten aktualisiert und in einigen Fällen gelöscht werden, wenn sie nicht mehr relevant sind. Aktualisieren Sie sie, um die neuen Dateisystempfade wiederzugeben, und speichern Sie die aktualisierte Datei pfile. Stellen Sie sicher, dass der vollständige Zielpfad aufgeführt ist. Um diese Parameter zu aktualisieren, führen Sie die folgenden Befehle aus:</block>
  <block id="9d0dce3e570fa0ec18269ca508809401" category="section-title">Deaktivieren Sie die ursprüngliche init.ora-Datei</block>
  <block id="03dda6526778417460fd0bbb7716b373" category="paragraph">Diese Datei befindet sich im<block ref="45c7302d9c2e8745b3a2bff0f992b6df" prefix=" " category="inline-code"></block> Verzeichnis und befindet sich in der Regel in einem pfile, das als Zeiger auf den spfile auf der ASM-Datenträgergruppe dient. Um sicherzustellen, dass der ursprüngliche Spfile nicht mehr verwendet wird, benennen Sie ihn um. Löschen Sie sie jedoch nicht, da diese Datei erforderlich ist, wenn die Migration abgebrochen werden muss.</block>
  <block id="6087f741090627369fd114fbc794abc4" category="paragraph">Dies ist der letzte Schritt bei der Verlagerung von Spfile. Der ursprüngliche spfile wird nicht mehr verwendet und die Datenbank wird derzeit mit der Zwischendatei gestartet (aber nicht gemountet). Der Inhalt dieser Datei kann wie folgt an den neuen Speicherort spfile geschrieben werden:</block>
  <block id="3f62847435205b7b2af1bd5aaf1d3277" category="paragraph">Sie müssen die Datenbank starten, um die Sperren der Zwischendatei freizugeben und die Datenbank nur mit der neuen Datei spfile zu starten. Das Starten der Datenbank beweist auch, dass der neue spfile-Speicherort korrekt ist und seine Daten gültig sind.</block>
  <block id="ea164abfd83078cd71a2f3ba5d237900" category="paragraph">Auf dem Pfad wurde eine Sicherungscontroldatei erstellt<block ref="7a1a1280501cff0194d8ce6e351f2a2c" prefix=" " category="inline-code"></block> Früher im Verfahren. Der neue spfile definiert die Speicherorte der controlfile als <block ref="b4d54c88ccade13a82dcaf8f7c07cac5" prefix="/" category="inline-code"></block> Und<block ref="cd300fb0386526438b368e7a6d1b8ace" prefix=" " category="inline-code"></block>. Diese Dateien sind jedoch noch nicht vorhanden.</block>
  <block id="f7ed72e578ca8d23dd45bfa2c0a61ed8" category="list-text">Mit diesem Befehl werden die controlfile-Daten auf den im spfile definierten Pfaden wiederhergestellt.</block>
  <block id="c947c89cb4c7a595782d0be73bbe8cfa" category="list-text">Geben Sie den Mount-Befehl ein, damit die Steuerdateien korrekt erkannt werden und gültige Daten enthalten.</block>
  <block id="da4ae71a31a1286600968f8a340fddb2" category="paragraph">Um den zu validieren<block ref="d98137bd230dac4372cf20a2e7839463" prefix=" " category="inline-code"></block> Parameter, führen Sie den folgenden Befehl aus:</block>
  <block id="c25a81770c591c46d6909aae84bf5814" category="paragraph">Die Datenbank verwendet derzeit die Datendateien am alten Speicherort. Bevor die Kopie verwendet werden kann, müssen die Datendateien synchronisiert werden. Die Zeit während des ersten Kopiervorgangs ist verstrichen, und Änderungen wurden hauptsächlich in den Archivprotokollen protokolliert. Diese Änderungen werden in den folgenden beiden Schritten repliziert.</block>
  <block id="95ea23a5654037c0ab2a5418478d9da2" category="list-text">Wiederholen Sie die Protokolle.</block>
  <block id="e726fdb8508ef59abc6d8ef533186382" category="list-text">Um die aktiven Datendateien zu ändern, führen Sie den aus<block ref="7705ebb59373d0b1dfc71d86ef726f93" prefix=" " category="inline-code"></block> Befehl:</block>
  <block id="7fdba4cfea0e0d298cda23e7f46e40c4" category="list-text">Obwohl die Datendateien vollständig konsistent sein sollten, ist ein letzter Schritt erforderlich, um die verbleibenden Änderungen, die in den Online-Wiederherstellungsprotokollen aufgezeichnet werden, wiederzugeben. Verwenden Sie die<block ref="81168dbef15af03d02c51a7447378e76" prefix=" " category="inline-code"></block> Befehl, um diese Änderungen erneut einzuspielen und die Kopie 100 % mit dem Original zu identisch zu machen. Die Kopie ist jedoch noch nicht geöffnet.</block>
  <block id="8eb94d53286760da56ca9c892a49cd8b" category="section-title">Temporäre Datendateien Verschieben</block>
  <block id="a1e7f15bee0eaa976661307aa884fd99" category="list-text">Ermitteln Sie den Speicherort der temporären Datendateien, die noch auf der ursprünglichen Laufwerksgruppe verwendet werden.</block>
  <block id="89b79c94ceba42d5bc646c1b4b1acd24" category="list-text">Um die Datendateien zu verschieben, führen Sie die folgenden Befehle aus. Wenn es viele Tempfiles gibt, verwenden Sie einen Texteditor, um den RMAN-Befehl zu erstellen, und schneiden Sie ihn dann aus und fügen Sie ihn ein.</block>
  <block id="81aa65cb154a5f125bbf3ede064d4b3f" category="paragraph">Der Migrationsprozess ist fast abgeschlossen, aber die Wiederherstellungsprotokolle befinden sich immer noch in der ursprünglichen ASM-Laufwerksgruppe. Wiederherstellungsprotokolle können nicht direkt verschoben werden. Stattdessen wird ein neuer Satz von Wiederherstellungsprotokollen erstellt und der Konfiguration hinzugefügt, gefolgt von einem Drop der alten Protokolle.</block>
  <block id="6e46687c6cc5deabe53fa42932683c4d" category="list-text">Erstellen Sie für jedes Wiederherstellungsprotokoll eine neue Gruppe, indem Sie die gleiche Größe wie die aktuelle Wiederherstellungsprotokollgruppe verwenden, die den neuen Speicherort des Dateisystems verwendet.</block>
  <block id="22fd48a866ce4d04edb57c15b2fad5da" category="list-text">Entfernen Sie die alten Logfile-Gruppen, die sich noch im vorherigen Speicher befinden.</block>
  <block id="94158400e59555bf69ecd550887bd9f6" category="list-text">Wenn ein Fehler auftritt, der das Löschen eines aktiven Protokolls blockiert, erzwingen Sie einen Switch zum nächsten Protokoll, um die Sperre freizugeben und einen globalen Kontrollpunkt zu erzwingen. Ein Beispiel ist unten dargestellt. Der Versuch, die Logfile-Gruppe 3, die sich am alten Speicherort befand, zu löschen, wurde abgelehnt, da noch aktive Daten in dieser Logdatei vorhanden waren. Eine Protokollarchivierung, gefolgt von einem Kontrollpunkt, ermöglicht das Löschen von Logdateien.</block>
  <block id="326770a786c5933416b6a167c854e7b8" category="list-text">Das folgende Skript zeigt, wie Sie diesen Prozess vereinfachen können.</block>
  <block id="ffdcdc8ee9653232a906773fa11358fd" category="list-text">Wenn die ASM-Datenträgergruppen vollständig evakuiert wurden, können sie jetzt mit abgehängt werden<block ref="ae709dc3414219bf2c9c8abc9ff6c67a" prefix=" " category="inline-code"></block>. In vielen Fällen können Dateien, die zu anderen Datenbanken oder der ASM-Datei spfile/passwd gehören, weiterhin vorhanden sein.</block>
  <block id="3d8b8f4734039817e35d5fb6993c8d08" category="section-title">Bereinigung der Datendatei</block>
  <block id="637607e2203ac522fc9dbc88deb6c36f" category="inline-link-macro">Bereinigung der ASM-Migration</block>
  <block id="18325b8b206963bc1ae6cca25406f942" category="paragraph">Der Migrationsprozess kann je nach Verwendung von Oracle RMAN zu Datendateien mit langer oder kryptischer Syntax führen. Im hier gezeigten Beispiel wurde das Backup mit dem Dateiformat von durchgeführt<block ref="1da91ad80bcfeb818066022a42cde773" prefix=" " category="inline-code"></block>.<block ref="432459869b7d0085e120ec9454032267" prefix=" " category="inline-code"></block> Gibt an, dass RMAN für jede Datendatei einen eindeutigen Standardnamen erstellen sollte. Das Ergebnis ist ähnlich wie im folgenden Text dargestellt. Die traditionellen Namen der Datendateien sind in die Namen eingebettet. Dies kann mithilfe des in dargestellten skriptgesteuerten Ansatzes bereinigt werden <block ref="bf0c2c579af181f7d1e4d0267c1385fe" category="inline-link-macro-rx"></block>.</block>
  <block id="5e8488a95f83d2789417a1f3298f2f31" category="section-title">Oracle ASM-Ausgleich</block>
  <block id="2768938325db3a71a6713959a0f309d9" category="paragraph">Wie bereits erläutert, kann eine Oracle ASM-Festplattengruppe mithilfe des Ausgleichs transparent auf ein neues Storage-System migriert werden. Zusammenfassend ist zu sagen, dass beim Ausbalancieren der vorhandenen LUN-Gruppe LUNs gleicher Größe hinzugefügt werden müssen, gefolgt von einem Drop-Vorgang der vorherigen LUN. Oracle ASM verlagert die zugrunde liegenden Daten automatisch in einem optimalen Layout auf neuen Speicher und gibt dann die alten LUNs nach Abschluss frei.</block>
  <block id="24a638b29b3c55f26c731aa4b9943a52" category="paragraph">Der Migrationsprozess nutzt effiziente sequenzielle I/O-Vorgänge und führt im Allgemeinen keine Performance-Unterbrechung durch. Bei Bedarf kann die Migrationsrate jedoch gedrosselt werden.</block>
  <block id="25d06b03dd002ad791b19500c58e9f72" category="section-title">Identifizieren Sie die zu migrierenden Daten</block>
  <block id="3709d4034873467e8e6ae138da54a443" category="section-title">Erstellen neuer LUNs</block>
  <block id="32176bd565539329eafb96db9447e517" category="paragraph">Erstellen Sie neue LUNs gleicher Größe und legen Sie die Mitgliedschaft für Benutzer und Gruppen nach Bedarf fest. Die LUNs sollten als angezeigt werden<block ref="bea4821516973214973a70aea8337c38" prefix=" " category="inline-code"></block> Festplatten.</block>
  <block id="6e59535a7b8dd239c67b8d015618f5e1" category="section-title">Neue LUNS hinzufügen</block>
  <block id="71f7e1ff1a6e075f8364d083f145b655" category="paragraph">Während die Add- und Drop-Vorgänge zusammen ausgeführt werden können, ist es in der Regel einfacher, neue LUNs in zwei Schritten hinzuzufügen. Fügen Sie zunächst die neuen LUNs der Festplattengruppe hinzu. Dieser Schritt führt dazu, dass die Hälfte der Extents von den aktuellen ASM-LUNs auf die neuen LUNs migriert wird.</block>
  <block id="7989dfdf722e8bee00001dac817e4833" category="paragraph">Die Ausgleichskraft gibt die Rate an, mit der Daten übertragen werden. Je höher die Zahl, desto höher ist die Parallelität der Datenübertragung. Die Migration erfolgt mit effizienten sequenziellen I/O-Vorgängen, die wahrscheinlich keine Performance-Probleme verursachen. Auf Wunsch kann die Ausgleichskraft einer laufenden Migration jedoch mit dem angepasst werden<block ref="e20ea7dfbbe351f6a5275d7adc71efbd" prefix=" " category="inline-code"></block> Befehl. Für typische Migrationen wird der Wert 5 verwendet.</block>
  <block id="2b69f08c262a142b3fb0868f4d31ab4f" category="section-title">Überwachen Sie den Betrieb</block>
  <block id="a5097a0967c777285f74d63bf0cc26a1" category="paragraph">Ein Ausgleichsoperation kann auf verschiedene Weise überwacht und verwaltet werden. Für dieses Beispiel haben wir den folgenden Befehl verwendet.</block>
  <block id="5d68829c11bdb5ae7a50b847bb126d44" category="paragraph">Nach Abschluss der Migration werden keine Vorgänge zur Ausbalancierung gemeldet.</block>
  <block id="957310262614cddc1992368d2d0b14b3" category="section-title">Alte LUNs ablegen</block>
  <block id="260c16583c8eb689202ed5b4a44708b1" category="paragraph">Die Migration ist nun zur Hälfte abgeschlossen. Einige grundlegende Performance-Tests stellen sicher, dass die Umgebung sich in einem ordnungsgemäßen Zustand befindet. Nach Bestätigung können die verbleibenden Daten durch Löschen der alten LUNs verschoben werden. Beachten Sie, dass dies nicht zur sofortigen Freigabe der LUNs führt. Der Drop-Vorgang signalisiert Oracle ASM, die Extents zuerst zu verschieben und dann die LUN freizugeben.</block>
  <block id="90423249814011b02ba06afd9fb2d617" category="paragraph">Der Ausgleichsoperation kann auf verschiedene Weise überwacht und verwaltet werden. Für dieses Beispiel haben wir den folgenden Befehl verwendet:</block>
  <block id="1544b3a52519b3856f1f7d1e704cb56f" category="section-title">Entfernen Sie alte LUNs</block>
  <block id="983d704730b30910fc03d3ed444278f0" category="paragraph">Bevor Sie die alten LUNs aus der Laufwerksgruppe entfernen, sollten Sie den Header-Status einer letzten Prüfung entnehmen. Nachdem eine LUN aus ASM freigegeben wurde, wird kein Name mehr aufgeführt, und der Kopfzeilenstatus wird als aufgeführt<block ref="e2ffc99cf675f5f0f1a3456438551a9a" prefix=" " category="inline-code"></block>. Dies bedeutet, dass diese LUNs sicher aus dem System entfernt werden können.</block>
  <block id="22a67c375eff91d37f2363ea69b0c41f" category="section-title">LVM-Migration</block>
  <block id="d52f83c78118c243801797ba9b795b72" category="paragraph">Das hier vorgestellte Verfahren zeigt die Prinzipien einer LVM-basierten Migration einer Volume-Gruppe namens<block ref="ec2db4422261eae02091227fb9e53c88" prefix=" " category="inline-code"></block>. Die Beispiele stammen aus Linux LVM, die Prinzipien gelten jedoch gleichermaßen für AIX, HP-UX und VxVM. Die genauen Befehle können variieren.</block>
  <block id="64a375907ede7a86c9e8a1b4b142f22e" category="list-text">Identifizieren Sie die LUNs, die sich derzeit im befinden<block ref="ec2db4422261eae02091227fb9e53c88" prefix=" " category="inline-code"></block> Volume-Gruppe.</block>
  <block id="0ae75856dd12545cdd98b8cad5c12ad8" category="list-text">Erstellen Sie neue LUNs mit derselben oder einer etwas größeren physischen Größe und definieren Sie sie als physische Volumes.</block>
  <block id="2426fa707e9d362c711977b79acd65bb" category="list-text">Fügen Sie die neuen Volumes zur Volume-Gruppe hinzu.</block>
  <block id="02443ebd7f86c3a688a1e3466d3f106a" category="list-text">Stellen Sie das aus<block ref="8167c9a6bd495f7ed235364201039099" prefix=" " category="inline-code"></block> Befehl, um die Extents jeder aktuellen LUN in die neue LUN zu verschieben. Der<block ref="1b464374742cfda0167b82bc6f9462f1" prefix=" " category="inline-code"></block> Argument überwacht den Fortschritt des Vorgangs.</block>
  <block id="ce4a174d56245f6ba5b8808527919921" category="list-text">Wenn dieser Vorgang abgeschlossen ist, löschen Sie die alten LUNs aus der Volume-Gruppe mithilfe von<block ref="3a4d1e7b0af1cf3d80e419c09d238535" prefix=" " category="inline-code"></block> Befehl. Wenn die LUN erfolgreich war, kann sie jetzt sicher aus dem System entfernt werden.</block>
  <block id="599a80136f745b38f35077e1c7eb020e" category="summary">Oracle-Migrationsverfahren</block>
  <block id="329ffa7a9038afa62748f87628b749d5" category="paragraph">Für die Oracle-Migrationsdatenbank sind zahlreiche Verfahren verfügbar. Das richtige hängt von Ihren geschäftlichen Anforderungen ab.</block>
  <block id="48a2d08de8943e7ca4718c02e6b791b6" category="paragraph">In vielen Fällen haben Systemadministratoren und DBAs ihre eigenen bevorzugten Methoden, um physische Volume-Daten zu verschieben, zu spiegeln und zu demirrieren oder Oracle RMAN zum Kopieren von Daten zu nutzen.</block>
  <block id="79d01f6e7efcfef7db530c0b3c5ea516" category="paragraph">Diese Verfahren dienen in erster Linie als Orientierungshilfe für IT-Mitarbeiter, die mit einigen der verfügbaren Optionen nicht vertraut sind. Des Weiteren werden die Aufgaben, der zeitliche Bedarf und der Qualifikationsbedarf für jeden Migrationsansatz dargestellt. Dadurch können auch andere Parteien wie NetApp und Partner Professional Services oder IT-Management die Anforderungen an die einzelnen Verfahren voll einschätzen.</block>
  <block id="5604c71a7d9ae37df511cc85052c1894" category="paragraph">Es gibt keine einzigen Best Practices für die Erstellung einer Migrationsstrategie. Um einen Plan zu erstellen, müssen zunächst die Verfügbarkeitsoptionen verstanden und anschließend die Methode ausgewählt werden, die den Anforderungen des Unternehmens am besten entspricht. Die folgende Abbildung zeigt die grundlegenden Überlegungen und typischen Schlussfolgerungen von Kunden, ist aber nicht universell auf alle Situationen anwendbar.</block>
  <block id="fa2e72668f7d48694bef3ba5474e3967" category="paragraph">Ein Schritt wirft beispielsweise das Problem der Gesamtgröße der Datenbank auf. Der nächste Schritt hängt davon ab, ob die Datenbank mehr oder weniger als 1 TB umfasst. Die empfohlenen Schritte sind genau das – Empfehlungen auf der Basis typischer Kundenpraktiken. Die meisten Kunden würden nicht mit DataGuard eine kleine Datenbank kopieren, aber einige könnten. Die meisten Kunden würden aufgrund der erforderlichen Zeit nicht versuchen, eine 50 TB große Datenbank zu kopieren, aber einige haben möglicherweise ein ausreichend großes Wartungsfenster, um einen solchen Vorgang zu ermöglichen.</block>
  <block id="82f59f5f005a6ea06f0466a4ffc18b6c" category="paragraph">Sie finden ein Flussdiagramm mit den Arten von Überlegungen, welche Migrationspfade am besten geeignet sind <block ref="d197151b12289ca0258c12e9b0e8fb1c" category="inline-link-macro-rx"></block>.</block>
  <block id="e38af1623479eee6cfe1782df43819d3" category="paragraph">Bei Oracle 12cR1 und höher kann eine Datendatei verschoben werden, während die Datenbank online bleibt. Es funktioniert außerdem zwischen verschiedenen Dateisystemtypen. Eine Datendatei kann beispielsweise von einem xfs-Dateisystem in ASM verschoben werden. Diese Methode wird im Allgemeinen nicht in der Größenordnung verwendet, da die Anzahl der erforderlichen individuellen Datendateiverschiebungsvorgänge erforderlich wäre. Es ist jedoch eine Option, die es sich lohnt, bei kleineren Datenbanken mit weniger Datendateien in Betracht zu ziehen.</block>
  <block id="5972a038819f045814401b2baea9ee09" category="paragraph">Darüber hinaus ist das einfache Verschieben einer Datendatei eine gute Option für die Migration von Teilen vorhandener Datenbanken. Beispielsweise können weniger aktive Datendateien auf kostengünstigeren Storage verschoben werden, beispielsweise auf ein FabricPool Volume, mit dem ungenutzte Blöcke im Objektspeicher gespeichert werden können.</block>
  <block id="fcdd0d9eae6df775f1bdc52f950a0160" category="section-title">Migration auf Datenbankebene</block>
  <block id="2b619622b2b8505c335acc8be3a2c3fd" category="paragraph">Die Migration auf Datenbankebene bedeutet, dass die Datenbank Daten verschieben kann. Konkret bedeutet dies Protokollversand. Technologien wie RMAN und ASM sind Oracle Produkte. Im Rahmen der Migration arbeiten sie jedoch auf Hostebene, wo sie Dateien kopieren und Volumes managen.</block>
  <block id="1048000638cc5357b8b2b36ab55cbc5a" category="section-title">Protokollversand</block>
  <block id="36f7294e33f88b462199b92362434684" category="paragraph">Die Grundlage für die Migration auf Datenbankebene ist das Oracle Archivprotokoll, das ein Protokoll der Änderungen an der Datenbank enthält. Meistens ist ein Archivprotokoll Bestandteil einer Backup- und Recovery-Strategie. Der Recovery-Prozess beginnt mit der Wiederherstellung einer Datenbank und dann mit der Wiedergabe eines oder mehrerer Archivprotokolle, um die Datenbank in den gewünschten Zustand zu bringen. Mit derselben Basistechnologie kann eine Migration mit nur minimaler bis keiner Unterbrechung des Betriebs durchgeführt werden. Noch wichtiger ist, dass diese Technologie die Migration ermöglicht und gleichzeitig die ursprüngliche Datenbank unberührt lässt. Dabei wird ein Back-Out-Pfad beibehalten.</block>
  <block id="d43de5ded302797939b76670bc488b51" category="paragraph">Der Migrationsprozess beginnt mit der Wiederherstellung eines Datenbank-Backups auf einem sekundären Server. Dies kann auf unterschiedliche Weise erfolgen, doch die meisten Kunden verwenden ihre normale Backup-Applikation, um die Datendateien wiederherzustellen. Nachdem die Datendateien wiederhergestellt sind, legen Benutzer eine Methode für den Protokollversand fest. Das Ziel besteht darin, einen konstanten Feed von Archivprotokollen zu erstellen, die von der primären Datenbank generiert werden, und diese in der wiederhergestellten Datenbank wiederzugeben, um sie nahe am selben Status zu halten. Wenn die Umstellung ankommt, wird die Quelldatenbank vollständig heruntergefahren und die letzten Archivprotokolle sowie in einigen Fällen die Wiederherstellungsprotokolle kopiert und wiedergegeben. Es ist wichtig, dass die Wiederherstellungsprotokolle auch berücksichtigt werden, da sie einige der letzten abgeschlossenen Transaktionen enthalten können.</block>
  <block id="f6fc42763ddbd981d5803ee6676dc7c3" category="paragraph">Nachdem diese Protokolle übertragen und wiedergegeben wurden, sind beide Datenbanken konsistent. Jetzt führen die meisten Kunden einige grundlegende Tests durch. Wenn während des Migrationsprozesses Fehler auftreten, sollte die Protokollwiedergabe Fehler melden und fehlschlagen. Es ist weiterhin ratsam, einige schnelle Tests basierend auf bekannten Abfragen oder applikationsgestützten Aktivitäten durchzuführen, um zu überprüfen, ob die Konfiguration optimal ist. Es ist auch üblich, eine abschließende Testtabelle zu erstellen, bevor die ursprüngliche Datenbank heruntergefahren wird, um zu überprüfen, ob sie in der migrierten Datenbank vorhanden ist. Dieser Schritt stellt sicher, dass während der endgültigen Protokollsynchronisierung keine Fehler gemacht wurden.</block>
  <block id="d8e9d23b4beb4db3da15d77542782747" category="paragraph">Eine einfache Log-Shipping-Migration kann Out-of-Band hinsichtlich der ursprünglichen Datenbank konfiguriert werden, was dies besonders für geschäftskritische Datenbanken nützlich macht. Für die Quelldatenbank sind keine Konfigurationsänderungen erforderlich, und die Wiederherstellung und Erstkonfiguration der Migrationsumgebung haben keine Auswirkungen auf den Produktionsbetrieb. Nachdem der Protokollversand konfiguriert wurde, werden einige I/O-Anforderungen an die Produktionsserver gestellt. Der Protokollversand besteht jedoch aus einfachen sequenziellen Lesevorgängen in den Archivprotokollen, was sich wahrscheinlich nicht auf die Performance der Produktionsdatenbank auswirken wird.</block>
  <block id="2c31403002a9f424c6ef56460c6b3715" category="paragraph">Der Protokollversand hat sich besonders für große Entfernungen bei Migrationen mit hohen Änderungsraten bewährt. In einer Instanz wurde eine einzelne 220 TB Datenbank an einen etwa 500 Meilen entfernten neuen Standort migriert. Die Änderungsrate war extrem hoch und Sicherheitsbeschränkungen verhinderten die Nutzung einer Netzwerkverbindung. Der Protokollversand wurde durch Tape und Kurier durchgeführt. Eine Kopie der Quelldatenbank wurde zunächst mithilfe der unten beschriebenen Verfahren wiederhergestellt. Die Protokolle wurden dann wöchentlich per Kurier bis zum Zeitpunkt der Umstellung versendet, als die endgültigen Tapes zugestellt wurden und die Protokolle auf die Replikatdatenbank angewendet wurden.</block>
  <block id="b8efa655c4deb7af8a24fc241f8b53ff" category="section-title">Oracle DataGuard</block>
  <block id="d3165c4060fc6d19c0a6364e7c4580ee" category="paragraph">In einigen Fällen ist eine vollständige DataGuard Umgebung gerechtfertigt. Es ist falsch, den Begriff DataGuard zu verwenden, um auf eine Protokollversendungs- oder Standby-Datenbankkonfiguration zu verweisen. Oracle DataGuard ist ein umfassendes Framework für das Management der Datenbankreplikation, es handelt sich jedoch nicht um eine Replizierungstechnologie. Der Hauptvorteil einer kompletten DataGuard-Umgebung bei einer Migration ist das transparente Umschalten von einer Datenbank zur anderen. DataGuard ermöglicht außerdem ein transparentes Switchover zurück zur Originaldatenbank, falls ein Problem erkannt wird, beispielsweise ein Problem mit der Performance oder der Netzwerkkonnektivität in der neuen Umgebung. Eine vollständig konfigurierte DataGuard-Umgebung erfordert nicht nur die Konfiguration der Datenbankschicht, sondern auch der Applikationen, damit Applikationen eine Änderung am primären Datenbankstandort erkennen können. Im Allgemeinen ist es nicht notwendig, eine Migration mit DataGuard durchzuführen, aber einige Kunden haben intern umfangreiche DataGuard-Kenntnisse und verlassen sich bei Migrationsaufgaben bereits auf diese.</block>
  <block id="f17c0a1ce359c1a6665412f89234bf41" category="section-title">Neuarchitektur</block>
  <block id="ece8d784e248d63091fc0d248cdeebc3" category="paragraph">Wie bereits erläutert, erfordert die Nutzung der erweiterten Funktionen von Storage Arrays manchmal eine Änderung des Datenbank-Layouts. Darüber hinaus verändert eine Änderung des Storage-Protokolls, wie etwa das Wechsel von ASM zu einem NFS Filesystem, zwangsläufig das Filesystem-Layout.</block>
  <block id="71843fb61639ed5fe216bfebc85af16f" category="paragraph">Einer der Hauptvorteile von Protokollversandmethoden, einschließlich DataGuard, besteht darin, dass das Replizierungsziel nicht mit der Quelle übereinstimmen muss. Bei der Migration von ASM zu einem normalen Dateisystem oder umgekehrt gibt es keine Probleme mit der Verwendung eines Protokollversandansatzes. Das genaue Layout der Datendateien kann am Ziel geändert werden, um die Verwendung der Pluggable Database (PDB)-Technologie zu optimieren oder QoS-Kontrollen für bestimmte Dateien selektiv festzulegen. Mit anderen Worten: Ein Migrationsprozess auf der Basis des Protokollversand ermöglicht Ihnen eine einfache und sichere Optimierung des Datenbank-Storage-Layouts.</block>
  <block id="f00ec1b23f539163f4c748a85e49e2dd" category="section-title">Server-Ressourcen</block>
  <block id="76c5d43a72d856a95b0eed94694ae696" category="paragraph">Eine Einschränkung für die Migration auf Datenbankebene besteht in der Notwendigkeit eines zweiten Servers. Dieser zweite Server kann auf zwei Arten verwendet werden:</block>
  <block id="6cb133f8b5045ef30c17e96ab281749e" category="list-text">Sie können den zweiten Server als permanentes neues Zuhause für die Datenbank verwenden.</block>
  <block id="f5133929790fe62dbc76a73db4c88544" category="list-text">Sie können den zweiten Server als temporären Staging-Server verwenden. Nachdem die Datenmigration zum neuen Storage-Array abgeschlossen und getestet wurde, werden die LUN- oder NFS-Dateisysteme vom Staging-Server getrennt und mit dem ursprünglichen Server verbunden.</block>
  <block id="48a00ba9881b62c610201cd833ee9c88" category="paragraph">Die erste Option ist die einfachste, aber in sehr großen Umgebungen, die sehr leistungsstarke Server erfordern, ist die Verwendung möglicherweise nicht möglich. Die zweite Option erfordert zusätzliche Arbeit, um die Dateisysteme wieder an den ursprünglichen Speicherort zu verschieben. Es kann sich um eine einfache Operation handelt, bei der NFS als Storage-Protokoll verwendet wird, da die File-Systeme vom Staging-Server abgehängt und dann wieder auf dem ursprünglichen Server gemountet werden können.</block>
  <block id="c223252c2d577984b75caddbd1dff9dc" category="paragraph">Blockbasierte Dateisysteme erfordern eine zusätzliche Arbeitsleistung für die Aktualisierung von FC-Zoning oder iSCSI-Initiatoren. Bei den meisten logischen Volume-Managern (einschließlich ASM) werden die LUNs automatisch erkannt und online geschaltet, nachdem sie auf dem ursprünglichen Server verfügbar gemacht wurden. Einige Dateisystem- und LVM-Implementierungen erfordern jedoch möglicherweise mehr Arbeit für den Export und Import der Daten. Die genaue Vorgehensweise kann variieren, es ist jedoch im Allgemeinen einfach, ein einfaches, wiederholbares Verfahren einzurichten, um die Migration abzuschließen und die Daten auf dem ursprünglichen Server wiederherzustellen.</block>
  <block id="2d22ab8be3661ce5dfd8c9910d1cc003" category="paragraph">Es ist zwar möglich, einen Protokollversand einzurichten und eine Datenbank in einer einzigen Server-Umgebung zu replizieren, aber die neue Instanz muss eine andere Prozess-SID haben, um die Protokolle wiederzugeben. Es ist möglich, die Datenbank vorübergehend unter einem anderen Satz von Prozess-IDs mit einer anderen SID zu erstellen und später zu ändern. Dies kann jedoch zu vielen komplizierten Management-Aktivitäten und einem Risiko von Benutzerfehlern führen.</block>
  <block id="2660e825d3a58f68aeec49e1c749f477" category="section-title">Migration auf Host-Ebene</block>
  <block id="fae5bb68519bf78c1b3711566283f4ef" category="paragraph">Bei der Migration von Daten auf Hostebene müssen das Host-Betriebssystem und die zugehörigen Dienstprogramme zum Abschluss der Migration verwendet werden. Dieser Prozess umfasst alle Utilitys zum Kopieren von Daten, darunter Oracle RMAN und Oracle ASM.</block>
  <block id="01070e0746a412afd171ccf162d3a170" category="section-title">Kopieren von Daten</block>
  <block id="180e717e34d5e4bd2991c47960d00f51" category="paragraph">Der Wert einer einfachen Kopieroperation sollte nicht unterschätzt werden. Moderne Netzwerkinfrastrukturen können Daten in Gigabytes pro Sekunde verschieben und Dateikopievorgänge basieren auf effizienten sequenziellen Lese- und Schreib-I/O. Im Vergleich zum Protokollversand lassen sich mehr Unterbrechungen durch Host-Kopien vermeiden, doch bei einer Migration handelt es sich nicht nur um die Datenverschiebung. Sie umfasst im Allgemeinen Änderungen am Netzwerk, den Neustartzeit der Datenbank und Tests nach der Migration.</block>
  <block id="750e04d167938f35054d1c30fd06af58" category="paragraph">Die tatsächlich zum Kopieren der Daten benötigte Zeit ist möglicherweise nicht signifikant. Darüber hinaus behält ein Kopiervorgang einen garantierten Back-out-Pfad bei, da die Originaldaten unverändert bleiben. Sollten während des Migrationsprozesses Probleme auftreten, können die ursprünglichen Dateisysteme mit den Originaldaten wieder aktiviert werden.</block>
  <block id="5a3572c65171e06d99a4e055f9d35d32" category="section-title">Ändern Der Plattform</block>
  <block id="d123cc133e4de7ab3a4b1a5af3bf37a7" category="paragraph">Replatforming bezieht sich auf eine Änderung des CPU-Typs. Wenn eine Datenbank von einer herkömmlichen Solaris-, AIX- oder HP-UX-Plattform zu x86 Linux migriert wird, müssen die Daten aufgrund von Änderungen in der CPU-Architektur neu formatiert werden. SPARC, IA64 und POWER CPUs werden als Big-Endian-Prozessoren bezeichnet, während die x86- und x86_64-Architekturen als Little-Endian bezeichnet werden. Daher werden einige Daten in Oracle-Datendateien je nach verwendetem Prozessor unterschiedlich sortiert.</block>
  <block id="6a03806f9c4b1f0048478bab7863fd2c" category="paragraph">In der Vergangenheit haben Kunden Daten mithilfe von DataPump plattformübergreifend repliziert. DataPump ist ein Dienstprogramm, das einen speziellen Typ des logischen Datenexports erzeugt, der schneller in die Zieldatenbank importiert werden kann. Da es eine logische Kopie der Daten erstellt, lässt DataPump die Abhängigkeiten der Prozessorabhängigkeit hinter sich. DataPump wird von einigen Kunden weiterhin für das Replatforming verwendet, aber mit Oracle 11g ist eine schnellere Option verfügbar: Plattformübergreifende transportable Tablespaces. Mit diesem Vorschub kann ein Tablespace in ein anderes endian-Format konvertiert werden. Dies ist eine physische Transformation, die eine bessere Leistung bietet als ein DataPump-Export, der physische Bytes in logische Daten konvertieren und dann zurück in physische Bytes konvertieren muss.</block>
  <block id="713bf8ff4ea4c4ece861f3345e15e3ea" category="paragraph">Eine vollständige Diskussion über DataPump und transportable Tablespaces geht über den Umfang der NetApp-Dokumentation hinaus. NetApp hat jedoch einige Empfehlungen, die auf unseren Erfahrungen basieren, die Kunden bei der Migration zu einem neuen Storage Array-Protokoll mit einer neuen CPU-Architektur unterstützt haben:</block>
  <block id="86b0ebca28354c7f55b4cc2fe79bee0e" category="list-text">Wenn DataPump verwendet wird, sollte die für den Abschluss der Migration erforderliche Zeit in einer Testumgebung gemessen werden. Kunden sind manchmal überrascht, wie lange sie für die Durchführung der Migration benötigen. Diese unerwartete zusätzliche Ausfallzeit kann zu Unterbrechungen führen.</block>
  <block id="8a592f25a72fd6f3718b1b01869ade30" category="list-text">Viele Kunden glauben irrtümlicherweise, dass plattformübergreifende transportable Tablespaces keine Datenkonvertierung erfordern. Wenn eine CPU mit einem anderen Endian verwendet wird, wird ein RMAN verwendet<block ref="31168275dcaac634489082b54c4c66d0" prefix=" " category="inline-code"></block> Der Betrieb muss zuvor an den Datendateien durchgeführt werden. Dies ist kein sofortiger Vorgang. In einigen Fällen kann der Konvertierungsprozess beschleunigt werden, indem mehrere Threads auf verschiedenen Dateien arbeiten, aber der Konvertierungsprozess kann nicht vermieden werden.</block>
  <block id="db7b3f86f4c9a2a6a76adac81614c03b" category="section-title">Migration über Manager eines logischen Volumes</block>
  <block id="86586aa50b0df80a7c68bcd3e86c8606" category="paragraph">LVMs nehmen eine Gruppe von einer oder mehreren LUNs und zerteilen sie in kleine Einheiten, die im Allgemeinen als Extents bezeichnet werden. Der Pool mit Erweiterungen wird dann als Quelle verwendet, um logische Volumes zu erstellen, die im Wesentlichen virtualisiert sind. Diese Virtualisierungsebene bietet auf verschiedene Weise einen Mehrwert:</block>
  <block id="68d083c44669b8b20f0421b0389c6ded" category="list-text">Logische Volumes können Extents verwenden, die von mehreren LUNs stammen. Wenn ein Filesystem auf einem logischen Volume erstellt wird, können alle Performance-Funktionen aller LUNs genutzt werden. Zudem wird die gleichmäßige Auslastung aller LUNs in der Volume-Gruppe gefördert, wodurch eine besser planbare Performance erzielt wird.</block>
  <block id="10d1e748082641ce33e82f457cabcbe7" category="list-text">Die Größe logischer Volumes kann durch Hinzufügen und in einigen Fällen durch Entfernen von Extents geändert werden. Die Größe eines Filesystems auf einem logischen Volume ist im Allgemeinen unterbrechungsfrei.</block>
  <block id="5efed6e7bf2fda8321882aff35768721" category="list-text">Logische Volumes können unterbrechungsfrei migriert werden, indem die zugrunde liegenden Extents verschoben werden.</block>
  <block id="96371ba57b3d2f331cc9bd7b5e34708b" category="paragraph">Migration mit einer LVM funktioniert auf zwei Arten: Ein Extent verschieben oder ein Extent spiegeln/demirrieren. Bei der LVM-Migration werden effiziente sequenzielle I/O große Blöcke eingesetzt, und es entstehen nur selten Performance-Probleme. Wenn dies zu einem Problem wird, gibt es in der Regel Optionen zur Drosselung der I/O-Rate. Dadurch erhöht sich die für den Abschluss der Migration erforderliche Zeit und gleichzeitig verringert sich die I/O-Last für Host- und Speichersysteme.</block>
  <block id="28084a93e6570f55c3923991e269816e" category="section-title">Spiegel und Demirror</block>
  <block id="f5b05967100f74bb14ae26d5021ef4e3" category="paragraph">Einige Volume-Manager, wie AIX LVM, erlauben dem Benutzer, die Anzahl der Kopien für jedes Extent festzulegen und zu steuern, welche Geräte die einzelnen Kopien hosten. Zur Migration wird ein vorhandenes logisches Volume erstellt, die zugrunde liegenden Extents zu den neuen Volumes gespiegelt, auf eine Synchronisierung der Kopien gewartet und anschließend die alte Kopie verworfen. Wenn ein Back- Out-Pfad gewünscht wird, kann vor dem Zeitpunkt, an dem die Spiegelungskopie abgelegt wird, ein Snapshot der Originaldaten erstellt werden. Alternativ kann der Server kurz heruntergefahren werden, um die ursprünglichen LUNs zu maskieren, bevor die enthaltenen Spiegelkopien erzwungen gelöscht werden. Dabei wird eine wiederherstellbare Kopie der Daten am ursprünglichen Speicherort aufbewahrt.</block>
  <block id="7151373ff69a9fafa4a579b40282beeb" category="section-title">Extent-Migration</block>
  <block id="682ba6adb168511d03877bdbf940a0b7" category="paragraph">Fast alle Volume-Manager erlauben die Migration von Extents, und manchmal gibt es mehrere Optionen. Beispielsweise ermöglichen einige Volume Manager einem Administrator, die einzelnen Extents für ein bestimmtes logisches Volume von altem zu neuem Storage zu verschieben. Volume-Manager wie Linux LVM2 bieten die<block ref="8167c9a6bd495f7ed235364201039099" prefix=" " category="inline-code"></block> Befehl, der alle Extents auf dem angegebenen LUN-Gerät auf eine neue LUN verlagert. Nach der Evakuierung der alten LUN kann sie entfernt werden.</block>
  <block id="8c232bd157fb78062260d11e1ec3fc2c" category="admonition">Das primäre Risiko für den Betrieb ist das Entfernen alter, nicht genutzter LUNs aus der Konfiguration. Beim Ändern des FC-Zoning und beim Entfernen veralteter LUN-Geräte ist besonders darauf zu achten.</block>
  <block id="41175a8b2053bedbf868e340edf92f55" category="section-title">Oracle Automatic Storage Management</block>
  <block id="dce3f0c1b1c85aaee6448197054602d1" category="paragraph">Oracle ASM ist ein kombinierter logischer Volume-Manager und ein Dateisystem. Oracle ASM erstellt eine Sammlung von LUNs, unterteilt sie in kleine Zuweisungseinheiten und präsentiert sie als einzelnes Volume, das als ASM-Festplattengruppe bezeichnet wird. ASM bietet auch die Möglichkeit, die Laufwerksgruppe durch Festlegen des Redundanzniveaus zu spiegeln. Ein Volume kann nicht gespiegelt (externe Redundanz), gespiegelt (normale Redundanz) oder dreifach gespiegelt (hohe Redundanz) werden. Bei der Konfiguration der Redundanzstufe ist darauf zu achten, dass sie nach der Erstellung nicht mehr geändert werden kann.</block>
  <block id="d0ac5c14a6207835f733f4366345089d" category="paragraph">ASM bietet auch Dateisystemfunktionen. Obwohl das Dateisystem nicht direkt vom Host aus sichtbar ist, kann die Oracle-Datenbank Dateien und Verzeichnisse auf einer ASM-Datenträgergruppe erstellen, verschieben und löschen. Außerdem kann die Struktur mit dem Dienstprogramm asmcmd navigiert werden.</block>
  <block id="e72c9da30cbec4daedddc9b6e6fdf03b" category="paragraph">Wie bei anderen LVM-Implementierungen optimiert Oracle ASM die I/O-Performance durch Striping und Lastausgleich der I/O-Vorgänge jeder Datei über alle verfügbaren LUNs. Zweitens können die zugrunde liegenden Extents verschoben werden, um sowohl die Größenänderung der ASM-Datenträgergruppe als auch die Migration zu ermöglichen. Oracle ASM automatisiert den Prozess durch den Rebalancing-Vorgang. Neue LUNs werden einer ASM-Festplattengruppe hinzugefügt und alte LUNs werden verworfen. Dies führt zu einer Extent-Verschiebung und einem nachfolgenden Drop der evakuierten LUN aus der Festplattengruppe. Dieser Prozess ist eine der bewährtesten Migrationsmethoden, und die Zuverlässigkeit von ASM bei der Bereitstellung einer transparenten Migration ist möglicherweise das wichtigste Merkmal.</block>
  <block id="d4ad443888b51ec4e13912c45da68f76" category="admonition">Da die Spiegelungsebene von Oracle ASM fest festgelegt ist, kann sie nicht mit der Mirror- und Demirror-Methode der Migration verwendet werden.</block>
  <block id="048429277e643e20907317612c1f3318" category="section-title">Migration auf Storage-Ebene</block>
  <block id="623bb7ffbb3730716ea39b5086d26f18" category="paragraph">Bei der Migration auf Storage-Ebene wird die Migration sowohl unter der Applikations- als auch unter der Betriebssystemebene durchgeführt. In der Vergangenheit bedeutete dies manchmal, spezialisierte Geräte zu verwenden, auf denen LUNs auf Netzwerkebene kopiert werden konnten. Diese Funktionen finden sich jedoch jetzt nativ in ONTAP.</block>
  <block id="794cb725c5631ad99b5b7c000307f0df" category="section-title">SnapMirror</block>
  <block id="963ce762febea70d619f1fd5c114d85c" category="paragraph">Mit der Datenreplizierungssoftware NetApp SnapMirror erfolgt die Migration von Datenbanken zwischen NetApp Systemen nahezu universell. Der Prozess beinhaltet die Einrichtung einer Spiegelbeziehung für die zu migrierenden Volumes, um sie zu synchronisieren und dann auf das Umstellungsfenster zu warten. Wenn sie eintrifft, wird die Quelldatenbank heruntergefahren, eine letzte Aktualisierung der Spiegelung durchgeführt und die Spiegelung wird unterbrochen. Die Replikatvolumes können dann verwendet werden, indem entweder ein enthaltenes NFS-Dateisystem-Verzeichnis gemountet oder die enthaltenen LUNs ermittelt und die Datenbank gestartet wird.</block>
  <block id="1871452e5ea7e53152b5c874a12a890b" category="paragraph">Das Verschieben von Volumes innerhalb eines einzigen ONTAP Clusters gilt nicht als Migration, sondern als Routine<block ref="0fc2ecb8aa71bddc595fbc39f593496a" prefix=" " category="inline-code"></block> Betrieb. SnapMirror wird als Datenreplizierungs-Engine im Cluster eingesetzt. Dieser Prozess ist vollständig automatisiert. Es gibt keine weiteren Migrationsschritte, die durchgeführt werden müssen, wenn Attribute des Volume, wie z. B. LUN-Zuordnung oder NFS-Exportberechtigungen, mit dem Volume selbst verschoben werden. Die Standortverlagerung hat keine Unterbrechung des Host-Betriebs. In manchen Fällen muss der Netzwerkzugriff aktualisiert werden, um sicherzustellen, dass auf die neu verlagerten Daten so effizient wie möglich zugegriffen wird. Diese Aufgaben sind aber auch unterbrechungsfrei.</block>
  <block id="19fee3ea4b7f4472b5c1853122e8f47b" category="section-title">Import fremder LUNs (FLI)</block>
  <block id="a73cf458eed5aeff5c15aa5d70298cce" category="paragraph">FLI ist eine Funktion, mit der ein Data ONTAP-System mit 8.3 oder höher eine vorhandene LUN von einem anderen Storage-Array migrieren kann. Das Verfahren ist einfach: Das ONTAP-System ist auf das bestehende Speicher-Array abgegrenzt, als ob es sich um einen anderen SAN-Host handelt. Data ONTAP übernimmt dann die Kontrolle über die gewünschten Legacy-LUNs und migriert die zugrunde liegenden Daten. Außerdem kommen bei der Migration von Daten im Importprozess die Effizienzeinstellungen des neuen Volume zum Einsatz, sodass Daten während des Migrationsprozesses inline komprimiert und dedupliziert werden können.</block>
  <block id="0ee4b09881406835f151f103412a2f1e" category="paragraph">Die erste Implementierung von FLI in Data ONTAP 8.3 erlaubte nur Offline-Migration. Dies war ein extrem schneller Transfer, aber trotzdem bedeuteten die LUN-Daten, dass sie erst nach Abschluss der Migration verfügbar waren. Die Online-Migration wurde mit Data ONTAP 8.3 eingeführt. Diese Migration minimiert Unterbrechungen, da ONTAP während der Übertragung LUN-Daten bereitstellen kann. Während die Host-Zone neu aufgeteilt wird, um die LUNs über ONTAP zu verwenden, kommt es zu einer kurzen Unterbrechung. Sobald diese Änderungen jedoch vorgenommen werden, sind die Daten wieder verfügbar und bleiben während des gesamten Migrationsprozesses zugänglich.</block>
  <block id="19d95ee75467fc2f9a06d150cc99d944" category="paragraph">Lese-I/O wird über ONTAP als Proxy übertragen, bis der Kopiervorgang abgeschlossen ist, während Schreib-I/O synchron sowohl auf die fremde als auch auf die ONTAP-LUN geschrieben wird. Die beiden LUN-Kopien werden auf diese Weise synchron gehalten, bis der Administrator eine vollständige Umstellung ausführt, die die fremde LUN freigibt und Schreibvorgänge nicht mehr repliziert.</block>
  <block id="5caad387757ca99ada41709ce30a31a5" category="paragraph">FLI ist für den Einsatz mit FC konzipiert. Wenn jedoch ein Wechsel zu iSCSI gewünscht wird, kann die migrierte LUN nach Abschluss der Migration problemlos als iSCSI-LUN neu zugeordnet werden.</block>
  <block id="7fa6cfc683e0f5f9e3a79f6be14e23f4" category="paragraph">Zu den Merkmalen von FLI gehört die automatische Ausrichtungserkennung und -Einstellung. In diesem Kontext bezieht sich der Begriff „Alignment“ auf eine Partition auf einem LUN-Gerät. Für eine optimale Performance muss der I/O mit 4-KB-Blöcken abgestimmt werden. Wenn eine Partition auf einem Offset platziert wird, der kein Vielfaches von 4K ist, leidet die Performance.</block>
  <block id="7b4ef266729f1ddfbc724cad17af4efc" category="paragraph">Es gibt einen zweiten Aspekt der Ausrichtung, der nicht korrigiert werden kann, indem ein Partitionsoffset angepasst wird: Die Blockgröße des Dateisystems. Ein ZFS-Dateisystem beispielsweise hat in der Regel eine interne Blockgröße von 512 Byte. Andere Kunden, die AIX verwenden, haben gelegentlich jfs2-Dateisysteme mit einer 512- oder 1, 024-Byte-Blockgröße erstellt. Auch wenn das Filesystem an eine 4-KB-Grenze ausgerichtet ist, bleiben die in diesem Filesystem erstellten Dateien jedoch nicht und die Performance leidet.</block>
  <block id="1d6b28ed67b1d554df806b0b5a020711" category="paragraph">FLI sollte unter diesen Umständen nicht verwendet werden. Obwohl nach der Migration auf die Daten zugegriffen werden kann, ergeben sich daraus Filesysteme mit erheblichen Performance-Einschränkungen. Grundsätzlich sollte jedes Filesystem, das einen zufälligen Überschreibvorgang auf ONTAP unterstützt, eine 4-KB-Blockgröße verwenden. Dies gilt insbesondere für Workloads wie Datenbankdateien und VDI-Implementierungen. Die Blockgröße kann mit den entsprechenden Host-Betriebssystembefehlen identifiziert werden.</block>
  <block id="4941562ef813562e0d6aaef673158b99" category="paragraph">Auf AIX kann beispielsweise die Blockgröße mit angezeigt werden<block ref="10c9a985c983a826424b496a708263ec" prefix=" " category="inline-code"></block>. Mit Linux<block ref="ba5265473f00b27178098cc38d3aef24" prefix=" " category="inline-code"></block> Und<block ref="1f8a87190704df357c64a49aee936874" prefix=" " category="inline-code"></block> Kann für verwendet werden<block ref="310201b6353c5f38bc039e0e51b079d3" prefix=" " category="inline-code"></block> Und<block ref="5382133ffbecb9bce9d47f2e44327b16" prefix=" " category="inline-code"></block>. Mit<block ref="8cbc6ba7c8bba133ce2bc44780d88742" prefix=" " category="inline-code"></block>, Der Befehl lautet<block ref="1615297782a0dff59b20451e2ca97ea7" prefix=" " category="inline-code"></block>.</block>
  <block id="033a4cb04b5225e2b7cf966f2ce16598" category="paragraph">Der Parameter, der die Blockgröße steuert, ist<block ref="81df978a8e3da4bee74b135548f390f3" prefix=" " category="inline-code"></block> Und im Allgemeinen ist der Standardwert 9, was 2^9 oder 512 Byte bedeutet. Für eine optimale Leistung, die<block ref="81df978a8e3da4bee74b135548f390f3" prefix=" " category="inline-code"></block> Wert muss 12 (2^12=4K) sein. Dieser Wert wird zum Zeitpunkt der Erstellung des zpool gesetzt und kann nicht geändert werden, was bedeutet, dass Data zpools mit einem<block ref="81df978a8e3da4bee74b135548f390f3" prefix=" " category="inline-code"></block> Andere als 12 sollten durch Kopieren der Daten in einen neu erstellten zpool migriert werden.</block>
  <block id="8bd9661d8c8eb9924c62b8242191af4e" category="paragraph">Oracle ASM hat keine grundlegende Blockgröße. Die einzige Voraussetzung ist, dass die Partition, auf der die ASM-Festplatte erstellt wird, ordnungsgemäß ausgerichtet sein muss.</block>
  <block id="ea7f7e1e8119ee64585b6173afe720e8" category="section-title">7-Mode Transition Tool</block>
  <block id="75df51cc2f43b8dde951695f97b838c0" category="paragraph">Bei dem 7-Mode Transition Tool (7MTT) handelt es sich um ein Automatisierungstool zur Migration großer 7-Mode Konfigurationen zu ONTAP. Die meisten Datenbankkunden finden andere Methoden einfacher, zum Teil, da sie in der Regel ihre Umgebungen einer Datenbank nach Datenbank migrieren, anstatt den gesamten Storage-Platzbedarf zu verschieben. Zudem sind Datenbanken häufig nur ein Teil einer größeren Storage-Umgebung. Daher werden Datenbanken oft einzeln migriert und die restliche Umgebung kann mit 7MTT verschoben werden.</block>
  <block id="85fd7dcbc2206c27059ae7f88712154d" category="paragraph">Es gibt eine kleine aber beträchtliche Anzahl von Kunden, die Storage-Systeme haben, die komplizierten Datenbankumgebungen gewidmet sind. Diese Umgebungen können viele Volumes, Snapshots und zahlreiche Konfigurationsdetails wie Exportberechtigungen, LUN-Initiatorgruppen, Benutzerberechtigungen und die Konfiguration des Lightweight Directory Access Protocol enthalten. In diesen Fällen können die Automatisierungsfunktionen von 7MTT die Migration vereinfachen.</block>
  <block id="2c87fbdecbf0dfe299f9f89958d61085" category="paragraph">7MTT kann in einem der beiden Modi ausgeführt werden:</block>
  <block id="dc818e71a5519d1b99c7e996cf21fd74" category="list-text">*Copy- Based Transition (CBT).* 7MTT mit CBT richtet SnapMirror Volumes aus einem bestehenden 7-Mode System in der neuen Umgebung ein. Nachdem die Daten synchronisiert sind, orchestriert 7MTT den Umstellungsprozess.</block>
  <block id="453bbc96e365e25cc2d091dced3565a6" category="list-text">*Copy- Free Transition (CFT).* 7MTT mit CFT basiert auf der in-Place Konvertierung vorhandener 7-Mode Platten-Shelfs. Es werden keine Daten kopiert und die vorhandenen Festplatten-Shelfs können wieder verwendet werden. Die vorhandene Konfiguration für Datensicherung und Storage-Effizienz bleibt erhalten.</block>
  <block id="16262236c3981cb3310b9320b5a67fd0" category="paragraph">Der primäre Unterschied zwischen diesen beiden Optionen ist der Copy-Free Transition. Er ist ein „Big-Bang“-Ansatz, bei dem alle mit dem ursprünglichen 7-Mode HA-Paar verbundenen Platten-Shelfs in die neue Umgebung verschoben werden müssen. Eine Untergruppe von Shelfs lässt sich nicht verschieben. Durch den Copy-basierten Ansatz können ausgewählte Volumes verschoben werden. Es besteht auch die Möglichkeit, dass ein längeres Umstellungsfenster mit Copy-Free Transition möglich ist, da für die Neuerstellung von Festplatten-Shelfs und die Konvertierung von Metadaten eine Verbindung erforderlich ist. Je nach Praxiserfahrung empfiehlt NetApp, für die Verlagerung und Neuverkabelung von Festplatten-Shelfs eine Stunde und für die Metadatenkonvertierung zwischen 15 Minuten und 2 Stunden zu verwenden.</block>
  <block id="c8365c28332d425fd91f2de2e2c22dfb" category="summary">Vorbereiten von ONTAP für eine FLI-Migration</block>
  <block id="25c18537e56595b3e7f3ce78905917ba" category="doc">FLI Planning - Oracle</block>
  <block id="f1033948d9d2d14612d27f1808720f12" category="inline-link">TR-4380: SAN Migration using Foreign LUN Import</block>
  <block id="58fc59a248fefa86003ac1867e5bd279" category="paragraph">Die Verfahren zur Migration von SAN-Ressourcen mithilfe von FLI sind in NetApp dokumentiert<block ref="5abd855dd5d8332b78fa966ac34c0f22" category="inline-link-rx"></block>.</block>
  <block id="795bbfbd054829fad905065087ba2d5a" category="paragraph">Aus Sicht der Datenbank und des Hosts sind keine besonderen Schritte erforderlich. Nachdem die FC-Zonen aktualisiert wurden und die LUNs auf ONTAP verfügbar werden, sollte die LVM in der Lage sein, die LVM-Metadaten von den LUNs zu lesen. Außerdem sind die Volume-Gruppen ohne weitere Konfigurationsschritte einsatzbereit. In seltenen Fällen können Umgebungen Konfigurationsdateien enthalten, die hartcodiert waren und Verweise auf das vorherige Storage-Array enthalten. Zum Beispiel ein Linux-System, das enthalten<block ref="dd5ff67ba72768d33f75e645aa2b8e56" prefix=" " category="inline-code"></block> Regeln, die auf einen WWN eines bestimmten Geräts verwiesen haben, müssen aktualisiert werden, um die von FLI eingeführten Änderungen wiederzugeben.</block>
  <block id="9e7ddc2ddefcd6f202fb11a82a80bc7e" category="admonition">Informationen zu unterstützten Konfigurationen finden Sie in der NetApp Kompatibilitätsmatrix. Falls Ihr System nicht im Lieferumfang enthalten ist, wenden Sie sich an Ihren NetApp Ansprechpartner.</block>
  <block id="0f5b3758229b3e28c8605b6c42398115" category="paragraph">Dieses Beispiel zeigt die Migration von ASM- und LVM-LUNs, die auf einem Linux-Server gehostet werden. FLI wird auf anderen Betriebssystemen unterstützt, und obwohl die Host-seitigen Befehle unterschiedlich sein können, sind die Prinzipien identisch, und die ONTAP-Verfahren sind identisch.</block>
  <block id="f1036cd97e461d07351c9df32fc5948d" category="section-title">LVM-LUNs identifizieren</block>
  <block id="88f7413f9621a816ee3d370703168647" category="paragraph">Der erste Schritt zur Vorbereitung besteht darin, die zu migrierenden LUNs zu identifizieren. In dem hier gezeigten Beispiel werden zwei SAN-basierte Dateisysteme in gemountet<block ref="572f241ef88fdb17d16eba97133d861f" prefix=" " category="inline-code"></block> Und<block ref="d14bc7787c7396144583e99a7df52f67" prefix=" " category="inline-code"></block>.</block>
  <block id="ecad615a52fda392a9b7c1075d2cb2c5" category="paragraph">Der Name der Volume-Gruppe kann aus dem Gerätenamen extrahiert werden, der das Format (Name der Volume-Gruppe)-(Name des logischen Volumes) verwendet. In diesem Fall wird die Volume-Gruppe aufgerufen<block ref="bb97320b8c517da828eae4ec543113db" prefix=" " category="inline-code"></block>.</block>
  <block id="b08986bb1757d5ae8de06d523c71803d" category="paragraph">Der<block ref="f1e2c495108b111c930735e3a0f9a04e" prefix=" " category="inline-code"></block> Mit dem Befehl können Sie die LUNs identifizieren, die diese Volume-Gruppe unterstützen. In diesem Fall sind 10 LUNs vorhanden<block ref="bb97320b8c517da828eae4ec543113db" prefix=" " category="inline-code"></block> Volume-Gruppe.</block>
  <block id="8b47fac6803dfff2e8d2cdad6f297cfa" category="section-title">ASM-LUNs identifizieren</block>
  <block id="a23d0124954ecdbfe9d0f3aceb9e17a2" category="paragraph">ASM-LUNs müssen ebenfalls migriert werden. Um die Anzahl der LUNs und LUN-Pfade von sqlplus als sysasm-Benutzer zu erhalten, führen Sie den folgenden Befehl aus:</block>
  <block id="918841992da84786f00de7c4c7d83dbf" category="paragraph">Die aktuelle Umgebung enthält 20 zu migrierende LUNs. Aktualisieren Sie das aktuelle SAN, damit ONTAP auf die aktuellen LUNs zugreifen kann. Daten werden noch nicht migriert, aber ONTAP muss die Konfigurationsinformationen der aktuellen LUNs lesen, um das neue Zuhause für diese Daten zu erstellen.</block>
  <block id="5816768a5d83977f34ffa5025c14f430" category="paragraph">Mindestens ein HBA-Port auf dem All Flash FAS/FAS System muss als Initiator-Port konfiguriert sein. Zudem müssen die FC-Zonen aktualisiert werden, damit ONTAP auf die LUNs auf dem fremden Storage Array zugreifen können. Bei einigen Speicher-Arrays ist die LUN-Maskierung konfiguriert, wodurch WWNs auf eine bestimmte LUN zugreifen können. In diesen Fällen muss die LUN-Maskierung ebenfalls aktualisiert werden, um Zugriff auf die ONTAP-WWNs zu gewähren.</block>
  <block id="030a992b1340f67584d67ef6230e9adf" category="paragraph">Nach Abschluss dieses Schritts sollte ONTAP in der Lage sein, das fremde Speicher-Array mit dem anzuzeigen<block ref="d90ba20b63acab53952d68665c50ec47" prefix=" " category="inline-code"></block> Befehl. Das Schlüsselfeld, das zurückgegeben wird, ist das Präfix, das zur Identifizierung der fremden LUN auf dem System verwendet wird. Im folgenden Beispiel werden die LUNs auf dem Fremdarray angezeigt<block ref="25103eba8d70e82b5bd837be0d2f63c4" prefix=" " category="inline-code"></block> Wird in ONTAP mit dem Präfix von angezeigt<block ref="6b35470d99880c4630ed3ca7b4c842e7" prefix=" " category="inline-code"></block>.</block>
  <block id="c1a0f5174323df40a8b659eb65ac5155" category="section-title">Identifizierung von Fremdarrays</block>
  <block id="6c1b8919e2e706972b3ec48cb7f014ba" category="section-title">Identifizierung fremder LUNs</block>
  <block id="63841e312d3a8531331e35bd826268d1" category="paragraph">Die LUNs können durch Bestehen des aufgelistet werden<block ref="907702f5103a7823393b8dd296a75c26" prefix=" " category="inline-code"></block> Bis zum<block ref="242f4ce1948273386f8bb487bdd3732f" prefix=" " category="inline-code"></block> Befehl. Die zurückgegebenen Daten werden während des Migrationsvorgangs mehrfach referenziert.</block>
  <block id="e5e94f7e2098883f0d621e064b1104f4" category="section-title">Registrieren Sie LUNs für Fremdarrays als Importkandidaten</block>
  <block id="c968ec41c1c0c449b0263962966d8293" category="paragraph">Die ausländischen LUNs werden zunächst als jeder bestimmte LUN-Typ klassifiziert. Bevor Daten importiert werden können, müssen die LUNs als fremd gekennzeichnet werden und daher als Kandidat für den Importprozess. Um diesen Schritt abzuschließen, geben Sie die Seriennummer an den weiter<block ref="93c633f7fa188f1b27df574c0e5e929a" prefix=" " category="inline-code"></block> Wie im folgenden Beispiel gezeigt. Beachten Sie, dass bei diesem Prozess nur die LUN als fremd innerhalb von ONTAP markiert wird. Es werden keine Daten auf die fremde LUN selbst geschrieben.</block>
  <block id="33380a523841f23815f2f83c9de1a628" category="section-title">Erstellung von Volumes zum Hosten migrierter LUNs</block>
  <block id="2c2ba8ca6bdd77da1da981b91a3fae4a" category="paragraph">Ein Volume ist erforderlich, um die migrierten LUNs zu hosten. Die genaue Volume-Konfiguration hängt von der Planung der Nutzung von ONTAP Funktionen ab. In diesem Beispiel werden die ASM-LUNs in einem Volume platziert und die LVM-LUNs in einem zweiten Volume platziert. Auf diese Weise können Sie die LUNs als unabhängige Gruppen managen, beispielsweise für Tiering, die Erstellung von Snapshots oder die Einstellung von QoS-Kontrollen.</block>
  <block id="8bc7d64e68e4be8f4908effd57293a2a" category="paragraph">Stellen Sie die ein<block ref="fb983ebeedc63d8723c0d4aa558a4c02" prefix=" " category="inline-code"></block>. Der Migrationsprozess kann sehr viel Datenfluktuation beinhalten. Daher kann es zu einem starken Anstieg des Platzverbrauchs kommen, wenn Snapshots versehentlich erstellt werden, weil unerwünschte Daten in den Snapshots erfasst werden.</block>
  <block id="8c0675d07e44f55f1f5aa6d45abe0cdb" category="section-title">Erstellen Sie ONTAP-LUNs</block>
  <block id="0b799020dac78a5e12a3d1a6400fd0c8" category="paragraph">Nach der Erstellung der Volumes müssen die neuen LUNs erstellt werden. Normalerweise erfordert die Erstellung einer LUN, dass der Benutzer Informationen wie die LUN-Größe angeben muss. In diesem Fall wird jedoch das Argument für eine fremde Festplatte an den Befehl übergeben. Infolgedessen repliziert ONTAP die aktuellen LUN-Konfigurationsdaten von der angegebenen Seriennummer. Außerdem werden die LUN-Geometrie und Partitionstabellen-Daten verwendet, um die LUN-Ausrichtung anzupassen und eine optimale Performance herzustellen.</block>
  <block id="5272a1dc3854f1eddc353c8073234e03" category="paragraph">In diesem Schritt müssen die Seriennummern mit dem Fremdarray verglichen werden, um sicherzustellen, dass die richtige fremde LUN mit der richtigen neuen LUN abgeglichen wird.</block>
  <block id="f6ee70ec9fce7bd34fa5a33d8969fb5e" category="section-title">Erstellen Sie Importbeziehungen</block>
  <block id="94700a911b95416221efe4064acbc2ba" category="paragraph">Die LUNs wurden jetzt erstellt, sind aber nicht als Replikationsziel konfiguriert. Bevor dieser Schritt durchgeführt werden kann, müssen die LUNs zunächst in den Offline-Modus versetzt werden. Dieser zusätzliche Schritt dient dem Schutz von Daten vor Benutzerfehlern. Wenn ONTAP die Durchführung einer Migration auf einer Online-LUN zulässt, besteht das Risiko, dass durch einen typografischen Fehler aktive Daten überschrieben werden. Durch den zusätzlichen Schritt, den Benutzer zum ersten Mal offline zu schalten, wird überprüft, ob die richtige Ziel-LUN als Migrationsziel verwendet wird.</block>
  <block id="85255e52054af9c6ffd3c4e79c723a34" category="paragraph">Nachdem die LUNs offline sind, können Sie die Importbeziehung wiederherstellen, indem Sie die Seriennummer der fremden LUN an den übergeben<block ref="04c2f87857699971f5aedd525e65690a" prefix=" " category="inline-code"></block> Befehl.</block>
  <block id="8e3c921431d2b7f66fa0cc85f3ae5c9d" category="paragraph">Nachdem alle Importbeziehungen eingerichtet sind, können die LUNs wieder online geschaltet werden.</block>
  <block id="ea382cbfdb353cee0cf25eaae9bba150" category="section-title">Erstellen einer Initiatorgruppe</block>
  <block id="152c4728a5fb152525a639439b9d7cb9" category="inline-link-macro">Protokollkonvertierung</block>
  <block id="2ba97db75ee4a901edea96edf3d2ddaa" category="paragraph">Eine Initiatorgruppe (Initiatorgruppe) ist Teil der ONTAP LUN-Masking-Architektur. Auf eine neu erstellte LUN kann nur dann zugegriffen werden, wenn einem Host der erste Zugriff gewährt wurde. Dazu wird eine Initiatorgruppe erstellt, die entweder die FC-WWNs oder iSCSI-Initiatornamen auflistet, denen Zugriff gewährt werden soll. Zum Zeitpunkt der Erstellung dieses Berichts wurde FLI nur für FC LUNs unterstützt. Die Konvertierung in iSCSI nach der Migration ist jedoch eine einfache Aufgabe, wie in dargestellt <block ref="4f9fd7f3e31161eaca60ca6de385a92c" category="inline-link-macro-rx"></block>.</block>
  <block id="298a1c3c736859f2cfa3cb8eb1f3fdcc" category="paragraph">In diesem Beispiel wird eine Initiatorgruppe erstellt, die zwei WWNs enthält, die den beiden auf dem HBA des Hosts verfügbaren Ports entsprechen.</block>
  <block id="4f6f03762bfcdc7174cdd30240ce45b3" category="section-title">Ordnen Sie neue LUNs dem Host zu</block>
  <block id="c22fee2d07a149be91ae1ae2ada1cb57" category="paragraph">Nach der Erstellung der Initiatorgruppe werden die LUNs dann der definierten Initiatorgruppe zugeordnet. Diese LUNs sind nur für die WWNs dieser Initiatorgruppe verfügbar. NetApp geht in dieser Phase des Migrationsprozesses davon aus, dass der Host nicht auf ONTAP abgegrenzt wurde. Dies ist wichtig, denn wenn der Host gleichzeitig auf das fremde Array und das neue ONTAP-System begrenzt ist, besteht das Risiko, dass LUNs mit derselben Seriennummer auf jedem Array erkannt werden können. Diese Situation kann zu Fehlfunktionen des Multipfad-Funktionszubers oder zu Schäden an Daten führen.</block>
  <block id="ecca392290c36269e0489c0b1cf36f50" category="summary">Beispielskripts für die Automatisierung von Oracle-Migrationsvorgängen</block>
  <block id="fc53c036602508ed6c2afc18e2fbdf51" category="doc">Beispielskripts</block>
  <block id="6f78af00b87bcad5d08c95c7b6066ad0" category="paragraph">Die vorgestellten Skripte werden als Beispiele für das Skript verschiedener Betriebssystem- und Datenbankaufgaben bereitgestellt. Sie werden wie sie sind geliefert. Wenn für eine bestimmte Vorgehensweise Support erforderlich ist, wenden Sie sich an NetApp oder einen NetApp Reseller.</block>
  <block id="3146889e40b3ca2b78c56a19178bff84" category="section-title">Datenbank wird heruntergefahren</block>
  <block id="5b98b9877c0c74dc3a3daf46cf943d3f" category="paragraph">Das folgende Perl-Skript nimmt ein einziges Argument der Oracle SID und fährt eine Datenbank herunter. Sie kann als Oracle-Benutzer oder als root ausgeführt werden.</block>
  <block id="7df41a3619af59182fb5df6d1920d11a" category="section-title">Starten der Datenbank</block>
  <block id="57249fb9cdac8ddc9ea8843636c4e088" category="section-title">Konvertieren Sie das Dateisystem in schreibgeschützt</block>
  <block id="f2977a22ba44544ca8921e2d75bce435" category="paragraph">Das folgende Skript nimmt ein Dateisystemargument an und versucht, es als schreibgeschützt zu entfernen und wieder zu mounten. Dies ist bei Migrationsprozessen sinnvoll, bei denen ein Dateisystem für die Datenreplikation verfügbar gehalten werden muss und dennoch vor versehentlichen Schäden geschützt werden muss.</block>
  <block id="4eac395595a8d266839db0b88fae31e4" category="section-title">Ersetzen Sie das Dateisystem</block>
  <block id="988d7030a130298e1641007b5b0aae20" category="paragraph">Das folgende Skriptbeispiel wird verwendet, um ein Dateisystem durch ein anderes zu ersetzen. Da die Datei `/etc/fstab `bearbeitet wird, muss sie als root ausgeführt werden. Es akzeptiert ein einzelnes kommagetrenntes Argument des alten und des neuen Dateisystems.</block>
  <block id="149c75d086adf78a50a16bcb5e349158" category="list-text">Führen Sie zum Ersetzen des Dateisystems das folgende Skript aus:</block>
  <block id="67a4c588434c781febb12c165c3e860a" category="paragraph">Nehmen Sie als Beispiel für die Verwendung dieses Skripts an, dass die Daten in enthalten sind<block ref="f006bf17b06c884c47190c4225d3215a" prefix=" " category="inline-code"></block> Wird auf migriert<block ref="27df80f143a5812bda1553d09c712efc" prefix=" " category="inline-code"></block> Und<block ref="0e62afc91abe157ef67895cca0a7f912" prefix=" " category="inline-code"></block> Wird auf migriert<block ref="1c988fc7a325635f00f9b55992128a08" prefix=" " category="inline-code"></block>. Eine der einfachsten Methoden, um diese Aufgabe durchzuführen, besteht darin, das neue Gerät mit einem einfachen Dateikopiervorgang wieder in den ursprünglichen Bereitstellungspunkt zu verschieben.</block>
  <block id="4a3d90c30a5e921650fe8ad0decf4827" category="list-text">Gehen Sie davon aus, dass die alten und die neuen Dateisysteme im vorhanden sind<block ref="816a3ef77b62ade41c3f936c958aa555" prefix=" " category="inline-code"></block> Datei wie folgt:</block>
  <block id="4588a4e3d2f8d0f7c036f59c1be2163f" category="list-text">Wenn dieses Skript ausgeführt wird, wird das aktuelle Dateisystem abgehängt und durch das neue ersetzt:</block>
  <block id="2d808cb44231d0a80164567e7220fc44" category="list-text">Das Skript aktualisiert auch die<block ref="816a3ef77b62ade41c3f936c958aa555" prefix=" " category="inline-code"></block> Entsprechende Datei erstellen. Im hier gezeigten Beispiel sind folgende Änderungen enthalten:</block>
  <block id="840967a448e36b9efeaacf7673f825aa" category="section-title">Automatisierte Datenbankmigration</block>
  <block id="1107dd36fe8ba0c18ea8abc8734986e2" category="paragraph">Dieses Beispiel zeigt, wie Skripts zum Herunterfahren, Starten und Ersetzen von Dateisystemen genutzt werden können, um eine Migration vollständig zu automatisieren.</block>
  <block id="36881541e7d9c7bced65fcac337ac327" category="section-title">Dateispeicherorte anzeigen</block>
  <block id="1e9a1acc40d4943a73e6865cdebaf560" category="paragraph">Dieses Skript sammelt eine Reihe wichtiger Datenbankparameter und druckt sie in einem leicht lesbaren Format aus. Dieses Skript kann bei der Überprüfung von Datenlayouts nützlich sein. Darüber hinaus kann das Skript für andere Zwecke geändert werden.</block>
  <block id="6172b49b7fdf806b59af0aeef8de71e3" category="section-title">Bereinigung der ASM-Migration</block>
  <block id="dd8d75d6766af495b5442e67eb27d387" category="section-title">Namenskonvertierung von ASM in Dateisystem</block>
  <block id="abc3fc91423668bb4bd49e6e837fa3e4" category="section-title">Wiedergabe von Protokollen in der Datenbank</block>
  <block id="cc7b9a518bb2532f61662a9893248133" category="paragraph">Dieses Skript akzeptiert ein einzelnes Argument einer Oracle SID für eine Datenbank, die sich im Mount-Modus befindet, und versucht, alle derzeit verfügbaren Archivprotokolle wiederzugeben.</block>
  <block id="2a5bd3a209a1ed33b81c5306780227ce" category="section-title">Wiedergabe von Protokollen in der Standby-Datenbank</block>
  <block id="ea7bebed0b4151a9b28acbde55fc0eb3" category="paragraph">Dieses Skript ist identisch mit dem vorhergehenden Skript, außer dass es für eine Standby-Datenbank konzipiert ist.</block>
  <block id="109be8945d38cda6c034a22373bdbd3b" category="summary">Ändern des SAN-Protokolls nach der FLI-Migration</block>
  <block id="b5e65fbdff41aa940dad918d9f7c0b9e" category="doc">FLI-Protokollkonvertierung - Oracle</block>
  <block id="2adcfd589637337984e39e94dd14ae33" category="paragraph">Das Ändern des Protokolls für den Zugriff auf eine LUN ist eine gängige Anforderung.</block>
  <block id="38fe6838f11a6023172d11d806adbfcf" category="paragraph">In einigen Fällen ist die Migration der Daten in die Cloud Teil einer Gesamtstrategie. TCP/IP ist das Protokoll der Cloud, und der Wechsel von FC zu iSCSI ermöglicht eine einfachere Migration in verschiedene Cloud-Umgebungen. In anderen Fällen kann iSCSI wünschenswert sein, die gesunkenen Kosten eines IP SAN zu nutzen. Gelegentlich kann eine Migration ein anderes Protokoll als temporäre Maßnahme verwenden. Wenn beispielsweise ein fremdes Array und ONTAP-basierte LUNs nicht auf denselben HBAs koexistieren können, können Sie iSCSI-LUNs verwenden, die lang genug sind, um Daten vom alten Array zu kopieren. Nachdem die alten LUNs aus dem System entfernt wurden, können Sie sie wieder zu FC konvertieren.</block>
  <block id="832c81bd0db3ad98a3804ff5ce996a58" category="paragraph">Das folgende Verfahren zeigt die Konvertierung von FC zu iSCSI, jedoch gelten die allgemeinen Prinzipien für eine umgekehrte iSCSI- zu FC-Konvertierung.</block>
  <block id="e21180783b17ea695cf9275fce8a0bc7" category="section-title">Installieren Sie den iSCSI-Initiator</block>
  <block id="0e1ddcc32a3ef636c9ca084a3d7706f5" category="paragraph">Die meisten Betriebssysteme enthalten standardmäßig einen Software-iSCSI-Initiator, aber wenn dieser nicht enthalten ist, kann er problemlos installiert werden.</block>
  <block id="289fe013df899f5f74fb362d4efcdd5d" category="section-title">Identifizieren Sie den iSCSI-Initiatornamen</block>
  <block id="8242e97b190184a6c7b8ec96c5662886" category="paragraph">Während der Installation wird ein eindeutiger iSCSI-Initiatorname generiert. Unter Linux befindet sie sich im<block ref="22565a44e8f73044eb2029acbb069639" prefix=" " category="inline-code"></block> Datei: Dieser Name dient zur Identifizierung des Hosts auf dem IP-SAN.</block>
  <block id="721a96eb0b922b337fa815839839b328" category="section-title">Erstellen Sie eine neue Initiatorgruppe</block>
  <block id="cda1311d977b7b77ad3aebe4a813b3bd" category="paragraph">Eine Initiatorgruppe (Initiatorgruppe) ist Teil der ONTAP LUN-Masking-Architektur. Auf eine neu erstellte LUN kann nur dann zugegriffen werden, wenn einem Host der erste Zugriff gewährt wurde. Hierzu wird eine Initiatorgruppe erstellt, die entweder die FC-WWNs oder die iSCSI-Initiatornamen enthält, die Zugriff erfordern.</block>
  <block id="6548788f050643897f7354b6df4488db" category="paragraph">In diesem Beispiel wird eine Initiatorgruppe erstellt, die den iSCSI-Initiator des Linux Hosts enthält.</block>
  <block id="da8490d81c1ef6b559b09c2ab94631d2" category="section-title">Fahren Sie die Umgebung herunter</block>
  <block id="0bf211160ad57fedca3499176f213b11" category="paragraph">Vor dem Ändern des LUN-Protokolls müssen die LUNs vollständig stillgelegt werden. Jede Datenbank auf einer der zu konvertierenden LUNs muss heruntergefahren, die File-Systeme deaktiviert und die Volume-Gruppen deaktiviert werden. Wenn ASM verwendet wird, stellen Sie sicher, dass die ASM-Laufwerksgruppe getrennt ist und fahren Sie alle Netzdienste herunter.</block>
  <block id="2ba1c509ee5f5e31f05b24aed2d23054" category="section-title">LUN-Zuordnungen zum FC-Netzwerk aufheben</block>
  <block id="2f9e42c479a76dd54d7946c181049dd4" category="paragraph">Nachdem die LUNs vollständig stillgelegt sind, entfernen Sie die Zuordnungen von der ursprünglichen FC-Initiatorgruppe.</block>
  <block id="5f889f52ef85be290c3e5c0211bbb8fa" category="section-title">LUN-Zuordnung zum IP-Netzwerk neu</block>
  <block id="4ac84701530b31d8d33d9aa742715d25" category="paragraph">Gewähren Sie der neuen iSCSI-basierten Initiatorgruppe Zugriff auf jede LUN.</block>
  <block id="3d59eaa280c8b75d8e997eac2cf5b3e6" category="section-title">ISCSI-Ziele erkennen</block>
  <block id="981b782c3eacf8b87d8231b887873f03" category="paragraph">Die iSCSI-Erkennung besteht aus zwei Phasen. Zum einen werden die Ziele ermittelt. Dies ist nicht dasselbe wie beim Erkennen einer LUN. Der<block ref="f88921f58beaaae5bcb9dffac54bf5ad" prefix=" " category="inline-code"></block> Der unten abgebildete Befehl prüft die vom angegebene Portalgruppe<block ref="24e12535882a30ad33a21d76d76bd0ff" prefix=" " category="inline-code"></block> Und speichert eine Liste aller IP-Adressen und Ports, die iSCSI-Dienste anbieten. In diesem Fall gibt es vier IP-Adressen, die iSCSI-Dienste auf dem Standardport 3260 haben.</block>
  <block id="0ab5dd035c7f92f4dce1026744c01604" category="admonition">Dieser Befehl kann mehrere Minuten dauern, wenn eine der Ziel-IP-Adressen nicht erreicht werden kann.</block>
  <block id="1dba8f39914c5f44e3cb635e7ac7563e" category="section-title">ISCSI-LUNs erkennen</block>
  <block id="68307bef4b9dc4071d875a0c2aadd321" category="paragraph">Nachdem die iSCSI-Ziele erkannt wurden, starten Sie den iSCSI-Dienst neu, um die verfügbaren iSCSI-LUNs zu ermitteln und zugehörige Geräte wie Multipath- oder ASMlib-Geräte zu erstellen.</block>
  <block id="25d811252f87ae85dda97f2ab9dd1f3a" category="section-title">Starten Sie die Umgebung neu</block>
  <block id="8a9aae851d31dae8baf96171f114955e" category="paragraph">Starten Sie die Umgebung neu, indem Sie Volume-Gruppen erneut aktivieren, Dateisysteme neu mounten, RAC-Dienste neu starten usw. Als Vorsichtsmaßnahme empfiehlt NetApp, den Server nach Abschluss des Konvertierungsprozesses neu zu starten, um sicherzustellen, dass alle Konfigurationsdateien korrekt sind und alle veralteten Geräte entfernt werden.</block>
  <block id="00f4c8378b0bf837cee4b0aed8886f31" category="paragraph">Achtung: Bevor Sie einen Host neu starten, stellen Sie sicher, dass alle Einträge in sind<block ref="816a3ef77b62ade41c3f936c958aa555" prefix=" " category="inline-code"></block> Diese Referenz migrierte SAN-Ressourcen werden kommentiert. Wenn dieser Schritt nicht durchgeführt wird und Probleme mit dem LUN-Zugriff auftreten, kann es zu einem Betriebssystem kommen, das nicht gebootet wird. Dieses Problem beschädigt die Daten nicht. Es kann jedoch sehr unbequem sein, in den Rettungsmodus oder einen ähnlichen Modus zu starten und zu korrigieren<block ref="816a3ef77b62ade41c3f936c958aa555" prefix=" " category="inline-code"></block> Damit das Betriebssystem gestartet werden kann, um die Fehlerbehebung zu ermöglichen.</block>
  <block id="7e712b6bec5dd0821f1822121da9f0c6" category="summary">Oracle Performance-Management mit QoS</block>
  <block id="ff8b87ff7571fb54e71c9589f1b886a3" category="doc">Quality of Service mit Oracle-Datenbanken</block>
  <block id="08e3cfb3c3dfa08d34bcbbfe07fe5f28" category="paragraph">Für die sichere und effiziente Verwaltung mehrerer Oracle Datenbanken ist eine effektive QoS-Strategie erforderlich. Der Grund dafür sind die stetig wachsenden Performance-Möglichkeiten eines modernen Storage-Systems.</block>
  <block id="3408fe4b6e4b2ed9366356f08e3b9ab0" category="summary">Oracle Datenbanken und Storage-Effizienz</block>
  <block id="151654fbc652cca26707bd7a060073d3" category="doc">Oracle Database und ONTAP-Effizienzfunktionen</block>
  <block id="4564218d346b0ef8263512ebe659337d" category="paragraph">Die Funktionen zur Steigerung der Speicherplatzeffizienz von ONTAP sind für Oracle Datenbanken optimiert. In fast allen Fällen besteht der beste Ansatz darin, die Standardeinstellungen bei aktivierten Effizienzfunktionen zu belassen.</block>
  <block id="794c6d3bb54da92d9a4a4022bc5c4e94" category="summary">RAID und Oracle Datenbanken</block>
  <block id="ead1ce56c368cc12c4f8932e01c92f65" category="doc">Oracle RAID-Anforderungen</block>
  <block id="e959fe6bb794f67f31a0d4e6bc5d5bf4" category="paragraph">RAID bezieht sich auf den Einsatz von Redundanz, um Daten vor dem Verlust eines Laufwerks zu schützen.</block>
  <block id="b60b0e7c75501fe2f322675f2e6da6d7" category="paragraph">Gelegentlich stellen sich Fragen zu RAID-Levels bei der Konfiguration von NetApp-Speicher, der für Oracle-Datenbanken und andere Enterprise-Applikationen verwendet wird. Viele, von Oracle bewährte Verfahren zur Storage Array-Konfiguration enthalten Warnungen über die Verwendung von RAID-Spiegelung und/oder Vermeidung bestimmter Arten von RAID. Obwohl in ihnen gültige Punkte aufgeführt sind, gelten diese Quellen nicht für RAID 4 und die in ONTAP verwendeten NetApp RAID DP und RAID-TEC Technologien.</block>
  <block id="6de6bcceac7c1a53ecb774d42b8d5c9a" category="summary">Oracle und ONTAP Thin Provisioning</block>
  <block id="e04c5c8668870edf8392b07169f96644" category="doc">Thin Provisioning mit Oracle</block>
  <block id="26c71bfc140fc9f2d56f83f7aedffd53" category="paragraph">Thin Provisioning für eine Oracle-Datenbank erfordert eine sorgfältige Planung, da im Ergebnis mehr Speicherplatz auf einem Storage-System konfiguriert wird, als unbedingt physisch verfügbar ist. Dieser Aufwand lohnt sich wirklich, denn bei korrekter Umsetzung ergeben sich erhebliche Kosteneinsparungen und Verbesserungen beim Management.</block>
  <block id="c9a6446e7a1a2aa2d3d06c76b3dd02ae" category="summary">SVM-Bereitstellung für Oracle-Datenbanken</block>
  <block id="eaa6380760494a867d1be23523aaba3e" category="doc">Oracle-Datenbanken und Storage Virtual Machines</block>
  <block id="ffa2dec61afa63c15c9906328e62e2e8" category="paragraph">Das Storage-Management für Oracle Datenbanken wird auf einer Storage Virtual Machine (SVM) zentralisiert.</block>
  <block id="ba0fd7b6bfa61ad7f7ad5326a0934d01" category="summary">Kenntnisse über Storage-Takeover- und Switchover-Funktionen sind erforderlich, damit Oracle Datenbankvorgänge nicht durch diese Vorgänge unterbrochen werden. Darüber hinaus können die Argumente für Takeover- und Switchover-Vorgänge die Datenintegrität beeinträchtigen, wenn sie falsch verwendet werden.</block>
  <block id="75f921b4326183319e82bc907e80cc42" category="doc">Failover/Switchover für Oracle und ONTAP-Controller</block>
  <block id="999548558d2844d78a3b5f9186c231a4" category="summary">Datenbanken und ONTAP Storage-Kapazität und freien Speicherplatz</block>
  <block id="3736e7d9912dca1541f3d86788010d1d" category="doc">Oracle und Storage-Kapazitätsmanagement</block>
  <block id="360612d74cdd78953036946ec943f795" category="paragraph">Für das Management von Datenbanken oder anderen Enterprise-Applikationen mit vorhersehbarem, leicht verwaltbarem, hochperformantem Enterprise-Storage ist auf den Laufwerken freier Speicherplatz für das Daten- und Metadaten-Management erforderlich. Die Menge des freien Speicherplatzes hängt vom Typ des verwendeten Laufwerks und von den Geschäftsprozessen ab.</block>
  <block id="655dc175973dc3d055e6e798ce1399a6" category="summary">Oracle Multiblock Read-Parameter</block>
  <block id="d3cc759510a3aba837fc8efeb2e24b91" category="doc">db_File_Multiblock_read_count</block>
  <block id="32faf0a922da10425f2be9f86a5f5e18" category="paragraph">Der<block ref="d3cc759510a3aba837fc8efeb2e24b91" prefix=" " category="inline-code"></block> Der Parameter steuert die maximale Anzahl von Oracle-Datenbankblöcken, die Oracle während sequenzieller I/O-Vorgänge als Einzelvorgang liest</block>
  <block id="36cb03af3dc688208e0e94fda31ca7a4" category="paragraph">Dieser Parameter wirkt sich jedoch weder auf die Anzahl der Blöcke aus, die Oracle während aller Lesevorgänge liest, noch auf zufälligen I/O. Nur die Blockgröße sequenzieller I/O ist betroffen.</block>
  <block id="2565c992b3732464484104f4c846d9b4" category="paragraph">Oracle empfiehlt dem Benutzer, diesen Parameter nicht festzulegen. Dadurch kann die Datenbanksoftware automatisch den optimalen Wert einstellen. Das bedeutet im Allgemeinen, dass dieser Parameter auf einen Wert gesetzt wird, der eine I/O-Größe von 1 MB ergibt. Zum Beispiel würde ein Lesevorgang von 1 MB mit 8-KB-Blöcken 128 Blöcke erfordern, und der Standardwert für diesen Parameter wäre daher 128.</block>
  <block id="0fd26e725a6c1a81508e013094776e2c" category="paragraph">Bei den meisten von NetApp an Kundenstandorten festgestellten Performance-Problemen bei Datenbanken handelt es sich um eine falsche Einstellung für diesen Parameter. Es gab triftige Gründe, diesen Wert mit den Oracle-Versionen 8 und 9 zu ändern. Daher kann der Parameter in vorhanden sein, ohne dass dies bekannt ist<block ref="b6bd7c570605affc5b50bbd3e436f0c0" prefix=" " category="inline-code"></block> Dateien, da die Datenbank auf Oracle 10 und höher aktualisiert wurde. Eine ältere Einstellung von 8 oder 16 beeinträchtigt im Vergleich zu einem Standardwert von 128 erheblich die sequenzielle I/O-Performance.</block>
  <block id="3f594bb922365c7a9f095f44822fa22e" category="admonition">*NetApp empfiehlt* die Einstellung<block ref="d3cc759510a3aba837fc8efeb2e24b91" prefix=" " category="inline-code"></block> Der Parameter darf nicht im vorhanden sein<block ref="b6bd7c570605affc5b50bbd3e436f0c0" prefix=" " category="inline-code"></block> Datei: NetApp hat noch nie eine Situation erlebt, in der sich durch die Änderung dieses Parameters die Performance verbesserte. In vielen Fällen wurde jedoch der sequenzielle I/O-Durchsatz deutlich beeinträchtigt.</block>
  <block id="669ebbf33c0b19005e2ccaf02ba69e5f" category="summary">Oracle RAC-Einstellungen mit Networked Storage</block>
  <block id="5c87e825763ec1e41a459f6baa4b2a44" category="doc">Oracle Real Application Clusters (RAC)</block>
  <block id="0eec903bb9d87349e379892ca99ef9ec" category="paragraph">Oracle RAC ist ein Clusterware-Produkt mit verschiedenen Arten von internen Heartbeat-Prozessen, die den Zustand des Clusters überwachen.</block>
  <block id="7c13d022c9fda6e792c4349a043a6c74" category="inline-link-macro">Fehlzählung</block>
  <block id="bab4ae46619fcbbb84e3375ef205e61c" category="admonition">Die Informationen im <block ref="9cd17d807316d35ef47b12cbecab4ec8" category="inline-link-macro-rx"></block> Der Abschnitt enthält wichtige Informationen für Oracle RAC-Umgebungen, die Netzwerkspeicher verwenden. In vielen Fällen müssen die standardmäßigen Oracle RAC-Einstellungen geändert werden, um sicherzustellen, dass der RAC-Cluster Netzwerkpfadänderungen und Speicher-Failover-/Switchover-Vorgänge überlebt.</block>
  <block id="0494651671c3dc7f1ccdf99a4368a2cf" category="section-title">Festplatten-Timeout</block>
  <block id="1973cfff3b7c6d828ede9d420b8481b5" category="paragraph">Der primäre speicherbezogene RAC-Parameter lautet<block ref="0494651671c3dc7f1ccdf99a4368a2cf" prefix=" " category="inline-code"></block>. Dieser Parameter steuert den Schwellenwert, innerhalb dessen die Abstimmungsdatei E/A abgeschlossen werden muss. Wenn der<block ref="0494651671c3dc7f1ccdf99a4368a2cf" prefix=" " category="inline-code"></block> Parameter überschritten wird, dann wird der RAC-Knoten aus dem Cluster entfernt. Der Standardwert für diesen Parameter ist 200. Dieser Wert sollte für standardmäßige Storage-Takeover- und Giveback-Verfahren ausreichen.</block>
  <block id="4aa33fc988e36b9531d36da80d35ec2f" category="paragraph">NetApp empfiehlt, die RAC-Konfigurationen vor ihrer Inbetriebnahme sorgfältig zu testen, da sich viele Faktoren auf einen Takeover oder Giveback auswirken. Neben der Zeit, die für den Abschluss des Storage-Failovers benötigt wird, ist auch für die Verbreitung der Änderungen des Link Aggregation Control Protocol (LACP) zusätzliche Zeit erforderlich. Darüber hinaus muss die SAN-Multipathing-Software eine I/O-Zeitüberschreitung erkennen und einen alternativen Pfad erneut versuchen. Wenn eine Datenbank extrem aktiv ist, muss eine große Menge an I/O-Vorgängen in die Warteschlange gestellt und erneut versucht werden, bevor die Abstimmungs-E/A-Vorgänge verarbeitet werden.</block>
  <block id="655a10764a0781d26dca3bfb939457b7" category="paragraph">Wenn ein tatsächlicher Storage Takeover oder Giveback nicht möglich ist, kann der Effekt durch Cable Pull-Tests auf dem Datenbankserver simuliert werden.</block>
  <block id="b2a9e8dd67b2d9a7333cb2c2495c2aa5" category="list-text">Verlassen des<block ref="0494651671c3dc7f1ccdf99a4368a2cf" prefix=" " category="inline-code"></block> Parameter mit dem Standardwert 200.</block>
  <block id="971a52f4b805c654dd133cf142457c53" category="list-text">Testen Sie eine RAC-Konfiguration immer gründlich.</block>
  <block id="cd7a91511dbfbe5c79de12fa7d394dc0" category="paragraph">Der<block ref="7c13d022c9fda6e792c4349a043a6c74" prefix=" " category="inline-code"></block> Der Parameter wirkt sich normalerweise nur auf den Netzwerk-Heartbeat zwischen RAC-Knoten aus. Die Standardeinstellung ist 30 Sekunden. Wenn sich die Grid-Binärdateien auf einem Storage Array befinden oder das Boot-Laufwerk des Betriebssystems nicht lokal ist, kann dieser Parameter wichtig werden. Dazu gehören Hosts mit Boot-Laufwerken in einem FC-SAN, über NFS gestartete Betriebssysteme und Boot-Laufwerke in Virtualisierungs-Datastores, beispielsweise eine VMDK-Datei.</block>
  <block id="9c1fd24d7d8e04847dadb944a6643121" category="paragraph">Wird der Zugriff auf ein Boot-Laufwerk durch eine Storage-Übernahme oder -Rückgabe unterbrochen, kann es sein, dass der Binärstandort des Grid oder das gesamte Betriebssystem vorübergehend nicht verfügbar ist. Die Zeit, die ONTAP bis zum Abschluss des Storage-Vorgangs und zum Ändern von Pfaden und zum Fortsetzen der I/O benötigt, kann größer sein als die<block ref="7c13d022c9fda6e792c4349a043a6c74" prefix=" " category="inline-code"></block> Schwellenwert. Infolgedessen wird ein Node sofort entfernt, nachdem die Verbindung zur Boot-LUN oder zu den Grid-Binärdateien wiederhergestellt wurde. In den meisten Fällen werden Entfernung und anschließende Neustarts ohne Protokollmeldungen durchgeführt, um den Grund für das Neubooten zu geben. Da nicht alle Konfigurationen betroffen sind, sollten Sie jeden SAN-Booting, NFS-Booting oder Datastore-basierten Host in einer RAC-Umgebung testen, damit RAC stabil bleibt, wenn die Kommunikation zum Startlaufwerk unterbrochen wird.</block>
  <block id="2b875dbca82565f3d7e2fa51633bc2c9" category="paragraph">Bei nicht-lokalen Startlaufwerken oder einem nicht lokalen Dateisystem, das hostet<block ref="ff4a008470319a22d9cf3d14af485977" prefix=" " category="inline-code"></block> Binärdateien, die<block ref="7c13d022c9fda6e792c4349a043a6c74" prefix=" " category="inline-code"></block> Muss entsprechend geändert werden<block ref="0494651671c3dc7f1ccdf99a4368a2cf" prefix=" " category="inline-code"></block>. Wenn dieser Parameter geändert wird, führen Sie weitere Tests durch, um auch alle Auswirkungen auf das RAC-Verhalten zu identifizieren, z. B. die Node-Failover-Zeit.</block>
  <block id="08d7a86ed9292993deaa28bee18d5ce5" category="list-text">Verlassen Sie den<block ref="7c13d022c9fda6e792c4349a043a6c74" prefix=" " category="inline-code"></block> Parameter mit dem Standardwert 30, sofern keine der folgenden Bedingungen zutrifft:</block>
  <block id="5b46e861366ffd98cd94c26abf2bf550" category="list-text"><block ref="ff4a008470319a22d9cf3d14af485977" prefix="" category="inline-code"></block> Binärdateien befinden sich auf einem Network-Attached-Laufwerk, einschließlich NFS-, iSCSI-, FC- und Datastore-basierten Laufwerken.</block>
  <block id="7ace6d79e63cb29c86093526fbddf845" category="list-text">Das Betriebssystem wird über SAN gebootet.</block>
  <block id="985511d6258bbf659d35bd76e0b0cea1" category="list-text">Prüfen Sie in solchen Fällen die Auswirkungen von Netzwerkunterbrechungen, die den Zugriff auf das Betriebssystem oder beeinträchtigen<block ref="9599929f8663b5e2093f7bc5cb20b0c2" prefix=" " category="inline-code"></block> File-Systeme. In einigen Fällen führen solche Unterbrechungen dazu, dass die Oracle RAC-Daemons abgewürgt werden, was zu einem führen kann<block ref="7c13d022c9fda6e792c4349a043a6c74" prefix=" " category="inline-code"></block>-Based Timeout und Entfernung. Die Zeitüberschreitung beträgt standardmäßig 27 Sekunden. Dies ist der Wert von<block ref="7c13d022c9fda6e792c4349a043a6c74" prefix=" " category="inline-code"></block> Minus<block ref="c9333b0a26b9f9e9fd808e6238d613b0" prefix=" " category="inline-code"></block>. In solchen Fällen erhöhen<block ref="7c13d022c9fda6e792c4349a043a6c74" prefix=" " category="inline-code"></block> Bis 200, um zu entsprechen<block ref="0494651671c3dc7f1ccdf99a4368a2cf" prefix=" " category="inline-code"></block>.</block>
  <block id="6cde0106c3eb71034259ac34de5e6a2c" category="summary">Oracle filesystemio_options</block>
  <block id="a3f7c31b8d967e0ac9f9dd30fc81c061" category="paragraph">Der Oracle-Initialisierungsparameter<block ref="f1110589be196c2310808482067fce1b" prefix=" " category="inline-code"></block> Steuert die Verwendung von asynchronem und direktem I/O.</block>
  <block id="d1fa3441fd96418a75a509ac2907d644" category="paragraph">Entgegen der allgemeinen Auffassung schließen sich asynchroner und direkter I/O nicht gegenseitig aus. NetApp hat festgestellt, dass dieser Parameter in Kundenumgebungen häufig falsch konfiguriert ist und dass diese Fehlkonfiguration direkt für viele Performance-Probleme verantwortlich ist.</block>
  <block id="0775b72ddf51e2a16e466ee2df8f75ab" category="paragraph">Asynchroner I/O bedeutet, dass Oracle-I/O-Vorgänge parallelisiert werden können. Bevor asynchroner I/O auf verschiedenen Betriebssystemen verfügbar war, konfigurierten Anwender zahlreiche dbwriter-Prozesse und änderten die Serverprozesskonfiguration. Bei asynchronem I/O führt das Betriebssystem selbst I/O im Auftrag der Datenbanksoftware hocheffizient und parallel aus. Dieser Prozess gefährdet keine Daten, und kritische Vorgänge wie die Oracle-Wiederherstellungsprotokollierung werden weiterhin synchron ausgeführt.</block>
  <block id="6b72950206966c1983e559eb6886ec69" category="paragraph">Direkter I/O umgeht den Puffercache des Betriebssystems. I/O auf einem UNIX-System durchläuft normalerweise den Puffercache des Betriebssystems. Dies ist nützlich für Applikationen, die keinen internen Cache verwalten, aber Oracle hat einen eigenen Puffer-Cache innerhalb des SGA. In fast allen Fällen ist es besser, direkten I/O zu ermöglichen und dem SGA Server-RAM zuzuweisen, anstatt sich auf den Puffercache des Betriebssystems zu verlassen. Oracle SGA nutzt den Speicher effizienter. Wenn I/O den Puffer des Betriebssystems durchläuft, finden weitere Verarbeitungsschritte statt, wodurch die Latenzen erhöht werden. Die erhöhten Latenzen sind besonders bei umfangreichen I/O-Schreibvorgängen spürbar, bei denen eine niedrige Latenz eine wichtige Anforderung ist.</block>
  <block id="d8590a940a5bb30d8a845f4359f3c779" category="paragraph">Die Optionen für<block ref="f1110589be196c2310808482067fce1b" prefix=" " category="inline-code"></block> Sind:</block>
  <block id="0aea10c6719256027228a859db38f291" category="list-text">*Async.* Oracle sendet I/O-Anfragen zur Verarbeitung an das Betriebssystem. Mit diesem Prozess kann Oracle andere Aufgaben ausführen, anstatt auf den I/O-Abschluss zu warten. Dadurch wird die I/O-Parallelisierung erhöht.</block>
  <block id="00cb0cc309682c42b3b936a19a042434" category="list-text">*Directio.* Oracle führt I/O direkt auf physische Dateien aus, anstatt I/O über den Host-BS-Cache zu leiten.</block>
  <block id="f9941e1b6cc84711e95db0e757efc36a" category="list-text">*None.* Oracle verwendet synchrone und gepufferte I/O. In dieser Konfiguration ist die Wahl zwischen Shared-Server- und dedizierten Server-Prozessen und der Anzahl der dbwriters wichtiger.</block>
  <block id="f0939ff6231565c83c5c8c9ce1eddc9d" category="list-text">*setall.* Oracle verwendet sowohl asynchrone als auch direkte I/O. In fast allen Fällen, die Verwendung von<block ref="aef8f91b1e026cc1bb55e8b08c491d35" prefix=" " category="inline-code"></block> Ist optimal.</block>
  <block id="8647b2eaf101a9425f69e6f2e67aeb9d" category="admonition">Der<block ref="f1110589be196c2310808482067fce1b" prefix=" " category="inline-code"></block> Parameter hat keine Auswirkungen in DNFS- und ASM-Umgebungen. Die Verwendung von DNFS oder ASM führt automatisch zur Verwendung von asynchronem und direktem I/O.</block>
  <block id="6dd5604aa0be2956f8b1b41c74fa648e" category="paragraph">Einige Kunden sind in der Vergangenheit auf Probleme mit asynchronem I/O gestoßen, insbesondere mit früheren Versionen von Red hat Enterprise Linux 4 (RHEL4). Einige veraltete Ratschläge im Internet deuten immer noch darauf hin, dass asynchrone IO aufgrund veraktueller Informationen vermieden wird. Asynchrone I/O-Vorgänge sind auf allen aktuellen Betriebssystemen stabil. Es gibt keinen Grund, es zu deaktivieren, ohne einen bekannten Fehler mit dem Betriebssystem.</block>
  <block id="1ea377466376b194b2d1bfc3ab2fa4c4" category="paragraph">Wenn in einer Datenbank gepufferte I/O verwendet wurden, könnte ein Wechsel zu direkten I/O auch eine Änderung der SGA-Größe rechtfertigen. Durch die Deaktivierung gepufferter I/O-Vorgänge werden die Performance-Vorteile eliminiert, die der Host-BS-Cache für die Datenbank bietet. Durch das Hinzufügen von RAM zum SGA wird dieses Problem behoben. Das Nettoergebnis sollte eine Verbesserung der I/O-Performance sein.</block>
  <block id="787b3d8b62af05ac3efd1c9ca7a8fc7e" category="paragraph">Obwohl es fast immer besser ist, RAM für Oracle SGA zu verwenden statt für das Zwischenspeichern von BS-Puffern, ist es unter Umständen nicht möglich, den besten Wert zu ermitteln. Es könnte beispielsweise besser sein, gepufferten I/O mit sehr kleinen SGA-Größen auf einem Datenbankserver mit vielen intermittierend aktiven Oracle-Instanzen zu verwenden. Diese Anordnung ermöglicht die flexible Nutzung des verbleibenden freien RAM auf dem Betriebssystem durch alle ausgeführten Datenbankinstanzen. Dies ist eine äußerst ungewöhnliche Situation, die jedoch an einigen Kundenstandorten beobachtet wurde.</block>
  <block id="d4157ab77eb31459bd406aa0f873e20c" category="admonition">*NetApp empfiehlt* Einstellung<block ref="f1110589be196c2310808482067fce1b" prefix=" " category="inline-code"></block> Bis<block ref="aef8f91b1e026cc1bb55e8b08c491d35" prefix=" " category="inline-code"></block>, Aber beachten Sie, dass unter bestimmten Umständen der Verlust des Host-Puffer-Caches eine Erhöhung des Oracle SGA erfordern kann.</block>
  <block id="caa6d47f2f011d5d1b5fb830e85a37f0" category="summary">Oracle Blockgröße</block>
  <block id="6db776dab2989df63d245511a4dccf08" category="doc">Oracle Blockgrößen</block>
  <block id="f8b42f9efd1a05ede10b0e0c11dfa8b0" category="paragraph">ONTAP verwendet intern eine variable Blockgröße, d. h. Oracle Datenbanken können mit beliebigen Blockgrößen konfiguriert werden. Allerdings können Blockgrößen des Dateisystems die Performance beeinträchtigen und in einigen Fällen kann eine größere Blockgröße für Wiederherstellungen die Performance verbessern.</block>
  <block id="0944aedb4703c4a5e94fb90de9d7a22f" category="section-title">Blockgrößen der Datendatei</block>
  <block id="cc4662c047050e0082701ce6f052dcb7" category="paragraph">Einige Betriebssysteme bieten eine Auswahl an Filesystem-Blockgrößen. Bei Filesystemen, die Oracle Datendateien unterstützen, sollte die Blockgröße bei Verwendung der Komprimierung 8 KB betragen. Wenn keine Komprimierung erforderlich ist, kann eine Blockgröße von 8 KB oder 4 KB verwendet werden.</block>
  <block id="e1a001cf8c7e2072c7a44ee65e8fee11" category="paragraph">Wenn eine Datendatei auf einem Dateisystem mit einem 512-Byte-Block abgelegt wird, sind falsch ausgerichtete Dateien möglich. Die LUN und das Filesystem sind möglicherweise basierend auf Empfehlungen von NetApp richtig ausgerichtet, der Datei-I/O wäre jedoch falsch ausgerichtet. Eine solche Fehlausrichtung würde zu schwerwiegenden Leistungsproblemen führen.</block>
  <block id="9514c8638f798f68108498dd218ec793" category="paragraph">Dateisysteme, die Redo-Protokolle unterstützen, müssen eine Blockgröße verwenden, die ein Vielfaches der Redo-Blockgröße ist. Dies erfordert in der Regel, dass sowohl das Redo-Log-Dateisystem als auch das Redo-Protokoll selbst eine Blockgröße von 512 Byte verwenden.</block>
  <block id="cac7d87a1164763b666ca7d02109d153" category="section-title">Wiederholen Sie die Blockgrößen</block>
  <block id="fa06b9584ea36af182742c07894220f0" category="paragraph">Bei sehr hohen Wiederherstellungsraten ist es möglich, dass 4-KB-Blockgrößen die Performance verbessern, da hohe Wiederherstellungsraten es ermöglichen, I/O in weniger und effizienteren Operationen auszuführen. Wenn Redo-Raten größer als 50 Mbit/s sind, sollten Sie eine 4-KB-Blockgröße testen.</block>
  <block id="781000593b4913b5625dd5ed9eebe87e" category="paragraph">Einige Kundenprobleme wurden mit Datenbanken identifiziert, die Wiederherstellungsprotokolle mit 512-Byte-Blockgröße auf einem Dateisystem mit 4-KB-Blockgröße und vielen sehr kleinen Transaktionen verwenden. Der Mehraufwand, der an der Anwendung mehrerer 512-Byte-Änderungen auf einen einzigen 4-KB-Dateisystemblock beteiligt war, führte zu Performance-Problemen, die behoben wurden, indem das Dateisystem auf eine Blockgröße von 512 Byte geändert wurde.</block>
  <block id="a02416fde36b174cf1196213fcf1bef6" category="admonition">*NetApp empfiehlt*, dass Sie die Größe des Redo-Blocks nicht ändern, es sei denn, Sie werden von einem zuständigen Kundensupport oder einer professionellen Serviceorganisation beraten oder die Änderung basiert auf der offiziellen Produktdokumentation.</block>
  <block id="00783c075f877e6e69c64079296967ed" category="summary">Oracle Disaster Recovery mit ONTAP</block>
  <block id="6a87f84ba62b57e5643d5bfa5967c7a8" category="doc">Disaster Recovery mit ONTAP</block>
  <block id="65a6ece62f52a5e2ff74baaae821ae86" category="paragraph">Disaster Recovery bezieht sich auf die Wiederherstellung von Datenservices nach einem schwerwiegenden Ereignis, beispielsweise durch einen Brand, der ein Storage-System oder sogar einen kompletten Standort zerstört.</block>
  <block id="e168b3b0b2f075f39012df52c5ea3c0a" category="admonition">Diese Dokumentation ersetzt zuvor veröffentlichte technische Berichte _TR-4591: Oracle Data Protection_ und _TR-4592: Oracle on MetroCluster._</block>
  <block id="a91982f09e6a0341a90dae002865ea11" category="paragraph">Disaster Recovery kann durch eine einfache Datenreplizierung mit SnapMirror durchgeführt werden, wobei viele Kunden gespiegelte Replikate natürlich so oft wie stündlich aktualisieren.</block>
  <block id="0f1b72a875a2bcb3d0e844ca2dcee233" category="paragraph">Bei den meisten Kunden benötigt DR mehr als nur einen Remote-Kopiervorgang, sondern muss in der Lage sein, diese Daten schnell zu nutzen. NetApp bietet zwei Technologien zur Erfüllung dieser Anforderungen: MetroCluster und SnapMirror Business Continuity (SM-BC).</block>
  <block id="ad2c5e9521f13e89cd84fdd65ec96c7d" category="paragraph">MetroCluster bezieht sich auf ONTAP in einer Hardwarekonfiguration mit synchron gespiegelten Storage auf niedriger Ebene und zahlreichen zusätzlichen Funktionen. Integrierte Lösungen wie MetroCluster vereinfachen die heutigen komplizierten, horizontal skalierbaren Datenbanken, Applikationen und Virtualisierungsinfrastrukturen. Sie ersetzt mehrere externe Datensicherungsprodukte und -Strategien durch ein einfaches, zentrales Storage-Array. Sie bietet außerdem integriertes Backup, Recovery, Disaster Recovery und Hochverfügbarkeit (HA) in einem einzigen geclusterten Storage-System.</block>
  <block id="05be1e741eba1ac3f0b7c924f261403b" category="paragraph">SnapMirror Business Continuity (SM-BC) basiert auf SnapMirror Synchronous. Mit MetroCluster ist jeder ONTAP Controller für die Replizierung seiner Laufwerksdaten an einen Remote-Standort verantwortlich. Mit SM-BC haben Sie im Grunde zwei verschiedene ONTAP-Systeme, die unabhängige Kopien Ihrer LUN-Daten führen, aber zusammenarbeiten, um eine einzige Instanz dieser LUN zu präsentieren. Auf Host-Ebene handelt es sich um eine einzelne LUN-Einheit.</block>
  <block id="70f47db03a0843fec433c8cc41a54635" category="paragraph">Obwohl SM-BC und MetroCluster intern sehr unterschiedlich arbeiten, ist das Ergebnis für einen Host sehr ähnlich. Der Hauptunterschied ist die Granularität. Wenn Sie nur ausgewählte Workloads für die synchrone Replizierung benötigen, ist SM-BC die bessere Option. Wenn ganze Umgebungen oder sogar Datacenter repliziert werden müssen, ist MetroCluster die bessere Option. Darüber hinaus ist SM-BC derzeit nur SAN, während MetroCluster Multi-Protokoll-Unterstützung einschließlich SAN, NFS und SMB bietet.</block>
  <block id="7389dc8e47495ffdde7fd2e0fc19df20" category="summary">Oracle Failover mit SM-BC</block>
  <block id="0a54809bbd5dc721967217b79aa04429" category="paragraph">Der Hauptgrund für das Hosten einer Oracle-Datenbank auf SM-BC ist die Bereitstellung eines transparenten Failover bei geplanten und ungeplanten Speicherereignissen.</block>
  <block id="cfb8f86af03363ef2c73933e34108390" category="summary">Einzelne Oracle Instanz auf ONTAP mit SM-BC</block>
  <block id="f25228759326d365adf4dca6b7b2cb8b" category="doc">Single Instance Oracle mit SM-BC</block>
  <block id="a38cb04f35bd24313f90398cdc07e149" category="paragraph">Die Abbildung unten zeigt ein einfaches Implementierungsmodell, bei dem Speichergeräte sowohl von den primären als auch von den Remote-Storage-Clustern für eine Oracle-Datenbank in Zonen eingeteilt oder verbunden werden.</block>
  <block id="ac38db4f14e512b48d088eedb84cd611" category="paragraph">Oracle ist nur auf dem primären konfiguriert. Dieses Modell ermöglicht bei Storage-seitigen Ausfällen ein nahtloses Storage Failover und verhindert Datenverlust ohne Applikationsausfallzeiten. Dieses Modell würde jedoch bei einem Standortausfall keine hohe Verfügbarkeit der Datenbankumgebung gewährleisten. Diese Architektur eignet sich für Kunden, die eine Lösung ohne Datenverlust und mit hoher Verfügbarkeit der Storage-Services suchen. Sie akzeptiert jedoch, dass ein Totalausfall des Datenbank-Clusters manuelle Arbeit erfordert.</block>
  <block id="ccc53ca027c7d8fb1e0d647249fd67cd" category="paragraph"><block ref="ccc53ca027c7d8fb1e0d647249fd67cd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4e072ef2eba1c46e59475046cd4fb880" category="paragraph">Mit diesem Ansatz können auch Kosten für Oracle Lizenzen eingespart werden. Für die Vorkonfiguration von Oracle-Datenbankknoten am Remote-Standort ist es erforderlich, dass alle Kerne unter den meisten Oracle Lizenzierungsvereinbarungen lizenziert werden. Wenn die Verzögerung, die durch die Installation eines Oracle-Datenbankservers und das Mounten der verbleibenden Kopie der Daten verursacht wird, akzeptabel ist, kann dieses Design sehr kostengünstig sein.</block>
  <block id="5e2dd7c2fa063e6d7af964efc0e488a0" category="summary">Oracle RAC auf ONTAP mit SM-BC</block>
  <block id="f7d366254f13816be07d3c8dff4ef00c" category="doc">Oracle RAC mit SM-BC</block>
  <block id="67bbc9e19672ee6c9c548cae8a472396" category="paragraph">SM-BC bietet granulare Kontrolle über die Datensatzreplikation für Zwecke wie Lastausgleich oder individuelles Applikations-Failover. Die Gesamtarchitektur sieht aus wie ein erweiterter RAC-Cluster, einige Datenbanken sind jedoch bestimmten Standorten zugewiesen und die Gesamtlast ist verteilt.</block>
  <block id="9331b3ad2bcf259818157930e1c82ad3" category="paragraph">Sie könnten beispielsweise einen Oracle RAC-Cluster erstellen, der sechs einzelne Datenbanken hostet. Der Storage für drei der Datenbanken würde hauptsächlich auf Standort A und der Storage für die anderen drei Datenbanken auf Standort B gehostet werden Diese Konfiguration sorgt durch die Minimierung des standortübergreifenden Datenverkehrs für eine bestmögliche Performance. Außerdem sollten Applikationen so konfiguriert werden, dass sie die im Storage-System lokalen Datenbankinstanzen mit aktiven Pfaden verwenden. Dies minimiert den RAC Interconnect-Datenverkehr. Schließlich stellt dieses Gesamtdesign sicher, dass alle Rechenressourcen gleichmäßig genutzt werden. Bei sich ändernden Workloads können Datenbanken selektiv standortübergreifend und hin- und herausgefallen sein, um ein gleichmäßiges Laden zu gewährleisten.</block>
  <block id="4278792a47efb1e599476fe07109dca4" category="inline-link-macro">Oracle RAC auf MetroCluster</block>
  <block id="1c6753ccdcc6629af3e1febabbf271b5" category="paragraph">Abgesehen von der Granularität sind die grundlegenden Prinzipien und Optionen für Oracle RAC unter Verwendung von SM-BC identisch <block ref="f7453402f1e4779ea0ec67d873358932" category="inline-link-macro-rx"></block></block>
  <block id="7e544b57620f5cdeb71865606eab0549" category="summary">Oracle mit SnapMirror Business Continuity (SM-BC)</block>
  <block id="33aa8b7a84723347d228956fab2a4de8" category="doc">Oracle und SnapMirror Business Continuity</block>
  <block id="41eec95e0dbb542c5cd25248ec5759d5" category="paragraph">SM-BC ermöglicht selektive synchrone RPO=0-Spiegelung für einzelne Oracle Datenbanken und Applikationsumgebungen.</block>
  <block id="563d0bf19fd5d623a031d90c30128dc1" category="summary">Fehlerszenarien für Oracle SM-BC</block>
  <block id="3c1ea312a3c6648fc3f94a1ccd12bebc" category="doc">Fehlerszenarien für Oracle SM-BC</block>
  <block id="87777c84375810d8b6fd65f604dd2561" category="paragraph">Es gibt mehrere SnapMirror Business Continuity (SM-BC)-Ausfallszenarien, die jeweils unterschiedliche Ergebnisse haben.</block>
  <block id="8eea62084ca7e541d918e823422bd82e" category="cell">Ergebnis</block>
  <block id="ee70ac41df7240931fee4110b599c39f" category="cell">Fehler bei der Replikationsverbindung</block>
  <block id="e79e76eca171f3e596eb56ba4bb24743" category="cell">Der Mediator erkennt dieses Split-Brain-Szenario und setzt die I/O-Vorgänge auf dem Node, auf dem sich die Master-Kopie befindet, fort. Wenn die Verbindung zwischen Standorten wieder online ist, führt der alternative Standort eine automatische Neusynchronisierung durch.</block>
  <block id="98a638ba6cee257a8f751bcf8d30e1f2" category="cell">Ausfall des primären Standortspeichers</block>
  <block id="b92af6cefecfe68535bbd851b797379f" category="cell">Der automatische ungeplante Failover wird von Mediator initiiert.

Keine I/O-Unterbrechung</block>
  <block id="ce9a584219636ca5b159a27f2dd8c445" category="cell">Fehler beim Storage am Remote-Standort</block>
  <block id="68a293bd16c4e2589057d43506a5afbd" category="cell">Es gibt keine I/O-Unterbrechung. Es gibt eine vorübergehende Pause, weil das Netzwerk dazu führt, dass die synchrone Replikation abgebrochen wird, und der Master feststellt, dass er der rechtmäßige Eigentümer ist, weiterhin I/O zu bedienen (Konsens). Daher liegt eine I/O-Pause von einigen Sekunden vor, die die I/O-Vorgänge wieder aufnehmen wird.

Es erfolgt eine automatische Neusynchronisierung, wenn die Site online ist.</block>
  <block id="64f4e3573d0b569ef7b5a08476fb9f7d" category="cell">Verlust des Mediators oder der Verbindung zwischen Mediator und den Speicher-Arrays</block>
  <block id="7e7abe23ef8e465ee1b6879b35e6bab3" category="cell">I/O wird fortgesetzt und bleibt mit dem Remote-Cluster synchron, aber automatisiertes ungeplantes/geplantes Failover und Failback ist ohne Mediator nicht möglich.</block>
  <block id="96b352ebd03c8c5b7589a527b18f1a2d" category="cell">Ausfall eines der Storage Controller im HA-Cluster</block>
  <block id="426c4468c3cc76191842240593fcfec3" category="cell">Der Partner-Node im HA-Cluster versucht eine Übernahme (NDO). Wenn die Übernahme fehlschlägt, erkennt Mediator, dass beide Knoten im Speicher ausgefallen sind, und führt einen automatischen ungeplanten Failover auf das Remote-Cluster durch.</block>
  <block id="0e578c93ab393c3d449d484e9fa4b84e" category="cell">Verlust von Festplatten</block>
  <block id="3d5fea5d89ec844fc92c08a585050e4e" category="cell">I/O wird bei bis zu drei aufeinanderfolgenden Festplattenausfällen fortgesetzt. Dies ist Teil von RAID-TEC.</block>
  <block id="bd300f92769c0ee071832cadaff91f04" category="cell">Verlust des gesamten Standorts in einer typischen Bereitstellung</block>
  <block id="9cfa40a514d333ea10de6fc8a75ac663" category="cell">Server auf dem ausgefallenen Standort sind offensichtlich nicht mehr verfügbar. Applikationen mit Clustering-Unterstützung können für die Ausführung an beiden Standorten und den Betrieb an einem alternativen Standort konfiguriert werden. Allerdings erfordern die meisten Applikationen eine Tiebreaker an einem dritten Standort, ähnlich wie SM-BC den Mediator erfordert.

Ohne Cluster auf Applikationsebene müssen Applikationen am noch aktiven Standort gestartet werden. Dies würde sich auf die Verfügbarkeit auswirken, aber RPO=0 wird beibehalten. Es gehen keine Daten verloren.</block>
  <block id="f2762385d394491398659925e75d5d01" category="summary">Physische Architektur von MetroCluster – Oracle</block>
  <block id="5be41b602a41d06df45e8986ec09a8dc" category="doc">Physische Architektur von MetroCluster - Oracle</block>
  <block id="d12be40db836559c628e8024f5d6ff56" category="paragraph">Um zu verstehen, wie Oracle Datenbanken in einer MetroCluster-Umgebung arbeiten, ist eine Erläuterung des physischen Designs eines MetroCluster-Systems erforderlich.</block>
  <block id="5e33c0d8a2417ce5fb6e7a211ad063bb" category="admonition">Diese Dokumentation ersetzt den zuvor veröffentlichten technischen Bericht _TR-4592: Oracle on MetroCluster._</block>
  <block id="bdec122112fe3ad35d588380dc643e48" category="summary">Logische Architektur von MetroCluster - Oracle</block>
  <block id="141402e8d9fa946970f252a09a01a462" category="doc">Logische Architektur von MetroCluster - Oracle</block>
  <block id="37fa92fc2662529308c62c84eb1b38ea" category="paragraph">Um zu verstehen, wie Oracle-Datenbanken in einer MetroCluster-Umgebung funktionieren, bedarf es einer Erklärung der logischen Funktionalität eines MetroCluster-Systems.</block>
  <block id="8b2ad15147d13b66fb05bc4b7f95e653" category="summary">Oracle auf MetroCluster - NVFAIL</block>
  <block id="67be2475945283126e261087dcc833b7" category="doc">MetroCluster und NVFAIL</block>
  <block id="2623b589ddbc1cdb6184ba32aa06e83f" category="inline-link-macro">NV-FEHLER</block>
  <block id="8b048af13e99be5215d8b6ba7542bd1d" category="paragraph">NVFAIL ist eine allgemeine Datenintegritätsfunktion in ONTAP, die für den Datenbank-Workload besonders wichtig ist und wird in ausführlicher behandelt <block ref="b361c920d00a4a9bf82fc2698602aeab" category="inline-link-macro-rx"></block>. Für NVFAIL gibt es auch MetroCluster-spezifische Überlegungen.</block>
  <block id="a59556e5d6eba6a88829152216638f70" category="section-title">Erweiterter RAC mit manuell erzwungenem NVFAIL</block>
  <block id="c8d0ea777fef88ebdbbedcb6a8534001" category="paragraph">Die sicherste Option, um eine Umschaltung mit einem erweiterten RAC-Cluster zu erzwingen, ist die Angabe<block ref="71e644310ff0f1164d905d6e80174023" prefix=" " category="inline-code"></block> An der Kommandozeile. Diese Option ist als Notfallmaßnahme verfügbar, um sicherzustellen, dass alle zwischengespeicherten Daten gelöscht werden. Wenn ein Host Speicherressourcen verwendet, die sich ursprünglich am Standort mit Notfällen befinden, erhält er entweder I/O-Fehler oder eine veraltete Dateihandle <block ref="a3c6541ac12f1f06a81cc9b03e6bd094" prefix="(" category="inline-code"></block>) Fehler. Oracle Datenbanken stürzt ab, und Dateisysteme werden entweder vollständig offline geschaltet oder in den schreibgeschützten Modus gewechselt.</block>
  <block id="193392122201d82edb280636f4751f06" category="paragraph">Nachdem die Umschaltung abgeschlossen ist, wird der angezeigt<block ref="6b0a5ec5ecf08db5d4b32d860214d098" prefix=" " category="inline-code"></block> Flag muss gelöscht werden und die LUNs müssen in den Online-Modus versetzt werden. Nach Abschluss dieser Aktivität kann die Datenbank neu gestartet werden. Diese Aufgaben können automatisiert werden, um die RTO zu reduzieren.</block>
  <block id="2d77d18df7345b1b12c19fed37f30094" category="section-title">Erweiterter RAC mit dr-Force-nvfail</block>
  <block id="ce1c367fd3b2234c847cdcde6df93cf6" category="paragraph">Die sicherste Konfiguration ist die Einstellung<block ref="a2626552f293b2377efe829e69d14daa" prefix=" " category="inline-code"></block> Markieren Sie auf allen Volumes, auf die von einem Remote-Standort aus zugegriffen werden kann. Daher stehen die Volumes beim Betreten nicht mehr zur Verfügung<block ref="6b0a5ec5ecf08db5d4b32d860214d098" prefix=" " category="inline-code"></block> Während einer Umschaltung. Nachdem die Umschaltung abgeschlossen ist, wird der angezeigt<block ref="6b0a5ec5ecf08db5d4b32d860214d098" prefix=" " category="inline-code"></block> Flag muss gelöscht und die LUNs müssen in den Online-Modus versetzt werden. Nach Abschluss dieser Aktivitäten kann die Datenbank neu gestartet werden. Diese Aufgaben können automatisiert werden, um die RTO zu reduzieren.</block>
  <block id="7227c057accb7ced8902796f7b957b5a" category="paragraph">Das Ergebnis ähnelt der Verwendung von<block ref="71e644310ff0f1164d905d6e80174023" prefix=" " category="inline-code"></block> Flagge. Die Anzahl der betroffenen Volumes kann jedoch auf die Volumes beschränkt werden, die vor Anwendungen oder Betriebssystemen mit veralteten Caches geschützt werden müssen.</block>
  <block id="ae929f778e3706520521bed541a8b46e" category="section-title">Erweiterter RAC ohne dr-Force-nvfail</block>
  <block id="91b508022987523900b69bdaf7649555" category="paragraph">Es gibt zwei entscheidende Anforderungen an eine Umgebung, die nicht verwendet wird<block ref="a2626552f293b2377efe829e69d14daa" prefix=" " category="inline-code"></block> Auf Datenbank-Volumes:</block>
  <block id="e6b6543ad688c7163e581e8cc41e14bf" category="list-text">Eine Umschaltung darf nicht während Wartungsarbeiten oder unter anderen Bedingungen erfolgen, bei denen SyncMirror Plexe oder NVRAM-Replizierung nicht synchron sind. Die erste Anforderung kann mithilfe der Tiebreaker Software erfüllt werden, die so konfiguriert ist, dass nach einem Standortausfall innerhalb von 30 Sekunden eine Umschaltung durchgeführt wird. Dies bedeutet jedoch nicht, dass die Umschaltung innerhalb von 30 Sekunden nach Erkennung eines Standortausfalls durchgeführt werden muss. Das bedeutet, dass es nicht mehr sicher ist, eine Umschaltung zu erzwingen, wenn 30 Sekunden vergangen sind, seit die Betriebsbereitschaft eines Standorts bestätigt wurde.</block>
  <block id="6ddd3d6bc3ad92b983699970b1596e0f" category="summary">Oracle mit MetroCluster</block>
  <block id="c1fac7a72cd91bcd345e567f6d6d93a3" category="doc">Oracle Failover mit MetroCluster</block>
  <block id="7a60cb119af7ddcdfe38fc872d2027a1" category="paragraph">Die Verwendung von MetroCluster trägt nicht notwendigerweise zur Ergänzung oder Änderung von Best Practices für den Betrieb von Enterprise-Applikationen und Datenbanken bei.</block>
  <block id="a4feacea8b05d0f24e5a4612a164a055" category="paragraph">Die üblichen Best Practices gelten weiterhin, und wenn Ihre Bedürfnisse nur RPO=0 Datensicherung erfordern, wird diese Anforderung mit MetroCluster erfüllt. Die meisten Kunden verwenden MetroCluster jedoch nicht nur für die RPO=0-Datensicherung, sondern auch zur Verbesserung der RTO in Notfallszenarien sowie zur Gewährleistung eines transparenten Failovers im Rahmen der Wartungsarbeiten an den Standorten.</block>
  <block id="3ff8bcf18c694581aa25b0a347508e0f" category="section-title">Failover mit einem vorkonfigurierten Betriebssystem</block>
  <block id="9bd9ad7f296a0e8ac3df804b3c6a392f" category="paragraph">SyncMirror liefert eine synchrone Kopie der Daten am Disaster Recovery-Standort. Um diese Daten verfügbar zu machen, sind jedoch ein Betriebssystem und die zugehörigen Applikationen erforderlich. Eine grundlegende Automatisierung kann die Failover-Zeit der gesamten Umgebung deutlich verbessern. Clusterware-Produkte wie Oracle RAC, Veritas Cluster Server (VCS) oder VMware HA werden oft verwendet, um standortübergreifend ein Cluster zu erstellen. In vielen Fällen kann der Failover-Prozess mit einfachen Skripten vorangetrieben werden.</block>
  <block id="c5a2f3b867d990c681a218d29a55fcfa" category="paragraph">Wenn die primären Knoten verloren gehen, ist die Clusterware (oder Skripte) so konfiguriert, dass die Anwendungen am alternativen Standort online geschaltet werden. Eine Möglichkeit besteht darin, Standby-Server zu erstellen, die für die NFS- oder SAN-Ressourcen, aus denen die Applikation besteht, vorkonfiguriert sind. Wenn der primäre Standort ausfällt, führt die Clusterware- oder skriptbasierte Alternative eine Abfolge von Aktionen durch, die der folgenden ähneln:</block>
  <block id="442f34633164f1be348a442b2c62d29d" category="list-text">Erzwingen einer MetroCluster-Umschaltung</block>
  <block id="e081e79ea1b1040c51d4a452e46de76d" category="list-text">Durchführen der Erkennung von FC-LUNs (nur SAN)</block>
  <block id="6f3fd86521759fc98ed93853eaf8a03a" category="list-text">Mounten von Dateisystemen</block>
  <block id="9d9ea7a9c532a3cec63305130018a45b" category="list-text">Starten der Anwendung</block>
  <block id="b8eca7b573624230962095fcadb03ddf" category="paragraph">Die primäre Anforderung dieses Ansatzes ist ein Betriebssystem, das am Remote Standort ausgeführt wird. Es muss mit Applikations-Binärdateien vorkonfiguriert werden. Das bedeutet auch, dass Aufgaben wie Patching am primären Standort und Standby-Standort durchgeführt werden müssen. Alternativ können die Binärdateien der Applikation auf den Remote-Standort gespiegelt und gemountet werden, wenn ein Notfall gemeldet wird.</block>
  <block id="e60946bf73021e18706a6ac33386b376" category="paragraph">Die eigentliche Aktivierung ist einfach. Befehle wie die LUN-Erkennung erfordern nur einige wenige Befehle pro FC-Port. Das Mounten des Filesystems ist nichts anderes als ein<block ref="19822b1b15d9eefc54c07ab49f87b100" prefix=" " category="inline-code"></block> Befehl, und sowohl Datenbanken als auch ASM können über die CLI mit einem einzigen Befehl gestartet und gestoppt werden. Wenn die Volumes und Dateisysteme vor dem Switchover nicht am Disaster-Recovery-Standort verwendet werden, müssen Sie sie nicht festlegen<block ref="3b93661df04b698b1340ff2da3238d16" prefix=" " category="inline-code"></block> Auf Volumes.</block>
  <block id="486eed21f55b6fb544db5504294592e6" category="section-title">Failover mit einem virtualisierten Betriebssystem</block>
  <block id="bf65e943f86f26b49698bfdac9b95f81" category="paragraph">Der Failover von Datenbankumgebungen kann auf das Betriebssystem selbst erweitert werden. In der Theorie kann dieses Failover mit Boot-LUNs durchgeführt werden, meistens erfolgt es jedoch mit einem virtualisierten Betriebssystem. Das Verfahren ähnelt den folgenden Schritten:</block>
  <block id="7c37589384e83d2b43bba430c18a45aa" category="list-text">Mounten der Datenspeicher, die die virtuellen Maschinen des Datenbankservers hosten</block>
  <block id="3d4d04d6cdab90b7ca0deb0344f04eec" category="list-text">Starten der virtuellen Maschinen</block>
  <block id="ba2f22f63087151f0a0694be5f35fcf2" category="list-text">Manuelles Starten von Datenbanken oder Konfigurieren der virtuellen Maschinen, um die Datenbanken automatisch zu starten</block>
  <block id="810078f3b19b93e24de8638d68f727b5" category="paragraph">Beispielsweise kann ein ESX Cluster mehrere Standorte umfassen. Bei einem Notfall können die Virtual Machines nach dem Switchover am Disaster Recovery-Standort online geschaltet werden. Solange die Datastores, die die virtualisierten Datenbankserver hosten, zum Zeitpunkt des Ausfalls nicht verwendet werden, ist keine Einstellung erforderlich<block ref="3b93661df04b698b1340ff2da3238d16" prefix=" " category="inline-code"></block> Auf zugeordneten Volumes.</block>
  <block id="681afe3bdc351138642f233429d64762" category="summary">Oracle und SyncMirror</block>
  <block id="bc8a6c6eac662831d2ddce97adbd4324" category="doc">SyncMirror – Oracle</block>
  <block id="c702c387f07bcb4f18482e68d69a155a" category="paragraph">Die Grundlage für die Oracle Datensicherung mit einem MetroCluster System ist SyncMirror, eine Technologie für die synchrone Spiegelung, die maximale Performance und horizontale Skalierbarkeit bietet.</block>
  <block id="9028b52caaa7bdbfb9be779eeb1fe00e" category="summary">Oracle Extended RAC mit MetroCluster</block>
  <block id="dbcedb2fd86e6012347a3c9ad111f3a8" category="doc">Erweiterter Oracle RAC auf MetroCluster</block>
  <block id="4d4d8a609e5b2ac58e622eb1e90f9e39" category="paragraph">Viele Kunden optimieren ihre RTO, indem sie einen Oracle RAC Cluster über mehrere Standorte verteilen und damit eine vollständig aktiv/aktiv-Konfiguration erzielen. Das gesamte Design wird komplizierter, da es die Quorumverwaltung von Oracle RAC beinhalten muss. Außerdem erfolgt der Datenzugriff von beiden Standorten aus. Ein forcierter Switchover kann dazu führen, dass eine veraltete Kopie der Daten verwendet wird.</block>
  <block id="89ffaa1a7d089080e9a1ce912bb8c2d3" category="paragraph">Obwohl eine Kopie der Daten auf beiden Standorten vorhanden ist, kann nur der Controller, der derzeit Eigentümer eines Aggregats ist, Daten bereitstellen. Daher müssen bei erweiterten RAC-Clustern die Remote-Knoten I/O über eine Site-to-Site-Verbindung durchführen. Es kommt zu zusätzlicher I/O-Latenz, aber diese Latenz ist im Allgemeinen kein Problem. Das RAC Interconnect-Netzwerk muss auch über mehrere Standorte verteilt sein, was bedeutet, dass ohnehin ein High-Speed-Netzwerk mit niedriger Latenz erforderlich ist. Falls die zusätzliche Latenz ein Problem verursacht, kann das Cluster aktiv/Passiv betrieben werden. I/O-intensive Vorgänge müssten dann zu den RAC-Knoten geleitet werden, die lokal zu dem Controller sind, der die Aggregate besitzt. Die Remote-Knoten führen dann weniger I/O-Vorgänge aus oder werden ausschließlich als Warm-Standby-Server verwendet.</block>
  <block id="375c3caa97162bd0c2c07869d9c5b026" category="paragraph">Wenn ein erweiterter aktiv/aktiv-RAC erforderlich ist, sollte die ASM Spiegelung anstelle von MetroCluster in Betracht gezogen werden. ASM-Spiegelung ermöglicht die bevorzugte Replikation der Daten. Daher kann ein erweiterter RAC-Cluster erstellt werden, in dem alle Lesevorgänge lokal stattfinden. Die Lese-I/O-Vorgänge gehen nie über Standorte hinweg, wodurch die geringstmögliche Latenz erzielt wird. Alle Schreibvorgänge müssen weiterhin die Verbindung zwischen den Standorten übertragen, dieser Traffic ist bei jeder Lösung mit synchroner Spiegelung jedoch unvermeidlich.</block>
  <block id="f441d5fdc388f3419fb87e071534f3ce" category="inline-link-macro">Oracle RAC mit ONTAP</block>
  <block id="59d934fc4614a6275fef2828bfab30cf" category="admonition">Wenn Boot-LUNs, einschließlich virtualisierter Boot-Festplatten, mit Oracle RAC verwendet werden, wird der verwendet<block ref="7c13d022c9fda6e792c4349a043a6c74" prefix=" " category="inline-code"></block> Parameter muss möglicherweise geändert werden. Weitere Informationen zu RAC-Timeout-Parametern finden Sie unter <block ref="75080d28a1748f78cf8a666ababf51af" category="inline-link-macro-rx"></block>.</block>
  <block id="58285fb769eb7fb05ab12d9e0efb3e50" category="section-title">Konfiguration an zwei Standorten</block>
  <block id="af1184f29d838fbfec8d5b5bf5225f66" category="paragraph">Eine erweiterte RAC-Konfiguration mit zwei Standorten kann aktiv/aktiv-Datenbankservices bereitstellen, die viele, aber nicht alle Ausfallszenarien unterbrechungsfrei überstehen.</block>
  <block id="7544489c7854fcae445508015240a865" category="section-title">RAC-Abstimmungsdateien</block>
  <block id="8b6e46422f88dab6ea82f2dbcadfc76b" category="paragraph">Die erste Überlegung bei der Implementierung von Extended RAC auf MetroCluster sollte das Quorum-Management sein. Oracle RAC verfügt über zwei Mechanismen zur Verwaltung des Quorums: Disk Heartbeat und Netzwerk Heartbeat. Der Disk Heartbeat überwacht den Speicherzugriff mithilfe der Abstimmungsdateien. Bei einer RAC-Konfiguration an einem Standort ist eine einzelne Abstimmressource ausreichend, solange das zugrunde liegende Storage-System HA-Funktionen bietet.</block>
  <block id="fafd618b82d1827eeb8197e1c38722bc" category="paragraph">In früheren Versionen von Oracle wurden die Abstimmungsdateien auf physischen Speichergeräten abgelegt, aber in aktuellen Versionen von Oracle werden die Abstimmungsdateien in ASM-Diskgroups gespeichert.</block>
  <block id="aeab2391a07321ac474989b9c9047226" category="admonition">Oracle RAC wird von NFS unterstützt. Während der Grid-Installation wird eine Reihe von ASM-Prozessen erstellt, um den für Grid-Dateien verwendeten NFS-Speicherort als ASM-Diskgruppe darzustellen. Der Prozess ist für den Endbenutzer nahezu transparent und erfordert nach Abschluss der Installation keine laufende ASM-Verwaltung.</block>
  <block id="42aca4aae768d5ec1cb0c50d41b7b8b7" category="paragraph">In einer Konfiguration mit zwei Standorten ist es als erstes erforderlich, sicherzustellen, dass jeder Standort immer auf mehr als die Hälfte der Abstimmungsdateien zugreifen kann und so einen unterbrechungsfreien Disaster Recovery-Prozess garantiert. Diese Aufgabe war einfach, bevor die Abstimmungsdateien in ASM-Diskgroups gespeichert wurden, aber heute müssen Administratoren grundlegende Prinzipien der ASM-Redundanz verstehen.</block>
  <block id="60a723853bb2c173648452baf2199e73" category="paragraph">ASM-Diskgruppen haben drei Optionen für Redundanz<block ref="6a21b6995a068148bbb65c8f949b3fb2" prefix=" " category="inline-code"></block>,<block ref="fea087517c26fadd409bd4b9dc642555" prefix=" " category="inline-code"></block>, und<block ref="8d966b2253a917086c8604959e152243" prefix=" " category="inline-code"></block>. Mit anderen Worten: Nicht gespiegelt, gespiegelt und 3-fach gespiegelt. Eine neuere Option namens<block ref="09d2bd168181f1e64c2b1651a80a8aa8" prefix=" " category="inline-code"></block> Ist auch verfügbar, aber nur selten verwendet. Die Redundanzstufe und die Platzierung der redundanten Geräte steuern, was in Ausfallszenarien geschieht. Beispiel:</block>
  <block id="32cdeb2c0245b51a0b590e6054f03c21" category="list-text">Platzieren der Abstimmungsdateien auf einem<block ref="d4f266c5956ee60df748738c483f3dc0" prefix=" " category="inline-code"></block> Mit<block ref="6a21b6995a068148bbb65c8f949b3fb2" prefix=" " category="inline-code"></block> Bei Ausfall der Verbindung zwischen den Standorten wird durch Redundanzressource die Entfernung eines Standorts garantiert.</block>
  <block id="a549b4f1fc0c2d14bc333c70bbde73dc" category="list-text">Platzieren der Abstimmungsdateien auf einem<block ref="d4f266c5956ee60df748738c483f3dc0" prefix=" " category="inline-code"></block> Mit<block ref="fea087517c26fadd409bd4b9dc642555" prefix=" " category="inline-code"></block> Redundanz mit nur einer ASM-Festplatte pro Standort garantiert die Entfernung von Knoten auf beiden Standorten, wenn die Verbindung zwischen Standorten verloren geht, da keiner der Standorte ein mehrheitlich Quorum hätte.</block>
  <block id="c15f1c43a368db0ab3dde90eca52582d" category="list-text">Platzieren der Abstimmungsdateien auf einem<block ref="d4f266c5956ee60df748738c483f3dc0" prefix=" " category="inline-code"></block> Mit<block ref="8d966b2253a917086c8604959e152243" prefix=" " category="inline-code"></block> Redundanz mit zwei Festplatten an einem Standort und einer einzigen Festplatte am anderen Standort ermöglicht aktiv-aktiv-Vorgänge, wenn beide Standorte betriebsbereit sind und beide Seiten miteinander erreichbar sind. Wenn der Standort mit einer Festplatte jedoch vom Netzwerk isoliert ist, wird dieser Standort entfernt.</block>
  <block id="478ced47a1ea1d6f0db02af749bfdaec" category="section-title">RAC-Netzwerk-Heartbeat</block>
  <block id="2432333dc52d6150fb3d58051bc8b0c2" category="paragraph">Der Heartbeat des Oracle RAC-Netzwerks überwacht die Erreichbarkeit des Knotens über den Cluster-Interconnect hinweg. Damit ein Node im Cluster verbleiben kann, muss er sich mit mehr als der Hälfte der anderen Nodes in Verbindung setzen können. In einer Architektur mit zwei Standorten werden folgende Auswahlmöglichkeiten für die Anzahl der RAC-Knoten erstellt:</block>
  <block id="3e36a59c8a51ee9cc2cba0e7051ed35f" category="list-text">Die Platzierung einer gleichen Anzahl von Nodes pro Standort führt zu einer Entfernung an einem Standort, falls die Netzwerkverbindung unterbrochen wird.</block>
  <block id="4955aede919912b3c62fadbc1039671b" category="list-text">Die Platzierung von N Nodes auf einem Standort und N+1 Nodes auf dem anderen Standort garantiert, dass der Verlust der Verbindung zwischen den Standorten zu einer größeren Anzahl von Knoten führt, die im Netzwerk-Quorum verbleiben, und zu einem Standort mit weniger Knoten.</block>
  <block id="80bd651a66488201c928634689e2e5cc" category="paragraph">Vor der Einführung von Oracle 12cR2 war es nicht praktikabel zu kontrollieren, auf welcher Seite bei einem Standortausfall eine Entfernung auftreten würde. Wenn jeder Standort über eine gleiche Anzahl von Knoten verfügt, wird die Entfernung vom Master-Knoten gesteuert, der im Allgemeinen der erste RAC-Knoten ist, der gestartet wird.</block>
  <block id="d128c05245b2e633856a5061db176b7e" category="paragraph">Oracle 12cR2 bietet Funktionen zur Knotengewichtung. Diese Funktion gibt einem Administrator mehr Kontrolle darüber, wie Oracle Split-Brain-Bedingungen löst. Der folgende Befehl legt als einfaches Beispiel die Präferenz für einen bestimmten Knoten in einem RAC fest:</block>
  <block id="104c5747f0d9dbb47b0d09953c709a8d" category="paragraph">Nach dem Neustart von Oracle High-Availability Services sieht die Konfiguration wie folgt aus:</block>
  <block id="693cce334ab6658c73ea67674775156b" category="paragraph">Knoten<block ref="a31853cdea7badfc68b560e70cbbeb02" prefix=" " category="inline-code"></block> Ist jetzt als kritischer Server festgelegt. Wenn die beiden RAC-Knoten isoliert sind,<block ref="a31853cdea7badfc68b560e70cbbeb02" prefix=" " category="inline-code"></block> Überlebt, und<block ref="bf38e7432ba60433c4c8967fc8da0258" prefix=" " category="inline-code"></block> Wird entfernt.</block>
  <block id="386839b09451962d03e26b7bbfabce74" category="admonition">Ausführliche Informationen finden Sie im Oracle Whitepaper „Oracle Clusterware 12c Release 2 Technical Overview“. „</block>
  <block id="11f65689342acc8f71c8014eeb7945ee" category="paragraph">Bei Versionen von Oracle RAC vor 12cR2 kann der Master-Knoten identifiziert werden, indem die CRS-Protokolle wie folgt geprüft werden:</block>
  <block id="c8b8cd80b31dac17fb85459c341042bd" category="paragraph">Dieses Protokoll gibt an, dass der Master-Node ist<block ref="c81e728d9d4c2f636f067f89cc14862c" prefix=" " category="inline-code"></block> Und dem Knoten<block ref="a31853cdea7badfc68b560e70cbbeb02" prefix=" " category="inline-code"></block> Hat eine ID von<block ref="c4ca4238a0b923820dcc509a6f75849b" prefix=" " category="inline-code"></block>. Diese Tatsache bedeutet das<block ref="a31853cdea7badfc68b560e70cbbeb02" prefix=" " category="inline-code"></block> Ist nicht der Master-Knoten. Die Identität des Master-Knotens kann mit dem Befehl bestätigt werden<block ref="08e7c60bbf8289a563b25cc033d431f7" prefix=" " category="inline-code"></block>.</block>
  <block id="fdf6179b59d3f4873b042609a5f09bc4" category="paragraph">Der Knoten mit der ID von<block ref="c81e728d9d4c2f636f067f89cc14862c" prefix=" " category="inline-code"></block> Ist<block ref="bf38e7432ba60433c4c8967fc8da0258" prefix=" " category="inline-code"></block>, Das ist der Master-Knoten. In einer Konfiguration mit gleicher Anzahl von Knoten an jedem Standort, der Standort mit<block ref="bf38e7432ba60433c4c8967fc8da0258" prefix=" " category="inline-code"></block> Ist der Standort, der überlebt, wenn die beiden Sets aus irgendeinem Grund die Netzwerkverbindung verlieren.</block>
  <block id="f2932b43ad604fa01d57212558608ed6" category="paragraph">Der Protokolleintrag, der den Master-Knoten identifiziert, kann möglicherweise aus dem System altern. In diesem Fall können die Zeitstempel der Oracle Cluster Registry (OCR) Backups verwendet werden.</block>
  <block id="50cd29958db0c1dcb6505d470f553e54" category="paragraph">Dieses Beispiel zeigt, dass der Master-Knoten ist<block ref="bf38e7432ba60433c4c8967fc8da0258" prefix=" " category="inline-code"></block>. Sie zeigt auch eine Änderung im Master-Knoten von an<block ref="a31853cdea7badfc68b560e70cbbeb02" prefix=" " category="inline-code"></block> Bis<block ref="bf38e7432ba60433c4c8967fc8da0258" prefix=" " category="inline-code"></block> Am 4. Mai zwischen 2:05 und 21:39 Uhr. Diese Methode zur Identifizierung des Master-Knotens ist nur dann sicher zu verwenden, wenn die CRS-Protokolle ebenfalls geprüft wurden, da sich der Master-Knoten möglicherweise seit der vorherigen OCR-Sicherung geändert hat. Wenn diese Änderung stattgefunden hat, sollte sie in den OCR-Protokollen sichtbar sein.</block>
  <block id="df044a3c3d7f7f244db7c42b347b9a90" category="paragraph">Die meisten Kunden wählen eine einzelne Abstimmdiskette, die die gesamte Umgebung und eine gleiche Anzahl von RAC-Knoten an jedem Standort unterstützt. Die Datenträgergruppe sollte auf dem Standort platziert werden, der die Datenbank enthält. Das Ergebnis ist, dass der Verlust der Verbindung zu einer Entfernung am Remote-Standort führt. Der Remote-Standort hätte weder Quorum noch würde er Zugriff auf die Datenbankdateien haben, aber der lokale Standort läuft weiterhin wie gewohnt. Wenn die Konnektivität wiederhergestellt ist, kann die Remote-Instanz wieder online geschaltet werden.</block>
  <block id="84a24276bfdfbe485b9d961c1a57a830" category="paragraph">Bei einem Notfall ist eine Umschaltung erforderlich, um die Datenbankdateien und die abstimmende Diskgruppe am verbleibenden Standort online zu schalten. Wenn AUSO die Umschaltung auslösen kann, wird das NVFAIL nicht ausgelöst, da bekannt ist, dass das Cluster synchron ist und die Speicherressourcen ordnungsgemäß online gehen. AUSO ist ein sehr schneller Vorgang und sollte vor dem abgeschlossen werden<block ref="0494651671c3dc7f1ccdf99a4368a2cf" prefix=" " category="inline-code"></block> Zeitraum läuft ab.</block>
  <block id="6244ee13e435dcc768edbc9b0b38b73e" category="paragraph">Da es nur zwei Standorte gibt, ist es nicht möglich, eine automatisierte externe Tiebreaking-Software zu verwenden, was bedeutet, dass die erzwungene Umschaltung eine manuelle Operation sein muss.</block>
  <block id="568c8c12fdb7c74f65125732ee717ad3" category="section-title">Konfigurationen mit drei Standorten</block>
  <block id="2c7696fb04f52eb5687d059415066fa7" category="paragraph">Ein erweiterter RAC-Cluster lässt sich mit drei Standorten viel einfacher erstellen. Die beiden Standorte, die jeweils die Hälfte des MetroCluster Systems hosten, unterstützen auch die Datenbank-Workloads, während der dritte Standort als Tiebreaker für die Datenbank und das MetroCluster System dient. Die Oracle Tiebreaker-Konfiguration kann so einfach sein, als ob ein Mitglied der ASM-Diskgroup, die für die Abstimmung an einem dritten Standort verwendet wird, platziert werden könnte, und kann auch eine Betriebsinstanz am dritten Standort enthalten, um sicherzustellen, dass es eine ungerade Anzahl von Knoten im RAC-Cluster gibt.</block>
  <block id="6265611ca77e9ad52249c5fdd4780da9" category="admonition">Wichtige Informationen zur Verwendung von NFS in einer erweiterten RAC-Konfiguration finden Sie in der Oracle Dokumentation zum Thema „Quorum-Fehlergruppe“. Zusammenfassend kann es sein, dass die NFS-Mount-Optionen geändert werden müssen, um sicherzustellen, dass der Verlust der Verbindung zum dritten Standort, der Quorumressourcen hostet, nicht die primären Oracle-Server oder Oracle RAC-Prozesse hängt.</block>
  <block id="d84d0eea463e72a6e15018c70a45af46" category="doc">Oracle, MetroCluster und NVFAIL</block>
  <block id="ee6c613c07239c0923d940dfd448493f" category="paragraph">NVFAIL ist eine allgemeine Datenintegritätsfunktion in ONTAP, die für Datenbank-Workloads besonders wichtig ist.</block>
  <block id="9dc6a9986107298da2a22e7c5a3efb00" category="summary">Einzelne Oracle Instanz auf MetroCluster</block>
  <block id="f8b28e31633ae72c2971ee8b815ed4af" category="paragraph">Wie bereits erwähnt, trägt das Vorhandensein eines MetroCluster-Systems nicht notwendigerweise zur Ergänzung oder Änderung von Best Practices für den Betrieb einer Datenbank bei. Bei den meisten Datenbanken, die derzeit auf MetroCluster Kundensystemen ausgeführt werden, handelt es sich um eine Einzelinstanz, und befolgen Sie die Empfehlungen in der Dokumentation zu Oracle auf ONTAP.</block>
  <block id="f4872c843923dd8d8731ef66462b5a99" category="paragraph">SyncMirror liefert eine synchrone Kopie der Daten am Disaster Recovery-Standort. Um diese Daten verfügbar zu machen, sind jedoch ein Betriebssystem und die zugehörigen Applikationen erforderlich. Eine grundlegende Automatisierung kann die Failover-Zeit der gesamten Umgebung deutlich verbessern. Clusterware Produkte wie Veritas Cluster Server (VCS) werden oft verwendet, um einen Cluster standortübergreifend zu erstellen, in vielen Fällen kann der Failover-Prozess mit einfachen Skripten angetrieben werden.</block>
  <block id="c50820a41eb4f23d0a3acc1eeddb391b" category="paragraph">Wenn die primären Knoten verloren gehen, ist die Clusterware (oder Skripte) so konfiguriert, dass die Datenbanken am alternativen Standort online geschaltet werden. Eine Option besteht darin, Standby-Server zu erstellen, die für die NFS- oder SAN-Ressourcen, aus denen die Datenbank besteht, vorkonfiguriert sind. Wenn der primäre Standort ausfällt, führt die Clusterware- oder skriptbasierte Alternative eine Abfolge von Aktionen durch, die der folgenden ähneln:</block>
  <block id="2a6f458321ddf666cb0c876ee39255f3" category="list-text">Mounten von Dateisystemen und/oder Mounten von ASM-Datenträgergruppen</block>
  <block id="3dee93bd9bc9b8b50dcdd2066a86009f" category="list-text">Die Datenbank wird gestartet</block>
  <block id="620515885465a26daea6cc6441403e34" category="paragraph">Die primäre Anforderung dieses Ansatzes ist ein Betriebssystem, das am Remote Standort ausgeführt wird. Sie muss mit Oracle-Binärdateien vorkonfiguriert sein, was auch bedeutet, dass Aufgaben wie das Patching von Oracle am primären Standort und am Standby-Standort durchgeführt werden müssen. Alternativ können die Oracle Binärdateien auf den Remote-Standort gespiegelt und gemountet werden, wenn ein Notfall deklariert wird.</block>
  <block id="edb5332feef69c0aa60ea10ed5d31a9f" category="list-text">Manuelles Starten von Datenbanken oder Konfigurieren der virtuellen Maschinen, um die Datenbanken automatisch zu starten, z. B. kann ein ESX-Cluster mehrere Standorte umfassen. Bei einem Notfall können die Virtual Machines nach dem Switchover am Disaster Recovery-Standort online geschaltet werden. Solange die Datastores, die die virtualisierten Datenbankserver hosten, zum Zeitpunkt des Ausfalls nicht verwendet werden, ist keine Einstellung erforderlich<block ref="3b93661df04b698b1340ff2da3238d16" prefix=" " category="inline-code"></block> Auf zugeordneten Volumes.</block>
  <block id="6c2e01aca4f10a83d34e3f3046435e82" category="summary">SnapMirror und SyncMirror</block>
  <block id="64bba30b717cb45555458da4fed880a1" category="paragraph">Nahezu jede Applikation erfordert Datenreplizierung.</block>
  <block id="25fb1fa02f326334533a22c105ad3e69" category="paragraph">Auf der einfachsten Ebene kann Replikation eine Kopie auf einem externen Band oder eine Replikation auf Anwendungsebene an einem Standby-Standort bedeuten. Bei Disaster Recovery werden diese Replikatkopien verwendet, um bei einem katastrophalen Serviceausfall einen Service online zu schalten.</block>
  <block id="eab6cb3a1168ef2311865e6155b8272c" category="paragraph">ONTAP bietet mehrere Replizierungsoptionen, um eine Vielzahl von Anforderungen nativ innerhalb des Storage Array zu erfüllen und so ein breites Spektrum an Anforderungen abzudecken. Diese Optionen können die einfache Replizierung von Backups an einen Remote-Standort bis hin zu einer synchronen, voll automatisierten Lösung umfassen, die sowohl Disaster Recovery als auch Hochverfügbarkeit auf derselben Plattform bietet.</block>
  <block id="32df0c1cabf839652741a56bdaac7def" category="paragraph">Die primären ONTAP Replizierungstechnologien, die für Applikationen anwendbar sind, sind NetApp SnapMirror und NetApp SyncMirror. Es handelt sich nicht um Add-on-Produkte, sondern sie sind vollständig in ONTAP integriert und werden durch das einfache Hinzufügen eines Lizenzschlüssels aktiviert. Auch die Replizierung auf Storage-Ebene ist nicht die einzige Option. Replizierung auf Applikationsebene wie Oracle DataGuard kann ebenfalls in eine auf ONTAP basierende Datensicherungsstrategie integriert werden.</block>
  <block id="a2259fa074bae962e46ca7fc7aa31be1" category="paragraph">Die richtige Wahl hängt von den spezifischen Replizierungs-, Recovery- und Aufbewahrungsanforderungen ab.</block>
  <block id="0d3b37ff5855bf299f3c4a154373c1e2" category="section-title">ONTAP SnapMirror</block>
  <block id="296e89e943f5160d338484b3b705a44e" category="paragraph">SnapMirror ist die asynchrone Replizierungslösung von NetApp und eignet sich ideal für die Sicherung großer, komplizierter und dynamischer Datensätze wie Datenbanken und zugehöriger Applikationen. Die wichtigsten Werte lauten wie folgt:</block>
  <block id="d9f36dae2818ace926c4259271530724" category="list-text">*Manageability.* SnapMirror ist einfach zu konfigurieren und zu verwalten, da es ein nativer Teil der Speichersoftware ist. Es sind keine Add-on-Produkte erforderlich. Replizierungsbeziehungen lassen sich innerhalb von Minuten einrichten und direkt auf dem Storage-System managen.</block>
  <block id="8f761eff026903aa0140319f597d1fb0" category="list-text">*Einfachheit.* die Replikation basiert auf FlexVol-Volumes, die Container von LUNs oder Dateien sind, die als einheitliche konsistente Gruppe repliziert werden.</block>
  <block id="8b737d6a9db3de6436966db508cb51d4" category="list-text">*Effizienz.* Nachdem die erste Replikationsbeziehung hergestellt ist, werden nur Änderungen repliziert. Darüber hinaus bleiben Effizienzfunktionen wie Deduplizierung und Komprimierung erhalten und verringern die zu übertragende Datenmenge an einen Remote-Standort weiter.</block>
  <block id="0783dadb67ff77ed26bbfc5d80fa0cbd" category="list-text">*Flexibilität.* Spiegelungen können vorübergehend unterbrochen werden, um das Testen von Disaster-Recovery-Verfahren zu ermöglichen. Anschließend kann die Spiegelung problemlos wiederhergestellt werden, ohne dass eine vollständige Neuspiegelung erforderlich ist. Nur die geänderten Daten müssen angewendet werden, um die Spiegelungen wieder zu synchronisieren. Die Spiegelung kann auch umgekehrt werden, um eine schnelle Resynchronisierung nach dem Zwischenfall und nach der Rückkehr des ursprünglichen Standorts möglich zu machen. Schließlich stehen Lese- und Schreibklone replizierter Daten für Test und Entwicklung zur Verfügung.</block>
  <block id="8a00f09d8937e890f2cfb4d7acf72733" category="paragraph">ONTAP bietet zwar mehrere verschiedene Replizierungstechnologien, die größte Flexibilität ist jedoch SnapMirror, eine asynchrone Spiegelungsoption von Volume zu Volume.</block>
  <block id="80c8fae3d0b5dd100cc984d9ba3eced7" category="paragraph">Wie bereits erwähnt, ist ein FlexVol Volume die grundlegende Managementeinheit für Snapshot-basierte Backups und SnapRestore-basierte Recovery. Ein FlexVol Volume ist außerdem die Basiseinheit für die SnapMirror-basierte Replizierung. Der erste Schritt ist die Erstellung der Basisspiegelung des Quell-Volume auf das Ziel-Volume. Nach der Initialisierung dieser Spiegelbeziehung basieren alle nachfolgenden Vorgänge allein auf der Replikation der geänderten Daten.</block>
  <block id="c1020b1755f65f23643158ce6a4d22cc" category="paragraph">Aus Sicht der Recovery gelten die folgenden zentralen Werte für SnapMirror:</block>
  <block id="50bde20b37cd4d57fbff2b95f2f8ec97" category="list-text">SnapMirror Vorgänge lassen sich leicht verstehen und einfach automatisieren.</block>
  <block id="66162be45733f65fee4abb22e989eb78" category="list-text">Bei einer einfachen Aktualisierung eines SnapMirror Replikats müssen nur die Delta-Änderungen repliziert werden. Dies reduziert die Bandbreitenanforderungen und ermöglicht häufigere Updates.</block>
  <block id="a3b4fbe416387a4991ccaa8b325a68be" category="list-text">SnapMirror bietet hohe Granularität. Er basiert auf einfachen Volume-to-Volume-Beziehungen und ermöglicht die Erstellung von Hunderten von unabhängig gemanagten Replikaten und Replikationsintervallen. Die Replikation muss nicht eine Einheitslösung sein.</block>
  <block id="4e3785883ef3ccad9938d7e35e493057" category="list-text">Die Spiegelungsrichtung kann leicht umgekehrt werden, wobei die Fähigkeit erhalten bleibt, die Beziehung allein auf der Grundlage der Änderungen zu aktualisieren. Dies ermöglicht ein schnelles Failback, nachdem der primäre Standort nach einem Ausfall, wie z. B. einem Stromausfall, wieder in Betrieb genommen wurde. Nur die Änderungen müssen zurück zur Quelle synchronisiert werden.</block>
  <block id="8b8325381cf528eff12c1e678a3112f9" category="list-text">Spiegelungen können einfach beschädigt und effizient neu synchronisiert werden, um eine Wiederholung des Disaster Recovery-Verfahrens zu ermöglichen.</block>
  <block id="b1f45b7d95bfc815351fb649fa94b671" category="list-text">SnapMirror, das im vollen Replizierungsmodus auf Blockebene arbeitet, repliziert nicht nur die Daten eines Volumes, sondern auch die Snapshots. Diese Funktion bietet sowohl eine Kopie der Daten als auch einen vollständigen Satz von Backups am Disaster-Recovery-Standort.</block>
  <block id="ffafd9ae31dee51209961eb2453ac806" category="paragraph">Im versionsflexiblen Modus von SnapMirror können spezifische Snapshots repliziert und unterschiedliche Aufbewahrungszeiten am primären und sekundären Standort ermöglicht werden.</block>
  <block id="974658d7ac018cb945e78365b0a760fb" category="section-title">SnapMirror Synchronous</block>
  <block id="ffbf9d0ce29a631b6eae8b22c41ec95e" category="paragraph">SnapMirror Synchronous (SM-S) ist eine Erweiterung von SnapMirror, die eine synchrone RPO=0-Replizierung bietet. Sie wird besonders häufig in Storage-Architekturen eingesetzt, in denen nur ein Teil der gesamten Daten eine synchrone Spiegelung erfordert.</block>
  <block id="e8a45c4c0391895df78421904703c933" category="paragraph">SM-S kann in zwei leicht unterschiedlichen Modi, Sync und StrictSync, betrieben werden.</block>
  <block id="15a4e16195fb9d30c5df0e11df5c2166" category="paragraph">Im synchronen Modus werden Änderungen repliziert, bevor sie bestätigt werden. Dadurch wird ein RPO von Null garantiert, sofern die Replizierung betriebsbereit ist. Wenn die Änderung nicht repliziert werden kann, kann SM-S den synchronen Modus beenden und den Betrieb fortsetzen. Dies ermöglicht RPO=0 unter normalen Umständen, aber die Datenprozesse werden nicht vollständig angehalten, wenn das Replikationsziel nicht verfügbar ist.</block>
  <block id="115455025d4664c0dd6deaaf3c1fc93c" category="paragraph">StrictSync garantiert ein RPO=0. Ein Fehler beim Replizieren von Änderungen führt zu einem I/O-Fehler, der in der Regel zum Herunterfahren der Applikation führt.</block>
  <block id="1b1ea0d1ad6e5cfb06253a14fcdcfe71" category="inline-link">TR-4733</block>
  <block id="9ccd61d6efc86cc37743fdff385832e8" category="paragraph">Eine vollständige Erläuterung von SM-S finden Sie unter<block ref="4459b84726c651a8047a6486e87e48fb" category="inline-link-rx"></block> Und die offizielle ONTAP-Dokumentation. Die Funktionen werden kontinuierlich mit neuen Versionen von ONTAP ergänzt.</block>
  <block id="6165c4352e1504dbaeef34d0cc50c187" category="section-title">Konsistenzgruppen</block>
  <block id="0651e813e385dbd62a9bca9baee23c6c" category="paragraph">ONTAP ermöglicht die Erstellung von Konsistenzgruppen-Snapshots. Ab 9.13.1 kann ONTAP Gruppen von Volumes (wobei zu beachten ist, dass ein Volume in der ONTAP-Terminologie keine LUN, sondern ein Management-Container aus einer oder mehreren Dateien oder LUNs ist) als konsistente Gruppe replizieren.</block>
  <block id="80c6d3e933105ad9a2c104ec78444b8c" category="paragraph">Die SnapMirror-Replizierung und die Unterbrechung der CG SnapMirror-Beziehung gewährleisten die Konsistenz über Volumes hinweg, und SnapMirror Synchronous und SnapMirror Business Continuity bewahren beide die Konsistenz über einzelne Volumes hinweg.</block>
  <block id="455c7758003d6ebd974e8858f5ef1d7d" category="paragraph">Das Ergebnis: Sie können einen Datensatz mit mehreren Volumes replizieren und sicherstellen, dass alle Volumes Cross-konsistent sind. Dadurch werden u. a. die Spiegelungen unterbrochen und DR-Vorgänge unterbrochen, ohne dass zusätzliche Schritte zur Applikations- oder Datenbank-Recovery nötig sind.</block>
  <block id="c44a2da164b7b770fce6338a987670ee" category="section-title">MetroCluster und SyncMirror</block>
  <block id="b1a1cfbf3988d8abdfdedaabc1742ae9" category="paragraph">MetroCluster ist außerdem eine Lösung für synchrone Replizierung für umfangreiche geschäftskritische Workloads. Die Replizierung basiert auf SyncMirror. SyncMirror erstellt auf der einfachsten Ebene zwei vollständige Sätze RAID-geschützter Daten an zwei verschiedenen Orten. Sie könnten sich in angrenzenden Räumen innerhalb eines Datacenters oder sogar viele Kilometer voneinander entfernt befinden.</block>
  <block id="89b8adf28db7abb0febecafdca5871ad" category="paragraph">SyncMirror ist vollständig in ONTAP integriert und wird knapp über dem RAID Level ausgeführt. Daher funktionieren alle üblichen ONTAP-Funktionen wie Snapshot Kopien, SnapRestore und NetApp FlexClone nahtlos. Es handelt sich noch immer um ONTAP und umfasst nur eine zusätzliche Ebene der synchronen Datenspiegelung.</block>
  <block id="75c677fa68f5d15c17efbf6fd1fe1765" category="paragraph">Eine Sammlung von ONTAP Controllern, die SyncMirror-Daten managen, wird als NetApp MetroCluster-Konfiguration bezeichnet. Der Hauptzweck von MetroCluster ist es, Hochverfügbarkeit auf synchron gespiegelte Daten in einer Vielzahl von typischen und Disaster-Recovery-Ausfallszenarien zu bieten.</block>
  <block id="af845652f0234e1f71bc37e241ab63dc" category="paragraph">Die Datensicherung mit MetroCluster und SyncMirror hat folgende zentrale Vorteile:</block>
  <block id="9ab80c5e33e343c3415c21be433c4447" category="list-text">Im normalen Betrieb ermöglicht SyncMirror standortübergreifendes, synchrones Spiegeln. Ein Schreibvorgang wird erst dann bestätigt, wenn er auf nicht-flüchtigen Medien an beiden Standorten vorhanden ist.</block>
  <block id="680ccf94624c9f922ed236c8cc0c1af2" category="list-text">Wenn die Verbindung zwischen Standorten ausfällt, wechselt SyncMirror automatisch in den asynchronen Modus, damit der primäre Standort Daten bereitstellt, bis die Verbindung wiederhergestellt ist. Bei einer Wiederherstellung ermöglicht es eine schnelle Neusynchronisierung, indem die am primären Standort angesammelten Änderungen effizient aktualisiert werden. Eine vollständige Neuinitialisierung ist nicht erforderlich.</block>
  <block id="c18ec55908c635b68abe8c6edbf6476e" category="paragraph">SnapMirror ist zudem vollständig mit SyncMirror-basierten Systemen kompatibel. Beispielsweise kann eine primäre Datenbank auf einem MetroCluster Cluster ausgeführt werden, das über zwei geografische Standorte verteilt ist. Diese Datenbank kann Backups auch als langfristige Archive an einem dritten Standort oder zur Erstellung von Klonen in einer DevOps-Umgebung replizieren.</block>
  <block id="0660b44d1a6d7e0d905c3fe28eef63ab" category="summary">Verfahren für Oracle auf ONTAP DR mit Protokollversand</block>
  <block id="54bae719e8fa53582d5b2781b4952c6b" category="doc">Disaster Recovery mit Protokolleinspielung</block>
  <block id="3a8111f0b903472ec78531619bf984f6" category="paragraph">Die Replikationsverfahren für eine Oracle-Datenbank sind im Wesentlichen dieselben wie die Backup-Verfahren. Die primäre Anforderung besteht darin, dass die Snapshots, die ein wiederherstellbares Backup darstellen, auf das Remote-Speichersystem repliziert werden müssen.</block>
  <block id="c62b3abab4fdbaf8f0a84e8c3559b5fd" category="paragraph">Wie bereits in der Dokumentation zur lokalen Datensicherheit beschrieben, kann ein wiederherstellbares Backup mit dem Hot-Backup-Prozess oder mithilfe von Snapshot-optimierten Backups erstellt werden.</block>
  <block id="3d8f8c6a5c90bcd85a22fbd17390a864" category="inline-link-macro">Datenlayout</block>
  <block id="30394da99a39ca8264b8f7c0e6f679e0" category="paragraph">Die wichtigste Anforderung ist die Isolierung der Datendateien in einem oder mehreren dedizierten Volumes. Sie müssen durch einen anderen Dateityp nicht kontaminiert sein. Der Grund dafür ist, sicherzustellen, dass die Datendateireplikation völlig unabhängig von der Replikation anderer Datentypen wie Archivprotokollen ist. Weitere Informationen zu Dateilayouts und wichtige Informationen zur Sicherstellung der Snapshot-freundlichen Speicherlayouts finden Sie unter  <block ref="5a4fdf6a1fc411e544cf6d70d47a8289" category="inline-link-macro-rx"></block>.</block>
  <block id="f3f227cc5c07a040d61c36679053a58a" category="paragraph">Angenommen, die Datendateien sind in dedizierten Volumes eingekapselt. Die nächste Frage ist, wie die Wiederherstellungsprotokolle, Archivprotokolle und Steuerdateien gemanagt werden. Am einfachsten ist es, alle diese Datentypen in einem einzelnen Volume zu platzieren. Der Vorteil dabei ist, dass replizierte Wiederherstellungsprotokolle, Archivprotokolle und Steuerdateien perfekt synchronisiert sind. Es besteht keine Notwendigkeit für unvollständige Wiederherstellung oder die Verwendung einer Backup-controlfile, obwohl es wünschenswert sein könnte, auch Skript-Erstellung von Backup-controlfiles für andere potenzielle Recovery-Szenarien.</block>
  <block id="927992cbeccc8211e382c97e81514ef9" category="section-title">Zwei-Volumes-Layout</block>
  <block id="fe1cf96940a710dc95fd30bbb7533b52" category="paragraph">Das einfachste Layout ist in der folgenden Abbildung dargestellt.</block>
  <block id="57f1db4bdf2ce49a98f375d8393f02bf" category="paragraph">Dies ist der häufigste Ansatz. Aus der Perspektive eines DBAs mag es ungewöhnlich erscheinen, alle Kopien der Wiederherstellungs- und Archivprotokolle auf demselben Volume zu vermengen. Allerdings bietet Trennung keinen besonderen Schutz, wenn die Dateien und LUNs sich alle noch auf derselben zugrunde liegenden Laufwerkgruppe befinden.</block>
  <block id="bc46e4831ef5654d084e456c4c544a42" category="section-title">Layout mit drei Volumes</block>
  <block id="f6e969769d9d166122489505d676769b" category="paragraph">Gelegentlich ist eine Trennung von Wiederherstellungsprotokollen erforderlich, da Bedenken hinsichtlich der Datensicherung bestehen oder Redo-Log-I/O über Controller verteilt werden müssen. In diesem Fall wird das in der Abbildung unten abgebildete Layout mit drei Volumes für die Replikation verwendet, während gleichzeitig die Notwendigkeit einer unvollständigen Wiederherstellung vermieden oder auf Backup-Controller-Dateien angewiesen ist.</block>
  <block id="4957c2feaa2cb72d80a0ab65228ad43f" category="paragraph">Dies ermöglicht das Striping der Redo-Protokolle und Steuerdateien über unabhängige Sätze von Spindeln und Controllern auf der Quelle. Die Archivprotokolle und ein Satz von Steuerdateien und Wiederherstellungsprotokollen können jedoch weiterhin in einem synchronisierten Zustand mit den Archivprotokollen repliziert werden.</block>
  <block id="39128da64bc55500b4b11391aa54a011" category="paragraph">In diesem Modell wird das Redo-Protokoll-B-Volume nicht repliziert.</block>
  <block id="c0ce858e99375deac8274c96b7e5d0ee" category="section-title">Disaster-Recovery-Verfahren – Hot-Backups</block>
  <block id="6993729228512b7e23e3ff3ec9099f33" category="paragraph">Gehen Sie wie folgt vor, um eine Disaster Recovery mithilfe von Hot Backups durchzuführen:</block>
  <block id="ee68e5b99222bbc29a480fcb0d1d6ee2" category="section-title">Voraussetzungen</block>
  <block id="41bde9c586a860264c425700c48bd375" category="list-text">Oracle Binärdateien werden auf dem Disaster Recovery Server installiert.</block>
  <block id="cebf7cec81152da2cadffd580d81937f" category="list-text">Datenbankinstanzen sind in aufgeführt<block ref="2c0b0433aa1c96a2be6f40d9e71bc6af" prefix=" " category="inline-code"></block>.</block>
  <block id="17f8e5eda67237f2ca94c7dcce3e4022" category="list-text">Der<block ref="76a2173be6393254e72ffa4d6df1030a" prefix=" " category="inline-code"></block> Und<block ref="6b2f852f7f63f2e5d4be597bbca97bb6" prefix=" " category="inline-code"></block> Oder<block ref="1737629d60b511cf45957529a8f046e2" prefix=" " category="inline-code"></block> Die Instanz muss sich im befinden<block ref="45c7302d9c2e8745b3a2bff0f992b6df" prefix=" " category="inline-code"></block> Verzeichnis. .</block>
  <block id="645a84975202e30700b572b49a5ee29d" category="section-title">Disaster Recovery</block>
  <block id="25d18766964d7515e1f5acd893094f6e" category="list-text">Brechen Sie die Spiegelungen für die Datendateien und das gemeinsame Protokoll-Volume auf.</block>
  <block id="8fc655e4752d521563db3bfa138ba62e" category="list-text">Stellen Sie die Datendatei-Volumes auf den neuesten Hot-Backup-Snapshot der Datendateien wieder her.</block>
  <block id="68a9c75816a16f6d4f7572fe287961bf" category="list-text">Wenn SAN verwendet wird, aktivieren Sie Volume-Gruppen und/oder mounten Sie Dateisysteme.</block>
  <block id="312007510a0f0dc7878d4ed6a7a01554" category="list-text">Geben Sie Archivprotokolle bis zum gewünschten Punkt wieder.</block>
  <block id="e54b793d8bfa83bbb1bd965992c3474e" category="list-text">Wiederholen Sie die aktuellen Wiederherstellungsprotokolle, wenn eine vollständige Wiederherstellung gewünscht wird.</block>
  <block id="72e5734d53581f86093de5c97d8a3a24" category="paragraph">Die Verwendung von NFS vereinfacht diesen Vorgang erheblich, da die NFS-Filesysteme für Datendateien und Protokolldateien jederzeit auf den Disaster Recovery-Server gemountet werden können. Wenn die Spiegelungen beschädigt sind, wird es zu Lesen/Schreiben.</block>
  <block id="de4735bc5bbfdcae3d690313c739ad67" category="section-title">Disaster Recovery-Verfahren – Snapshot optimierte Backups</block>
  <block id="6b2b8ef11e5ded8a083372ba49d488d2" category="paragraph">Die Wiederherstellung von Snapshot-optimierten Backups ist mit dem Hot-Backup-Recovery-Verfahren mit den folgenden Änderungen fast identisch:</block>
  <block id="af1e49e7bc2b25ce36bd93df09433fb4" category="list-text">Stellen Sie die Datendatei-Volumes auf einem Snapshot wieder her, der vor dem aktuellen Replikat des Protokollvolumes erstellt wurde.</block>
  <block id="5e09669c98226c5d3a748f7e0f0333ad" category="paragraph">Diese Unterschiede vereinfachen das gesamte Recovery-Verfahren, da nicht sichergestellt werden muss, dass ein Snapshot ordnungsgemäß auf der Quelle erstellt wurde, während sich die Datenbank im Hot Backup-Modus befand. Das Disaster-Recovery-Verfahren basiert auf den Zeitstempeln der Snapshots auf dem Disaster-Recovery-Standort. Der Zustand der Datenbank, zu dem die Snapshots erstellt wurden, ist nicht wichtig.</block>
  <block id="81d6beef7eaf28bbce692d4b59888f3e" category="section-title">Disaster Recovery mit Hot-Backup-Snapshots</block>
  <block id="dc711b77f0d6a9c9ccf88b424509440a" category="paragraph">Dies ist ein Beispiel für eine Disaster-Recovery-Strategie, die auf der Replizierung von Hot-Backup-Snapshots basiert. Er ist auch ein Beispiel für eine einfache und skalierbare lokale Backup-Strategie.</block>
  <block id="edaef18e1c956b9284405fd664c4ca4a" category="paragraph">Die Beispieldatenbank befindet sich in einer grundlegenden Architektur mit zwei Volumes.<block ref="f006bf17b06c884c47190c4225d3215a" prefix=" " category="inline-code"></block> Enthält Datendateien und<block ref="894db1fc1592356880976f1b92c3e6a2" prefix=" " category="inline-code"></block> Wird für kombinierte Redo-Logs, Archivprotokolle und Steuerdateien verwendet.</block>
  <block id="fc0e7b6cd7cd15929987b1429d1c3a7e" category="paragraph">Es sind zwei Zeitpläne erforderlich, einer für die nächtlichen Datendatei-Backups und einer für die Protokolldatei-Backups. Diese werden Mitternacht bzw. 15 Minuten genannt.</block>
  <block id="44c0956347a70c78d2124c1041321049" category="paragraph">Diese Zeitpläne werden dann innerhalb der Snapshot-Richtlinien verwendet<block ref="44dc83cda2d6b3ce99cc25803e824061" prefix=" " category="inline-code"></block> Und<block ref="9b055600529d69c4ae0d2a9408dc7aa3" prefix=" " category="inline-code"></block>, Wie unten gezeigt:</block>
  <block id="180e86b8e3c5049779c98c2c1006bb15" category="paragraph">Diese Snapshot-Richtlinien werden schließlich auf die Volumes angewendet.</block>
  <block id="2887f2c14c7efbc97d53ac2f914c5657" category="paragraph">Dadurch wird der Backup-Zeitplan der Volumes definiert. Datendatei-Snapshots werden um Mitternacht erstellt und für 60 Tage aufbewahrt. Das Protokollvolumen enthält 72 Snapshots, die in 15-Minuten-Intervallen erstellt wurden, was bis zu 18 Stunden Abdeckung ergibt.</block>
  <block id="e1e5ef0e7100311d950b4ffebe040670" category="paragraph">Stellen Sie dann sicher, dass sich die Datenbank im Hot-Backup-Modus befindet, wenn ein Datendatei-Snapshot erstellt wird. Dies wird mit einem kleinen Skript gemacht, das einige grundlegende Argumente akzeptiert, die den Backup-Modus auf der angegebenen SID starten und stoppen.</block>
  <block id="683cdd7abd993faf3ace355cd6870b6f" category="paragraph">Dieser Schritt stellt sicher, dass sich die Datenbank während eines vierminütigen Fensters um den Mitternacht-Snapshot im Hot Backup-Modus befindet.</block>
  <block id="ccff7eb3ad0059a184886709c87f4889" category="paragraph">Die Replikation zum Disaster Recovery-Standort ist wie folgt konfiguriert:</block>
  <block id="42d3752a745fb0cdae528f6cc425b569" category="paragraph">Das Ziel des Protokollvolumes wird alle 15 Minuten aktualisiert. Somit wird eine RPO von etwa 15 Minuten erzielt. Das genaue Update-Intervall variiert ein wenig abhängig vom Gesamtvolumen der Daten, die während der Aktualisierung übertragen werden müssen.</block>
  <block id="e272424001d72919ad498e0e9d3c2cc4" category="paragraph">Das Ziel des Datendatei-Volumes wird alle sechs Stunden aktualisiert. Dies hat keine Auswirkung auf RPO oder RTO. Wenn eine Disaster-Recovery erforderlich ist, besteht einer der ersten Schritte darin, das Datendateivolume wieder auf einen Hot-Backup-Snapshot wiederherzustellen. Der Zweck des häufigeren Aktualisierungsintervalls besteht darin, die Übertragungsrate dieses Volumens zu glätten. Wenn die Aktualisierung einmal pro Tag geplant ist, müssen alle Änderungen, die während des Tages angesammelt wurden, gleichzeitig übertragen werden. Bei häufigeren Updates werden die Änderungen schrittweise im Laufe des Tages repliziert.</block>
  <block id="ce176ff569d716c1fa73d0754aba684b" category="paragraph">Im Falle eines Ausfalls besteht der erste Schritt darin, die Spiegelungen für beide Volumes zu unterbrechen:</block>
  <block id="4b9cdb6e2096c0828aeccd2ee5eecf42" category="paragraph">Die Replikate sind jetzt Lese-/Schreibzugriff. Im nächsten Schritt wird der Zeitstempel des Protokoll-Volumes überprüft.</block>
  <block id="b4d461e48f5be5d08f677045d11e8200" category="paragraph">Die neueste Kopie des Logvolumens ist der 14. März um 13:30:00.</block>
  <block id="96f75a4b63f4377efdf64d571d71caec" category="paragraph">Identifizieren Sie als Nächstes den Hot-Backup-Snapshot, der unmittelbar vor dem Status des Protokollvolumes erstellt wurde. Dies ist erforderlich, da die Protokollwiedergabe alle Archivprotokolle erfordert, die im Hot Backup-Modus erstellt wurden. Das Replikat des Protokollvolumes muss daher älter als die Hot-Backup-Images sein, da sonst die erforderlichen Protokolle nicht enthalten wären.</block>
  <block id="d358e4eb10a2f4e0b591e16941d7782c" category="paragraph">Der zuletzt erstellte Snapshot ist<block ref="c001e27abf0e66d13790bb8a7e00da54" prefix=" " category="inline-code"></block>. Hierbei handelt es sich um das neueste Hot-Backup-Image der Datendateien, das wie folgt wiederhergestellt wird:</block>
  <block id="d2037035a976c9be71cf6f372300c8c3" category="paragraph">In dieser Phase kann die Datenbank nun wiederhergestellt werden. Wenn es sich um eine SAN-Umgebung handelt, würde der nächste Schritt die Aktivierung von Volume-Gruppen und das Mounten von Dateisystemen umfassen, ein einfach automatisierter Prozess. Da in diesem Beispiel NFS verwendet wird, sind die Dateisysteme bereits gemountet und wurden in Schreib- und Lesezugriff eingebunden, ohne dass in dem Moment, in dem die Spiegelungen beschädigt wurden, eine weitere Bereitstellung oder Aktivierung erforderlich war.</block>
  <block id="2edce22eade45b42bc6b2665057fa082" category="paragraph">Die Datenbank kann jetzt bis zum gewünschten Zeitpunkt wiederhergestellt werden, oder sie kann in Bezug auf die Kopie der replizierten Wiederherstellungsprotokolle vollständig wiederhergestellt werden. Dieses Beispiel zeigt den Wert des kombinierten Archivprotokolls, der Steuerdatei und des Wiederherstellungsprotokolls. Der Recovery-Prozess ist drastisch einfacher, da es keine Notwendigkeit, auf Backup-Steuerdateien oder Reset-Protokolldateien verlassen.</block>
  <block id="51f74a82c7125b3b288755b6668091b1" category="section-title">Disaster Recovery mit Snapshot-optimierten Backups</block>
  <block id="3680a4757ddad43934237ab6a0ca955c" category="paragraph">Der Disaster-Recovery-Vorgang mithilfe von Snapshot optimierten Backups ist nahezu identisch mit dem Disaster-Recovery-Verfahren für Hot Backups. Wie beim Hot Backup Snapshot Verfahren ist es auch im Grunde eine Erweiterung einer lokalen Backup-Architektur, in der die Backups für die Disaster Recovery repliziert werden. Das folgende Beispiel zeigt das detaillierte Konfigurations- und Wiederherstellungsverfahren. Dieses Beispiel nennt auch die wichtigsten Unterschiede zwischen Hot Backups und Snapshot optimierten Backups.</block>
  <block id="330dadae5e2585726f41ed1f90e88f9f" category="paragraph">Die Beispieldatenbank befindet sich in einer grundlegenden Architektur mit zwei Volumes.<block ref="f006bf17b06c884c47190c4225d3215a" prefix=" " category="inline-code"></block> Enthält Datendateien, und<block ref="894db1fc1592356880976f1b92c3e6a2" prefix=" " category="inline-code"></block> Wird für kombinierte Redo-Logs, Archivprotokolle und Steuerdateien verwendet.</block>
  <block id="1669f47e046ce7e069e9d143f42e025d" category="paragraph">Es sind zwei Zeitpläne erforderlich: Eine für die nächtlichen Datendatei-Backups und eine für die Protokolldatei-Backups. Diese werden Mitternacht bzw. 15 Minuten genannt.</block>
  <block id="ef4adcab3e9bd572d0670f9f2073c311" category="paragraph">Dadurch wird der ultimative Backup-Plan der Volumes gesteuert. Snapshots werden um Mitternacht erstellt und 60 Tage aufbewahrt. Das Protokollvolumen enthält 72 Snapshots, die in 15-Minuten-Intervallen erstellt wurden, was bis zu 18 Stunden Abdeckung ergibt.</block>
  <block id="f9d5149b630a43ff5996adc26c6e1f08" category="paragraph">Das Ziel des Protokollvolumes wird alle 15 Minuten aktualisiert. Dadurch wird ein RPO von ca. 15 Minuten erreicht, wobei das genaue Update-Intervall etwas variiert, je nach dem Gesamtvolumen der Daten, die während der Aktualisierung übertragen werden müssen.</block>
  <block id="992398ebd9e9f825f0aa4415519abdba" category="paragraph">Das Datendatei-Volume-Ziel wird alle 6 Stunden aktualisiert. Dies hat keine Auswirkung auf RPO oder RTO. Wenn eine Disaster Recovery erforderlich ist, müssen Sie das Datendatei-Volume zunächst auf einem Hot-Backup-Snapshot wiederherstellen. Der Zweck des häufigeren Aktualisierungsintervalls besteht darin, die Übertragungsrate dieses Volumens zu glätten. Wenn die Aktualisierung einmal pro Tag geplant wurde, müssen alle Änderungen, die sich während des Tages angesammelt haben, gleichzeitig übertragen werden. Bei häufigeren Updates werden die Änderungen schrittweise im Laufe des Tages repliziert.</block>
  <block id="9e85b8590ac2f9ff5ebc8d1def51ae82" category="paragraph">Im Falle eines Ausfalls besteht der erste Schritt darin, die Spiegelungen für alle Volumes zu unterbrechen:</block>
  <block id="fd2834dcadb39f00eb897fdcdc07a03d" category="paragraph">Die neueste Kopie des Logvolumens ist der 14. März um 13:30. Identifizieren Sie als nächstes den Datendatei-Snapshot, der unmittelbar vor dem Status des Protokoll-Volumes erstellt wurde. Dies ist erforderlich, da für die Protokollwiedergabe alle Archivprotokolle von kurz vor dem Snapshot zum gewünschten Wiederherstellungspunkt erforderlich sind.</block>
  <block id="810e47566b9cd5aa3b28e6514ec95735" category="paragraph">Der zuletzt erstellte Snapshot ist<block ref="c001e27abf0e66d13790bb8a7e00da54" prefix=" " category="inline-code"></block>. Diesen Snapshot wiederherstellen.</block>
  <block id="87d83a0406ac6622efcdf91c42784ecd" category="paragraph">Die Datenbank kann nun wiederhergestellt werden. Wenn es sich um eine SAN-Umgebung handelt, würden Sie dann Volume-Gruppen aktivieren und Filesysteme mounten, ein einfach automatisierter Prozess. In diesem Beispiel wird jedoch NFS verwendet, d. h. die Dateisysteme sind bereits gemountet und wurden in Lese- und Schreibzugriff überführt. In dem Moment, in dem die Spiegelungen beschädigt wurden, ist keine weitere Bereitstellung oder Aktivierung erforderlich.</block>
  <block id="7a2e97f17454be76b7e522ce612ff961" category="paragraph">Die Datenbank kann jetzt bis zum gewünschten Zeitpunkt wiederhergestellt werden, oder sie kann in Bezug auf die Kopie der replizierten Wiederherstellungsprotokolle vollständig wiederhergestellt werden. Dieses Beispiel zeigt den Wert des kombinierten Archivprotokolls, der Steuerdatei und des Wiederherstellungsprotokolls. Der Wiederherstellungsvorgang ist wesentlich einfacher, da keine Notwendigkeit besteht, sich auf Backup-Steuerdateien oder Reset-Protokolldateien zu verlassen.</block>
  <block id="d6597945276340ba33115e737eb4b489" category="summary">Konsistenzgruppenreplizierung für Oracle-Datenbanken</block>
  <block id="fc506ae4ea109f50758acc176bcb5341" category="doc">Disaster Recovery für Konsistenzgruppen</block>
  <block id="5eda890cc07e4b7cd409730d8af8ddc3" category="paragraph">Die Replizierung von Konsistenzgruppen kann so einfach wie die Terminierung der Replizierung eines einzelnen Volumes über SnapMirror erfolgen. Dazu gehören Datendateien, Steuerdateien, Archivprotokolle und Wiederherstellungsprotokolle. Jedes SnapMirror Update führt zu einer neuen Kopie der Datenbank am Zielstandort, die konsistent und einsatzbereit ist, indem sie die Spiegelung bricht.</block>
  <block id="89cb1432594ce7c25dadf229401874e7" category="paragraph">Wenn eine Datenbank Volumes umfassen muss, ist ein Snapshot einer Konsistenzgruppe (cg-Snapshot) erforderlich.</block>
  <block id="f96b125d1bacc785389957041be148e9" category="paragraph">Ein weiterer Vorteil dieser Strategie bei Verwendung mit SnapMirror im Replizierungsmodus auf Blockebene ist die vollständige Replizierung aller Snapshots auf dem Quell-Storage-System. Neben der Disaster-Recovery-Kopie wird die volle Anzahl der Backups repliziert.</block>
  <block id="77fda44088666155052f9d4224878cbc" category="summary">Tiering von Oracle Archivprotokollen</block>
  <block id="113d9dffdeb8fa14877fc8cf8ca7c9d5" category="doc">Oracle Protokoll-Tiering</block>
  <block id="8625af69ad0b5f76799d87df777e3c86" category="paragraph">Die wahrscheinlich wichtigste Verwendung für FabricPool ist die Verbesserung der Effizienz bekannter, kalter Daten, wie z. B. Transaktions-Logs der Datenbank.</block>
  <block id="a98d546484d238b37b7e2584ae8d399d" category="summary">Backup-Tiering für Oracle</block>
  <block id="9f409a250e4be99904c9e90259cb747d" category="paragraph">Zu den herkömmlichen Applikations-Backups gehören Produkte wie der Oracle Recovery Manager, die dateibasierte Backups außerhalb des Standorts der Originaldatenbank erstellen.</block>
  <block id="6cddb309df5eb8791dc990f72ef2deb2" category="summary">Tiering-Richtlinien für Oracle</block>
  <block id="7ba3322dbc0b3c33a66f1963e80b7a2a" category="doc">Tiering-Richtlinien für Oracle Datenbanken</block>
  <block id="4627801bdbb24a1991e64f30a2d80cb1" category="paragraph">In ONTAP stehen vier Richtlinien zur Verfügung, die steuern, wie Oracle-Daten auf der Performance-Tier zu einem Kandidaten für die Verlagerung auf die Kapazitäts-Tier werden.</block>
  <block id="47f6817eca23122cc683f7c2759e6ecb" category="summary">Oracle Full Tile Tiering</block>
  <block id="1def0ac22a738b54cce584e969065918" category="doc">Vollständiges File Tiering für Oracle</block>
  <block id="2eea2725f31529888b5e57b36492819f" category="paragraph">FabricPool Tiering wird zwar auf Block-Ebene ausgeführt, kann jedoch in einigen Fällen für Tiering auf Dateiebene verwendet werden.</block>
  <block id="468853d9ed2134af17ede5fd165a8dff" category="summary">Partielles Datei-Tiering mit FabricPool</block>
  <block id="5638b2f30ee966b3ff84bac350092971" category="doc">Oracle ermöglicht ein partielles File Tiering</block>
  <block id="f935a501eae76f9c13d430bc3879cd0d" category="paragraph">Da FabricPool auf Block-Ebene arbeitet, können geänderte Dateien teilweise auf Objekt-Storage verschoben werden und dennoch nur teilweise auf Performance-Tier verbleiben.</block>
  <block id="dd22ff2cf158f98efbd92f4522b3064b" category="summary">Datenbankzugriff bei Unterbrechungen des Zugriffs auf Objektspeicher</block>
  <block id="cc4e17c26faf6b70b383529b6215ba0f" category="doc">Unterbrechungen des Zugriffs auf Objektspeicher</block>
  <block id="bbb21240a2cc48eb7a229ec824e70cdf" category="summary">Überblick über Oracle mit FabricPool Tiering</block>
  <block id="ec2ffb259f21d115e5481eb0f215aa0d" category="doc">Oracle Tiering – Überblick</block>
  <block id="ec35a176f3e7c086273baee0c7f374d5" category="paragraph">Um zu verstehen, wie sich FabricPool Tiering auf Oracle und andere Datenbanken auswirkt, benötigen Sie ein Verständnis der Low-Level-FabricPool-Architektur.</block>
  <block id="cd6b77e4d343896571bc445479f24588" category="summary">Abrufrichtlinien für Pracle Tiering</block>
  <block id="3bf6f5a455b1889775d79713ad4e19ed" category="doc">Abrufrichtlinien</block>
  <block id="6edf1821ddc55278229c2156f42905f0" category="paragraph">Die Tiering-Richtlinien steuern, welche Oracle-Datenbankblöcke von der Performance-Tier auf die Kapazitäts-Tier verschoben werden. Abrufrichtlinien steuern, was passiert, wenn ein gestaffeltes Block gelesen wird.</block>
  <block id="95ab96ac5aaeae15f7b499d0fa0313cf" category="summary">Oracle Snapshot Tiering</block>
  <block id="d01cbb2be77343ccdb1d3372c4b9891e" category="summary">Richtlinien zur Größenanpassung von Oracle Datenbanken und zur LUN-Anzahl</block>
  <block id="b9e88e2eb3d5eef807fc42db706d866a" category="doc">Größenanpassung von Oracle-LUNs und LUN-Anzahl</block>
  <block id="51f96d1f8b50084e3a2ddc21ceef8b2f" category="paragraph">Die Auswahl der optimalen LUN-Größe und der Anzahl der zu verwendenden LUNs ist für optimale Performance und einfaches Management der Oracle-Datenbanken von entscheidender Bedeutung.</block>
  <block id="3d1bd23e74923cdc48fe992d0687809f" category="summary">Oracle-Datenbanken und NFS Leasing und Locks</block>
  <block id="472f36eb81330c2c27f02245ce8a911e" category="doc">NFS Leasing und Locks - Oracle</block>
  <block id="cec6f8a988408ba212798e1cc32658c7" category="paragraph">NFSv3 ist statusfrei. Das bedeutet effektiv, dass der NFS-Server (ONTAP) nicht verfolgt, welche Dateisysteme gemountet sind, von wem oder welche Sperren tatsächlich vorhanden sind.</block>
  <block id="7c96331bd03e63c4eb3505c526b42244" category="paragraph">ONTAP verfügt über einige Funktionen, die Mount-Versuche aufzeichnen, sodass Sie eine Vorstellung davon haben, welche Clients möglicherweise auf Daten zugreifen, und es gibt möglicherweise Hinweissperren, aber diese Informationen sind nicht garantiert zu 100% vollständig. Es kann nicht vollständig sein, da die Nachverfolgung des NFS-Client-Status nicht Teil des NFSv3-Standards ist.</block>
  <block id="20733ad7135aa0ede95fd8637fe05cf6" category="section-title">Status der NFSv4-Daten</block>
  <block id="3f7c11f662fc6e07a91179fdf2322ef5" category="paragraph">Im Gegensatz dazu ist NFSv4 zustandsbehafteten. Der NFSv4-Server verfolgt, welche Clients welche Dateisysteme verwenden, welche Dateien existieren, welche Dateien und/oder Regionen von Dateien gesperrt sind usw. Dies bedeutet, dass eine regelmäßige Kommunikation zwischen einem NFSv4-Server erforderlich ist, um die Statusdaten auf dem aktuellen Stand zu halten.</block>
  <block id="6f7e4a1e570f45fa3db0b8a0ed80a38f" category="paragraph">Die wichtigsten Zustände, die vom NFS-Server verwaltet werden, sind NFSv4-Locks und NFSv4-Leases, und sie sind sehr miteinander verflochten. Sie müssen verstehen, wie jede einzelne von sich aus funktioniert und wie sie miteinander in Beziehung stehen.</block>
  <block id="0d55fd4062f29237d0fb3b7f666fb8eb" category="section-title">NFSv4-Sperren</block>
  <block id="bf4139ff42e411ae5483e062387b3f70" category="paragraph">Bei NFSv3 sind Sperren Empfehlung. Ein NFS-Client kann weiterhin „gesperrte“ Dateien ändern oder löschen. Eine NFSv3-Sperre läuft nicht von selbst ab, sie muss entfernt werden. Dies führt zu Problemen. Wenn Sie beispielsweise über eine geclusterte Applikation verfügen, die NFSv3-Sperren erstellt, und einer der Nodes ausfällt, wie gehen Sie vor? Sie können die Anwendung auf den verbleibenden Knoten codieren, um die Sperren zu entfernen, aber wie können Sie wissen, dass das sicher ist? Vielleicht ist der „ausgefallene“ Knoten funktionsfähig, kommuniziert aber nicht mit dem Rest des Clusters?</block>
  <block id="11d1c33ac6b190a233c00cdbdd6a355b" category="paragraph">Mit NFSv4 haben Sperren eine begrenzte Dauer. Solange der Client mit den Sperren weiterhin mit dem NFSv4-Server eincheckt, darf kein anderer Client diese Sperren erwerben. Wenn ein Client nicht mit dem NFSv4 eincheckt, werden die Sperren schließlich vom Server widerrufen und andere Clients können Sperren anfordern und erhalten.</block>
  <block id="c17985911e0182dc5e96c4d60aadf139" category="section-title">NFSv4-Leasing</block>
  <block id="596bcfef3aaccfe299bb45a969afcaf0" category="paragraph">NFSv4-Sperren sind einem NFSv4-Leasing zugeordnet. Wenn ein NFSv4-Client eine Verbindung mit einem NFSv4-Server herstellt, erhält er eine Leasing-Option. Wenn der Kunde eine Sperre erhält (es gibt viele Arten von Sperren), dann ist die Sperre mit dem Leasing verbunden.</block>
  <block id="b5248856b1835e14738aa32e053e30e0" category="paragraph">Diese Lease hat ein definiertes Timeout. Standardmäßig setzt ONTAP den Timeout-Wert auf 30 Sekunden:</block>
  <block id="7e2a66190f452806ac1183721a43eaa1" category="paragraph">Dies bedeutet, dass ein NFSv4-Client alle 30 Sekunden mit dem NFSv4-Server einchecken muss, um seine Mietverträge zu erneuern.</block>
  <block id="809c552ae0a4d377e87f495b4e3ac62b" category="paragraph">Der Lease wird automatisch durch jede Aktivität erneuert, sodass, wenn der Kunde arbeitet, keine zusätzlichen Operationen durchgeführt werden müssen. Wenn eine Anwendung still wird und keine echte Arbeit macht, muss sie stattdessen eine Art Keep-Alive-Vorgang (SEQUENZ genannt) durchführen. Es ist im Grunde nur sagen: "Ich bin immer noch hier, bitte aktualisieren Sie meine Mietverträge."</block>
  <block id="70cb78bb7e91dcafab559f9b72e40bb6" category="paragraph">NFSv3 ist statusfrei. Es wird keine Kommunikation der Clients erwartet. NFSv4 ist zustandsbehaftet. Sobald dieser Leasingzeitraum verstrichen ist, läuft der Leasingvertrag ab, Sperren werden aufgehoben und die gesperrten Dateien werden anderen Clients zur Verfügung gestellt.</block>
  <block id="2ee5d81cfa6306ae71ce534ed9b31431" category="paragraph">Mit NFSv3 können Sie Netzwerkkabel umlegen, Netzwerk-Switches neu booten, Konfigurationsänderungen vornehmen und ziemlich sicher sein, dass nichts Schlimmes passiert. Anwendungen würden normalerweise nur geduldig warten, bis die Netzwerkverbindung wieder funktioniert.</block>
  <block id="8900ff182e4197f8eb2acd7d2b7fd902" category="paragraph">Mit NFSv4 haben Sie 30 Sekunden (es sei denn, Sie haben den Wert dieses Parameters innerhalb von ONTAP erhöht), um Ihre Arbeit abzuschließen. Wenn Sie das überschreiten, Ihre Leasing-Zeit aus. Normalerweise führt dies zu einem Absturz der Anwendung.</block>
  <block id="ffa8c7744b3e2d43b18c67aec0fe7743" category="paragraph">Wenn Sie beispielsweise über eine Oracle-Datenbank verfügen und die Netzwerkverbindung (manchmal auch als „Netzwerkpartition“ bezeichnet) unterbrochen wird, die das Lease-Timeout überschreitet, stürzt die Datenbank ab.</block>
  <block id="33b9897348039594b4b17bf1e1629c74" category="paragraph">Dies ist ein Beispiel dafür, was im Oracle-Alarmprotokoll passiert, wenn dies geschieht:</block>
  <block id="85608585bf8e790a579c49ba9af705c6" category="paragraph">Wenn Sie sich die Syslogs ansehen, sollten Sie mehrere der folgenden Fehler sehen:</block>
  <block id="e19b338de53dada4cf4da3837aaba76d" category="paragraph">Die Protokollmeldungen sind in der Regel das erste Anzeichen eines Problems, das nicht durch das Einfrieren der Anwendung verursacht wird. In der Regel sehen Sie während des Netzwerkausfalls überhaupt nichts, da Prozesse und das Betriebssystem selbst blockiert sind und versuchen, auf das NFS-Dateisystem zuzugreifen.</block>
  <block id="7a3c8c17a9dd10fa565f79e0ebb5bba7" category="paragraph">Die Fehler werden angezeigt, nachdem das Netzwerk wieder betriebsbereit ist. Im obigen Beispiel hat das Betriebssystem versucht, die Sperren nach der Wiederherstellung der Verbindung erneut zu erfassen, aber es war zu spät. Der Mietvertrag war abgelaufen und die Schlösser wurden entfernt. Dies führt zu einem Fehler, der sich auf die Oracle-Ebene ausbreitet und die Meldung im Alarmprotokoll verursacht. Je nach Version und Konfiguration der Datenbank können Sie Abweichungen von diesen Mustern sehen.</block>
  <block id="4bec5e793e34a5819aefb68e4f65db26" category="paragraph">Zusammenfassend lässt sich sagen, dass NFSv3 eine Netzwerkunterbrechung toleriert, aber NFSv4 ist sensibler und sieht einen definierten Leasing-Zeitraum vor.</block>
  <block id="069de2d717910b2677190b9a9b5ed1cf" category="paragraph">Was ist, wenn eine 30-Sekunden-Zeitüberschreitung nicht akzeptabel ist? Was tun Sie, wenn Sie ein dynamisch verändertes Netzwerk verwalten, in dem Switches neu gestartet oder Kabel verlegt werden, und das Ergebnis ist eine gelegentliche Netzwerkunterbrechung? Sie könnten die Leasingdauer verlängern, aber ob Sie dies tun möchten, erfordert eine Erklärung der NFSv4-Kulanzzeiträume.</block>
  <block id="4b84416146795544deb5c9de89187f91" category="section-title">NFSv4-Kulanzzeiträume</block>
  <block id="7d98e091c5f7be92cd5fb85b985d8d20" category="paragraph">Wenn ein NFSv3 Server neu gestartet wird, ist er fast sofort in der Lage, I/O zu bedienen. Es war nicht die Aufrechterhaltung einer Art von Zustand über Kunden. Dies führt dazu, dass ein ONTAP-Übernahmevorgang oft fast unmittelbar zu erfolgen scheint. Sobald ein Controller bereit ist, mit der Datenbereitstellung zu beginnen, sendet er ein ARP an das Netzwerk, das die Änderung der Topologie signalisiert. Clients erkennen dies normalerweise nahezu sofort, und die Daten werden wieder fließend gespeichert.</block>
  <block id="173d4fd05086441236dbee4710639d10" category="paragraph">NFSv4 erzeugt jedoch eine kurze Pause. Nur ein Teil davon, wie NFSv4 funktioniert.</block>
  <block id="21483115213b27583a07dc2ca994671c" category="paragraph">NFSv4-Server müssen die Leasing-Optionen, Sperren und die Verwendung welcher Daten verfolgen. Wenn ein NFS-Server in Panik Gerät und neu startet oder einen Moment lang Strom verliert oder während der Wartungsaktivitäten neu gestartet wird, führt dies zu einer Lease/Sperre und zum Verlust anderer Clientinformationen. Der Server muss herausfinden, welcher Client welche Daten verwendet, bevor er den Betrieb wiederaufnehmen kann. Hier kommt die Kulanzzeit ins Spiel.</block>
  <block id="09b6f386094bd895d3c9694f28bfdf65" category="paragraph">Wenn Sie Ihren NFSv4-Server plötzlich aus- und wieder einschalten. Wenn es wieder verfügbar ist, erhalten Kunden, die versuchen, die E/A-Vorgänge fortzusetzen, eine Antwort, die im Wesentlichen besagt: „Ich habe die Leasing-/Sperrdaten verloren. Möchten Sie Ihre Sperren erneut registrieren?“ Das ist der Anfang der Gnadenfrist. Die Standardeinstellung ist 45 Sekunden bei ONTAP:</block>
  <block id="e4f8aa90af36d76254e2f02e56232aed" category="paragraph">Das Ergebnis ist, dass ein Controller nach einem Neustart I/O-Vorgänge pausiert, während alle Clients ihre Mietverträge und Sperren zurückfordern. Nach Ablauf der Kulanzzeit nimmt der Server die E/A-Vorgänge wieder auf.</block>
  <block id="bb2b26fdcb4e947cda6f8e38724ecfc9" category="section-title">Leasing-Timeouts im Vergleich zu Kulanzzeiträumen</block>
  <block id="563494d7f0f6ebcb6698cac7f9705aaa" category="paragraph">Die Kulanzzeit und die Leasingdauer sind miteinander verknüpft. Wie bereits erwähnt, beträgt das standardmäßige Leasingzeitlimit 30 Sekunden, was bedeutet, dass NFSv4-Clients mindestens alle 30 Sekunden beim Server einchecken müssen, oder sie verlieren ihre Leasingverhältnisse und damit ihre Sperren. Die Kulanzzeit ist vorhanden, um einem NFS-Server zu ermöglichen, Lease/Lock-Daten neu zu erstellen, und es ist standardmäßig 45 Sekunden. Für ONTAP muss die Kulanzzeit 15 Sekunden länger sein als die Leasingfrist. Dadurch wird sichergestellt, dass eine NFS-Client-Umgebung, die zur Verlängerung von Leasingverträgen mindestens alle 30 Sekunden entwickelt wurde, nach einem Neustart beim Server einchecken kann. Eine Nachfrist von 45 Sekunden sorgt dafür, dass alle Kunden, die erwarten, ihre Mietverträge mindestens alle 30 Sekunden auf jeden Fall die Möglichkeit haben, dies zu tun.</block>
  <block id="5e6b60906bbbb9a41b140c0749591489" category="paragraph">Wenn ein Timeout von 30 Sekunden nicht akzeptabel ist, können Sie die Leasingdauer verlängern. Wenn Sie das Lease-Timeout auf 60 Sekunden erhöhen möchten, um einem 60-Sekunden-Netzwerkausfall standzuhalten, müssen Sie die Kulanzzeit auf mindestens 75 Sekunden erhöhen. Für ONTAP muss die Laufzeit 15 Sekunden überschreiten. Das bedeutet, dass Sie längere I/O-Pausen während Controller-Failover erleben.</block>
  <block id="4611c7c931fc15a6feba513fe72e22de" category="paragraph">Das sollte normalerweise kein Problem sein. In der Regel aktualisieren ONTAP Controller nur ein oder zwei Mal pro Jahr, und ein ungeplanter Failover aufgrund von Hardwareausfällen ist äußerst selten. Darüber hinaus würden Sie bei einem Netzwerk, wo ein Netzwerkausfall von 60 Sekunden zu besorgen war und Sie eine Leasingzeit von 60 Sekunden benötigen, wahrscheinlich auch keinem seltenen Storage-System-Failover widersprechen, was zu einer Pause von 75 Sekunden führt. Sie haben bereits bestätigt, dass Sie ein Netzwerk haben, das ziemlich häufig über 60 Sekunden anhält.</block>
  <block id="c4fb6f7d31d205bc07dbff47d0ae4bb3" category="summary">Oracle Direct NFS</block>
  <block id="f58bdad9659176e411f064fdb414233f" category="doc">Oracle directNFS</block>
  <block id="1bd6ec1185ba67395dc6f9cd2b458ec8" category="paragraph">Oracle Databases können NFS auf zweierlei Weise verwenden.</block>
  <block id="96997ca5c577dd19a3ba5f7ff771f27a" category="paragraph">Zunächst kann es ein Dateisystem verwenden, das mit dem nativen NFS-Client gemountet ist, der Teil des Betriebssystems ist. Dies wird manchmal Kernel NFS oder kNFS genannt. Das NFS-Dateisystem ist gemountet und von der Oracle-Datenbank genau so verwendet wie jede andere Anwendung ein NFS-Dateisystem verwenden würde.</block>
  <block id="95c17c63df7ceea39a175b1d96955bb7" category="paragraph">Die zweite Methode ist Oracle Direct NFS (dNFS). Hierbei handelt es sich um eine Implementierung des NFS-Standards in der Oracle Datenbanksoftware. Die Art und Weise, wie Oracle-Datenbanken vom DBA konfiguriert oder verwaltet werden, bleibt unverändert. Sofern das Storage-System selbst die richtigen Einstellungen hat, sollte die Verwendung von dNFS für das DBA-Team und die Endanwender transparent sein.</block>
  <block id="43539d2fca21e5b644484efb94614a7b" category="paragraph">Eine Datenbank mit aktivierter dNFS-Funktion hat noch die üblichen NFS-Dateisysteme gemountet. Sobald die Datenbank geöffnet ist, öffnet die Oracle-Datenbank eine Reihe von TCP/IP-Sitzungen und führt NFS-Vorgänge direkt aus.</block>
  <block id="26e7ebad3936387b4b3f7c4f5688ef27" category="section-title">Direktes NFS</block>
  <block id="6d431a52c8a41a7c2335f98e2ae8c454" category="paragraph">Der Hauptwert von Direct NFS von Oracle besteht darin, den NFS-Client des Hosts zu umgehen und NFS-Dateivorgänge direkt auf einem NFS-Server auszuführen. Wenn Sie diese Option aktivieren, muss nur die Oracle Disk Manager (ODM)-Bibliothek geändert werden. Anweisungen zu diesem Prozess finden Sie in der Oracle-Dokumentation.</block>
  <block id="8401d91735209aeccbe56f33b4e2db73" category="paragraph">Die Verwendung von dNFS führt zu einer deutlichen Verbesserung der I/O-Performance und verringert die Last auf dem Host und dem Storage-System, da I/O so effizient wie möglich ausgeführt wird.</block>
  <block id="b0dedecb00787180a9e0c657cfb278c9" category="paragraph">Darüber hinaus enthält Oracle dNFS eine *Option* für Multipathing und Fehlertoleranz der Netzwerkschnittstelle. Beispielsweise können zwei 10-GB-Schnittstellen verbunden werden, um eine Bandbreite von 20 GB bereitzustellen. Ein Ausfall einer Schnittstelle führt dazu, dass die I/O-Vorgänge auf der anderen Schnittstelle wiederholt werden. Der gesamte Vorgang ähnelt dem FC-Multipathing. Multipathing war schon vor Jahren üblich, als 1 GB ethernet der häufigste Standard war. Für die meisten Oracle Workloads ist eine 10-Gbit-NIC ausreichend. Wird jedoch mehr benötigt, können 10-Gbit-NICs verbunden werden.</block>
  <block id="11e50b3c816105439151db3a3b4fdda3" category="paragraph">Wenn dNFS verwendet wird, ist es wichtig, dass alle Patches, die in Oracle Doc 1495104.1 beschrieben werden, installiert sind. Wenn ein Patch nicht installiert werden kann, muss die Umgebung überprüft werden, um sicherzustellen, dass die in diesem Dokument beschriebenen Fehler keine Probleme verursachen. In manchen Fällen kann dNFS nicht verwendet werden, da die erforderlichen Patches nicht installiert werden können.</block>
  <block id="8f98002fee392ad6151679875de1a7cc" category="paragraph">Verwenden Sie dNFS nicht mit Round-Robin-Namensauflösungen wie DNS, DDNS, NIS oder anderen Methoden. Dazu gehört auch die in ONTAP verfügbare DNS-Lastausgleichsfunktion. Wenn eine Oracle-Datenbank mit dNFS einen Hostnamen in eine IP-Adresse auflöst, darf sie sich bei nachfolgenden Suchen nicht ändern. Dies kann zu Abstürzen der Oracle-Datenbank und einer möglichen Beschädigung von Daten führen.</block>
  <block id="e80ad3efb180dc2d016b27506b7b24ce" category="section-title">Direkter NFS- und Host-Filesystem-Zugriff</block>
  <block id="4c38a8c0a49e721bf2a378d0b4fb2010" category="paragraph">Die Verwendung von dNFS kann gelegentlich Probleme für Applikationen oder Benutzeraktivitäten verursachen, die auf den sichtbaren Filesystemen basieren, die auf dem Host gemountet sind, da der dNFS-Client vom Host-Betriebssystem aus auf das Filesystem zugreift. Der dNFS-Client kann Dateien ohne Kenntnis des Betriebssystems erstellen, löschen und ändern.</block>
  <block id="c03389fdb295f2acb079603123e6d0e3" category="paragraph">Wenn die Mount-Optionen für Single-Instance-Datenbanken verwendet werden, ermöglichen sie das Caching von Datei- und Verzeichnisattributen, was auch bedeutet, dass der Inhalt eines Verzeichnisses zwischengespeichert wird. Daher kann dNFS eine Datei erstellen, und es gibt eine kurze Verzögerung, bevor das Betriebssystem den Verzeichnisinhalt erneut liest und die Datei für den Benutzer sichtbar wird. Dies ist in der Regel kein Problem, aber in seltenen Fällen können Dienstprogramme wie SAP BR*Tools Probleme haben. Beheben Sie in diesem Fall das Problem, indem Sie die Mount-Optionen ändern, um die Empfehlungen für Oracle RAC zu verwenden. Mit dieser Änderung wird das gesamte Host-Caching deaktiviert.</block>
  <block id="a370a203383b565c3fb746c1c2e1a64b" category="paragraph">Mount-Optionen nur ändern, wenn (a) dNFS verwendet wird und (b) ein Problem auf eine Verzögerung bei der Dateisichtbarkeit zurückzuführen ist. Wenn dNFS nicht verwendet wird, führt die Verwendung der Oracle RAC Mount-Optionen auf einer Single-Instance-Datenbank zu einer verminderte Performance.</block>
  <block id="b1ced01e4bbcd95ec43a2756131f8f9d" category="admonition">Siehe den Hinweis über<block ref="4740c034d97ca90a96b8050082816605" prefix=" " category="inline-code"></block> In <block ref="657185beb26ec14433f7e083717fa98b" category="inline-link-macro-rx"></block> Für ein Linux-spezifisches dNFS-Problem, das ungewöhnliche Ergebnisse liefern kann.</block>
  <block id="22a7a03175addfd9aa5b1fa2c351e833" category="summary">NFS-Konfiguration für Oracle Datenbanken</block>
  <block id="6cb2edd2369a17890dce007723d98a6f" category="paragraph">NetApp bietet seit über 30 Jahren NFS-Storage der Enterprise-Klasse. Seine Einsatzbereich wächst aufgrund der Einfachheit mit dem Trend zu Cloud-basierten Infrastrukturen.</block>
  <block id="95e0ac965f4d3a739263ba13584b6411" category="inline-link-macro">TR-4067 NFS on NetApp ONTAP Best Practices</block>
  <block id="c46e4d65876bc5d9253e8e293f59b613" category="paragraph">Das NFS-Protokoll umfasst mehrere Versionen mit unterschiedlichen Anforderungen. Eine vollständige Beschreibung der NFS-Konfiguration mit ONTAP finden Sie unter <block ref="e3fa0577f1d5ea8870d93a30eb76667f" category="inline-link-macro-rx"></block>. In den folgenden Abschnitten werden einige der kritischeren Anforderungen und häufigen Benutzerfehler behandelt.</block>
  <block id="0f8a941fcc56687ad8e3914162c19a41" category="section-title">NFS-Versionen</block>
  <block id="d0972be450ccf257fb73d4878bce204e" category="paragraph">Der NFS-Client des Betriebssystems muss von NetApp unterstützt werden.</block>
  <block id="7722a2ae10cef9bccea115dfdfe78a99" category="list-text">NFSv3 wird von Betriebssystemen unterstützt, die dem NFSv3 Standard folgen.</block>
  <block id="a3550edc6962850398d217f78cc4ad0d" category="list-text">NFSv3 wird vom Oracle dNFS-Client unterstützt.</block>
  <block id="89c45ebba54478419aa679a7ece8593d" category="list-text">NFSv4 wird von allen Betriebssystemen unterstützt, die dem NFSv4-Standard entsprechen.</block>
  <block id="471ff51c89daf6e35e8e2b5111039744" category="inline-link-macro">NetApp IMT</block>
  <block id="8594659e8c4292db778973052a30ab86" category="list-text">Für NFSv4.1 und NFSv4.2 ist ein spezieller Support für das Betriebssystem erforderlich. Konsultieren Sie die <block ref="d98f827de8e80b3365d5f4160c243cdc" category="inline-link-macro-rx"></block> Für unterstützte Betriebssysteme.</block>
  <block id="d1eb4c2a4d74705a5aa7945f734eff7c" category="list-text">Oracle dNFS Unterstützung für NFSv4.1 erfordert Oracle 12.2.0.2 oder höher.</block>
  <block id="d8bacc1a7a9d6baaeb962e367920593b" category="inline-link-macro">NetApp Support-Matrix</block>
  <block id="f16dcce07ca44aa38c7ebe3016b981b2" category="admonition">Der <block ref="f1e4f72fb4419d4270270c5ed1e0d9f6" category="inline-link-macro-rx"></block> Für NFSv3 und NFSv4 sind keine spezifischen Betriebssysteme enthalten. Alle Betriebssysteme, die der RFC entsprechen, werden in der Regel unterstützt. Wenn Sie die Online-IMT nach Unterstützung für NFSv3 oder NFSv4 suchen, wählen Sie kein bestimmtes Betriebssystem aus, da keine Treffer angezeigt werden. Alle Betriebssysteme werden implizit von der allgemeinen Richtlinie unterstützt.</block>
  <block id="26ed9768d6a659a9768842d903d0025f" category="section-title">Linux NFSv3 TCP-Slot-Tabellen</block>
  <block id="c56ec9836fbbd9c0a426a40fc71c265c" category="paragraph">TCP-Slot-Tabellen sind das NFSv3 Äquivalent zur Warteschlangentiefe des Host Bus Adapters (HBA). Diese Tabellen steuern die Anzahl der NFS-Vorgänge, die zu einem beliebigen Zeitpunkt ausstehen können. Der Standardwert ist normalerweise 16, was für eine optimale Performance viel zu niedrig ist. Das entgegengesetzte Problem tritt auf neueren Linux-Kerneln auf, die automatisch die Begrenzung der TCP-Slot-Tabelle auf ein Niveau erhöhen können, das den NFS-Server mit Anforderungen sättigt.</block>
  <block id="5270700baa50d07af667096293a27564" category="paragraph">Um eine optimale Performance zu erzielen und Performance-Probleme zu vermeiden, passen Sie die Kernel-Parameter an, die die TCP-Slot-Tabellen steuern.</block>
  <block id="5b29db1d99e19013580fa375a5f87fa5" category="paragraph">Führen Sie die aus<block ref="1a1e44f7a3390ed4647a7d5b7e8b08ed" prefix=" " category="inline-code"></block> Und beobachten Sie die folgenden Parameter:</block>
  <block id="8821adf56df4952370cfaa57ccaac68d" category="paragraph">Alle Linux-Systeme sollten enthalten<block ref="c5f48b899461d4c2b9ddc0b24ea87744" prefix=" " category="inline-code"></block>, Aber nur einige enthalten<block ref="6f72acaebcb9a0de6696aaf3508a6144" prefix=" " category="inline-code"></block>. Beide sollten auf 128 gesetzt werden.</block>
  <block id="3a954c4e5e8d5ac3af590651efc5a2cb" category="cell">Wenn diese Parameter nicht eingestellt werden, kann dies erhebliche Auswirkungen auf die Leistung haben. In einigen Fällen ist die Performance eingeschränkt, da das linux-Betriebssystem nicht genügend I/O ausgibt In anderen Fällen erhöht sich die I/O-Latenz, wenn das linux Betriebssystem versucht, mehr I/O-Vorgänge auszustellen, als gewartet werden kann.</block>
  <block id="837f157b2f309f5415420467f7643e3a" category="section-title">AdR und NFS</block>
  <block id="c0e7bb1383be0bf1268d1d70280bef6d" category="paragraph">Einige Kunden haben Performance-Probleme gemeldet, die auf übermäßig viele I/O-Vorgänge für Daten im führen<block ref="18ca3ed022c239421418de608ceb49c5" prefix=" " category="inline-code"></block> Standort. Das Problem tritt in der Regel erst auf, wenn sich viele Performance-Daten angesammelt haben. Der Grund für den übermäßigen I/O ist unbekannt, aber dieses Problem scheint darauf zurückzuführen zu sein, dass Oracle-Prozesse das Zielverzeichnis wiederholt auf Änderungen scannen.</block>
  <block id="99be2ae95d50120a7c33c818afda1834" category="paragraph">Entfernen des<block ref="79fea224ffd9e8111e4e87cab732464b" prefix=" " category="inline-code"></block> Und/oder<block ref="3504e2b0e7c968444314433be465518d" prefix=" " category="inline-code"></block> Mount-Optionen ermöglichen das Caching des Host-Betriebssystems und reduzieren die Storage-I/O-Level.</block>
  <block id="8950578c587f9503f949dfc6a274b611" category="admonition">*NetApp empfiehlt* nicht zu platzieren<block ref="18ca3ed022c239421418de608ceb49c5" prefix=" " category="inline-code"></block> Daten auf einem Filesystem mit<block ref="79fea224ffd9e8111e4e87cab732464b" prefix=" " category="inline-code"></block> Oder<block ref="3504e2b0e7c968444314433be465518d" prefix=" " category="inline-code"></block> Weil Performance-Probleme wahrscheinlich sind. Trennen<block ref="18ca3ed022c239421418de608ceb49c5" prefix=" " category="inline-code"></block> Daten an einen anderen Bereitstellungspunkt, falls erforderlich.</block>
  <block id="cdb92b4a73ae99cde4df55c06e20dd3c" category="section-title">Nur nfs-Rootonly und Mount-Rootonly</block>
  <block id="c1f0a21ee026237bef11139a30b07040" category="paragraph">ONTAP enthält die NFS-Option<block ref="77743dec92afc92eca95c255fd9333d7" prefix=" " category="inline-code"></block> Damit wird gesteuert, ob der Server NFS-Datenverkehrsverbindungen von hohen Ports akzeptiert. Als Sicherheitsmaßnahme ist es nur dem Root-Benutzer erlaubt, TCP/IP-Verbindungen über einen Quellport unter 1024 zu öffnen, da solche Ports normalerweise für die Verwendung durch das Betriebssystem und nicht für Benutzerprozesse reserviert sind. Durch diese Einschränkung wird sichergestellt, dass NFS-Datenverkehr von einem tatsächlichen Betriebssystem-NFS-Client stammt und kein schädlicher Prozess, der einen NFS-Client emuliert. Der Oracle dNFS-Client ist ein Benutzerspeichertreiber, aber der Prozess läuft als root, daher ist es in der Regel nicht erforderlich, den Wert von zu ändern<block ref="77743dec92afc92eca95c255fd9333d7" prefix=" " category="inline-code"></block>. Die Verbindungen werden von niedrigen Ports hergestellt.</block>
  <block id="832b4524bcec11d28ca777ef9cdb4084" category="paragraph">Der<block ref="eb6c1a5ecd1e17d4cd46fa5c9d415816" prefix=" " category="inline-code"></block> Die Option gilt nur für NFSv3. Er steuert, ob der RPC-MOUNT-Aufruf von Ports über 1024 akzeptiert wird. Wenn dNFS verwendet wird, läuft der Client wieder als root, so dass er Ports unter 1024 öffnen kann. Dieser Parameter hat keine Auswirkung.</block>
  <block id="57c47a1451485bec1ebb060afdf65cb4" category="paragraph">Prozesse, die Verbindungen mit dNFS über NFS Version 4.0 und höher öffnen, laufen nicht als Root und erfordern daher Ports über 1024. Der<block ref="77743dec92afc92eca95c255fd9333d7" prefix=" " category="inline-code"></block> Der Parameter muss auf disabled gesetzt werden, damit dNFS die Verbindung herstellen kann.</block>
  <block id="4dd73247734d116e5039cc04c4979f2c" category="paragraph">Wenn<block ref="77743dec92afc92eca95c255fd9333d7" prefix=" " category="inline-code"></block> Ist aktiviert, ist das Ergebnis ein Hängezustand während der Mount-Phase beim Öffnen von dNFS-Verbindungen. Der sqlplus-Ausgang sieht ähnlich aus wie folgt:</block>
  <block id="f62d72479920ff0f8dc9a3ca6f301b5d" category="paragraph">Der Parameter kann wie folgt geändert werden:</block>
  <block id="47fc6c6691aed3ba0dbdc66c7896c61b" category="admonition">In seltenen Fällen müssen Sie möglicherweise sowohl nfs-rootonly als auch Mount-rootonly auf disabled ändern. Wenn ein Server eine extrem große Anzahl von TCP-Verbindungen verwaltet, ist es möglich, dass keine Ports unter 1024 verfügbar sind und das Betriebssystem gezwungen ist, höhere Ports zu verwenden. Diese beiden ONTAP-Parameter müssen geändert werden, damit die Verbindung abgeschlossen werden kann.</block>
  <block id="10b4eb170fe7bd035f21e7d863796683" category="section-title">NFS-Export-Richtlinien: Superuser und setuid</block>
  <block id="98bfec37486e95443730cc3d462022fb" category="paragraph">Wenn sich Oracle-Binärdateien auf einer NFS-Freigabe befinden, muss die Exportrichtlinie Superuser- und setuid-Berechtigungen enthalten.</block>
  <block id="3c0699ba2c56cb17c145bbda5580ed67" category="paragraph">Für allgemeine Fileservices wie Home Directories der Benutzer verwendete Shared NFS-Exporte vernichten normalerweise den Root-Benutzer. Dies bedeutet, dass eine Anfrage des Root-Benutzers auf einem Host, der ein Dateisystem gemountet hat, als anderer Benutzer mit niedrigeren Berechtigungen neu zugeordnet wird. Dies hilft, Daten zu sichern, indem ein Root-Benutzer auf einem bestimmten Server daran gehindert wird, auf Daten auf dem freigegebenen Server zuzugreifen. Das setuid-Bit kann auch ein Sicherheitsrisiko in einer gemeinsam genutzten Umgebung darstellen. Mit dem setuid-Bit kann ein Prozess als ein anderer Benutzer ausgeführt werden als der Benutzer, der den Befehl aufruft. Beispielsweise wird ein Shell-Skript, das im Besitz von root war, mit dem setuid-Bit als root ausgeführt. Wenn dieses Shell-Skript von anderen Benutzern geändert werden könnte, könnte jeder Benutzer, der nicht root ist, einen Befehl als root ausgeben, indem er das Skript aktualisiert.</block>
  <block id="e341736b7d51c23cb7ef95615832e502" category="paragraph">Die Oracle-Binärdateien enthalten Dateien im Besitz von root und verwenden das setuid-Bit. Wenn Oracle-Binärdateien auf einer NFS-Freigabe installiert sind, muss die Exportrichtlinie die entsprechenden Superuser- und setuid-Berechtigungen enthalten. Im folgenden Beispiel enthält die Regel beides<block ref="1efaeada4e3307369aca511f5da0498a" prefix=" " category="inline-code"></block> Und Genehmigungen<block ref="0baea2f0ae20150db78f58cddac442a9" prefix=" " category="inline-code"></block> (Root)-Zugriff für NFS-Clients unter Verwendung der Systemauthentifizierung.</block>
  <block id="f1a0fa258c785ac546835a1a75017faf" category="section-title">Konfiguration von NFSv4/4.1</block>
  <block id="52f9ad2e353a42e61d9bf7dd9f59d0cb" category="paragraph">Für die meisten Applikationen gibt es kaum einen Unterschied zwischen NFSv3 und NFSv4. Applikations-I/O ist in der Regel sehr einfach I/O und nicht von einigen der erweiterten Funktionen, die in NFSv4 verfügbar sind, erheblich profitieren. Höhere Versionen von NFS sollten nicht aus Sicht des Datenbank-Storage als „Upgrade“ betrachtet werden, sondern als Versionen von NFS, die zusätzliche Features enthalten. Wenn beispielsweise die End-to-End-Sicherheit des kerberos Datenschutzmodus (krb5p) erforderlich ist, ist NFSv4 erforderlich.</block>
  <block id="5cee42a6ee353ec8d6538898f8e63d2d" category="inline-link">TR-4067 NFS on NetApp ONTAP Best Practices</block>
  <block id="1ca271e9db310f8a7fb925b114fd6811" category="paragraph">Der Wechsel zu NFSv4 ist komplizierter als einfach die Mount-Optionen von vers=3 auf vers=4.1 zu ändern. Eine ausführlichere Erläuterung der NFSv4-Konfiguration mit ONTAP, einschließlich Anleitungen zur Konfiguration des Betriebssystems, finden Sie unter<block ref="2d2395ce3ab8a9852abebca9822b9553" category="inline-link-rx"></block>. Die folgenden Abschnitte dieses TR erklären einige der Grundvoraussetzungen für die Verwendung von NFSv4.</block>
  <block id="a1dc4350330c061ae52050f5a3400e25" category="section-title">NFSv4-Domäne</block>
  <block id="c30669603c950b31f6093d8beaf8060a" category="paragraph">Eine vollständige Erklärung der NFSv4/4.1-Konfiguration geht über den Umfang dieses Dokuments hinaus, aber ein häufig aufgetretendes Problem ist eine Diskrepanz bei der Domänenzuordnung. Aus Sicht von sysadmin scheinen sich die NFS-Dateisysteme normal zu verhalten, aber Anwendungen melden Fehler über Berechtigungen und/oder setuid auf bestimmte Dateien. In einigen Fällen haben Administratoren fälschlicherweise festgestellt, dass die Berechtigungen der Anwendungsbinärdateien beschädigt wurden und chown- oder chmod-Befehle ausgeführt haben, wenn das eigentliche Problem der Domänenname war.</block>
  <block id="f0c6c8a632eeaa954640907ee1da277d" category="paragraph">Der NFSv4-Domänenname wird auf der ONTAP SVM festgelegt:</block>
  <block id="97a98ebe6ac1f4a8eaf69158419dd818" category="paragraph">Der NFSv4-Domänenname auf dem Host wird in festgelegt<block ref="60969252b5b8391a3378335ae420d2e8" prefix=" " category="inline-code"></block></block>
  <block id="4ade50e8135e817e75aa3086851eaaa8" category="paragraph">Die Domänennamen müssen übereinstimmen. Wenn dies nicht der Fall ist, werden ähnliche Zuordnungsfehler wie die folgenden in angezeigt<block ref="452905a167cf4509fd08acb964fdb20c" prefix=" " category="inline-code"></block>:</block>
  <block id="c0eb73bb35a4c58d87b330cd00f1986a" category="paragraph">Anwendungsbinärdateien, wie z. B. Oracle-Datenbank-Binärdateien, enthalten Dateien im Besitz von root mit dem setuid-Bit, was bedeutet, dass eine Diskrepanz in den NFSv4-Domänennamen Fehler beim Starten von Oracle verursacht und eine Warnung über die Eigentumsrechte oder Berechtigungen einer Datei namens enthält<block ref="dd440398b298ff16eb1188ba8afca6df" prefix=" " category="inline-code"></block>, Die sich im befindet<block ref="002f94d606ac06f290f33a5fcc67b264" prefix=" " category="inline-code"></block> Verzeichnis. Sie sollte wie folgt aussehen:</block>
  <block id="21cc6f8790de2a7022b344914915604e" category="paragraph">Wenn diese Datei mit der Eigentümerschaft von Niemand angezeigt wird, kann es ein Problem mit der NFSv4-Domänenzuordnung geben.</block>
  <block id="203f1cdb2421d34e9eb7391e03ffcaf6" category="paragraph">Um dies zu beheben, überprüfen Sie die<block ref="60969252b5b8391a3378335ae420d2e8" prefix=" " category="inline-code"></block> Datei mit der v4-id-Domain-Einstellung auf ONTAP und stellen Sie sicher, dass sie konsistent sind. Wenn dies nicht der Fall ist, nehmen Sie die erforderlichen Änderungen vor, und führen Sie aus<block ref="1c7ebfbcaa2681599e41320ed491ca91" prefix=" " category="inline-code"></block>, Und warten Sie einen Moment, bis sich die Änderungen fortpflanzen. Die Dateieigentümerschaft sollte dann ordnungsgemäß als root erkannt werden. Wenn ein Benutzer versucht hatte, ausgeführt zu werden<block ref="05f0da969f2e0e6ecf3ab445e1e665ad" prefix=" " category="inline-code"></block> Vor der Korrektur der Konfiguration der NFS-Domänen in dieser Datei muss möglicherweise ausgeführt werden<block ref="05f0da969f2e0e6ecf3ab445e1e665ad" prefix=" " category="inline-code"></block> Ein weiteres Jahr in der</block>
  <block id="51fb8677d45bb006235a9f8cbe477f6f" category="summary">NFS Attribute Caching-Datenbanken</block>
  <block id="4da0a3b9c2e8fc0df8844a41ac133401" category="doc">NFS Caching mit Datenbanken</block>
  <block id="748f6387bf49161b9a69b7bfd691dcd2" category="paragraph">Das Vorhandensein einer der folgenden Mount-Optionen bewirkt, dass das Host-Caching deaktiviert wird:</block>
  <block id="9f75df502ef11eaef4292c94110cb673" category="paragraph">Diese Einstellungen können sich stark negativ auf die Geschwindigkeit der Softwareinstallation, des Patches und der Backup-/Wiederherstellungsvorgänge auswirken. In manchen Fällen, insbesondere bei geclusterten Applikationen, sind diese Optionen unweigerlich erforderlich, weil die Cache-Kohärenz über alle Nodes im Cluster hinweg gewährleistet werden muss. In anderen Fällen verwenden Kunden diese Parameter irrtümlich und das Ergebnis ist ein unnötiger Leistungsschaden.</block>
  <block id="8d23519d53d6611bc42fef8dc4a432df" category="paragraph">Viele Kunden entfernen diese Mount-Optionen vorübergehend während der Installation oder dem Patching der Binärdateien der Anwendung. Diese Entfernung kann sicher durchgeführt werden, wenn der Benutzer überprüft, dass während der Installation oder des Patching-Prozesses keine anderen Prozesse aktiv das Zielverzeichnis verwenden.</block>
  <block id="f73bede4039d47664f70de3c2d1f2b46" category="summary">LVM Stripe-Konfiguration für Oracle-Datenbanken</block>
  <block id="7844f2cc495a938f3039da5801958506" category="doc">LVM Striping mit Oracle Datenbanken</block>
  <block id="1b5681ffc153e25d2a48ae3f3f01b9f5" category="paragraph">LVM-Striping bezieht sich auf die Verteilung von Daten über mehrere LUNs. So lässt sich die Performance vieler Datenbanken deutlich steigern.</block>
  <block id="358b9a846de3e04b423c68bac9bc6d53" category="summary">LUN-Ausrichtung mit Oracle Datenbanken</block>
  <block id="c4cb2c6af5d7b6c38cd7e588d846e8b4" category="doc">LUN-Ausrichtung für Oracle I/O</block>
  <block id="3e00e4d28b17eedd6f6c2c38233e06a8" category="paragraph">LUN-Ausrichtung bezieht sich auf die I/O-Optimierung in Bezug auf das zugrunde liegende Filesystem-Layout.</block>
  <block id="a6c7e85d51ae3b98197ceb3eafa3686a" category="inline-link-macro">Effizienz</block>
  <block id="8b91f52c07f84050ec607efaba519342" category="paragraph">Weitere Informationen finden Sie auch in der Diskussion zur Blockausrichtung der Komprimierung im Abschnitt <block ref="507b43f44c8d150acacbc8cc7264d717" category="inline-link-macro-rx"></block>. Jedes Layout, das an 8-KB-Komprimierungsblockgrenzen ausgerichtet ist, ist auch an 4-KB-Grenzen ausgerichtet.</block>
  <block id="6e2524d5663b2bdc0c7985fa3e57cc55" category="section-title">Warnungen wegen Falschausrichtung</block>
  <block id="79e721357e358d77c4700c25c863fc37" category="inline-link">ONTAP SAN-Host-Konfiguration</block>
  <block id="268b1da3f1ff11d32e385d0223101718" category="paragraph">Die Ausrichtung in Solaris-Umgebungen ist komplizierter. Siehe<block ref="2d33e0364c07dc165b4079892340d4fe" category="inline-link-rx"></block> Finden Sie weitere Informationen.</block>
  <block id="6d017248f1e4f0ec7e2cd19d967b6bee" category="cell">Achten Sie in Solaris x86-Umgebungen besonders auf die richtige Ausrichtung, da die meisten Konfigurationen mehrere Ebenen von Partitionen haben. Solaris x86-Partitionsschichten befinden sich in der Regel oben auf einer Standard-Master-Bootdatensammelpartitionstabelle.</block>
  <block id="b1230060a0220caf9d68d64b9dd85e6f" category="summary">NFS-Transfergröße mit Oracle</block>
  <block id="fabe34ed4a5e432f4d1c4f6584956d8d" category="doc">NFS-Transfergröße mit Oracle Datenbanken</block>
  <block id="1e207db9a7c8127a6c43c771b89254fb" category="paragraph">Standardmäßig beschränkt ONTAP die NFS-I/O-Größe auf 64K.</block>
  <block id="72d22e3b9af95e272859e64eb1d82df7" category="paragraph">Zufälliger I/O mit den meisten Applikationen und Datenbanken verwendet eine viel kleinere Blockgröße, die weit unter dem 64K-Maximum liegt. Der I/O großer Blöcke wird in der Regel parallelisiert, sodass die 64K-Maximalgröße auch keine Einschränkung für die Erzielung der maximalen Bandbreite darstellt.</block>
  <block id="ebf61afddb34d070825eb696bea48813" category="paragraph">Es gibt einige Workloads, bei denen das 64K-Maximum eine Einschränkung darstellt. Insbesondere Vorgänge in einem einzigen Thread, wie Backup- oder Recovery-Vorgänge oder ein vollständiger Tabellenscan in einer Datenbank, laufen schneller und effizienter, wenn die Datenbank weniger, aber größere I/OS ausführen kann. Die optimale I/O-Handhabungsgröße für ONTAP beträgt 256 KB.</block>
  <block id="b0a5b394f3a29e64573049cda19fbacc" category="paragraph">Die maximale Übertragungsgröße für eine bestimmte ONTAP SVM kann wie folgt geändert werden:</block>
  <block id="b070b82d66be7116d5fd6dfd8172351b" category="cell">Verringern Sie niemals die maximal zulässige Übertragungsgröße auf ONTAP unter den Wert rsize/wsize der aktuell gemounteten NFS-Dateisysteme. Dies kann bei einigen Betriebssystemen zu Hängebleiben oder sogar Datenbeschädigungen führen. Wenn beispielsweise NFS-Clients derzeit auf 65536 rsize/wsize gesetzt sind, dann könnte die maximale Übertragungsgröße für ONTAP ohne Auswirkung auf die Clients selbst begrenzt werden, zwischen 65536 und 1048576 angepasst werden. Wenn Sie die maximale Übertragungsgröße unter 65536 verringern, können die Verfügbarkeit oder die Daten beeinträchtigt werden.</block>
  <block id="a5c97d9c3645b9a26e3febeb4bc95e24" category="summary">ASM Reclamation Utility mit ONTAP</block>
  <block id="861a5ecc95a8478c750be41bf2ddd6f5" category="doc">ASM Reclamation Utility und Zero-Block Detection</block>
  <block id="8eb703f2756cafd21dbac4f23c0d6416" category="paragraph">Bei aktivierter Inline-Komprimierung entfernt ONTAP effizient Blöcke, die auf Dateien oder LUNs geschrieben werden, auf Null gesetzt. Dienstprogramme wie das Oracle ASM Reclamation Utility (ASRU) schreiben Nullen in ungenutzte ASM-Extents.</block>
  <block id="1f65360ea8eb578d0ace3d58c460f3dc" category="paragraph">Auf diese Weise können DBAs nach dem Löschen von Dateien Speicherplatz im Speicher-Array zurückgewinnen. ONTAP fängt die Nullen ab und hebt den Speicherplatz von der LUN ab. Die Rückgewinnung erfolgt äußerst schnell, da innerhalb des Storage-Systems keine Daten geschrieben werden.</block>
  <block id="9de53c14f2bae0c5d4b6e19be495ee94" category="paragraph">Aus der Datenbankperspektive enthält die ASM-Datenträgergruppe Nullen, und das Lesen dieser Bereiche der LUNs würde zu einem Strom von Nullen führen, ONTAP speichert die Nullen jedoch nicht auf Laufwerken. Stattdessen werden einfache Metadatenänderungen vorgenommen, die intern die Bereiche, in denen der Wert auf Null gesetzt wurde, als leer von Daten markieren.</block>
  <block id="06348c6e795160187e298a91b25a37a3" category="paragraph">Aus ähnlichen Gründen sind Performance-Tests mit gelöschten Daten nicht gültig, da Blöcke mit Nullen tatsächlich nicht als Schreibvorgänge innerhalb des Storage-Arrays verarbeitet werden.</block>
  <block id="cee584f1e6223f6dbb73c0d64d599228" category="admonition">Stellen Sie bei der Verwendung von ASRU sicher, dass alle von Oracle empfohlenen Patches installiert sind.</block>
  <block id="17ff263bc6eb701aecb8e79f9ef53efd" category="summary">LUN- und LVM-Größe mit Oracle-Datenbanken</block>
  <block id="e0327f97ac271a738dd1ac6b182a4369" category="doc">LUN-Größe und LVM-basierte Größenanpassung</block>
  <block id="ff15e8b125dae74c1231f09380e48886" category="paragraph">Wenn ein SAN-basiertes Dateisystem seine Kapazitätsgrenze erreicht hat, gibt es zwei Möglichkeiten, den verfügbaren Speicherplatz zu erhöhen:</block>
  <block id="827be6b2fb8e678a5bd56af225ba21d1" category="list-text">Erhöhen Sie die Größe der LUNs.</block>
  <block id="1948e4ed4d6efa0efb6adb5ab56bfcb2" category="list-text">Fügen Sie einer vorhandenen Volume-Gruppe eine LUN hinzu und vergrößern Sie die enthaltenen logischen Volumes.</block>
  <block id="4182200437c090276a01ad8ca54076b0" category="summary">Konfigurieren von NVFAIL zum Schutz von Oracle-Datenbanken</block>
  <block id="60e002164f8988e984cf4a95b240f19d" category="doc">Oracle und NVFAIL</block>
  <block id="370bdf5dd39278264774ea595054e243" category="paragraph">NVFAIL ist eine Funktion von ONTAP, die in katastrophalen Failover-Szenarien die Integrität sicherstellt.</block>
  <block id="80250c1f1d70fc693877be6f22cc134e" category="paragraph">Datenbanken sind bei Storage Failover-Ereignissen anfällig für Beschädigungen, da große interne Caches verfügbar sind. Wenn ein katastrophales Ereignis das Erzwingen eines ONTAP-Failovers oder das Erzwingen einer MetroCluster-Umschaltung erfordert, kann das Ergebnis, unabhängig vom Zustand der Gesamtkonfiguration, effektiv verworfen werden. Der Inhalt des Storage-Arrays springt zurück in die Zeit, und der Status des Datenbank-Cache entspricht nicht mehr dem Status der Daten auf der Festplatte. Diese Inkonsistenz führt zu Datenbeschädigung.</block>
  <block id="68114defc717054e7e3b02df438cdbe1" category="paragraph">Caching kann auf Applikations- oder Serverebene erfolgen. Beispielsweise werden in einer Oracle RAC-Konfiguration (Real Application Cluster) mit Servern, die sowohl auf einem primären Standort als auch an einem Remote-Standort aktiv sind, Daten innerhalb des Oracle SGA zwischengespeichert. Bei einem erzwungenen Switchover-Vorgang, der zu einem Datenverlust führte, würde die Datenbank beschädigt werden, da die im SGA gespeicherten Blöcke möglicherweise nicht mit den Blöcken auf der Festplatte übereinstimmen.</block>
  <block id="162de6d405c04ce8f152f1d246ed9187" category="paragraph">Eine weniger offensichtliche Verwendung von Caching erfolgt auf der Ebene des Betriebssystems. Blöcke aus einem gemounteten NFS-Filesystem können im OS zwischengespeichert werden. Alternativ kann ein geclustertes Filesystem, das auf LUNs am primären Standort basiert, auf Servern am Remote-Standort gemountet werden, und wieder einmal konnten Daten zwischengespeichert werden. Ein Ausfall von NVRAM oder eine erzwungene Übernahme oder ein erzwungenes Switchover kann in diesen Situationen zu einer Beschädigung des File-Systems führen.</block>
  <block id="04ca8d9ad570a3bdf1d76e23bc108ae5" category="paragraph">ONTAP schützt Datenbanken und Betriebssysteme vor diesem Szenario mit NVFAIL und den zugehörigen Einstellungen.</block>
  <block id="41392c0810a247913390639ac55b02f3" category="inline-link-macro">NVFAIL mit HA-Paaren</block>
  <block id="c85e3cf60aca3604436a612414b4862b" category="inline-link-macro">NVFAIL mit MetroCluster</block>
  <block id="4c81a151f262848af64b7c3617f2957f" category="paragraph">Für wichtige zusätzliche Informationen lesen Sie bitte <block ref="7dd171303802b4fd88eb6286775f7e90" category="inline-link-macro-rx"></block> Und <block ref="d70bba050e7743789ce865415fea7eaf" category="inline-link-macro-rx"></block></block>
  <block id="45293b650c7dacd88d269bebf219b8ef" category="summary">Die schnelle Wiederherstellung von Oracle Datenbanken in ONTAP anhand einer Snapshot Kopie wird durch NetApp SnapRestore Technologie ermöglicht.</block>
  <block id="82ef718f4ebe0c276814ee3d51e33361" category="doc">SnapRestore</block>
  <block id="863696626734d6591db8be57b41c7eec" category="paragraph">Die schnelle Datenwiederherstellung in ONTAP anhand eines Snapshots wird durch die NetApp SnapRestore Technologie ermöglicht.</block>
  <block id="9099b669f87419bc03914f11f5779c60" category="paragraph">Wenn ein kritischer Datensatz nicht verfügbar ist, laufen die geschäftskritischen Prozesse ab. Tapes können beschädigt werden und selbst Restores aus festplattenbasierten Backups können die Übertragung über das Netzwerk verlangsamen. SnapRestore vermeidet diese Probleme durch eine nahezu sofortige Wiederherstellung der Datensätze. Selbst Datenbanken im Petabyte-Bereich lassen sich in wenigen Minuten vollständig wiederherstellen.</block>
  <block id="b02fb7dec22d0e276ca01cc60b9efb48" category="paragraph">Es gibt zwei Arten von SnapRestore: Datei-/LUN-basiert und Volume-basiert.</block>
  <block id="520e4b70b10aa2755a82b77e438a510f" category="list-text">Einzelne Dateien oder LUNs lassen sich innerhalb von Sekunden wiederherstellen, egal ob es sich um eine 2-TB-LUN oder eine 4-KB-Datei handelt.</block>
  <block id="45e8a84fe4ac58c8b30a7bdaf17c0b7f" category="list-text">Der Container von Dateien oder LUNs kann innerhalb von Sekunden wiederhergestellt werden, egal ob es sich um 10 GB oder 100 TB an Daten handelt.</block>
  <block id="4be4677be8cd434956b9b9af515b971a" category="paragraph">Ein „Container mit Dateien oder LUNs“ würde sich normalerweise auf ein FlexVol Volume beziehen. Beispielsweise können Sie 10 LUNs aufweisen, aus denen sich eine LVM-Festplattengruppe in einem einzelnen Volume befindet. Alternativ kann ein Volume die NFS-Home-Verzeichnisse von 1000 Benutzern speichern. Anstatt für jede einzelne Datei oder jedes LUN einen Wiederherstellungsvorgang auszuführen, können Sie das gesamte Volume als einzelnen Vorgang wiederherstellen. Der Prozess funktioniert auch mit horizontal skalierbaren Containern, die mehrere Volumes enthalten, wie z. B. eine FlexGroup oder eine ONTAP-Konsistenzgruppe.</block>
  <block id="a8d6a4d1b7fc6e1f60bb0ab716b4e72f" category="paragraph">Der Grund, warum SnapRestore so schnell und effizient arbeitet, liegt in der Natur einer Snapshot-Kopie, die im Grunde eine parallele schreibgeschützte Ansicht der Inhalte eines Volumes zu einem bestimmten Zeitpunkt ist. Aktive Blöcke sind die realen Blöcke, die geändert werden können, während der Snapshot eine schreibgeschützte Ansicht des Status der Blöcke ist, die die Dateien und LUNs zum Zeitpunkt der Snapshot-Erstellung ausmachen.</block>
  <block id="55abea92d64d6738f9e0ed48799696e7" category="paragraph">ONTAP erlaubt nur schreibgeschützten Zugriff auf Snapshot-Daten, die Daten können jedoch mit SnapRestore reaktiviert werden. Der Snapshot wird als Lese-/Schreibansicht der Daten wieder aktiviert und gibt die Daten in ihren vorherigen Zustand zurück. SnapRestore kann auf Volume- oder Dateiebene betrieben werden. Die Technologie ist im Wesentlichen die gleiche mit ein paar geringfügigen Unterschiede im Verhalten.</block>
  <block id="f10f2af75e2770a8ed3c2fde594e986d" category="section-title">Volume SnapRestore</block>
  <block id="ca9846346bc3b03cdec10f9fff456866" category="paragraph">Volume-basierte SnapRestore stellt das gesamte Datenvolumen in einen früheren Zustand zurück. Dieser Vorgang erfordert keine Datenverschiebung, d. h., der Wiederherstellungsprozess erfolgt im Wesentlichen unmittelbar, obwohl die Verarbeitung der API- oder CLI-Vorgänge einige Sekunden dauern kann. Die Wiederherstellung von 1 GB Daten ist nicht komplizierter und zeitaufwändiger als die Wiederherstellung von 1 PB Daten. Diese Funktion ist der Hauptgrund dafür, dass viele Enterprise-Kunden zu ONTAP Storage-Systemen migrieren. Die RTO wird in Sekunden für selbst größte Datensätze gemessen.</block>
  <block id="627436e77bb011a6a312ae87b12f98ea" category="paragraph">Ein Nachteil von Volume-basierten SnapRestore ist die Tatsache, dass Änderungen innerhalb eines Volumes im Laufe der Zeit kumuliert werden. Daher sind jeder Snapshot und die Daten der aktiven Datei von den bis zu diesem Zeitpunkt vorgenommenen Änderungen abhängig. Das Zurücksetzen eines Volumes in einen früheren Zustand bedeutet, dass alle nachfolgenden Änderungen, die an den Daten vorgenommen wurden, verworfen werden. Weniger offensichtlich ist jedoch, dass dies nachträglich erstellte Snapshots einschließt. Das ist nicht immer wünschenswert.</block>
  <block id="5c956f2c1cfc5b9e5bac32ad1acba314" category="paragraph">Beispielsweise kann in einem SLA für die Datenaufbewahrung eine nächtliche Sicherung von 30 Tagen festgelegt werden. Wenn ein Datensatz auf einen vor fünf Tagen mit Datenträger SnapRestore erstellten Snapshot wiederhergestellt wird, werden alle in den letzten fünf Tagen erstellten Snapshots verworfen und dies verstößt gegen den SLA.</block>
  <block id="8bf9e697004f47ed6133aef724a8a42c" category="paragraph">Es gibt eine Reihe von Optionen, um diese Einschränkung zu beheben:</block>
  <block id="ad3b75456e625de5fe347fb918f59a22" category="list-text">Daten können von einem früheren Snapshot kopiert werden, anstatt eine SnapRestore des gesamten Volumes durchzuführen. Diese Methode eignet sich am besten für kleinere Datensätze.</block>
  <block id="90541eb74c7c56cadc2f90ec6fb6f0c0" category="list-text">Ein Snapshot kann geklont und nicht wiederhergestellt werden. Die Einschränkung dieses Ansatzes besteht darin, dass der Quell-Snapshot eine Abhängigkeit des Klons ist. Daher kann sie nur gelöscht oder in ein unabhängiges Volume aufgesplittet werden.</block>
  <block id="ab6045d3463c0f68ce2fa405dce9d554" category="list-text">Verwendung von dateibasiertem SnapRestore.</block>
  <block id="7f7599a8b92846b691484dc91e090164" category="section-title">File SnapRestore</block>
  <block id="f03eebe4f07d362dbfe4c1d4e76c724d" category="paragraph">Bei File-basierten SnapRestore handelt es sich um einen granulareren Snapshot-basierten Wiederherstellungsprozess. Anstatt den Status eines gesamten Volume zurückzusetzen, wird der Status einer einzelnen Datei oder LUN zurückgesetzt. Es müssen keine Snapshots gelöscht werden. Durch diesen Vorgang wird auch keine Abhängigkeit von einem vorherigen Snapshot erzeugt. Die Datei oder LUN ist im aktiven Volume sofort verfügbar.</block>
  <block id="e432fdcc277fc74a1b2b94cfeec8a7d2" category="paragraph">Bei einem SnapRestore Restore einer Datei oder eines LUN sind keine Datenverschiebungen erforderlich. Einige interne Metadaten-Updates sind jedoch erforderlich, um abzubilden, dass die zugrunde liegenden Blöcke in einer Datei oder einem LUN jetzt sowohl in einem Snapshot als auch in dem aktiven Volume vorhanden sind. Die Performance sollte sich nicht auswirken, doch bei diesem Prozess wird die Erstellung von Snapshots blockiert, bis dieser abgeschlossen ist. Die Verarbeitungsrate beträgt ca. 5 Gbit/s (18 TB/Stunde), basierend auf der Gesamtgröße der wiederhergestellten Dateien.</block>
  <block id="a68b31b502bf7555cda2514354e553c2" category="summary">ONTAP Datensicherungsstrategien</block>
  <block id="6bb9a5aec98309d1414b32f7e0751415" category="doc">Planung der Datensicherheit</block>
  <block id="45c46768a1cb073f0d13245a0dc816f2" category="paragraph">Die richtige Datensicherungsarchitektur hängt von den geschäftlichen Anforderungen für die Datenaufbewahrung, Recovery-Fähigkeit und Ausfalltoleranz bei verschiedenen Ereignissen ab.</block>
  <block id="46e1b2893bdb002c0ede448cbfe1cb14" category="paragraph">Betrachten Sie beispielsweise die Anzahl der im Umfang enthaltenen Applikationen, Datenbanken und wichtigen Datensätze. Die Entwicklung einer Backup-Strategie für einen einzelnen Datensatz gewährleistet, dass die Compliance mit typischen SLAs relativ unkompliziert ist, da nicht viele Objekte zu managen sind. Je mehr Datensätze es gibt, desto komplizierter wird das Monitoring und Administratoren müssen sich zunehmend mit dem Vermeiden von Backup-Fehlern befassen. Wenn eine Umgebung also die Skalierung von Cloud- und Service-Provider-Umgebungen erreicht, braucht es einen ganz anderen Ansatz.</block>
  <block id="b70d233428e03d072b1134a97d853ab2" category="paragraph">Die Datensatzgröße wirkt sich auch auf die Strategie aus. Es gibt beispielsweise viele Optionen für Backup und Recovery mit einer Datenbank mit 100 GB, da die Datenmenge so klein ist. Das einfache Kopieren der Daten von Backup-Medien mit herkömmlichen Tools bietet normalerweise eine ausreichende RTO für die Recovery. Eine 100-TB-Datenbank benötigt normalerweise eine komplett andere Strategie, es sei denn, das RTO erlaubt einen mehrtägigen Ausfall. In diesem Fall könnte ein herkömmliches Backup und Recovery auf Basis von Kopien akzeptabel sein.</block>
  <block id="64848fee9c168231f5d0f13322ed0a87" category="paragraph">Schließlich gibt es Faktoren, die nicht dem Backup- und Recovery-Prozess selbst unterliegen. Gibt es zum Beispiel Datenbanken, die kritische Produktionsaktivitäten unterstützen, was das Recovery zu einem seltenen Ereignis macht, das nur von erfahrenen DBAs durchgeführt wird? Sind Datenbanken alternativ Teil einer großen Entwicklungsumgebung, in der häufig ein Recovery erfolgt und von einem IT-Team mit Generalisten gemanagt wird?</block>
  <block id="e26b57887de9a65c0316a87d49bf6c44" category="section-title">Ist ein Snapshot eine Sicherung?</block>
  <block id="c3fd105ab426caff0a0ade2e93476543" category="paragraph">Ein häufig vorgebrachter Einwand gegen die Verwendung von Snapshots als Datensicherungsstrategie ist die Tatsache, dass sich die „echten“ Daten und die Snapshot-Daten auf denselben Laufwerken befinden. Der Verlust dieser Laufwerke würde sowohl zum Verlust der Primärdaten als auch des Backups führen.</block>
  <block id="12d1adb01d24027626b2a47660fb5b81" category="paragraph">Das ist ein berechtigte Anliegen. Lokale Snapshots werden für tägliche Backup- und Recovery-Anforderungen verwendet, in dieser Hinsicht ist der Snapshot ein Backup. Beinahe 99 % aller Recovery-Szenarien in NetApp Umgebungen basieren auf Snapshots, um selbst die anspruchsvollsten RTO-Anforderungen zu erfüllen.</block>
  <block id="fc34c9966c8ecb7307468637d9e79933" category="paragraph">Lokale Snapshots sollten jedoch nie die einzige Backup-Strategie sein. Aus diesem Grund bietet NetApp Technologien wie SnapMirror Replizierung, mit denen Snapshots schnell und effizient auf einen unabhängigen Laufwerkssatz repliziert werden können. In einer richtig konzipierten Lösung mit Snapshots und Snapshot-Replikation kann die Verwendung von Tapes auf ein vierteljährliches Archiv minimiert oder ganz eliminiert werden.</block>
  <block id="1ea948130a9dbbc02e3a80648a99ff57" category="section-title">Backups von Konsistenzgruppen</block>
  <block id="9b234a126e57777ab83807827d4e7078" category="paragraph">Bei einem Konsistenzgruppenbackup wird der Status eines Datensatzes (oder mehrerer Datensätze) zu einem einzelnen atomischen Zeitpunkt erfasst. Als Datenbankbeispiel umfasst dies alle Datenbankkomponenten, z. B. Datendateien, Protokolldateien und andere Dateien, die direkt mit der Datenbank verknüpft sind. Dies funktioniert mit fast allen relationalen Datenbankprodukten, einschließlich Oracle RDBMS, Microsoft SQL Server, SAP HANA, PostgreSQL, MySQL und MariaDB. Der Schutz einer VMware-Konfiguration mit einer Consistency Group-Sicherung wäre ähnlich - Erfassung aller Datenspeicher und potenziell der ESX-Boot-LUNs in einem einzigen atomaren Point-in-Time.</block>
  <block id="5a1f7038c74e54c08669efa6722f1091" category="paragraph">Die Erstellung eines solchen Snapshots einer Konsistenzgruppe simuliert im Wesentlichen einen Absturz. Aus diesem Grund werden solche Backups häufig als Crash-konsistente Backups bezeichnet. Es gibt manchmal Bedenken bei der Unterstützung für Recovery-Szenarien, aber es ist wichtig zu verstehen, dass in der Regel kein Recovery-Verfahren erforderlich ist. Wenn die Anwendung nach dem Wiederherstellen einer Consistency Group-Sicherung gestartet wird, führt sie die üblichen Protokollwiederherstellungsprozesse, Wiederholungen von Dateisystemjournalen und andere Aufgaben aus, um alle I/O-Vorgänge, die am Zeitpunkt des Backups im laufenden Vorgang waren, wiederzugeben. Die Anwendung startet dann wie gewohnt.</block>
  <block id="aebdbddec25f7eba6434244a989fb659" category="paragraph">Somit können grundsätzlich alle Applikationen geschützt werden, die einem Stromausfall oder Serverabsturz ohne Datenbeschädigung standhalten. Dass dies funktioniert, zeigt sich auch an der großen Zahl an Applikationen, die mit synchronen und asynchronen Spiegelungsprodukten vieler verschiedener Anbieter geschützt sind. Wenn plötzlich am primären Standort ein Notfall eintritt, enthält der Replikatstandort zum Zeitpunkt des Ausfalls ein konsistentes Abbild der ursprünglichen Umgebung. Auch hier ist kein besonderes Recovery-Verfahren erforderlich.</block>
  <block id="e085ffefd89f8fb66260a9720e3fb6f8" category="paragraph">Der RPO für diesen Ansatz ist in der Regel auf den Punkt des Backups begrenzt. Im Allgemeinen beträgt der RPO-Mindestwert für Snapshots mit einem einzigen Volume eine Stunde. Zum Beispiel sind 48 stündliche Schnappschüsse plus weitere 30 Tage nächtlicher Schnappschüsse vernünftig und würden nicht die Aufbewahrung einer übermäßigen Anzahl von Snapshots erfordern. Ein RPO von unter einer Stunde ist schwieriger zu erreichen. Es wird nicht empfohlen, ohne zuvor die NetApp Professional Services einzuarbeiten, um sich mit den Anforderungen in Bezug auf Umgebung, Skalierung und Datensicherung vertraut zu machen.</block>
  <block id="1fe119a790b393b7dd7e79b63f15f52b" category="paragraph">Die RTO kann in der Regel in Sekunden gemessen werden. Eine Anwendung wird heruntergefahren, die Volumes wiederhergestellt und die Anwendung neu gestartet.</block>
  <block id="444cd304758b7607c8f7a3f627a5bc1f" category="paragraph">Am einfachsten legen Sie alle Dateien oder LUNs in einer einzelnen Volume-Konsistenzgruppe ab, wodurch die Erstellung von Snapshots direkt in ONTAP geplant werden kann. Wenn ein Datensatz über mehrere Volumes erstrecken muss, ist ein KonsistenzgruppenSnapshot (cg-Snapshot) erforderlich. Dies kann mit System Manager oder RESTful API-Aufrufen konfiguriert werden. Außerdem ist SnapCenter in der Lage, einen einfachen KonsistenzgruppenSnapshot auf einer definierten Liste von Volumes zu erstellen.</block>
  <block id="689b0155b42a554594a44cddc736eb67" category="section-title">Architektur für Replizierung und Disaster Recovery</block>
  <block id="1749d12df3df2319d3eee218a277ff83" category="inline-link-macro">MetroCluster</block>
  <block id="7b8111b0a2fc76252bbacbbc9de542a4" category="inline-link-macro">SnapMirror Business Continuity</block>
  <block id="96a7c86d5bc52a478876c48dc6dcc9f0" category="paragraph">In diesem Abschnitt geht es um die Remote-Datensicherung, bei der Daten zum sicheren externen Storage und zur Disaster Recovery an einen Remote-Standort repliziert werden. Beachten Sie, dass diese Tabellen keine Datensicherung für die synchrone Spiegelung berücksichtigen. Informationen zu dieser Anforderung finden Sie in der NetApp MetroCluster-Dokumentation einschließlich <block ref="5c964f26ec7fbbad5ac67aaa5dcf9269" category="inline-link-macro-rx"></block> Und <block ref="30831ec866621e18e7521d6c2750acaa" category="inline-link-macro-rx"></block></block>
  <block id="f443592081a2b3ddc55b94abe49ba128" category="paragraph">Das DR RPO wird durch die verfügbare Netzwerkbandbreite und die Gesamtgröße der zu sichernden Daten begrenzt. Nach der Erstellung des ersten Basistransfers basieren die Updates nur auf den geänderten Daten. Dies ist in der Regel ein geringer Prozentsatz des gesamten Datacenter-Platzbedarfs, obwohl es Ausnahmen gibt.</block>
  <block id="89e87a831dae60244ba34496d70fd45d" category="paragraph">Beispielsweise weist eine 10-TB-Datenbank mit einer wöchentlichen Änderungsrate von 10 % im Schnitt eine Gesamtänderung von 6 GB pro Stunde auf. Mit 10 GB Konnektivität benötigt diese Datenbank etwa sechs Minuten für die Übertragung. Die Änderungsrate unterliegt Schwankungen der Änderungsrate der Datenbank, sollte jedoch insgesamt ein Update-Intervall von 15 Minuten und somit ein RPO von 15 Minuten erreichbar sein. Wenn es 100 solche Datenbanken gibt, dann sind 600 Minuten erforderlich, um die Daten zu übertragen. Daher ist ein RPO von einer Stunde nicht möglich. Ebenso kann ein Replikat einer einzelnen Datenbank mit einer Größe von 100 TB mit einer wöchentlichen Änderungsrate von 10 % nicht innerhalb einer Stunde zuverlässig aktualisiert werden.</block>
  <block id="3c886a803aef21f5ac9f7bcea7408cbb" category="paragraph">Zusätzliche Faktoren können sich auf die Replikation auswirken, wie etwa der Overhead für die Replikation und Einschränkungen bei der Anzahl gleichzeitiger Replikationsvorgänge. Die Gesamtplanung einer Replikationsstrategie für ein einzelnes Volume kann jedoch auf der verfügbaren Bandbreite basieren, und ein Replikations-RPO von einer Stunde ist im Allgemeinen erreichbar. Ein RPO von unter einer Stunde ist schwieriger zu erreichen und sollte erst nach Rücksprache mit den NetApp Professional Services durchgeführt werden. In einigen Fällen sind 15 Minuten mit einer sehr guten Site-to-Site-Netzwerkverbindung möglich. Wenn jedoch insgesamt ein RPO von unter einer Stunde erforderlich ist, liefert die Architektur für die Wiedergabe mehrerer Volumes bessere Ergebnisse.</block>
  <block id="5e2cbdd214e7a73bca1af8ed5cc04626" category="paragraph">Das RTO mit Konsistenzgruppenreplikation in einem Disaster Recovery-Szenario ist ausgezeichnet, das aus Storage-Sicht in Sekunden gemessen wird. Der übersichtlichste Ansatz besteht darin, die Spiegelung zu zerbrechen und die Datenbank zu starten. Der Start der Datenbank dauert in der Regel ca. 10 Sekunden, aber sehr große Datenbanken mit vielen protokollierten Transaktionen können einige Minuten dauern.</block>
  <block id="1c18c939e73ddb1ceee34e8a33079d1a" category="paragraph">Der wichtigere Faktor bei der Bestimmung der RTO ist nicht das Speichersystem, sondern die Anwendung und das Host-Betriebssystem, auf dem es ausgeführt wird. Die replizierten Daten können beispielsweise in ein oder zwei Sekunden verfügbar gemacht werden, aber dies stellt nur die Daten dar. Es muss auch ein korrekt konfiguriertes Betriebssystem mit Anwendungsbinärdateien vorhanden sein, um die Daten verwenden zu können.</block>
  <block id="6fab898feea25b9d7fd4477911b90b31" category="paragraph">In einigen Fällen haben Kunden Disaster-Recovery-Instanzen schon vor der Zeit vorbereitet, da der Speicher auf Betriebssystemen vorerkannt wurde. In diesen Fällen erfordert die Aktivierung des Disaster-Recovery-Szenarios nicht mehr als das Brechen einer Spiegelung und das Starten der Anwendung. In anderen Fällen können das Betriebssystem und die zugehörigen Applikationen neben der Datenbank als ESX Virtual Machine Disk (VMDK) gespiegelt werden. In diesen Fällen hängt der RPO davon ab, wie viel ein Kunde in die Automatisierung investiert hat, um die VMDK schnell zu booten und damit die Applikationen zu starten.</block>
  <block id="c7d5d755b896edf43189fbb020202913" category="paragraph">Die Aufbewahrungszeit wird zum Teil durch das Snapshot Limit gesteuert. Volumes in ONTAP haben beispielsweise eine Grenze von 1024 Snapshots. In einigen Fällen haben Kunden die Replikation multipliziert, um das Limit zu erhöhen. Wenn zum Beispiel 2000 Tage Backups erforderlich sind, kann eine Quelle auf zwei Volumes repliziert werden, wobei Aktualisierungen an alternativen Tagen stattfinden. Dies erfordert eine Erhöhung des anfänglichen Platzbedarfs, stellt aber dennoch einen wesentlich effizienteren Ansatz dar als ein herkömmliches Backup-System, bei dem mehrere vollständige Backups durchgeführt werden müssen.</block>
  <block id="7ec0f114b69016879106b5018cdf10b9" category="section-title">Konsistenzgruppe in einem einzelnen Volume</block>
  <block id="cd70f3e596e275fe80fbbe5d7858ce1a" category="paragraph">Am einfachsten werden alle Dateien oder LUNs in einer einzigen Volume-Konsistenzgruppe abgelegt, wodurch SnapMirror und SnapVault Updates direkt im Storage-System geplant werden können. Es ist keine externe Software erforderlich.</block>
  <block id="909e8df57072d0b3c6d7d64b11acb571" category="section-title">Konsistenzgruppe mit mehreren Volumes</block>
  <block id="c7371eded617935ace6c71a33cfbf3fd" category="paragraph">Wenn eine Datenbank über mehrere Volumes hinweg erstellt werden muss, ist ein KonsistenzgruppenSnapshot (cg-Snapshot) erforderlich. Wie oben erwähnt, kann dies mit System Manager- oder RESTful-API-Aufrufen konfiguriert werden. Außerdem kann SnapCenter einen einfachen KonsistenzgruppenSnapshot auf einer definierten Liste von Volumes erstellen.</block>
  <block id="9c991b38c054d7bec0632efd6667540c" category="paragraph">Des Weiteren sollte die Verwendung von konsistenten Snapshots mit mehreren Volumes für Disaster Recovery zusätzlich berücksichtigt werden. Bei der Aktualisierung mehrerer Volumes kann es zu einer Katastrophe kommen, während noch ein Transfer durchgeführt wird. Das Ergebnis wäre ein Satz von Volumes, die nicht konsistent sind. In diesem Fall müssen einige Volumes in einen früheren Snapshot-Zustand zurückgesetzt werden, um ein Datenbank-Image zu liefern, das ausfallkonsistent und einsatzbereit ist.</block>
  <block id="fad8a5f46ebd89f74383b461e32dd6b9" category="section-title">Disaster Recovery: Aktivierung</block>
  <block id="5ac319591298468b0af89c2c469201f8" category="paragraph">Der Prozess zur Aktivierung der Disaster Recovery-Kopie hängt vom Speichertyp ab. Mit NFS können die Dateisysteme auf dem Disaster Recovery-Server vorgemountet werden. Sie befinden sich im schreibgeschützten Zustand und werden Lese- und Schreibzugriff, wenn die Spiegelung beschädigt ist. Dadurch verkürzen sich die RPO-Werte, und der gesamte Disaster Recovery-Prozess ist zuverlässiger, da weniger Teile gemanagt werden müssen.</block>
  <block id="b829fc11ff11b57af8d4632d38d7d7e8" category="paragraph">Die Aktivierung von SAN-Konfigurationen im Falle einer Disaster Recovery wird komplizierter. Die einfachste Option besteht im Allgemeinen darin, die Spiegelungen vorübergehend zu unterbrechen und die SAN-Ressourcen zu mounten, einschließlich Schritte wie das Erkennen der LVM-Konfiguration (einschließlich anwendungsspezifischer Funktionen wie Oracle Automatic Storage Management [ASM]) und das Hinzufügen von Einträgen zu /etc/fstab.</block>
  <block id="335a5796fb106a877544d121062534be" category="paragraph">Dies führt dazu, dass die LUN-Gerätepfade, Namen von Volume-Gruppen und andere Gerätepfade dem Zielserver bekannt werden. Diese Ressourcen können dann heruntergefahren und anschließend die Spiegelungen wiederhergestellt werden. Als Folge dessen befindet sich ein Server, durch den die Applikation schnell online geschaltet werden kann. Die einzelnen Schritte zur Aktivierung von Volume-Gruppen, zum Mounten von Dateisystemen oder zum Starten von Datenbanken und Anwendungen lassen sich einfach automatisieren.</block>
  <block id="b1a175c5f42da29f6c27f4ea29684b63" category="paragraph">Es ist unbedingt zu beachten, dass die Disaster-Recovery-Umgebung auf dem neuesten Stand ist. Beispielsweise werden neue LUNs wahrscheinlich dem Quellserver hinzugefügt. Das bedeutet, dass die neuen LUNs auf dem Ziel vorab erkannt werden müssen, damit der Disaster-Recovery-Plan wie erwartet funktioniert.</block>
  <block id="90426ba53f908049843b3ea392578d04" category="doc">Disaster Recovery mit Oracle</block>
  <block id="ef09e87f183c8862564ee20992a229af" category="paragraph">NetApp MetroCluster bietet eine hochverfügbare Lösung ohne Datenverlust für geschäftskritische Oracle Workloads.</block>
  <block id="d93c585474124fbc2aec0fe5ed4c204a" category="paragraph">Zusätzlich vereinfachen integrierte Lösungen wie MetroCluster die komplizierte, horizontal skalierbare Oracle Datenbank, Applikation und Virtualisierungsinfrastrukturen von heute. MetroCluster ersetzt mehrere externe Datensicherungsprodukte und -Strategien durch ein einfaches, zentrales Storage Array. Sie bietet integriertes Backup, Recovery, Disaster Recovery und Hochverfügbarkeit (HA) innerhalb eines einzigen geclusterten Storage-Systems.</block>
  <block id="7fe779a487e8f113f1ffdff0fb80353f" category="summary">Backups von Konsistenzgruppen für Oracle auf ONTAP</block>
  <block id="773f9afa3df0cf82ed853c988183c73f" category="doc">Backup von Oracle Konsistenzgruppen</block>
  <block id="5afd3dc3f8d489d47587e10e6663c512" category="paragraph">Für die einfachste mögliche Sicherung, platzieren Sie einfach die gesamte Oracle-Datenbank in einem einzigen Volume.</block>
  <block id="2a4fa9d9434561574119e3086112023f" category="paragraph">Der Schutz von Datendateien, Archivprotokollen, Wiederherstellungsprotokollen und Steuerdateien mit einem einzelnen Snapshot ist eine gültige Backup-, Restore- und Replizierungsmethode.  Das RPO ist jedoch auf den Punkt des Backups selbst beschränkt. Er eignet sich für einen RPO von einer Stunde oder länger. Wenn eine Datenbank mehrere Volumes umfasst, sind cg-Snapshots mit einem der zuvor beschriebenen Tools erforderlich.</block>
  <block id="93310f4cebc752304c164f00d67e0bca" category="paragraph">Beispielsweise kann sich die gesamte Datenbank in einem einzigen Volume mit dem folgenden Snapshot-Zeitplan befinden:</block>
  <block id="a33821be4b3522d65daed1ec317299f6" category="list-text">72 stündliche Snapshots</block>
  <block id="0eea0679ac7bf43c19d603cd78e81de9" category="list-text">30 nächtliche Schnappschüsse</block>
  <block id="c4546c401776d279c5577011584577fa" category="list-text">12 monatliche Snapshots</block>
  <block id="b63db1b650d128c342617b377baf928a" category="paragraph">Dadurch wird ein RPO von einer Stunde für den festgelegten Zeitraum von 72 Stunden sowie zusätzliche nächtliche und monatliche Backups erzielt. Mehrere Datenbanken oder Applikationsdateien können auch in das einzelne Volume oder den Satz von cg-Snapshots aufgenommen werden, um konsistente Backups in einer größeren Umgebung zu ermöglichen.</block>
  <block id="5eb532bcede5a8d57b8fb4429d5cc7ec" category="summary">Maximieren Sie die Verfügbarkeit mit Oracle auf ONTAP</block>
  <block id="b4343a8438e1b9cc9e9486f85831f2a1" category="doc">Oracle Datenverfügbarkeit mit ONTAP</block>
  <block id="686540783626106489734a1990d4930d" category="paragraph">ONTAP wurde für eine maximale Verfügbarkeit von Oracle-Datenbanken konzipiert. Eine vollständige Beschreibung der Hochverfügbarkeitsfunktionen von ONTAP übersteigt den Rahmen dieses Dokuments. Wie bei der Datensicherheit ist jedoch ein grundlegendes Verständnis dieser Funktionalität bei der Entwicklung einer Datenbankinfrastruktur wichtig.</block>
  <block id="b049fcbe8198301adc6bf87634a02845" category="section-title">HA-Paare</block>
  <block id="1a7c11d1e2d03d3d1b57cff284ebd761" category="paragraph">Die Basiseinheit der Hochverfügbarkeit ist das HA-Paar. Jedes Paar enthält redundante Links, um die Replikation von Daten in NVRAM zu unterstützen. NVRAM ist kein Schreib-Cache. Der RAM im Controller dient als Schreib-Cache. Der Zweck von NVRAM besteht darin, Daten vorübergehend zu protokollieren, um Schutz vor unerwarteten Systemausfällen zu bieten. In dieser Hinsicht ähnelt es einem Datenbank-Redo-Protokoll.</block>
  <block id="cd2e54027dfcfeddd07ddd580db527c0" category="paragraph">Sowohl NVRAM als auch ein Datenbank-Wiederherstellungsprotokoll werden verwendet, um Daten schnell zu speichern, sodass Datenänderungen so schnell wie möglich vorgenommen werden können. Die Aktualisierung der persistenten Daten auf Laufwerken (oder Datendateien) findet erst später bei einem Prozess statt, der sowohl auf ONTAP- als auch auf den meisten Datenbankplattformen als Checkpoint bezeichnet wird. Weder NVRAM-Daten noch Datenbank-Wiederherstellungsprotokolle werden im normalen Betrieb gelesen.</block>
  <block id="4e044ec0c36e513506c77c0a97d53539" category="paragraph">Wenn ein Controller abrupt ausfällt, sind in NVRAM wahrscheinlich noch nicht gespeicherte Änderungen zu erwarten, die noch nicht auf die Laufwerke geschrieben wurden. Der Partner-Controller erkennt den Ausfall, übernimmt die Kontrolle über die Laufwerke und wendet die erforderlichen Änderungen an, die im NVRAM gespeichert wurden.</block>
  <block id="310e46747ebab6a43d5a15998f6e2b33" category="section-title">Takeover und Giveback</block>
  <block id="1d739263e44469ad28f77fe7329fa78d" category="paragraph">Takeover und Giveback beziehen sich auf den Prozess, bei dem die Verantwortung für Storage-Ressourcen zwischen Nodes in einem HA-Paar übertragen wird. Takeover und Giveback sind zweierlei Aspekte:</block>
  <block id="f2d43d90397aa8140414437eda14febb" category="list-text">Verwaltung der Netzwerkverbindung, die den Zugriff auf die Laufwerke ermöglicht</block>
  <block id="6e1c794c81468e3286a23138460bb3fb" category="list-text">Verwaltung der Antriebe selbst.</block>
  <block id="89d3f6c60c53a11e16a6756bde03ca00" category="paragraph">Die Netzwerkschnittstellen, die CIFS- und NFS-Datenverkehr unterstützen, werden sowohl mit dem Home-Standort als auch mit dem Failover-Standort konfiguriert. Eine Übernahme umfasst das Verschieben der Netzwerkschnittstellen zu ihrem temporären Home-Standort auf einer physischen Schnittstelle, die sich in denselben Subnetzen befindet wie der ursprüngliche Standort. Bei einem Giveback werden die Netzwerkschnittstellen zurück an ihre ursprünglichen Standorte verschoben. Das genaue Verhalten kann nach Bedarf angepasst werden.</block>
  <block id="108018656caf59cc565f1172047dab38" category="paragraph">Netzwerkschnittstellen, die SAN-Blockprotokolle wie iSCSI und FC unterstützen, werden während des Takeover und Giveback nicht verlagert. Stattdessen sollten LUNs mit Pfaden bereitgestellt werden, die ein vollständiges HA-Paar enthalten, was zu einem primären Pfad und einem sekundären Pfad führt.</block>
  <block id="80795d5dd590e432b4f5945aba47caf4" category="admonition">Zusätzliche Pfade zu zusätzlichen Controllern können auch konfiguriert werden, um das Verschieben von Daten zwischen Nodes in einem größeren Cluster zu unterstützen. Dies ist jedoch nicht Teil des HA-Prozesses.</block>
  <block id="aae63904d16fd1c522dc5ff53eb695b5" category="paragraph">Der zweite Aspekt von Takeover und Giveback ist die Übertragung der Eigentumsrechte an den Festplatten. Der genaue Prozess hängt von mehreren Faktoren ab, einschließlich dem Grund für das Takeover/Giveback und den ausgegebenen Befehlszeilenoptionen. Das Ziel ist es, die Operation so effizient wie möglich durchzuführen. Obwohl der Gesamtprozess möglicherweise mehrere Minuten in Anspruch nimmt, kann der tatsächliche Zeitpunkt, in dem die Eigentumsrechte an dem Laufwerk von einem Node auf einen Node übertragen werden, in der Regel in Sekunden gemessen werden.</block>
  <block id="61775b9e8f759f26eafd6b03448d1f30" category="section-title">Takeover-Zeit</block>
  <block id="3224b51e62790c4ce988d8c1876fb36e" category="paragraph">Host I/O durchläuft zwar eine kurze I/O-Pause bei Takeover- und Giveback-Vorgängen, jedoch sollte in einer korrekt konfigurierten Umgebung keine Applikationsunterbrechung auftreten. Der eigentliche Transitionsprozess, bei dem I/O verzögert wird, wird in der Regel in Sekunden gemessen. Der Host benötigt jedoch möglicherweise zusätzliche Zeit, um die Änderung der Datenpfade zu erkennen und die I/O-Vorgänge erneut auszuführen.</block>
  <block id="40f291752a9848bfecb7264cfd9aa8ee" category="paragraph">Die Art der Störung hängt vom Protokoll ab:</block>
  <block id="cb44db7841f8fb68230a260c4c68bfe0" category="list-text">Eine Netzwerkschnittstelle, die NFS- und CIFS-Datenverkehr unterstützt, stellt nach dem Übergang zu einem neuen physischen Standort eine ARP-Anforderung (Address Resolution Protocol) an das Netzwerk aus. Dies führt dazu, dass die Netzwerk-Switches ihre MAC-Adresstabellen (Media Access Control) aktualisieren und die I/O-Verarbeitung fortsetzen Im Falle von geplanten Takeover und Giveback werden Störungen in der Regel in Sekunden gemessen und oftmals nicht feststellbar. Einige Netzwerke sind möglicherweise langsamer, um die Änderung des Netzwerkpfads vollständig zu erkennen, und einige Betriebssysteme können in sehr kurzer Zeit viele I/O-Vorgänge in Warteschlange stellen, die erneut versucht werden müssen. Dadurch kann die für die I/O-Wiederaufnahme erforderliche Zeit verlängert werden</block>
  <block id="6a410522094e0b0f874dab5784e81ab8" category="list-text">Eine Netzwerkschnittstelle, die SAN-Protokolle unterstützt, kann nicht an einen neuen Speicherort verschoben werden. Ein Host-Betriebssystem muss den oder die verwendeten Pfade ändern. Die vom Host beobachtete I/O-Pause hängt von mehreren Faktoren ab. Aus Sicht des Storage-Systems beträgt der Zeitraum, in dem I/O nicht mehr ausgeführt werden kann, nur wenige Sekunden. Verschiedene Host-Betriebssysteme erfordern jedoch möglicherweise eine zusätzliche Zeit, damit eine I/O-Dauer vor einem erneuten Versuch wieder aberkannt wird. Neuere Betriebssysteme können eine Pfadänderung viel schneller erkennen, aber ältere Betriebssysteme benötigen in der Regel bis zu 30 Sekunden, um eine Änderung zu erkennen.</block>
  <block id="cabc4f9cda7d4bfb99181166c863a374" category="paragraph">Die zu erwartenden Übernahmezeiten, während denen das Storage-System keine Daten für eine Applikationsumgebung bereitstellen kann, sind in der folgenden Tabelle aufgeführt. Es sollte keine Fehler in einer Applikationsumgebung geben, das Takeover sollte stattdessen als kurze Pause bei der I/O-Verarbeitung erscheinen.</block>
  <block id="c8984126713ed072b9cb0a44a162be4d" category="cell">AFF</block>
  <block id="b7b46ce5d1a547db89c0bc615ff272a5" category="cell">ASA</block>
  <block id="ed3467fac861f6a32cd66093ac415805" category="cell">Geplante Übernahme</block>
  <block id="57a915dfa0e8469b25c1b8b947f7ee2c" category="cell">15 Sek.</block>
  <block id="cd5dce62294e9a79e9c2165ee0903f5f" category="cell">6-10 Sek.</block>
  <block id="cbfdbb11fd5eab0d9fdd078ae66a1c69" category="cell">2-3 Sek.</block>
  <block id="1a066f0304c1d3a279466c70359c5103" category="cell">Ungeplante Übernahme</block>
  <block id="0f4a6e109a34d3483995e427b6581130" category="cell">30 Sek.</block>
  <block id="a4985782267828ce03a3d13f37392de1" category="summary">Prüfsummen und Oracle-Datensicherung</block>
  <block id="407941abab873f61b271b481e105eb33" category="doc">Prüfsummen und Oracle-Datenintegrität</block>
  <block id="b93232347a11497969d0ea20d34cd16e" category="paragraph">Eine häufig an NetApp gerichtete Frage ist der Schutz der Datenintegrität in einer Oracle-Datenbank.</block>
  <block id="dbfb054670bc82c6e08a7e101c0f0ef4" category="paragraph">Die logische Datensicherung innerhalb von ONTAP setzt sich aus drei Kernanforderungen zusammen:</block>
  <block id="b6cc6762545d78ab663e39c37d172bd2" category="list-text">Daten müssen vor Datenbeschädigung geschützt werden.</block>
  <block id="e7c7e14f4b6ca1b3ae32b2279243dba6" category="list-text">Die Daten müssen vor Laufwerksausfällen geschützt werden.</block>
  <block id="1168469b387027a850496f6cac9f3529" category="list-text">Änderungen an Daten müssen vor Verlust geschützt werden.</block>
  <block id="864a6ca5da4b36656beba11c90f4c4e5" category="paragraph">Diese drei Anforderungen werden in den folgenden Abschnitten erläutert.</block>
  <block id="a05b54004946aa523bfe7c1e92a52f52" category="section-title">Netzwerkkorruption: Prüfsummen</block>
  <block id="ed95581a613a4f19be367c10cd063cc2" category="paragraph">Die grundlegendste Stufe des Datenschutzes ist die Prüfsumme, die einen speziellen Fehler erkennenden Code ist, der neben den Daten gespeichert wird. Eine Beschädigung der Daten bei der Netzwerkübertragung wird mit Hilfe einer Prüfsumme und in einigen Fällen mehreren Prüfsummen erkannt.</block>
  <block id="c1343e51090396cf011509389bc0adab" category="paragraph">Ein FC-Frame enthält beispielsweise eine Form der Prüfsumme, die als zyklische Redundanzprüfung (CRC, Cyclic Redundancy Check) bezeichnet wird, um sicherzustellen, dass die Nutzlast während der Übertragung nicht beschädigt ist. Der Sender sendet sowohl die Daten als auch den CRC der Daten. Der Empfänger eines FC-Frames berechnet den CRC der empfangenen Daten neu, um sicherzustellen, dass er mit dem übertragenen CRC übereinstimmt. Wenn der neu berechnete CRC nicht mit dem CRC übereinstimmt, der dem Frame zugeordnet ist, sind die Daten beschädigt und der FC-Frame wird verworfen oder abgelehnt. Eine iSCSI-I/O-Operation umfasst Prüfsummen auf TCP/IP- und Ethernet-Ebenen und kann für zusätzlichen Schutz optional auch den CRC-Schutz auf der SCSI-Schicht beinhalten. Jede Bit-Beschädigung auf dem Kabel wird von der TCP-Schicht oder IP-Schicht erkannt, was zu einer erneuten Übertragung des Pakets führt. Wie bei FC führen Fehler im SCSI CRC zu einem Verwerfen oder Zurückweisen des Vorgangs.</block>
  <block id="1f08639c540e47068c16c3ac48ea7bbe" category="section-title">Laufwerkbeschädigungen: Prüfsummen</block>
  <block id="c5d50bc8d916a4b26166bbda091cd6d4" category="paragraph">Mit Prüfsummen wird auch die Integrität der auf Laufwerken gespeicherten Daten überprüft. Auf Laufwerke geschriebene Datenblöcke werden mit einer Prüfsummenfunktion gespeichert, die eine unvorhersehbare Anzahl ergibt, die mit den Originaldaten verknüpft ist. Wenn Daten vom Laufwerk gelesen werden, wird die Prüfsumme neu berechnet und mit der gespeicherten Prüfsumme verglichen. Wenn sie nicht übereinstimmt, sind die Daten beschädigt und müssen von der RAID-Schicht wiederhergestellt werden.</block>
  <block id="8edc44db01815f20f6508db8b5630cfe" category="section-title">Datenbeschädigung: Verlorene Schreibvorgänge</block>
  <block id="972eab86b2aecd693914feabc5a3b65c" category="paragraph">Eine der schwierigsten Arten von Korruption ist ein verlorenes oder falsch geschaltenes Schreiben. Wenn ein Schreibvorgang bestätigt wird, muss er an der richtigen Stelle auf das Medium geschrieben werden. Datenbeschädigungen lassen sich mithilfe einer einfachen Prüfsumme, die mit den Daten gespeichert wurde, relativ einfach erkennen. Wenn der Schreibvorgang jedoch einfach verloren geht, dann könnte die vorherige Version der Daten noch existieren und die Prüfsumme wäre korrekt. Wenn der Schreibvorgang an einem falschen physischen Speicherort platziert wird, ist die zugehörige Prüfsumme erneut für die gespeicherten Daten gültig, auch wenn der Schreibvorgang andere Daten zerstört hat.</block>
  <block id="53830741c46fbc560962b086f582e79a" category="paragraph">Die Lösung für diese Herausforderung ist wie folgt:</block>
  <block id="656d064400822ca2ffb25f52c9fc95db" category="list-text">Ein Schreibvorgang muss Metadaten enthalten, die den Speicherort angeben, an dem der Schreibvorgang erwartungsgemäß gefunden werden soll.</block>
  <block id="37a60b1c7392a26270880a361f85db55" category="list-text">Ein Schreibvorgang muss eine Art Versionskennung enthalten.</block>
  <block id="4275b2e68761baa23b112833facf4ca1" category="paragraph">Wenn ONTAP einen Block schreibt, schließt er Daten ein, zu denen der Block gehört. Wenn ein nachfolgender Lesezugriff einen Block identifiziert, der jedoch aufgrund der Metadaten zu Standort 123 gehört, als er an Position 456 gefunden wurde, wurde der Schreibvorgang fehlgestellt.</block>
  <block id="009b13bf07c7db21c1e4769526e60694" category="paragraph">Es ist schwieriger, einen vollständig verlorenen Schreibvorgang zu erkennen. Die Erklärung ist sehr kompliziert, aber im Wesentlichen speichert ONTAP Metadaten so, dass ein Schreibvorgang zu Updates an zwei verschiedenen Orten auf den Laufwerken führt. Wenn ein Schreibvorgang verloren geht, werden bei einem nachfolgenden Lesen der Daten und der zugehörigen Metadaten zwei unterschiedliche Versionsidentitäten angezeigt. Dies zeigt an, dass der Schreibvorgang vom Laufwerk nicht abgeschlossen wurde.</block>
  <block id="3b04a99c209a31ad69e7865ea94e5c94" category="paragraph">Verloren gegangene und falsch verlegte Schreibvorgänge sind äußerst selten, doch steigt mit zunehmendem Laufwerksanzahl und steigenden Datenmengen der Datensätze das Risiko. Jedes Storage-System, das Datenbank-Workloads unterstützt, sollte die verlorener Schreibschutz enthalten.</block>
  <block id="e978ccc010ec4d37148d52e2fbf439dd" category="section-title">Laufwerksausfälle: RAID, RAID DP und RAID-TEC</block>
  <block id="a9fffaaf2b1b518afb56ef273736c0c2" category="paragraph">Wenn ein Datenblock auf einem Laufwerk erkannt wird, dass er beschädigt ist oder das gesamte Laufwerk ausfällt und nicht verfügbar ist, müssen die Daten wiederhergestellt werden. Dies wird in ONTAP mithilfe von Paritätslaufwerken durchgeführt. Die Daten werden auf mehreren Datenlaufwerken verteilt und anschließend Paritätsdaten generiert. Diese wird getrennt von den Originaldaten gespeichert.</block>
  <block id="54abdf00b7122c16619266482eb09f43" category="paragraph">ONTAP verwendete ursprünglich RAID 4, das für jede Gruppe von Datenlaufwerken ein Single-Parity-Laufwerk verwendet. Das Ergebnis war, dass ein Laufwerk in der Gruppe ausfallen konnte, ohne dass es zu Datenverlust kam. Bei einem Ausfall des Paritätslaufwerks wurden keine Daten beschädigt und ein neues Paritätslaufwerk erstellt. Wenn ein einzelnes Datenlaufwerk ausfällt, können die verbleibenden Laufwerke zusammen mit dem Paritätslaufwerk verwendet werden, um die fehlenden Daten neu zu generieren.</block>
  <block id="6d1ccb512ce2b25e53d90e6d8d459e18" category="paragraph">Bei geringen Laufwerksanzahl war die statistische Wahrscheinlichkeit, dass zwei Laufwerke gleichzeitig ausfallen, vernachlässigbar. Mit wachsenden Laufwerkskapazitäten hat sich auch die Zeit entwickelt, die für die Wiederherstellung von Daten nach einem Laufwerksausfall benötigt wird. Dadurch erhöht sich das Zeitfenster, in dem ein zweiter Laufwerksausfall zum Datenverlust führen würde. Darüber hinaus erzeugt der Neuerstellungsvorgang eine Menge zusätzlicher I/O auf den verbleibenden Laufwerken. Mit zunehmendem Festplattenalter steigt auch das Risiko, dass die zusätzliche Last zu einem zweiten Laufwerksausfall führt. Selbst wenn das Risiko eines Datenverlusts mit der fortgesetzten Nutzung von RAID 4 nicht Anstieg, würden die Folgen eines Datenverlusts schwerwiegender. Je mehr Daten im Falle eines Ausfalls einer RAID-Gruppe verloren gehen würden, desto länger würde die Wiederherstellung der Daten dauern, wodurch die Unterbrechung des Geschäftsbetriebs käme.</block>
  <block id="caef9e75bcd55d5a9a4ec855b5a6385c" category="paragraph">Aus diesen Problemen entwickelte NetApp die NetApp RAID DP-Technologie, eine Variante von RAID 6. Diese Lösung umfasst zwei Paritätslaufwerke, d. h., zwei beliebige Laufwerke einer RAID-Gruppe können ohne Datenverlust ausfallen. Die Größe der Laufwerke wurde weiter vergrößert, wodurch NetApp schließlich die NetApp RAID-TEC-Technologie entwickelt hat, wodurch ein drittes Paritätslaufwerk eingeführt wird.</block>
  <block id="704c2697ee323569003b7b7ea203ae0f" category="paragraph">Einige bewährte Verfahren für historische Datenbanken empfehlen die Verwendung von RAID-10, auch als Striped Mirroring bekannt. Dies bietet weniger Datensicherheit als RAID DP, da mehrere zwei-Festplatten-Fehlerszenarien auftreten, während es in RAID DP keine gibt.</block>
  <block id="3d0147402d7506d1d3a5227fe447427a" category="paragraph">Es gibt auch einige historische Best Practices für Datenbanken, die darauf hinweisen, dass RAID-10 aufgrund von Performance-Bedenken den Optionen RAID-4/5/6 vorzuziehen ist. Diese Empfehlungen beziehen sich manchmal auf einen RAID-Abzug. Obwohl diese Empfehlungen in der Regel richtig sind, gelten sie nicht für die Implementierungen von RAID innerhalb von ONTAP. Die Leistungsbedenken beziehen sich auf die Paritäts-Regeneration. Bei herkömmlichen RAID-Implementierungen müssen bei der Verarbeitung der routinemäßigen, zufälligen Schreibvorgänge durch eine Datenbank mehrere Lesezugriffe auf die Festplatte durchgeführt werden, um die Paritätsdaten neu zu generieren und den Schreibvorgang abzuschließen. Der Abzug wird definiert als die zusätzlichen Lese-IOPS, die zum Ausführen von Schreibvorgängen erforderlich sind.</block>
  <block id="84ff015d2df40fc0ebb34485173f39e4" category="paragraph">Bei ONTAP kommt es nicht zu RAID-Einbußen, da Schreibvorgänge in den Speicher ausgelagert werden, wo Parität erzeugt wird und dann als einzelner RAID-Stripe auf die Festplatte geschrieben wird. Zum Abschließen des Schreibvorgangs sind keine Lesevorgänge erforderlich.</block>
  <block id="b7fe11ecbd8b434a231195335b4894ac" category="paragraph">Zusammengefasst bieten RAID DP und RAID-TEC im Vergleich zu RAID 10 viel mehr nutzbare Kapazität, besseren Schutz vor Festplattenausfällen und keine Performance-Einbußen.</block>
  <block id="e5e0dc0629a299f8e56ebe7de38f49f9" category="section-title">Schutz vor Hardware-Ausfällen: NVRAM</block>
  <block id="1db5fde40e489d805029f9d5be6375e7" category="paragraph">Jedes Storage-Array für Datenbank-Workloads muss Schreibvorgänge so schnell wie möglich durchführen. Darüber hinaus muss ein Schreibvorgang vor einem Verlust durch unerwartete Ereignisse, wie z. B. einen Stromausfall, geschützt werden. Das bedeutet, dass jeder Schreibvorgang sicher an mindestens zwei Orten gespeichert werden muss.</block>
  <block id="ff540b857af868ec85f8f53ddc1f1bd1" category="paragraph">AFF und FAS Systeme vertrauen zur Erfüllung dieser Anforderungen auf NVRAM. Der Schreibvorgang funktioniert wie folgt:</block>
  <block id="049f2df0de743a6be8d3ec69864f234a" category="list-text">Die eingehenden Schreibdaten werden im RAM gespeichert.</block>
  <block id="976be2293c2f4499d079224003644acf" category="list-text">Die Änderungen, die an Daten auf Festplatte vorgenommen werden müssen, werden sowohl auf dem lokalen Node als auch auf dem Partner-Node in NVRAM eingetragen. NVRAM ist kein Schreib-Cache, sondern ein Journal, das einem Datenbank-Wiederherstellungsprotokoll ähnelt. Unter normalen Bedingungen wird sie nicht gelesen. Sie wird nur für die Wiederherstellung verwendet, z. B. nach einem Stromausfall während der I/O-Verarbeitung.</block>
  <block id="8ae87ed4a421bec56e020cd0e83bd748" category="list-text">Der Schreibvorgang wird dann dem Host bestätigt.</block>
  <block id="3a7682bcbb490353074b5ee69e18f01c" category="paragraph">Der Schreibvorgang in dieser Phase ist aus Sicht der Applikation abgeschlossen, und die Daten sind vor Verlust geschützt, da sie an zwei verschiedenen Standorten gespeichert werden. Schließlich werden die Änderungen auf die Festplatte geschrieben, doch dieser Prozess ist aus Sicht der Applikation bandextern, da er nach dem Quittieren des Schreibvorgangs auftritt und sich somit nicht auf die Latenz auswirkt. Dieser Prozess ist wieder ähnlich wie die Datenbankprotokollierung. Eine Änderung an der Datenbank wird so schnell wie möglich in den Wiederherstellungsprotokollen aufgezeichnet und die Änderung wird dann als festgeschrieben bestätigt. Die Updates der Datendateien erfolgen viel später und haben keinen direkten Einfluss auf die Geschwindigkeit der Verarbeitung.</block>
  <block id="c17f09622da5f1e0064f7b6a65cb8b01" category="paragraph">Bei einem Controller-Ausfall übernimmt der Partner-Controller die erforderlichen Festplatten und gibt die protokollierten Daten im NVRAM wieder, um I/O-Vorgänge, die beim Ausfall gerade ausgeführt wurden, wiederherzustellen.</block>
  <block id="24e6592d53b3bd56ed8827d2f51bb1ab" category="section-title">Schutz vor Hardware-Ausfällen: NVFAIL</block>
  <block id="7965eb54acae120d25d0c77b012b8f90" category="paragraph">Wie zuvor bereits erläutert, wird ein Schreibvorgang erst bestätigt, wenn er in lokalem NVRAM und NVRAM auf mindestens einem anderen Controller angemeldet wurde. Dieser Ansatz stellt sicher, dass ein Hardware-Ausfall oder ein Stromausfall nicht zum Verlust der aktiven I/O führen Wenn der lokale NVRAM ausfällt oder die Verbindung zum HA-Partner ausfällt, werden diese aktiven Daten nicht mehr gespiegelt.</block>
  <block id="307b6d3e63c12ada7fbcf75cdda0b574" category="paragraph">Wenn der lokale NVRAM einen Fehler meldet, wird der Node heruntergefahren. Dieses Herunterfahren führt zu einem Failover auf einen HA-Partner-Controller. Es gehen keine Daten verloren, da der Controller den Schreibvorgang nicht bestätigt hat.</block>
  <block id="6e0c6c8fe69a50581a4ac18acb2c04dd" category="paragraph">ONTAP lässt kein Failover zu, wenn die Daten nicht synchron sind, es sei denn, das Failover wird erzwungen. Durch das Erzwingen einer solchen Änderung der Bedingungen wird bestätigt, dass Daten im ursprünglichen Controller zurückgelassen werden können und dass ein Datenverlust akzeptabel ist.</block>
  <block id="a3961862ed464a06ef6fa4e23935fef2" category="paragraph">Datenbanken sind besonders anfällig für Beschädigungen, wenn ein Failover erzwungen wird, da Datenbanken große interne Daten-Caches auf der Festplatte aufbewahren. Wenn ein erzwungenes Failover auftritt, werden zuvor bestätigte Änderungen effektiv verworfen. Der Inhalt des Storage Arrays springt effektiv zurück in die Zeit, und der Zustand des Datenbank-Cache entspricht nicht mehr dem Status der Daten auf der Festplatte.</block>
  <block id="b46ce3019d702ee3ece327e5df990be0" category="paragraph">Um Daten aus dieser Situation zu schützen, können mit ONTAP Volumes für speziellen Schutz vor NVRAM-Ausfällen konfiguriert werden. Wenn dieser Schutzmechanismus ausgelöst wird, gelangt ein Volume in den Status „NVFAIL“. Dieser Status führt zu I/O-Fehlern, die dazu führen, dass Applikationen heruntergefahren werden, sodass keine veralteten Daten verwendet werden. Daten sollten nicht verloren gehen, da alle bestätigten Schreibvorgänge auf dem Speicher-Array vorhanden sein sollten.</block>
  <block id="322e1f85910dfc206274f8bd58a54a9d" category="list-text">Jeder Laufwerkssatz an einem bestimmten Standort wird automatisch als eine oder mehrere vollständig redundante RAID-DP- oder RAID-TEC-Gruppen konfiguriert, und zwar unabhängig vom Einsatz der Spiegelung. So wird eine kontinuierliche Datensicherung auch nach dem Verlust eines Standorts gewährleistet.</block>
  <block id="dee2dfce5ab0c47301b3c12970a57aa6" category="paragraph">Die Abbildung oben zeigt eine Beispiel-SyncMirror-Konfiguration. Es wurde ein Aggregat mit 24 Laufwerken auf dem Controller mit 12 Laufwerken aus einem an Standort A zugewiesenen Shelf und 12 Laufwerken aus einem an Standort B zugewiesenen Shelf erstellt Die Laufwerke wurden in zwei gespiegelte RAID-Gruppen gruppiert. RAID-Gruppe 0 enthält einen Plex mit 6 Laufwerken an Standort A, der auf einen Plex mit 6 Laufwerken an Standort B gespiegelt wird Ebenso enthält RAID-Gruppe 1 einen Plex mit 6 Laufwerken an Standort A, der auf einen Plex mit 6 Laufwerken an Standort B gespiegelt wird</block>
  <block id="4fbc0abe91c0c1381d0a742f58b4e537" category="paragraph">Normalerweise wird SyncMirror für die Remote-Spiegelung bei MetroCluster Systemen verwendet, wobei eine Kopie der Daten an jedem Standort vorhanden ist. Gelegentlich wurde es verwendet, um eine zusätzliche Redundanz in einem einzigen System bereitzustellen. Insbesondere bietet sie Redundanz auf Shelf-Ebene. Ein Festplatten-Shelf enthält bereits duale Netzteile und Controller und ist im Großen und Ganzen etwas mehr als Bleche, doch in einigen Fällen ist möglicherweise der zusätzliche Schutz gewährleistet. Ein NetApp Kunde beispielsweise hat SyncMirror für eine mobile Echtzeitanalyse-Plattform für Automobiltests implementiert. Das System wurde in zwei physische Racks getrennt, die von unabhängigen USV-Systemen mit Strom versorgt wurden.</block>
  <block id="95a3cc99b05998d49d8e035b994815bc" category="paragraph">==Prüfsummen</block>
  <block id="0cac56685de94a3ef0e1fd2bfca0c112" category="paragraph">Das Thema Prüfsummen ist von besonderem Interesse für DBAs, die es gewohnt sind, Oracle RMAN Streaming Backups zu Snapshot-basierten Backups zu verwenden. Eine Funktion von RMAN besteht darin, dass es während der Backups Integritätsprüfungen durchführt. Auch wenn dieses Feature einen gewissen Wert bietet, ist der Hauptvorteil für eine Datenbank, die nicht in einem modernen Storage-Array verwendet wird. Wenn physische Laufwerke für eine Oracle-Datenbank verwendet werden, ist es fast sicher, dass eine Beschädigung irgendwann auftritt, wenn die Laufwerke altern, ein Problem, das durch Array-basierte Prüfsummen in echten Storage-Arrays behoben wird.</block>
  <block id="58d7088c13cf2013ef373d85e3c27de7" category="paragraph">Mit einem echten Storage-Array wird die Datenintegrität durch die Verwendung von Prüfsummen auf mehreren Ebenen gesichert. Wenn Daten in einem IP-basierten Netzwerk beschädigt sind, weist die TCP-Schicht (Transmission Control Protocol) die Paketdaten zurück und fordert eine erneute Übertragung an. Das FC-Protokoll umfasst Prüfsummen sowie eingekapselte SCSI-Daten. Nachdem es sich auf dem Array befindet, verfügt ONTAP über RAID- und Prüfsummenschutz. Es kann zu einer Beschädigung kommen, aber wie in den meisten Enterprise-Arrays wird sie erkannt und korrigiert. In der Regel fällt ein ganzes Laufwerk aus, was zu einer RAID-Neuerstellung führt, und die Datenbankintegrität bleibt davon unberührt. Seltener erkennt ONTAP einen Prüfsummenfehler, was bedeutet, dass die Daten auf dem Laufwerk beschädigt werden. Das Laufwerk ist dann ausgefallen, und die RAID-Wiederherstellung beginnt. Auch hier bleibt die Datenintegrität erhalten.</block>
  <block id="8b7b33533c2b36c157a0a482bdd52a8e" category="paragraph">Die Architektur der Oracle-Datendatei- und des Wiederherstellungsprotokolls wurde auch für höchste Datenintegrität entwickelt, selbst unter extremen Bedingungen. Auf der einfachsten Ebene enthalten Oracle-Blöcke Prüfsumme und grundlegende logische Prüfungen mit fast jedem I/O Wenn Oracle nicht abgestürzt ist oder einen Tablespace offline genommen hat, sind die Daten intakt. Der Grad der Datenintegritätsprüfung ist einstellbar und Oracle kann auch zur Bestätigung von Schreibvorgängen konfiguriert werden. Dadurch können fast alle Crash- und Ausfallszenarien wiederhergestellt werden. Im äußerst seltenen Fall einer nicht wiederherstellbaren Situation wird eine Beschädigung umgehend erkannt.</block>
  <block id="4066c36b811913c85aa86346e30cee4d" category="paragraph">Die meisten NetApp-Kunden, die Oracle-Datenbanken einsetzen, beenden die Nutzung von RMAN und anderen Backup-Produkten nach der Migration zu Snapshot-basierten Backups. Es gibt nach wie vor Optionen, mit RMAN Recovery auf Blockebene mit SnapCenter durchgeführt werden kann. Allerdings werden RMAN, NetBackup und andere Produkte täglich nur gelegentlich verwendet, um monatliche oder vierteljährliche Archivkopien zu erstellen.</block>
  <block id="d0cf0e689669c61d564607d2ef7deb79" category="paragraph">Einige Kunden wählen zu laufen<block ref="d308cbfce7e270e5b41a84d84385645f" prefix=" " category="inline-code"></block> Regelmäßige Integritätsprüfungen der vorhandenen Datenbanken durchführen. NetApp rät von dieser Vorgehensweise ab, da dadurch unnötige I/O-Last erzeugt werden. Wie oben erwähnt, wenn die Datenbank zuvor keine Probleme hatte, die Chance von<block ref="d308cbfce7e270e5b41a84d84385645f" prefix=" " category="inline-code"></block> Das Erkennen eines Problems ist nahezu gleich null, und dieses Dienstprogramm erzeugt eine sehr hohe sequenzielle I/O-Last auf dem Netzwerk und dem Speichersystem. Es sei denn, es gibt Grund zu der Annahme, dass Korruption vorhanden ist, wie die Offenlegung eines bekannten Oracle-Fehlers, gibt es keinen Grund, ausgeführt zu werden<block ref="d308cbfce7e270e5b41a84d84385645f" prefix=" " category="inline-code"></block>.</block>
  <block id="db97518eeb3e040b5a78c451efd4b252" category="summary">Snapshot optimiertes Backup</block>
  <block id="431bbcf828b8d3513280cb1207824991" category="doc">Oracle Storage Snapshot optimierte Backups</block>
  <block id="52fb042c0d82d8e7bdf9ae239c387729" category="paragraph">Snapshot basiertes Backup und Recovery werden mit Oracle 12c noch einfacher, da eine Datenbank nicht im Hot-Backup-Modus platziert werden muss. Daraus ergibt sich die Möglichkeit, Snapshot basierte Backups direkt auf einem Storage-System zu planen und dennoch eine vollständige oder zeitpunktgenaue Recovery durchzuführen.</block>
  <block id="c9447fe684870cf68e9cb4f23f44db43" category="paragraph">Obwohl DBAs mit der Hot-Backup-Wiederherstellung vertrauter sind, ist es seit langem möglich, Snapshots zu verwenden, die nicht erstellt wurden, während sich die Datenbank im Hot-Backup-Modus befand. Für Oracle 10g und 11g waren während der Recovery zusätzliche manuelle Schritte erforderlich, um die Datenbankkonsistenz zu gewährleisten. Mit Oracle 12c,<block ref="a84f4f3da79386c29ab6dfa560af786e" prefix=" " category="inline-code"></block> Und<block ref="075b7d3bd3bbe7767f7ef62f430bc22b" prefix=" " category="inline-code"></block> Enthalten die zusätzliche Logik zur Wiedergabe von Archivprotokollen für Datendatei-Backups, die sich nicht im Hot-Backup-Modus befanden.</block>
  <block id="5c7dba68615d3fa5c4c90a36dab57bcb" category="paragraph">Wie bereits erwähnt, erfordert die Wiederherstellung eines Snapshot-basierten Hot-Backups zwei Datensätze:</block>
  <block id="50a7086972cada154c8164dc1c6b3539" category="list-text">Ein Snapshot der Datendateien, der im Backup-Modus erstellt wurde</block>
  <block id="c72d009669a638aab75c21a28a2101de" category="list-text">Die Archivprotokolle, die generiert wurden, während sich die Datendateien im Hot-Backup-Modus befanden</block>
  <block id="b8de4b1201e5595bc3de878f2bf59d9b" category="paragraph">Während der Recovery liest die Datenbank Metadaten aus den Datendateien, um die erforderlichen Archivprotokolle für die Recovery auszuwählen.</block>
  <block id="66ee0a6fd90f3cfab8320e1de1341cbd" category="paragraph">Storage Snapshot optimierte Recovery erfordert geringfügig unterschiedliche Datensätze, um die gleichen Ergebnisse zu erzielen:</block>
  <block id="6030a1d9761fca3806ef0a0329438071" category="list-text">Ein Snapshot der Datendateien und eine Methode zur Identifizierung des Zeits, zu dem der Snapshot erstellt wurde</block>
  <block id="4e822d4c19600b654f176d335c158829" category="list-text">Archivieren Sie Protokolle vom Zeitpunkt des letzten Datendatei-Kontrollpunkts bis zum genauen Zeitpunkt des Snapshots</block>
  <block id="604432b50055c69f34df17a8ed5befb5" category="paragraph">Während der Recovery liest die Datenbank Metadaten aus den Datendateien, um das früheste erforderliche Archivprotokoll zu identifizieren. Eine vollständige oder zeitpunktgenaue Recovery kann durchgeführt werden. Bei einer zeitpunktgenauen Recovery ist es wichtig, die Zeit des Snapshots der Datendateien zu kennen. Der angegebene Wiederherstellungspunkt muss nach der Erstellungszeit der Snapshots liegen. NetApp empfiehlt, die Snapshot-Zeit um mindestens einige Minuten zu erweitern, um Uhrschwankungen zu berücksichtigen.</block>
  <block id="08bfe39c49a2dc07b08bd2ccd77d8281" category="paragraph">Ausführliche Informationen finden Sie in der Oracle-Dokumentation zum Thema „Recovery Using Storage Snapshot Optimization“, die in verschiedenen Versionen der Oracle 12c-Dokumentation verfügbar ist. Weitere Informationen zur Snapshot-Unterstützung von Drittanbietern finden Sie unter Oracle Document ID Doc ID 604683.1.</block>
  <block id="d22a890163762fcf7a4cb7605c29b7e6" category="section-title">Datenlayout</block>
  <block id="6a7fc1f74262f6973420f4fc849ba7f7" category="paragraph">Am einfachsten ist es, die Datendateien in einem oder mehreren dedizierten Volumes zu isolieren. Sie müssen durch einen anderen Dateityp nicht kontaminiert sein. Dadurch soll sichergestellt werden, dass die Datendatei-Volumes mit einem SnapRestore-Vorgang schnell wiederhergestellt werden können, ohne dass ein wichtiges Wiederherstellungsprotokoll, eine Steuerdatei oder ein Archivprotokoll zerstört werden.</block>
  <block id="ff6fb5d2136ab516e182f4b23f45886d" category="paragraph">SAN hat ähnliche Anforderungen für die Isolation von Datendateien in dedizierten Volumes. Bei einem Betriebssystem wie Microsoft Windows kann ein einzelnes Volume mehrere Datendatei-LUNs mit jeweils einem NTFS-Filesystem enthalten. Bei anderen Betriebssystemen gibt es in der Regel auch einen logischen Volume Manager. Mit Oracle ASM wäre es beispielsweise am einfachsten, Laufwerksgruppen auf ein einzelnes Volume zu beschränken, das als Einheit gesichert und wiederhergestellt werden kann. Wenn aus Gründen der Performance oder des Kapazitätsmanagements zusätzliche Volumes erforderlich sind, erleichtert die Erstellung einer zusätzlichen Laufwerksgruppe auf dem neuen Volume das Management.</block>
  <block id="a06956ba6de69aec2dc2b015074e5821" category="paragraph">Wenn diese Richtlinien befolgt werden, können Snapshots direkt auf ONTAP geplant werden, ohne dass ein Snapshot einer Konsistenzgruppe erforderlich ist. Der Grund hierfür liegt darin, dass Snapshot-optimierte Backups keine gleichzeitige Sicherung von Datendateien erfordern.</block>
  <block id="9e422c12420f1bd8c73e3c0f63da55e9" category="paragraph">Eine Komplikation entsteht in Situationen wie einer ASM-Datenträgergruppe, die auf Volumes verteilt ist. In diesen Fällen muss ein cg-Snapshot ausgeführt werden, um sicherzustellen, dass die ASM-Metadaten über alle zusammengehörigen Volumes hinweg konsistent sind.</block>
  <block id="7a7969d6a47ed242c25f6a38f2da0e36" category="paragraph">[Hinweis]Vergewissern Sie sich, dass sich die ASM-Spfile- und Passwd-Dateien nicht in der Festplattengruppe befinden, die die Datendateien hostet. Dies beeinträchtigt die Fähigkeit, Datendateien und nur Datendateien selektiv wiederherzustellen.</block>
  <block id="12eb3ceede91a01c74368e0fab03dbe4" category="section-title">Verfahren zur lokalen Wiederherstellung – NFS</block>
  <block id="e1a03fcc478ae212f07b5044b11ff369" category="paragraph">Dieses Verfahren kann manuell oder über eine Anwendung wie SnapCenter gesteuert werden. Das Grundverfahren ist wie folgt:</block>
  <block id="abb0083d6ab87bbe9d906632fea121ae" category="list-text">Stellen Sie die Datendatei-Volumes unmittelbar vor dem gewünschten Wiederherstellungspunkt auf den Snapshot wieder her.</block>
  <block id="3450fe1e1eea00fa55cfb5cb835a3d80" category="paragraph">Bei diesem Verfahren wird davon ausgegangen, dass die gewünschten Archivprotokolle noch im aktiven Dateisystem vorhanden sind. Wenn dies nicht der Fall ist, müssen die Archivprotokolle wiederhergestellt werden, oder<block ref="075b7d3bd3bbe7767f7ef62f430bc22b" prefix=" " category="inline-code"></block> Oder<block ref="a84f4f3da79386c29ab6dfa560af786e" prefix=" " category="inline-code"></block> Kann auf die Daten im weitergeleitet werden<block ref="a15da8cecb1f1192c4d913b8ba676121" prefix=" " category="inline-code"></block> Verzeichnis.</block>
  <block id="e43e33171833b26f6b024d28cb8b1afd" category="paragraph">Außerdem können Datendateien bei kleineren Datenbanken von einem Endbenutzer direkt aus wiederhergestellt werden<block ref="a15da8cecb1f1192c4d913b8ba676121" prefix=" " category="inline-code"></block> Directory ohne Unterstützung durch Automatisierungs-Tools oder einen Storage-Administrator, um einen SnapRestore-Befehl auszuführen.</block>
  <block id="097230f6ad5345abbe261eabbf533a68" category="section-title">Verfahren zur lokalen Wiederherstellung – SAN</block>
  <block id="4e3110543ebf2a771c16b3b2101f1f88" category="list-text">Legen Sie die Festplattengruppe(n), die die Datendateien hosten, still. Die Vorgehensweise hängt vom gewählten Logical Volume Manager ab. Bei ASM muss die Datenträgergruppe demontieren. Bei Linux müssen die Dateisysteme getrennt und die logischen Volumes und Volume-Gruppen deaktiviert werden. Ziel ist es, alle Aktualisierungen auf der Zieldatentengruppe zu stoppen, die wiederhergestellt werden sollen.</block>
  <block id="1d0ecd206531f96737f8e8002be4a047" category="list-text">Stellen Sie die Datendatei-Datenträgergruppen auf dem Snapshot unmittelbar vor dem gewünschten Wiederherstellungspunkt wieder her.</block>
  <block id="946fe41f610ab658e270a1844c992bcc" category="list-text">Reaktivieren Sie die neu wiederhergestellten Datenträgergruppen.</block>
  <block id="c21d8f41541fc2a0259e7ea5e51edac3" category="paragraph">Bei diesem Verfahren wird davon ausgegangen, dass die gewünschten Archivprotokolle noch im aktiven Dateisystem vorhanden sind. Wenn dies nicht der Fall ist, müssen die Archivprotokolle wiederhergestellt werden, indem die Archivprotokoll-LUNs offline geschaltet und eine Wiederherstellung durchgeführt wird. Dies ist ebenfalls ein Beispiel, bei dem sich Archivprotokolle in dedizierte Volumes aufteilen lassen. Wenn die Archivprotokolle eine Volume-Gruppe mit Wiederherstellungsprotokollen gemeinsam nutzen, müssen die Wiederherstellungsprotokolle vor der Wiederherstellung des gesamten LUN-Satzes an eine andere Stelle kopiert werden, damit die letzten aufgezeichneten Transaktionen nicht verloren gehen.</block>
  <block id="3fd5b2a08b3d7c4db29da8590ef6013f" category="section-title">Beispiel für eine vollständige Wiederherstellung</block>
  <block id="31679daa394b7091acfd728d940b7322" category="paragraph">Angenommen, die Datendateien wurden beschädigt oder zerstört, und eine vollständige Recovery ist erforderlich. Das Verfahren ist wie folgt:</block>
  <block id="aa09ca247daac25fc18c2633124ca9b6" category="section-title">Beispiel für eine zeitpunktgenaue Recovery</block>
  <block id="935ff627038d1f5001220c8df7f0e1b9" category="paragraph">Der gesamte Wiederherstellungsvorgang erfolgt über einen einzigen Befehl:<block ref="3df448f0a5ec82cac76d91ba14c0fa1d" prefix=" " category="inline-code"></block>.</block>
  <block id="dcd27cf8b8ceae2cd84c898d3c1b9fdb" category="paragraph">Wenn eine Point-in-Time-Recovery erforderlich ist, muss der Zeitstempel der Snapshots bekannt sein und kann wie folgt identifiziert werden:</block>
  <block id="17108ef3ad2e1e613b844beb5f2c6d29" category="paragraph">Die Erstellungszeit für Snapshots wird als 9. März und 10:10:06 aufgeführt. Um sicher zu sein, wird der Snapshot-Zeit eine Minute hinzugefügt:</block>
  <block id="904b0a17b003c70e398ea85996f0f9ba" category="paragraph">Die Wiederherstellung ist nun gestartet. Es gab eine Snapshot-Zeit von 10:11:00, eine Minute nach der aufgezeichneten Zeit, um mögliche Taktabweichungen zu berücksichtigen, und eine Ziel-Recovery-Zeit von 10:44 an. Als Nächstes fordert sqlplus die Archivprotokolle an, die benötigt werden, um die gewünschte Wiederherstellungszeit von 10:44 zu erreichen.</block>
  <block id="91f99c5ad04365fb4d00e509963e2a0c" category="admonition">Führen Sie die Wiederherstellung einer Datenbank mithilfe von Snapshots mit dem durch<block ref="3df448f0a5ec82cac76d91ba14c0fa1d" prefix=" " category="inline-code"></block> Für Befehl ist keine spezifische Lizenzierung erforderlich, aber die zeitpunktgenaue Recovery mit<block ref="72104026d9850e8c478c23b2e2e4e8e9" prefix=" " category="inline-code"></block> Erfordert die Oracle Advanced Compression-Lizenz.</block>
  <block id="87161b635cff9308859c719a20929913" category="summary">Backup Tools für Oracle und NetApp</block>
  <block id="9173402b63dc5f55506a692258f185e8" category="doc">SnapCenter und andere Tools</block>
  <block id="400937771ac8b3d4e7be82bf39033db5" category="paragraph">Der Hauptnutzen von ONTAP in einer Applikationsumgebung ergibt sich aus den zentralen ONTAP Technologien, beispielsweise sofortigen Snapshot Kopien, einfacher SnapMirror Replizierung und der effizienten Erstellung von FlexClone Volumes.</block>
  <block id="5459c1727c923baa303ff472498dbe97" category="paragraph">In manchen Fällen erfüllt eine einfache Konfiguration dieser Kernfunktionen direkt in ONTAP die Anforderungen, für kompliziertere Anforderungen ist jedoch eine Orchestrierungsschicht erforderlich.</block>
  <block id="aeeb3212c35c26d321183e81d4926e57" category="paragraph">SnapCenter ist das Vorzeigeprodukt für die Datensicherung von NetApp. Sie ähnelt im Hinblick auf die Durchführung von Datenbank-Backups den SnapManager Produkten. Sie wurde jedoch von Grund auf entwickelt, um bei NetApp Storage-Systemen eine zentrale Konsole für das Management der Daten zu bieten.</block>
  <block id="e538db970e1ed1ffe018725fdf223f9e" category="paragraph">SnapCenter umfasst Grundfunktionen wie auf Snapshot Kopien basierende Backups und Restores, SnapMirror und SnapVault Replizierung sowie weitere Funktionen, die für den Einsatz in großen Unternehmen erforderlich sind. Zu diesen erweiterten Funktionen gehören eine erweiterte Funktion zur rollenbasierten Zugriffssteuerung (RBAC), RESTful APIs zur Integration in Orchestrierungsprodukte von Drittanbietern, unterbrechungsfreies, zentrales Management von SnapCenter Plug-ins auf Datenbank-Hosts und eine Benutzeroberfläche für Cloud-skalierbare Umgebungen.</block>
  <block id="50780f47f6839d47d60bc4555ee00c3f" category="section-title">RUHE</block>
  <block id="a0bac638f30c704da8e03aba136da86d" category="paragraph">ONTAP enthält außerdem einen umfangreichen RESTful API-Satz. Drittanbieter sind so in der Lage, Datensicherungs- und Management-Applikationen mit enger Integration in ONTAP zu erstellen. Darüber hinaus kann die RESTful API von Kunden genutzt werden, die ihre eigenen Automatisierungs-Workflows und Dienstprogramme erstellen möchten.</block>
  <block id="e4cea644160fe9fa4ccd92ab3f079363" category="summary">Snapshot-basierte Backups und Recovery für Oracle</block>
  <block id="9adc36f162691b8ed14a886b6068f368" category="doc">Online-Backups für Oracle</block>
  <block id="a3b43ae3d4028e3c7ccac3d5720e9fb0" category="paragraph">Zwei Datensätze sind erforderlich, um eine Oracle Datenbank im Backup-Modus zu schützen und wiederherzustellen. Beachten Sie, dass dies nicht die einzige Oracle-Backup-Option ist, aber es ist die häufigste.</block>
  <block id="8e523970ff7c41dba74e723511d14717" category="list-text">Ein Snapshot der Datendateien im Backup-Modus</block>
  <block id="deeddf207b1a29c63ae7c1943f90f3d9" category="list-text">Die Archivprotokolle, die erstellt wurden, während sich die Datendateien im Backup-Modus befanden</block>
  <block id="fa1229103a2e02a4ed8790098c98f71f" category="paragraph">Wenn eine vollständige Recovery einschließlich aller festgeschriebenen Transaktionen notwendig ist, ist ein dritter Artikel erforderlich:</block>
  <block id="7c11b244c2549a2cc477c134ec4c5635" category="list-text">Ein Satz aktueller Wiederherstellungsprotokolle</block>
  <block id="8522faf14bc9d4ab497945bb48adc870" category="paragraph">Es gibt eine Reihe von Möglichkeiten, die Recovery eines Online-Backups zu fördern. Viele Kunden stellen Snapshots mithilfe der ONTAP CLI wieder her und verwenden dann Oracle RMAN oder sqlplus, um die Recovery abzuschließen. Dies ist besonders bei großen Produktionsumgebungen der Fall, in denen die Wahrscheinlichkeit und Häufigkeit der Wiederherstellung von Datenbanken äußerst gering ist und alle Wiederherstellungsverfahren von einem erfahrenen DBA durchgeführt werden. Für die vollständige Automatisierung verfügen Lösungen wie NetApp SnapCenter über ein Oracle Plug-in mit Befehlszeile und grafischer Benutzeroberfläche.</block>
  <block id="f88f41d4801183a5d53a4b71f383d144" category="paragraph">Einige große Kunden haben einen einfacheren Ansatz verfolgt, indem sie einfache Skripte auf den Hosts konfigurieren, um die Datenbanken zu einem bestimmten Zeitpunkt in den Backup-Modus zu versetzen, um einen geplanten Snapshot vorzubereiten. Planen Sie beispielsweise den Befehl<block ref="56f72994c4cc84b13a4c20dab49fea35" prefix=" " category="inline-code"></block> Um 23:58<block ref="84c8391d82cbfe300a9615844e0a167f" prefix=" " category="inline-code"></block> Um 00:02 Uhr, und planen Sie dann Snapshots direkt auf dem Speichersystem um Mitternacht. Das Ergebnis ist eine einfache, hochgradig skalierbare Backup-Strategie, für die keine externe Software oder Lizenzen erforderlich sind.</block>
  <block id="719fbeb74939b8c065321f175de3d222" category="paragraph">Am einfachsten ist es, Datendateien in einem oder mehreren dedizierten Volumes zu isolieren. Sie müssen durch einen anderen Dateityp nicht kontaminiert sein. Dadurch soll sichergestellt werden, dass die Datendatei-Volumes über einen SnapRestore-Vorgang schnell wiederhergestellt werden können, ohne dass ein wichtiges Wiederherstellungsprotokoll, eine Steuerdatei oder ein Archivprotokoll zerstört werden.</block>
  <block id="19156bdcbf322e8e3189909bbb7a69e8" category="paragraph">SAN hat ähnliche Anforderungen für die Isolation von Datendateien in dedizierten Volumes. Bei einem Betriebssystem wie Microsoft Windows kann ein einzelnes Volume mehrere Datendatei-LUNs mit jeweils einem NTFS-Filesystem enthalten. Bei anderen Betriebssystemen gibt es in der Regel einen logischen Volume Manager. Mit Oracle ASM wäre es beispielsweise am einfachsten, die LUNs einer ASM-Laufwerksgruppe auf ein einzelnes Volume zu beschränken, das als Einheit gesichert und wiederhergestellt werden kann. Wenn aus Gründen der Performance oder des Kapazitätsmanagements zusätzliche Volumes erforderlich sind, vereinfacht sich das Management durch die Erstellung einer zusätzlichen Festplattengruppe auf dem neuen Volume.</block>
  <block id="993afa8643b7200c5c9e527c24c1d8b2" category="paragraph">Wenn diese Richtlinien befolgt werden, können Snapshots direkt auf dem Speichersystem geplant werden, ohne dass ein Snapshot einer Konsistenzgruppe erforderlich ist. Der Grund hierfür liegt darin, dass für Oracle-Backups keine Datendateien gleichzeitig gesichert werden müssen. Das Online-Backup-Verfahren wurde entwickelt, damit Datendateien weiterhin aktualisiert werden können, da sie im Laufe der Stunden langsam auf Tape gestreamt werden.</block>
  <block id="a2ea5ea024e4a68e4d7f4abeca3441a1" category="paragraph">Eine Komplikation entsteht in Situationen wie der Verwendung einer ASM-Datenträgergruppe, die auf Volumes verteilt ist. In diesen Fällen muss ein cg-Snapshot ausgeführt werden, um sicherzustellen, dass die ASM-Metadaten über alle zusammengehörigen Volumes hinweg konsistent sind.</block>
  <block id="0a3ecb97c1b7c97e5075bae0daaa45aa" category="paragraph">*Achtung:* Überprüfen Sie, dass der ASM<block ref="1737629d60b511cf45957529a8f046e2" prefix=" " category="inline-code"></block> Und<block ref="76a2173be6393254e72ffa4d6df1030a" prefix=" " category="inline-code"></block> Die Dateien befinden sich nicht in der Festplattengruppe, in der die Datendateien gehostet werden. Dies beeinträchtigt die Fähigkeit, Datendateien und nur Datendateien selektiv wiederherzustellen.</block>
  <block id="2f8a5e254c86a42ebcc8b7d3c84cd22e" category="paragraph">Bei diesem Verfahren wird davon ausgegangen, dass die gewünschten Archivprotokolle noch im aktiven Dateisystem vorhanden sind. Ist dies nicht der Fall, müssen die Archivprotokolle wiederhergestellt werden oder rman/sqlplus kann zu den Daten im Snapshot-Verzeichnis geleitet werden.</block>
  <block id="a67a69f712a877950e94edd27310b40e" category="paragraph">Außerdem können Datendateien bei kleineren Datenbanken von einem Endbenutzer direkt aus wiederhergestellt werden<block ref="a15da8cecb1f1192c4d913b8ba676121" prefix=" " category="inline-code"></block> Verzeichnis ohne die Unterstützung von Automatisierungs-Tools oder Storage-Administratoren, ein auszuführen<block ref="a4c0ce4da6fb04943b499690fb3afd6e" prefix=" " category="inline-code"></block> Befehl.</block>
  <block id="6da8ebf3245e4fbe4654e7f92f0330d7" category="list-text">Legen Sie die Festplattengruppe(n), die die Datendateien hosten, still. Die Vorgehensweise hängt vom gewählten Logical Volume Manager ab. Bei ASM muss die Datenträgergruppe demontieren. Bei Linux müssen die Dateisysteme demontiert und die logischen Volumes und Volume-Gruppen deaktiviert werden. Ziel ist es, alle Aktualisierungen auf der Zieldatentengruppe zu stoppen, die wiederhergestellt werden sollen.</block>
  <block id="931ab211ac6773d20c03a998f9f921ce" category="list-text">Wiederholen Sie alle Wiederherstellungsprotokolle, wenn eine vollständige Wiederherstellung gewünscht wird.</block>
  <block id="b6575c3fca5eaaa56eeb8e9ce8867f05" category="paragraph">Bei diesem Verfahren wird davon ausgegangen, dass die gewünschten Archivprotokolle noch im aktiven Dateisystem vorhanden sind. Wenn dies nicht der Fall ist, müssen die Archivprotokolle wiederhergestellt werden, indem die Archivprotokoll-LUNs offline geschaltet und eine Wiederherstellung durchgeführt wird. Dies ist ebenfalls ein Beispiel, bei dem sich Archivprotokolle in dedizierte Volumes aufteilen lassen. Wenn die Archivprotokolle eine Volume-Gruppe mit Wiederherstellungsprotokollen gemeinsam nutzen, müssen die Wiederherstellungsprotokolle vor der Wiederherstellung des gesamten LUN-Satzes an eine andere Stelle kopiert werden. Dieser Schritt verhindert den Verlust dieser letzten aufgezeichneten Transaktionen.</block>
  <block id="1536f0d3e3ee227abdec76f432b89cae" category="summary">Oracle Datensicherungs-SLAs</block>
  <block id="e9c8b7044dfae7a21f1a9c4d08628a66" category="doc">Recovery-Zeitvorgabe, Recovery-Zeitpunkt und Service Level Agreements</block>
  <block id="020e620c60ad38b75f0ff2a2fe4067b0" category="paragraph">Eine Datensicherungsstrategie sollte durch geschäftliche Anforderungen definiert werden.</block>
  <block id="65fd6f7f97414140b4d6060b743dc645" category="paragraph">Zu diesen Anforderungen gehören Faktoren wie die Geschwindigkeit der Recovery, der maximal zulässige Datenverlust und die Anforderungen an die Aufbewahrung von Backups. Der Datensicherungsplan muss zudem verschiedene gesetzliche Vorgaben für die Datenaufbewahrung und -Wiederherstellung berücksichtigen. Schließlich müssen verschiedene Datenwiederherstellungsszenarien in Betracht gezogen werden, von der typischen und vorhersehbaren Wiederherstellung aufgrund von Benutzer- oder Applikationsfehlern bis hin zu Disaster Recovery-Szenarien, die den vollständigen Ausfall eines Standorts beinhalten.</block>
  <block id="2bd1d35ff88de136066c33905c0fd677" category="paragraph">Kleine Änderungen an Richtlinien zur Datensicherung und Wiederherstellung können sich erheblich auf die Gesamtarchitektur von Storage, Backup und Recovery auswirken. Es ist wichtig, Standards zu definieren und zu dokumentieren, bevor mit dem Design begonnen wird, um eine Verkomplizierung einer Datensicherungsarchitektur zu vermeiden. Unnötige Schutzfunktionen oder -Ebenen führen zu unnötigen Kosten und Management-Overhead. Eine zunächst übersehene Anforderung kann ein Projekt in die falsche Richtung führen oder kurzfristig Designänderungen erfordern.</block>
  <block id="a60e6b87ede45aef49d8d095435db22b" category="section-title">Recovery-Zeitvorgabe</block>
  <block id="3d3b341e14c584d1edcea9fe13619ee1" category="paragraph">Die Recovery-Zeitvorgabe (Recovery Time Objective, RTO) definiert die maximal zulässige Zeit für die Recovery eines Services. Eine Personaldatenbank könnte beispielsweise eine RTO von 24 Stunden haben, da, obwohl es sehr unpraktisch wäre, den Zugriff auf diese Daten während der Arbeitszeit zu verlieren, das Unternehmen dennoch arbeiten kann. Im Gegensatz dazu würde bei einer Datenbank, die das Hauptbuch einer Bank unterstützt, eine RTO in Minuten oder sogar Sekunden gemessen werden. Ein RTO von null ist nicht möglich, da es eine Möglichkeit geben muss, zwischen einem tatsächlichen Serviceausfall und einem Routineereignis wie einem verlorenen Netzwerkpaket zu unterscheiden. Typische Anforderungen sind jedoch ein RTO von nahezu null.</block>
  <block id="5a27873285a0397cc06f9f47280c9426" category="section-title">Recovery-Zeitpunkt</block>
  <block id="f3ae061e139f47d793058ee596a5243f" category="paragraph">Der Recovery Point Objective (RPO) definiert den maximal tolerierbaren Datenverlust. In vielen Fällen wird der RPO lediglich durch die Häufigkeit von Snapshots oder snapmirror Updates bestimmt.</block>
  <block id="2d68fbd3cefeb34bfd64c8f89caba64d" category="paragraph">In manchen Fällen lässt sich der RPO-Wert aggressiver einsetzen, da er bestimmte Daten selektiv häufiger schützt. Im Datenbankkontext ist der RPO in der Regel eine Frage, wie viele Protokolldaten in einer bestimmten Situation verloren gehen können. In einem typischen Recovery-Szenario, bei dem eine Datenbank aufgrund eines Produktfehlers oder eines Benutzerfehlers beschädigt wird, sollte der RPO gleich null sein, d. h. es darf keine Daten verloren gehen. Bei der Wiederherstellung wird eine frühere Kopie der Datenbankdateien wiederhergestellt und anschließend die Protokolldateien wiedergegeben, um den Datenbankstatus auf den gewünschten Zeitpunkt zu bringen. Die für diesen Vorgang erforderlichen Protokolldateien sollten sich bereits am ursprünglichen Speicherort befinden.</block>
  <block id="57df8b025934bcd0f7e96bae19cf0688" category="paragraph">In ungewöhnlichen Szenarien können Protokolldaten verloren gehen. Zum Beispiel eine versehentliche oder böswillige<block ref="4609acba202877f99742342f4195d95e" prefix=" " category="inline-code"></block> Der Datenbankdateien können zum Löschen aller Daten führen. Die einzige Option wäre die Wiederherstellung aus dem Backup, einschließlich Protokolldateien, und einige Daten würden unweigerlich verloren gehen. Die einzige Option zur Verbesserung des RPO in einer herkömmlichen Backup-Umgebung besteht in der Durchführung wiederholter Backups der Protokolldaten. Dies hat jedoch Einschränkungen aufgrund der ständigen Datenverschiebung und der Schwierigkeiten, ein Backup-System als ständig laufenden Service zu warten. Einer der Vorteile erweiterter Storage-Systeme besteht in der Möglichkeit, Daten vor versehentlichen oder böswilligen Schäden an Dateien zu schützen und somit ein besseres RPO ohne Datenverschiebung zu ermöglichen.</block>
  <block id="3d08c71e26ac92e34925e02570c4bd22" category="paragraph">Disaster Recovery umfasst die IT-Architektur, Richtlinien und Verfahren, die zur Wiederherstellung eines Services bei einem physischen Ausfall erforderlich sind. Dies kann Überschwemmungen, Brände oder Personen sein, die mit böswilliger oder fahrlässiger Absicht handeln.</block>
  <block id="78f4e749ec0c6bb2627abbbc00bce296" category="paragraph">Disaster Recovery ist mehr als nur eine Reihe von Recovery-Verfahren. Der gesamte Prozess umfasst die Identifizierung der verschiedenen Risiken, die Definition der Anforderungen an die Datenwiederherstellung und die Servicekontinuität sowie die Bereitstellung der richtigen Architektur mit den zugehörigen Verfahren.</block>
  <block id="75bcd60b234aba82b5827cd7a5171563" category="paragraph">Bei der Festlegung von Datensicherungsanforderungen ist es entscheidend, zwischen den typischen RPO- und RTO-Anforderungen und den für die Disaster Recovery erforderlichen RPO- und RTO-Anforderungen zu unterscheiden. Einige Applikationsumgebungen erfordern einen RPO von null und ein RTO von nahezu null für Datenverluste – von einem relativ normalen Benutzerfehler bis hin zu einem Brand, der ein Datacenter zerstört. Für diese hohen Schutzniveaus gibt es jedoch Kosten- und administrative Konsequenzen.</block>
  <block id="756651fea87d05811d7a42451d074b60" category="paragraph">Im Allgemeinen sollten die Anforderungen an die nicht-Disaster-Recovery aus zwei Gründen strikt erfüllt werden. Zunächst sind Anwendungsfehler und Benutzerfehler, die zu Datenschäden führen, bis zu dem Punkt vorhersehbar, an dem sie fast unvermeidlich sind. Zweitens ist es nicht schwierig, eine Backup-Strategie zu entwickeln, die einen RPO von null und ein RTO von niedrigen Vorgaben liefern kann, solange das Storage-System nicht zerstört wird. Es gibt keinen Grund, ein erhebliches Risiko, das leicht behoben werden kann, nicht anzugehen. Deshalb sollten die RPO- und RTO-Ziele für die lokale Recovery aggressiv sein.</block>
  <block id="cb6faee28dd34d25f06bd0b33abe1c2f" category="paragraph">Disaster Recovery-RTO- und RPO-Anforderungen variieren stärker, je nach Wahrscheinlichkeit eines Ausfalls und den Folgen des damit verbundenen Datenverlusts oder der Unterbrechung des Geschäftsbetriebs. RPO- und RTO-Anforderungen sollten auf den tatsächlichen geschäftlichen Anforderungen basieren und nicht auf allgemeinen Prinzipien. Sie müssen mehrere logische und physische Ausfallszenarien berücksichtigen.</block>
  <block id="68f31611fc8a5e6a20793905280a7001" category="section-title">Logische Ausfälle</block>
  <block id="07f5727077caaf8dedf895542181d26b" category="paragraph">Zu logischen Katastrophen gehören Datenbeschädigungen durch Benutzer, Applikations- oder Betriebssystemfehler und Fehlfunktionen. Zu logischen Katastrophen können auch böswillige Angriffe durch externe Parteien mit Viren oder Würmern gehören oder die Ausnutzung von Schwachstellen von Applikationen. In diesen Fällen wird die physische Infrastruktur unbeschädigt, die zugrunde liegenden Daten sind jedoch nicht mehr gültig.</block>
  <block id="3cb5ee5f24e42f56ba6dac48b7b046d2" category="paragraph">Eine immer häufiger vorauftretende logische Katastrophe wird als Ransomware bezeichnet. Bei ihr werden Daten mit einem Angriffsvektor verschlüsselt. Die Verschlüsselung schädigt die Daten nicht, macht sie jedoch erst verfügbar, wenn die Zahlung an einen Dritten erfolgt. Immer mehr Unternehmen sind gezielt auf Ransomware-Hacks ausgerichtet. Für diese Bedrohung bietet NetApp manipulationssichere Snapshots, bei denen nicht einmal der Storage-Administrator geschützte Daten vor dem konfigurierten Ablaufdatum ändern kann.</block>
  <block id="91c87f53ce0a1f416308a67ce119c623" category="section-title">Physische Ausfälle</block>
  <block id="79055ca11f54a97d22617a656eab8b9b" category="paragraph">Zu physischen Ausfällen gehört der Ausfall von Komponenten einer Infrastruktur, die die Redundanzmerkmale übertreffen und zu einem Datenverlust oder erweitertem Service-Verlust führen. Der RAID-Schutz bietet beispielsweise Redundanz für Laufwerke, und die Verwendung von HBAs bietet Redundanz für FC-Port und FC-Kabel. Hardwareausfälle solcher Komponenten sind vorhersehbar und beeinträchtigen nicht die Verfügbarkeit.</block>
  <block id="3f7c55fe5f35f94cd2c4bd73b9cbb11b" category="paragraph">In einer Unternehmensumgebung ist es in der Regel möglich, die Infrastruktur eines gesamten Standorts mit redundanten Komponenten so weit zu schützen, dass das einzige vorhersehbare physische Ausfallszenario ein vollständiger Verlust des Standorts ist. Die Planung des Disaster Recovery hängt dann von der Site-to-Site-Replizierung ab.</block>
  <block id="7f3dd7bdd41f7af6853732a383bbd7e2" category="section-title">Synchrone und asynchrone Datensicherung</block>
  <block id="c5ac17d5693914368f39b40a07af23d4" category="paragraph">Im Idealfall würden alle Daten zwischen geografisch verteilten Standorten synchron repliziert werden. Eine solche Replikation ist nicht immer möglich oder sogar aus mehreren Gründen möglich:</block>
  <block id="28c59a675d03e1f62a48958bb53ae523" category="list-text">Die synchrone Replikation erhöht zwangsläufig die Schreiblatenz, da alle Änderungen an beiden Standorten repliziert werden müssen, bevor die Applikation/Datenbank mit der Verarbeitung fortfahren kann. Der daraus resultierende Performance-Effekt ist manchmal nicht akzeptabel, sodass die Verwendung von synchroner Spiegelung ausgeschlossen wird.</block>
  <block id="50a05ceeb998c4dac7e8b5d706fe2029" category="list-text">Die zunehmende Einführung von 100 % SSD-Storage bedeutet, dass zusätzliche Schreiblatenz mit größerer Wahrscheinlichkeit zu verzeichnen ist, da die Performance-Erwartungen Hunderttausende IOPS und eine Latenz von unter einer Millisekunde umfassen. Um das volle Potenzial von 100 % SSDs auszuschöpfen, kann ein erneuter Besuch der Disaster-Recovery-Strategie erforderlich sein.</block>
  <block id="04d90fe6288ce6cceba54a2b71e55727" category="list-text">Die Anzahl der Datensätze nimmt weiterhin an Byte zu. Dies stellt Unternehmen vor Herausforderungen, wenn es darum geht, genügend Bandbreite für eine synchrone Replizierung sicherzustellen.</block>
  <block id="d3aaae220bd5b3d68dd4ccec3bf78197" category="list-text">Die Komplexität der Datensätze nimmt zu und führt zu Herausforderungen beim Management einer umfassenden synchronen Replizierung.</block>
  <block id="c3a841e0bfc640f91b0a00c4af8c6f5c" category="list-text">Cloud-basierte Strategien sind häufig mit höheren Replizierungsentfernungen und Latenz verbunden, wodurch die Nutzung einer synchronen Spiegelung weiterhin ausgeschlossen wird.</block>
  <block id="7df1515e247dfa2063c433b9339c2d4a" category="paragraph">NetApp bietet Lösungen, die sowohl synchrone Replikation für höchste Anforderungen an die Datenwiederherstellung als auch asynchrone Lösungen für eine bessere Performance und Flexibilität beinhalten. Darüber hinaus lässt sich die NetApp Technologie nahtlos in viele Replizierungslösungen von Drittanbietern integrieren, wie z. B. Oracle DataGuard</block>
  <block id="4d2c802af835583121763e1a6acc3f9b" category="section-title">Aufbewahrungszeit</block>
  <block id="123dbb4c09a5c8fb993a856cf65c9d25" category="paragraph">Der letzte Aspekt einer Datensicherungsstrategie ist die Zeit für die Datenaufbewahrung, die sehr unterschiedlich sein kann.</block>
  <block id="d3a424909a8559a2d076e5d9a28d834f" category="list-text">Eine typische Anforderung sind nächtliche Backups von 14 Tagen auf dem primären Standort und 90 Tage Backups auf einem sekundären Standort.</block>
  <block id="1d7c2d97c3bfd5ca9489e0ffeb06b150" category="list-text">Viele Kunden erstellen vierteljährliche eigenständige Archive, die auf unterschiedlichen Medien gespeichert sind.</block>
  <block id="61ae175e4a0c88c4624184a0cb9b04d2" category="list-text">Eine ständig aktualisierte Datenbank benötigt möglicherweise keine Verlaufsdaten, und Backups müssen nur für einige Tage aufbewahrt werden.</block>
  <block id="8bb85c2149e1e808032e7025b0a27b80" category="list-text">Gesetzliche Vorschriften erfordern möglicherweise die Wiederherstellbarkeit bis zu einem beliebigen Zeitpunkt jeder beliebigen Transaktion innerhalb eines Zeitfensters von 365 Tagen.</block>
  <block id="a83f7a3ea63946cbdc1977d641e8460c" category="summary">Oracle auf ONTAP und die Rolle der Snapshots</block>
  <block id="05280349760feacdd6227fb8012e39d7" category="doc">Snapshot basierte Backups</block>
  <block id="5e3f0537b2a1927f4a24b28e9157cc0b" category="paragraph">Die Grundlage der Oracle Datensicherung auf ONTAP ist die NetApp Snapshot Technologie.</block>
  <block id="a4c2aeedbfeeda21f232cbf45be91693" category="paragraph">Die wichtigsten Werte sind:</block>
  <block id="d06c89cff665ecdde6eded3c9d44cd2b" category="list-text">*Einfachheit.* Ein Snapshot ist eine schreibgeschützte Kopie des Inhalts eines Datencontainers zu einem bestimmten Zeitpunkt.</block>
  <block id="175888ba89c31a851f719bdd271cae9c" category="list-text">*Effizienz.* Snapshots benötigen zum Zeitpunkt der Erstellung keinen Platz. Der Speicherplatz wird nur dann verbraucht, wenn Daten geändert werden.</block>
  <block id="d853e9e275a6e58b3a9a56fa641cbb9f" category="list-text">*Verwaltbarkeit.* Eine auf Snapshots basierende Backup-Strategie lässt sich einfach konfigurieren und verwalten, da Snapshots ein nativer Teil des Storage-Betriebssystems sind. Wenn das Speichersystem eingeschaltet ist, kann es Backups erstellen.</block>
  <block id="b564e5fbab71af776ed54a19d09b268c" category="list-text">*Skalierbarkeit.* bis zu 1024 Backups eines einzigen Dateicontainers und LUNs können beibehalten werden. Bei komplexen Datensätzen können diverse Daten-Container durch einen einzelnen, konsistenten Satz von Snapshots gesichert werden.</block>
  <block id="7159872a568b97a971b9ea182fb23b7c" category="list-text">Die Performance bleibt davon unberührt, ob ein Volume 1024 Snapshots enthält oder keine.</block>
  <block id="1a54f7e14e6e652bb32b12df22faf387" category="paragraph">Viele Storage-Anbieter liefern zwar Snapshot-Technologie, doch ist die Snapshot Technologie bei ONTAP einzigartig und bietet in Enterprise-Applikations- und Datenbankumgebungen deutliche Vorteile:</block>
  <block id="d77b23e355dc2f65b90fb52ed9a90f9c" category="list-text">Snapshot Kopien sind Teil des zugrunde liegenden Write-Anywhere-Dateilayouts (WAFL). Es handelt sich nicht um ein Add-on oder eine externe Technologie. Dies vereinfacht das Management, da das Storage-System das Backup-System ist.</block>
  <block id="8b888e6a2d883c0111428c101532294a" category="list-text">Snapshot-Kopien beeinträchtigen die Performance nicht. Ausnahmen bilden Edge-Fälle, in denen so viele Daten in Snapshots gespeichert werden, dass sich das zugrunde liegende Storage-System füllt.</block>
  <block id="2283ea50a243a5d1ad551f7d21f39895" category="list-text">Der Begriff „Konsistenzgruppe“ wird häufig verwendet, um eine Gruppierung von Storage-Objekten zu referenzieren, die als konsistente Sammlung von Daten gemanagt werden. Ein Snapshot eines bestimmten ONTAP Volumes stellt ein Konsistenzgruppenbackup dar.</block>
  <block id="ac72c83a8204d600d567261b41c5488c" category="paragraph">ONTAP Snapshots lassen sich auch besser skalieren als bei Technologien von Mitbewerbern. Kunden können ohne Beeinträchtigung der Performance 5, 50 oder 500 Snapshots speichern. Derzeit sind in einem Volume maximal 1024 Snapshots zulässig. Wenn eine zusätzliche Snapshot-Aufbewahrung erforderlich ist, gibt es Optionen, die Snapshots an zusätzliche Volumes zu übergeben.</block>
  <block id="3b7ff39ba50f1bc3f56d38c41ba51855" category="paragraph">Daher ist die Sicherung eines auf ONTAP gehosteten Datensatzes einfach und hochskalierbar. Backups erfordern keine Verschiebung von Daten. Daher kann eine Backup-Strategie auf die Bedürfnisse des Unternehmens zugeschnitten werden und nicht auf die Beschränkungen der Netzwerkübertragungsraten, der großen Anzahl von Bandlaufwerken oder der Bereiche, in denen Festplatten bereitgestellt werden.</block>
  <block id="55c5bbb3aad88266600eaa1a526406d4" category="paragraph">Eine häufig gestellte Frage zur Verwendung von Snapshots als Datensicherungsstrategie ist die Tatsache, dass sich die „echten“ Daten und Snapshot-Daten auf denselben Laufwerken befinden. Der Verlust dieser Laufwerke würde sowohl zum Verlust der Primärdaten als auch des Backups führen.</block>
  <block id="68870deb35eeb53373325a314030bd11" category="paragraph">Lokale Snapshots sollten jedoch nie die einzige Backup-Strategie sein. Deshalb bietet NetApp Technologien wie SnapMirror und SnapVault-Replizierung, um Snapshots schnell und effizient auf einen unabhängigen Laufwerkssatz zu replizieren. In einer richtig konzipierten Lösung mit Snapshots und Snapshot-Replikation kann die Verwendung von Tapes auf ein vierteljährliches Archiv minimiert oder ganz eliminiert werden.</block>
  <block id="73d3fd255835ca3dc926f59d50223f91" category="paragraph">Für die Sicherung Ihrer Daten gibt es viele Optionen für den Einsatz von ONTAP Snapshots. Snapshots bilden die Basis vieler anderer ONTAP Funktionen wie Replizierung, Disaster Recovery und Klonen. Eine vollständige Beschreibung der Snapshot-Technologie geht über den Umfang dieses Dokuments hinaus. Die folgenden Abschnitte bieten jedoch einen allgemeinen Überblick.</block>
  <block id="7441577327d1d49b71cc2f6403e17e7b" category="paragraph">Es gibt zwei primäre Ansätze zum Erstellen eines Snapshots eines Datensatzes:</block>
  <block id="b38ba43128207852ef5149e6c578ba89" category="list-text">Absturzkonsistente Backups</block>
  <block id="dc64a2f6075820724476e435a1ebd7fa" category="list-text">Applikationskonsistente Backups</block>
  <block id="7733cc553d118547b64c858cb4281f24" category="paragraph">Ein absturzkonsistentes Backup eines Datensatzes bezieht sich auf die Erfassung der gesamten Datensatzstruktur zu einem bestimmten Zeitpunkt. Wenn der Datensatz in einem einzigen NetApp FlexVol Volume gespeichert wird, ist der Vorgang einfach. Ein Snapshot kann jederzeit erstellt werden. Wenn ein Datensatz in mehreren Volumes gespeichert ist, muss ein Snapshot einer Konsistenzgruppe (CG) erstellt werden. Für das Erstellen von Snapshots von Konsistenzgruppen stehen verschiedene Optionen zur Verfügung, darunter NetApp SnapCenter-Software, native Funktionen von ONTAP-Konsistenzgruppen und vom Benutzer verwaltete Skripts.</block>
  <block id="32561979f55bc68c4f028fd26a9975f6" category="paragraph">Absturzkonsistente Backups kommen vor allem dann zum Einsatz, wenn die Recovery am Point-of-the-Backup ausreichend ist. Wenn ein granulareres Recovery erforderlich ist, sind in der Regel applikationskonsistente Backups erforderlich.</block>
  <block id="367735591e5e6e04c17b7930acb29b7d" category="paragraph">Das Wort „konsistent“ in „anwendungskonsistent“ ist oft eine Fehlbezeichnung. Das Platzieren einer Oracle-Datenbank in den Backup-Modus wird beispielsweise als applikationskonsistentes Backup bezeichnet, die Daten werden jedoch in keiner Weise konsistent oder stillgelegt. Die Daten ändern sich während des Backups weiterhin. Im Gegensatz dazu machen die meisten MySQL und Microsoft SQL Server Backups die Daten tatsächlich stillgelegt, bevor sie das Backup ausführen. VMware kann bestimmte Dateien konsistent machen oder auch nicht.</block>
  <block id="ebf90723e7659cb5381545104b618612" category="paragraph">Der Begriff „Konsistenzgruppe“ bezieht sich auf die Fähigkeit eines Speicherarrays, mehrere Speicherressourcen als ein einziges Image zu verwalten. Beispielsweise kann eine Datenbank aus 10 LUNs bestehen. Das Array muss in der Lage sein, diese 10 LUNs konsistent zu sichern, wiederherzustellen und zu replizieren. Eine Wiederherstellung ist nicht möglich, wenn die Images der LUNs zum Zeitpunkt des Backups nicht konsistent waren. Die Replikation dieser 10 LUNs erfordert, dass alle Replikate perfekt miteinander synchronisiert sind.</block>
  <block id="3f8a43f1defaa984435092f616876545" category="paragraph">Der Begriff „Konsistenzgruppe“ wird nicht oft verwendet, wenn es um ONTAP geht, da Konsistenz immer eine Grundfunktion der Volume- und Aggregat-Architektur in ONTAP war. Viele andere Storage Arrays managen LUNs oder File-Systeme als einzelne Einheiten. Sie könnten aus Datenschutzgründen optional als „Konsistenzgruppe“ konfiguriert werden, dies ist jedoch ein zusätzlicher Schritt in der Konfiguration.</block>
  <block id="74e816c3c784f5c30c79dca4590d7f59" category="paragraph">ONTAP war schon immer in der Lage, konsistente lokale und replizierte Images von Daten zu erfassen. Auch wenn die verschiedenen Volumes auf einem ONTAP-System normalerweise nicht formal als Konsistenzgruppe beschrieben werden, so sind sie doch das. Ein Snapshot dieses Volumes ist ein Konsistenzgruppenabbild, die Wiederherstellung dieses Snapshots ist eine Wiederherstellung der Konsistenzgruppe, und sowohl SnapMirror als auch SnapVault bieten Konsistenzgruppenreplikation.</block>
  <block id="15cc4389a08c3f4748e98622e630ad3e" category="section-title">Snapshots von Konsistenzgruppen</block>
  <block id="d286b747757ef3d8d3abac27bfae65f9" category="paragraph">Konsistenzgruppen-Snapshots (cg-Snapshots) sind eine Erweiterung der grundlegenden ONTAP-Snapshot-Technologie. Bei einem standardmäßigen Snapshot-Vorgang wird ein konsistentes Image aller Daten innerhalb eines einzelnen Volumes erstellt. In manchen Fällen ist es jedoch erforderlich, einen konsistenten Satz von Snapshots über mehrere Volumes und sogar über mehrere Storage-Systeme hinweg zu erstellen. Das Ergebnis ist ein Satz von Snapshots, die auf die gleiche Weise wie ein Snapshot von nur einem einzelnen Volume verwendet werden können. Sie können für die lokale Datenwiederherstellung verwendet, für Disaster Recovery-Zwecke repliziert oder als einheitliche konsistente Einheit geklont werden.</block>
  <block id="7c199465bc6344e648e2f73c88131605" category="paragraph">Die größte Verwendung von cg-Snapshots ist eine Datenbankumgebung mit einer Größe von ca. 1 PB und 12 Controllern. Die cg-Snapshots, die auf diesem System erstellt wurden, werden für Backups, Wiederherstellungen und Klonvorgänge verwendet.</block>
  <block id="e5c199b4a97409f33d5caae984957744" category="paragraph">Wenn ein Datensatz über mehrere Volumes verteilt und die Schreibreihenfolge beibehalten werden muss, wird meist automatisch ein cg-Snapshot von der ausgewählten Managementsoftware verwendet. Es besteht in solchen Fällen nicht die Notwendigkeit, die technischen Details von cg-Snapshots zu verstehen. Allerdings gibt es Situationen, in denen komplizierte Datensicherungsanforderungen eine detaillierte Kontrolle über den Datenschutz- und Replizierungsprozess erfordern. Einige Optionen sind Automatisierungs-Workflows oder der Einsatz benutzerdefinierter Skripte, um cg-Snapshot-APIs aufzurufen. Das Verständnis der besten Option und der Rolle von cg-Snapshot erfordert eine detailliertere Erläuterung der Technologie.</block>
  <block id="cf3c30ea5c240a8aef02d240f42cdff7" category="paragraph">Die Erstellung eines Satzes von cg-Snapshots erfolgt in zwei Schritten:</block>
  <block id="f30455406a91bd776afbc88e60b9697e" category="list-text">Erstellung von Write Fencing auf allen Ziel-Volumes</block>
  <block id="c7afe45d94f2fd172a01e851d7f92a2f" category="list-text">Erstellen Sie Snapshots dieser Volumes im abgetrennten Zustand.</block>
  <block id="c464d4671e489eaad9a8cbf0a8086ea9" category="paragraph">Schreibzaun wird seriell hergestellt. Das bedeutet, dass bei der Einrichtung des Fencing-Prozesses über mehrere Volumes hinweg die I/O-Schreibvorgänge auf dem ersten Volume in der Sequenz eingefroren werden, da sie weiterhin auf Volumes übertragen werden, die später angezeigt werden. Dies mag anfänglich möglicherweise gegen die Vorgabe verstoßen, die Schreibreihenfolge zu erhalten, gilt aber nur für I/O-Vorgänge, die asynchron auf dem Host ausgegeben werden und nicht von anderen Schreibvorgängen abhängen.</block>
  <block id="688656b1f8644ee299edf7be87a8fc75" category="paragraph">Beispielsweise kann eine Datenbank eine Vielzahl asynchroner Datendatei-Updates ausgeben und dem Betriebssystem ermöglichen, die I/O-Vorgänge neu zu ordnen und sie gemäß seiner eigenen Scheduler-Konfiguration abzuschließen. Die Reihenfolge dieser E/A-Typen kann nicht garantiert werden, da die Anwendung und das Betriebssystem bereits die Anforderung zur Wahrung der Schreibreihenfolge freigegeben haben.</block>
  <block id="599ce07d1bae0fa6169959e2bdb97ada" category="paragraph">Als Zählerbeispiel sind die meisten Datenbankprotokollierungsaktivitäten synchron. Die Datenbank fährt erst mit weiteren Protokollschreibvorgängen fort, nachdem der I/O-Vorgang bestätigt wurde und die Reihenfolge dieser Schreibvorgänge erhalten bleiben muss. Wenn ein Protokoll-I/O auf einem Volume mit Fencing ankommt, wird dies nicht bestätigt, und die Applikation blockiert weitere Schreibvorgänge. Ebenso ist der I/O der Filesystem-Metadaten in der Regel synchron. Beispielsweise darf ein Dateilösch nicht verloren gehen. Wenn ein Betriebssystem mit einem xfs-Dateisystem eine Datei und den I/O gelöscht hat, der die xfs-Dateisystemmetadaten aktualisiert hat, um den Verweis auf diese Datei zu entfernen, der auf einem umzäunten Volume gelandet ist, wird die Dateisystemaktivität angehalten. Dies garantiert die Integrität des Dateisystems während cg-Snapshot-Vorgängen.</block>
  <block id="0f0c0f05310f9cf257d65bfd936f15c5" category="paragraph">Nach der Einrichtung von Write Fencing über die Ziel-Volumes hinweg sind sie für die Snapshot-Erstellung bereit. Die Snapshots müssen nicht genau zur gleichen Zeit erstellt werden, da der Zustand der Volumes aus einer abhängigen Schreibweise eingefroren wird. Um sich vor einem Fehler in der Anwendung zu schützen, die cg-Snapshots erstellt, enthält das anfängliche Write Fencing ein konfigurierbares Timeout, bei dem ONTAP die Fencing automatisch freigibt und die Schreibverarbeitung nach einer definierten Anzahl von Sekunden wieder aufnimmt. Wenn alle Snapshots erstellt werden, bevor die Zeitüberschreitung abgelaufen ist, dann ist der resultierende Snapshot-Satz eine gültige Konsistenzgruppe.</block>
  <block id="df4925d1c6c3f3258e80ff35ce62b17d" category="section-title">Abhängige Schreibreihenfolge</block>
  <block id="6c78ee478b93fbb573157b85fb1114db" category="paragraph">Aus technischer Sicht ist der Schlüssel zu einer Konsistenzgruppe die Aufrechterhaltung der Schreibreihenfolge und insbesondere der abhängigen Schreibreihenfolge. Beispielsweise wird eine Datenbank, die in 10 LUNs schreibt, gleichzeitig auf alle geschrieben. Viele Schreibvorgänge werden asynchron ausgegeben. Dies bedeutet, dass die Reihenfolge ihrer Fertigstellung unwichtig ist und die Reihenfolge ihrer Fertigstellung je nach Betriebssystem und Netzwerkverhalten variiert.</block>
  <block id="69d87c00869001f3f06ad4a1494eac21" category="paragraph">Einige Schreibvorgänge müssen auf der Festplatte vorhanden sein, bevor die Datenbank mit zusätzlichen Schreibvorgängen fortfahren kann. Diese kritischen Schreibvorgänge werden als abhängige Schreibvorgänge bezeichnet. Nachfolgende Schreib-I/O hängt davon ab, ob diese Schreibvorgänge auf der Festplatte vorhanden sind. Jeder Snapshot, jede Wiederherstellung oder Replikation dieser 10 LUNs muss sicherstellen, dass die abhängige Schreibreihenfolge gewährleistet ist. Dateisystemaktualisierungen sind ein weiteres Beispiel für Schreibvorgänge in Schreibreihenfolge. Die Reihenfolge, in der Dateisystemänderungen vorgenommen werden, muss beibehalten werden, oder das gesamte Dateisystem kann beschädigt werden.</block>
  <block id="74fbae5d0b3c16e1774c5f4dce2c1c36" category="section-title">Strategien</block>
  <block id="53e858edb9bd9ff3f9ead52cebf5731d" category="paragraph">Es gibt zwei primäre Ansätze bei Snapshot-basierten Backups:</block>
  <block id="f87f61f625a005bd32c53f808d235eea" category="list-text">Snapshot geschützte Hot-Backups</block>
  <block id="c81725eb350a685210d69762bd5d725d" category="paragraph">Ein absturzkonsistentes Backup einer Datenbank bezieht sich auf die Erfassung der gesamten Datenbankstruktur, einschließlich Datendateien, Wiederherstellungsprotokolle und Kontrolldateien zu einem bestimmten Zeitpunkt. Wenn die Datenbank in einem einzigen NetApp FlexVol Volume gespeichert wird, ist der Vorgang einfach. Ein Snapshot kann jederzeit erstellt werden. Wenn eine Datenbank in mehreren Volumes gespeichert ist, muss ein Snapshot einer Konsistenzgruppe (CG) erstellt werden. Für das Erstellen von Snapshots von Konsistenzgruppen stehen verschiedene Optionen zur Verfügung, darunter NetApp SnapCenter-Software, native Funktionen von ONTAP-Konsistenzgruppen und vom Benutzer verwaltete Skripts.</block>
  <block id="c32eba270db95747b471fd53e203a47b" category="paragraph">Absturzkonsistente Snapshot Backups werden in erster Linie verwendet, wenn die Recovery eines bestimmten Backup ausreichend ist. Archivprotokolle können unter bestimmten Umständen eingesetzt werden. Wenn jedoch eine granularere zeitpunktgenaue Recovery erforderlich ist, ist ein Online-Backup vorzuziehen.</block>
  <block id="82cc23cd5dc667cc9fb78ff6e76ac15b" category="paragraph">Das grundlegende Verfahren für ein Snapshot-basiertes Online-Backup ist wie folgt:</block>
  <block id="dbaf4855045e45fbcf678fa4cd1ab2db" category="list-text">Platzieren Sie die Datenbank in<block ref="402051f4be0cc3aad33bcf3ac3d6532b" prefix=" " category="inline-code"></block> Modus.</block>
  <block id="c3e07fb8aef84ef3d94e3f9d5376c091" category="list-text">Erstellen Sie einen Snapshot aller Volumes, die Datendateien hosten.</block>
  <block id="2d0e58ff1a25bd9fd8a85ad8ce6f2665" category="list-text">Beenden<block ref="402051f4be0cc3aad33bcf3ac3d6532b" prefix=" " category="inline-code"></block> Modus.</block>
  <block id="4196c5674aaa9e4317b2b4c54f94a905" category="list-text">Führen Sie den Befehl aus<block ref="9d2840394bc37850da4e360dbf60c0dc" prefix=" " category="inline-code"></block> So erzwingen Sie die Protokollarchivierung.</block>
  <block id="f2736e795871e2fc2d36addb9436f337" category="list-text">Erstellen Sie Snapshots aller Volumes, die die Archivprotokolle hosten.</block>
  <block id="f24880a3fe8b242fdd1aba5a2d11196f" category="paragraph">Dieses Verfahren ergibt einen Satz von Snapshots, die Datendateien im Backup-Modus enthalten, und die kritischen Archivprotokolle, die im Backup-Modus generiert wurden. Dies sind die beiden Anforderungen für das Recovery einer Datenbank. Dateien wie Kontrolldateien sollten ebenfalls aus Gründen der Bequemlichkeit geschützt werden, aber die einzige absolute Anforderung ist die Sicherung von Datendateien und Archivprotokollen.</block>
  <block id="0c32649da44277db19fcfa3fe4dac28f" category="paragraph">Auch wenn unterschiedliche Kunden möglicherweise sehr unterschiedliche Strategien verfolgen, basieren fast alle diese Strategien letztendlich auf den unten erläuterten Prinzipien.</block>
  <block id="88f451afed04f47352987f617f805826" category="section-title">Snapshot-basierte Recovery</block>
  <block id="c092a9763068c8382be82f9c77bb9658" category="paragraph">Beim Entwurf von Volume-Layouts für Oracle-Datenbanken ist die erste Entscheidung, ob die Volume-basierte VBSR-Technologie (NetApp SnapRestore) verwendet wird.</block>
  <block id="15a0b8dc4d1b340d403bf6515f7e61b8" category="paragraph">Mit Volume-basierten SnapRestore kann ein Volume fast sofort auf einen früheren Zeitpunkt zurückgesetzt werden. Da alle Daten auf dem Volume zurückgesetzt werden, ist VBSR möglicherweise nicht für alle Anwendungsfälle geeignet. Wenn beispielsweise eine gesamte Datenbank, einschließlich Datendateien, Wiederherstellungs- und Archivprotokolle, auf einem einzelnen Volume gespeichert ist und dieses Volume mit VBSR wiederhergestellt wird, gehen Daten verloren, da das neuere Archivprotokoll und die Wiederherstellungsdaten verworfen werden.</block>
  <block id="e63c0ca12b07a654ccadd92527a95c47" category="paragraph">VBSR ist für die Wiederherstellung nicht erforderlich. Viele Datenbanken können mithilfe von dateibasiertem Single-File SnapRestore (SFSR) oder einfach durch Kopieren von Dateien aus dem Snapshot zurück in das aktive Dateisystem wiederhergestellt werden.</block>
  <block id="2093e578085fede0f022c4efdb79c336" category="paragraph">VBSR wird bevorzugt, wenn eine Datenbank sehr groß ist oder wenn sie so schnell wie möglich wiederhergestellt werden muss, und die Verwendung von VBSR erfordert die Isolierung der Datendateien. In einer NFS-Umgebung müssen die Datendateien einer bestimmten Datenbank in dedizierten Volumes gespeichert werden, die nicht durch andere Dateitypen kontaminiert sind. In einer SAN-Umgebung müssen Datendateien in dedizierten LUNs auf dedizierten FlexVol Volumes gespeichert werden. Wenn ein Volume-Manager verwendet wird (einschließlich Oracle Automatic Storage Management [ASM]), muss die Festplattengruppe auch für Datendateien reserviert sein.</block>
  <block id="b38bd603a952c93872eae2ea858cb15f" category="paragraph">Werden Datendateien auf diese Weise isoliert, können sie in einen früheren Zustand zurückgesetzt werden, ohne andere Filesysteme zu beschädigen.</block>
  <block id="5755a6275c3ecd99e8159efc58a8ff6c" category="section-title">Snapshot Reserve</block>
  <block id="957abb72f2db3a20e0b570a5fa3a1dcc" category="paragraph">Für jedes Volume mit Oracle-Daten in einer SAN-Umgebung die<block ref="9ca25b30dcc119f9115aad6d85fd12ce" prefix=" " category="inline-code"></block> Sollte auf null gesetzt werden, da das Reservieren von Speicherplatz für einen Snapshot in einer LUN-Umgebung nicht nützlich ist. Wenn die fraktionale Reserve auf 100 eingestellt ist, benötigt ein Snapshot eines Volumes mit LUNs genug freien Platz im Volumen, ausgenommen die Snapshot-Reserve, um 100% Umsatz aller Daten aufzunehmen. Wenn die fraktionale Reserve auf einen niedrigeren Wert eingestellt ist, dann ist entsprechend weniger freier Speicherplatz erforderlich, schließt jedoch immer die Snapshot Reserve aus. Das bedeutet, dass der Speicherplatz der Snapshot-Reserve in einer LUN-Umgebung verschwendet wird.</block>
  <block id="d5a06adf11e69f265f3ee3277212764e" category="paragraph">In einer NFS-Umgebung gibt es zwei Optionen:</block>
  <block id="7631336a8e2e03f6ac500c145445b2d7" category="list-text">Stellen Sie die ein<block ref="9ca25b30dcc119f9115aad6d85fd12ce" prefix=" " category="inline-code"></block> Basiert auf dem erwarteten Snapshot-Speicherplatzverbrauch.</block>
  <block id="acc4c5d06fc4a9ac93880c9c2d0a6e76" category="list-text">Stellen Sie die ein<block ref="9ca25b30dcc119f9115aad6d85fd12ce" prefix=" " category="inline-code"></block> Zur gemeinsamen Nutzung von Speicherplatz und Snapshots sowie zur Vermeidung und zum Management dieser Kapazitäten.</block>
  <block id="44806986c5abfcd6261803f4f75a7b56" category="paragraph">Mit der ersten Option<block ref="9ca25b30dcc119f9115aad6d85fd12ce" prefix=" " category="inline-code"></block> Wird auf einen Wert ungleich Null gesetzt, normalerweise etwa 20 %. Dieser Raum wird dann vor dem Benutzer ausgeblendet. Dieser Wert schafft jedoch keine Begrenzung der Auslastung. Wenn bei einer Datenbank mit einer Reservierung von 20 % 30 % anfällt, kann der Snapshot-Platz über die Grenze der 20-prozentigen Reserve hinauswachsen und nicht reservierten Speicherplatz belegen.</block>
  <block id="c8910acb0bfa30f82b423ff09a9710ca" category="paragraph">Der Hauptvorteil, wenn Sie eine Reserve auf einen Wert wie 20% setzen, besteht darin zu überprüfen, ob etwas Speicherplatz für Snapshots immer verfügbar ist. Bei einem 1-TB-Volume mit einer Reserve von 20 % wäre es beispielsweise nur einem Datenbankadministrator (DBA) möglich, 800 GB an Daten zu speichern. Diese Konfiguration garantiert mindestens 200 GB Speicherplatz für den Snapshot-Verbrauch.</block>
  <block id="be233226a8cb890c0a8bbf041c06ac6b" category="paragraph">Wenn<block ref="9ca25b30dcc119f9115aad6d85fd12ce" prefix=" " category="inline-code"></block> Ist auf null festgelegt, sodass der gesamte Speicherplatz im Volume für den Endbenutzer verfügbar ist, sodass bessere Sichtbarkeit gewährleistet wird. Ein DBA muss verstehen, dass ein 1-TB-Volume, das Snapshots nutzt, 1 TB Speicherplatz zwischen aktiven Daten und dem Snapshot-Umsatz gemeinsam genutzt wird.</block>
  <block id="b10efee713968b90d211d08ec8345d20" category="paragraph">Es gibt keine klare Präferenz zwischen Option 1 und Option 2 unter den Endbenutzern.</block>
  <block id="8112d08173571f2d01372cadea3ea76d" category="section-title">Snapshots von ONTAP und Drittanbietern</block>
  <block id="0cc082f7cc7618a904f6cde556295cbd" category="paragraph">Oracle Doc ID 604683.1 erläutert die Anforderungen für die Snapshot-Unterstützung von Drittanbietern und die verschiedenen verfügbaren Optionen für Backup- und Wiederherstellungsvorgänge.</block>
  <block id="130a02f8381e6c54b2ea07d2bdaf6f0b" category="paragraph">Der Drittanbieter muss sicherstellen, dass die Snapshots des Unternehmens den folgenden Anforderungen entsprechen:</block>
  <block id="97eb59a0f249226523b31dd52d557e00" category="list-text">Snapshots müssen sich in die von Oracle empfohlenen Restore- und Recovery-Vorgänge integrieren.</block>
  <block id="083e9332dc2b6bf064139ac2e670eee9" category="list-text">Snapshots müssen zum Zeitpunkt des Snapshots auch beim Absturz einer Datenbank konsistent sein.</block>
  <block id="9dae8634b638a6949dab0f7eaf7988bd" category="list-text">Die Schreibreihenfolge wird für jede Datei in einem Snapshot beibehalten.</block>
  <block id="7bc868657652757ca8505ddcd297456f" category="paragraph">Die Oracle Managementprodukte von ONTAP und NetApp erfüllen diese Anforderungen.</block>
  <block id="9ec85da221bc7f0822b82657e52f4955" category="summary">Einführung in die Oracle Datensicherung</block>
  <block id="9e19caeb431a5e29a1a63e3cee4b36c9" category="doc">Oracle Datensicherung mit ONTAP</block>
  <block id="6f1383567177df0041e76e845c3629f2" category="paragraph">Die geschäftskritischsten Daten befinden sich in Datenbanken.</block>
  <block id="848aab87f65bfade12f80d4e864ec046" category="paragraph">Ein Unternehmen kann nicht ohne Zugriff auf seine Daten arbeiten, und manchmal definieren die Daten das Unternehmen. Diese Daten müssen geschützt werden. Bei der Datensicherung geht es jedoch mehr als nur um das Sicherstellen eines nutzbaren Backups. Es geht darum, die Backups schnell und zuverlässig durchzuführen und diese sicher zu speichern.</block>
  <block id="28a0304f97f876b27cf541f4ad9a30d7" category="paragraph">Die andere Seite der Datensicherung ist die Datenwiederherstellung. Wenn auf Daten nicht zugegriffen werden kann, ist das Unternehmen betroffen und kann nicht mehr in Betrieb sein, bis die Daten wiederhergestellt werden. Dieser Prozess muss schnell und zuverlässig sein. Schließlich müssen die meisten Datenbanken vor Ausfällen geschützt werden, was bedeutet, dass ein Replikat der Datenbank beibehalten wird. Das Replikat muss ausreichend aktuell sein. Außerdem muss es schnell und einfach sein, das Replikat zu einer voll funktionsfähigen Datenbank zu machen.</block>
  <block id="3d601b26d05eac41fc6a7eba92fdc8b9" category="admonition">Diese Dokumentation ersetzt den zuvor veröffentlichten technischen Bericht _TR-4591: Oracle Data Protection: Backup, Recovery und Replication._</block>
  <block id="21d28aa03f67eb242b1c95a6a0594ff5" category="section-title">Planung</block>
  <block id="0bf5784d6c307e4ee0371d46053937c0" category="summary">Oracle-Performance-Tests</block>
  <block id="3993fbf2fe01237c798f68ece0b84724" category="doc">Performance-Optimierung und -Benchmarking von Oracle</block>
  <block id="355ba59494fea8b20be391a73cc755eb" category="paragraph">Das genaue Testen der Datenbank-Storage-Performance ist dabei ein extrem kompliziertes Thema. Sie müssen die folgenden Probleme verstehen:</block>
  <block id="b57041cc3b57577b5c21eff44739e3f9" category="list-text">IOPS und Durchsatz</block>
  <block id="236e7fd957ada95e8094e302623980d3" category="list-text">Der Unterschied zwischen Vorder- und Hintergrund-I/O-Vorgängen</block>
  <block id="902f90cc4ab59808cac5606f767f61c4" category="list-text">Auswirkungen der Latenz auf die Datenbank</block>
  <block id="196198dbaa1d1ea17cfc478fbb2f419f" category="list-text">Zahlreiche Betriebssystem- und Netzwerkeinstellungen, die ebenfalls die Storage-Performance beeinträchtigen</block>
  <block id="5ff18eadb2ef3fc20e13bed3e5b61d79" category="paragraph">Darüber hinaus müssen Aufgaben außerhalb von Storage-Datenbanken berücksichtigt werden. An diesem Punkt kann die Optimierung der Storage-Performance keine nützlichen Vorteile ergeben, da die Storage-Performance keinen einschränkenden Faktor mehr für die Performance darstellt.</block>
  <block id="92d509b1796c0ac8e185dc559cb7e294" category="paragraph">Da sich die meisten Datenbankkunden nun für All-Flash-Arrays entscheiden, sind weitere Überlegungen anzustellen. Betrachten Sie beispielsweise Performance-Tests auf einem AFF8080 System mit zwei Nodes:</block>
  <block id="4eb08b8b1c39980bb639a6e5890ec0de" category="list-text">Mit einem Lese-/Schreib-Verhältnis von 75/25 können zwei AFF8080 Nodes über 300.000 zufällige Datenbank-IOPS liefern, bevor die Latenz sogar die 1-ms-Marke überschreitet. Dies geht weit über die aktuellen Performance-Anforderungen der meisten Datenbanken hinaus, sodass sich die erwartete Verbesserung nur schwer vorhersagen lässt. Storage würde zu einem großen Teil als Engpass gelöscht werden.</block>
  <block id="32a993d3f497a6dd4392d3348b05ebc3" category="list-text">Die Netzwerkbandbreite ist eine immer häufiger auftretende Ursache für Leistungseinschränkungen. Lösungen mit rotierenden Festplatten sind beispielsweise häufig Engpässe in der Datenbank-Performance, da die I/O-Latenz sehr hoch ist. Wenn Latenzbeschränkungen von einem All-Flash-Array beseitigt werden, verschiebt sich die Barriere häufig in das Netzwerk. Dies ist insbesondere bei virtualisierten Umgebungen und Blade-Systemen so bemerkenswert, dass sich die tatsächliche Netzwerkverbindung nur schwer visualisieren lässt. Das kann Performance-Tests erschweren, wenn das Storage-System selbst aufgrund von Bandbreiteneinschränkungen nicht vollständig ausgelastet werden kann.</block>
  <block id="8caa382fb0f5f7a8279424d306dd003d" category="list-text">Der Vergleich der Performance eines All-Flash-Arrays mit einem Array mit rotierenden Festplatten ist im Allgemeinen aufgrund der deutlich verbesserten Latenz von All-Flash-Arrays nicht möglich. Die Testergebnisse sind in der Regel nicht aussagekräftig.</block>
  <block id="bc2b8b37bdda467f2ce639ab28bf4646" category="list-text">Der Vergleich der IOPS-Spitzenperformance mit einem All-Flash-Array ist häufig kein nützlicher Test, da Datenbanken nicht durch Storage-I/O eingeschränkt werden Angenommen, ein Array unterstützt 500.000 zufällige IOPS, ein anderes dagegen 300.000. Der Unterschied ist in der Praxis irrelevant, wenn eine Datenbank 99 % ihrer Zeit für die CPU-Verarbeitung aufwendet. Die Workloads schöpfen dabei niemals alle Kapazitäten des Storage-Arrays aus. Demgegenüber sind IOPS-Spitzenfunktionen bei einer Konsolidierungsplattform durchaus von großer Bedeutung, bei der das Storage-Array voraussichtlich auf seine Spitzenfunktionen ausgelastet ist.</block>
  <block id="0c2cbb26e6baa58b7d3a3309f95a2786" category="list-text">Berücksichtigen Sie bei jedem Storage-Test sowohl Latenz als auch IOPS. Viele Storage Arrays auf dem Markt bieten angeblich ein äußerst extremes IOPS-Niveau, doch aufgrund der Latenz sind diese IOPS in einem solchen Maß nutzlos. Ein typisches Ziel mit All-Flash-Arrays ist die Marke von 1 ms. Ein besserer Testansatz ist nicht die Messung der maximal möglichen IOPS, sondern die Ermittlung der IOPS-Anzahl, die ein Storage-Array verarbeiten kann, bevor die durchschnittliche Latenz größer als 1 ms ist.</block>
  <block id="e6d8362588e550c19912b0f3f0e1a129" category="section-title">Oracle Automatic Workload Repository und Benchmarking</block>
  <block id="d035df494751722dd56d4cf4a8d1f795" category="paragraph">Der Goldstandard für die Performance-Vergleiche mit Oracle ist ein Oracle Automatic Workload Repository (AWR) Bericht.</block>
  <block id="95f7e55383674168e90b01b708bc88db" category="paragraph">Es gibt mehrere Typen von AWR-Berichten. Aus Sicht des Speicherpunkts ein Bericht, der durch Ausführen des generiert wird<block ref="5053a9940effa118d38161a53f3b80f8" prefix=" " category="inline-code"></block> Der Befehl ist der umfassendste und wertvollste, da er auf eine bestimmte Datenbankinstanz abzielt und einige detaillierte Histogramme enthält, die Speicher-I/O-Ereignisse basierend auf Latenz aufteilen.</block>
  <block id="7b79802e5668e6e5b990081db481505d" category="paragraph">Um zwei Performance-Arrays zu vergleichen, wird idealerweise derselbe Workload auf jedem Array ausgeführt und ein AWR-Bericht erstellt, der genau auf den Workload abzielt. Bei einer sehr langen Arbeitslast kann ein einzelner AWR-Bericht mit einer verstrichenen Zeit, die die Start- und Stoppzeit umfasst, verwendet werden. Es ist jedoch vorzuziehen, die AWR-Daten als mehrere Berichte auszuteilen. Wenn beispielsweise ein Batch-Job von Mitternacht bis 6 Uhr ausgeführt wurde, erstellen Sie eine Reihe einstündiger AWR-Berichte von Mitternacht bis 1 Uhr, von 1 bis 2 Uhr usw.</block>
  <block id="e39ecb86ad7d25413ba8ad2976fd3e4a" category="paragraph">In anderen Fällen sollte eine sehr kurze Abfrage optimiert werden. Die beste Option ist ein AWR-Bericht, der auf einem AWR-Snapshot basiert, der beim Start der Abfrage erstellt wurde, und ein zweiter AWR-Snapshot, der beim Ende der Abfrage erstellt wurde. Der Datenbankserver sollte ansonsten ruhig sein, um die Hintergrundaktivität zu minimieren, die die Aktivität der analysierten Abfrage verdunkeln würde.</block>
  <block id="2fe7152c186ec1b5b0451e13ec8b968b" category="admonition">Wenn AWR-Berichte nicht verfügbar sind, sind Oracle Statspack-Berichte eine gute Alternative. Sie enthalten die meisten der gleichen I/O-Statistiken wie ein AWR-Bericht.</block>
  <block id="8b8c73ac7e509a897688356d1d283d75" category="section-title">Oracle AWR und Fehlerbehebung</block>
  <block id="42a92c79ee82f4343e7d65f2f1cf2dd2" category="paragraph">Ein AWR-Bericht ist auch das wichtigste Werkzeug zur Analyse eines Leistungsproblems.</block>
  <block id="ad5387afbab7c506c781c8b12b0a4b24" category="paragraph">Wie bei Benchmarking muss auch bei der Performance-Fehlerbehebung ein bestimmter Workload genau gemessen werden. Wenn möglich, geben Sie AWR-Daten ein, wenn Sie dem NetApp Support Center ein Performance-Problem melden oder wenn Sie mit einem NetApp oder einem Partner Account Team an einer neuen Lösung arbeiten.</block>
  <block id="6471146c0e33e2a8ec8a5c6635c837bc" category="paragraph">Beachten Sie bei der Bereitstellung von AWR-Daten die folgenden Anforderungen:</block>
  <block id="5c3ba265890805919f93c246b3f8d2d6" category="list-text">Führen Sie die aus<block ref="5053a9940effa118d38161a53f3b80f8" prefix=" " category="inline-code"></block> Befehl zum Generieren des Berichts. Die Ausgabe kann entweder Text oder HTML sein.</block>
  <block id="25db65f9a36910f3e488a8b7407130de" category="list-text">Wenn Oracle Real Application Clusters (RACs) verwendet werden, erstellen Sie AWR-Berichte für jede Instanz im Cluster.</block>
  <block id="96d55341f8208c60720e68b3155f3aa1" category="list-text">Ziel der Zeitpunkt, zu dem das Problem aufgetreten ist. Die maximal zulässige verstrichene Zeit eines AWR-Berichts beträgt in der Regel eine Stunde. Wenn ein Problem mehrere Stunden andauert oder einen mehrstündigen Vorgang wie einen Batch-Job umfasst, stellen Sie mehrere einstündige AWR-Berichte bereit, die den gesamten zu analysierenden Zeitraum abdecken.</block>
  <block id="4533b15b837909c68a0171d2638494d2" category="list-text">Wenn möglich, stellen Sie das AWR-Snapshot-Intervall auf 15 Minuten ein. Diese Einstellung ermöglicht eine detailliertere Analyse. Dies erfordert auch zusätzliche Ausführungen von<block ref="5053a9940effa118d38161a53f3b80f8" prefix=" " category="inline-code"></block> Um einen Bericht für jedes 15-Minuten-Intervall bereitzustellen.</block>
  <block id="97eb6d04cc93934c1be4ab95054cd0b0" category="list-text">Wenn es sich bei dem Problem um eine sehr kurze laufende Abfrage handelt, geben Sie einen AWR-Bericht an, der auf einem AWR-Snapshot basiert, der beim Start des Vorgangs erstellt wurde, und einen zweiten AWR-Snapshot, der nach Beendigung des Vorgangs erstellt wurde. Der Datenbankserver sollte ansonsten ruhig sein, um die Hintergrundaktivität zu minimieren, die die Aktivität des analysierten Vorgangs verdunkeln würde.</block>
  <block id="5186f459ce7d75e587a083bcb7c5927a" category="list-text">Wenn ein Leistungsproblem zu bestimmten Zeiten gemeldet wird, aber nicht zu anderen, liefern Sie zusätzliche AWR-Daten, die eine gute Leistung zum Vergleich zeigen.</block>
  <block id="108a72dad388aa310cc52ee3bac7d1cc" category="section-title">Kalibrieren_io</block>
  <block id="f1c07dfccef6a6c47a5ccef938e10e3d" category="paragraph">Der<block ref="108a72dad388aa310cc52ee3bac7d1cc" prefix=" " category="inline-code"></block> Der Befehl sollte niemals zum Testen, Vergleichen oder Vergleichen von Storage-Systemen verwendet werden. Wie in der Oracle-Dokumentation beschrieben, werden mit diesem Verfahren die I/O-Funktionen des Speichers kalibriert.</block>
  <block id="872892cce56a2665ad7ceecc44b38166" category="paragraph">Kalibrierung ist nicht dasselbe wie Benchmarking. Mit diesem Befehl können Sie I/O-Vorgänge ausgeben, um Datenbankvorgänge zu kalibrieren und ihre Effizienz zu verbessern, indem Sie die I/O-Ausgabe für den Host optimieren. Da der Typ der I/O, die vom ausgeführt wird<block ref="108a72dad388aa310cc52ee3bac7d1cc" prefix=" " category="inline-code"></block> Der Betrieb entspricht nicht der tatsächlichen I/O von Datenbankbenutzern, die Ergebnisse sind nicht vorhersehbar und häufig nicht einmal reproduzierbar.</block>
  <block id="e66807fad19acd41db50eedff918a4dd" category="section-title">SLOB2</block>
  <block id="0a6192ff5412539c31db2c7a98f408b3" category="inline-link-macro"><block ref="0a6192ff5412539c31db2c7a98f408b3" category="inline-link-rx"></block></block>
  <block id="d1f6fb23f52090ffd944dc54549735b8" category="paragraph">SLOB2, der Silly Little Oracle Benchmark, ist zum bevorzugten Tool für die Bewertung der Datenbank-Performance geworden. Es wurde von Kevin Closson entwickelt und ist verfügbar unter <block ref="3ccce0719b1965cd915da75778e4e706" category="inline-link-macro-rx"></block>. Die Installation und Konfiguration dauert nur wenige Minuten und mithilfe einer echten Oracle-Datenbank lassen sich I/O-Muster auf einem benutzerdefinierbaren Tablespace generieren. Es ist eine der wenigen verfügbaren Testoptionen, die die Auslastung eines All-Flash-Arrays mit I/O-Vorgängen ermöglichen Er eignet sich auch zur Generierung von deutlich niedrigeren I/O-Werten, um Storage-Workloads zu simulieren, die zwar niedrige IOPS, aber latenzempfindlich sind.</block>
  <block id="baffd8ac40ca7b966340e7b257b4c7b4" category="section-title">Wechselbank</block>
  <block id="905a59d6f73f4e2aea1dc232a3bcd195" category="paragraph">SwingBench kann zum Testen der Datenbank-Performance nützlich sein, aber es ist extrem schwierig, SwingBench auf eine Art und Weise zu verwenden, die den Storage belastet. Bei NetApp gab es noch keine Tests von Swingbench, die genug I/O ergaben, um auf jedem AFF Array eine erhebliche Belastung zu sein. In begrenzten Fällen kann der Order Entry Test (OET) verwendet werden, um die Storage-Systeme unter Latenzsicht zu bewerten. Dies kann in Situationen nützlich sein, in denen eine Datenbank eine bekannte Latenzabhängigkeit für bestimmte Abfragen hat. Achten Sie unbedingt darauf, dass Host und Netzwerk ordnungsgemäß konfiguriert sind, um die Latenzpotenziale eines All-Flash-Arrays auszuschöpfen.</block>
  <block id="e3cf940afa524b20b15c43b20405be77" category="section-title">HammerDB</block>
  <block id="5c9408da71d2ff7554b9fd11add795cf" category="paragraph">HammerDB ist ein Datenbank-Test-Tool, das unter anderem TPC-C- und TPC-H-Benchmarks simuliert. Es kann eine Menge Zeit dauern, bis ein ausreichend großer Datensatz für die ordnungsgemäße Ausführung eines Tests erstellt wurde. Er kann aber ein effektives Tool zur Performance-Evaluierung für OLTP- und Data Warehouse-Applikationen sein.</block>
  <block id="7e1ad070b7fff621d9d64a71cec87684" category="section-title">Orion</block>
  <block id="56fedcbec2842fb62a743c5f84311597" category="paragraph">Das Oracle Orion Tool wurde häufig mit Oracle 9 verwendet, wurde jedoch nicht gewartet, um die Kompatibilität mit Änderungen in verschiedenen Host-Betriebssystemen zu gewährleisten. Er wird aufgrund der Inkompatibilitäten mit der Betriebssystem- und Storage-Konfiguration selten mit Oracle 10 oder Oracle 11 verwendet.</block>
  <block id="38622bf572fa7bec2dc7f3915ebd345f" category="paragraph">Oracle hat das Tool neu geschrieben und es wird standardmäßig mit Oracle 12c installiert. Obwohl dieses Produkt verbessert wurde und viele der gleichen Aufrufe verwendet, die eine echte Oracle-Datenbank verwendet, verwendet es nicht genau den gleichen Codepfad oder das gleiche I/O-Verhalten, das von Oracle verwendet wird. Beispielsweise werden die meisten Oracle I/OS synchron ausgeführt, was bedeutet, dass die Datenbank angehalten wird, bis der I/O-Vorgang abgeschlossen ist, während der I/O-Vorgang im Vordergrund abgeschlossen ist. Eine einfache Überflutung eines Storage-Systems mit zufälligen I/OS ist keine Reproduktion von realen Oracle I/O und bietet keine direkte Methode, Storage Arrays zu vergleichen oder die Auswirkungen von Konfigurationsänderungen zu messen.</block>
  <block id="bb68dfada5ca20e256bbd3ffbbfab9e6" category="paragraph">Dennoch gibt es einige Anwendungsfälle für Orion, wie z. B. die generelle Messung der maximal möglichen Performance einer bestimmten Host-Netzwerk-Storage-Konfiguration oder die Abmessung des Zustands eines Storage-Systems. Mit sorgfältigen Tests können nutzbare Orion Tests entwickelt werden, um Storage-Arrays zu vergleichen oder die Auswirkungen einer Konfigurationsänderung zu bewerten, sofern zu den Parametern IOPS, Durchsatz und Latenz gehören und versucht werden, einen realistischen Workload originalgetreu zu replizieren.</block>
  <block id="6b64090d226d30776368e89b08c7c71b" category="summary">WAFL-Ausrichtung für Oracle Datenbanken</block>
  <block id="03a35ba2b6191f8cfbd1cca378eefc91" category="doc">Überprüfung der WAFL Ausrichtung von Oracle Datenbanken</block>
  <block id="219900dcd21cee2f958254a708ad36f6" category="paragraph">Eine korrekte WAFL-Ausrichtung ist für eine gute Performance von entscheidender Bedeutung. Obwohl ONTAP Blöcke in 4-KB-Einheiten managt, bedeutet dies nicht, dass ONTAP alle Vorgänge in 4-KB-Einheiten ausführt. ONTAP unterstützt zwar Blockoperationen unterschiedlicher Größen, die zugrunde liegende Buchhaltung wird jedoch von WAFL in 4-KB-Einheiten gemanagt.</block>
  <block id="5d3a5c290e14d74acf49b20d15120886" category="paragraph">Der Begriff „Alignment“ bezieht sich darauf, wie Oracle I/O diesen 4-KB-Einheiten entspricht. Für eine optimale Performance ist ein Oracle 8-KB-Block auf zwei physischen 4-KB-WAFL-Blöcken eines Laufwerks erforderlich. Wenn ein Block durch 2 KB verrechnet wird, befindet sich dieser Block auf der Hälfte eines 4-KB-Blocks, einem separaten vollständigen 4-KB-Block und dann der Hälfte eines dritten 4-KB-Blocks. Diese Anordnung führt zu Leistungseinbußen.</block>
  <block id="0073ce99d632b066d5ac09a4ad0cf7fc" category="paragraph">Bei NAS-File-Systemen ist die Ausrichtung nicht relevant. Oracle Datendateien werden am Anfang der Datei auf Basis der Größe des Oracle Blocks ausgerichtet. Daher sind Blockgrößen von 8 KB, 16 KB und 32 KB immer ausgerichtet. Alle Blockoperationen werden vom Anfang der Datei in Einheiten von 4 Kilobyte versetzt.</block>
  <block id="d7f7edd61ab216efc34578584a7d0e7c" category="paragraph">LUNs enthalten dagegen in der Regel zu Beginn eine Art Treiber-Header oder Filesystem-Metadaten, wodurch ein Offset erzeugt wird. Die Ausrichtung ist in modernen Betriebssystemen selten ein Problem, da diese Betriebssysteme für physische Laufwerke ausgelegt sind, die möglicherweise einen nativen 4-KB-Sektor verwenden, was außerdem die Ausrichtung der I/O an 4-KB-Grenzen erfordert, um eine optimale Performance zu erzielen.</block>
  <block id="38b3d1cd67903560954ad297a92e3de1" category="paragraph">Es gibt jedoch einige Ausnahmen. Eine Datenbank wurde möglicherweise von einem älteren Betriebssystem migriert, das nicht für 4 KB I/O optimiert wurde, oder ein Benutzerfehler während der Partitionserstellung hat möglicherweise zu einem Offset geführt, der sich nicht in Einheiten von 4 KB befindet.</block>
  <block id="612eeadd26ceeace7b043d37f8e24b1f" category="paragraph">Die folgenden Beispiele sind Linux-spezifisch, aber das Verfahren kann für jedes Betriebssystem angepasst werden.</block>
  <block id="1d5b772bea21e5e949413e09eedf17de" category="section-title">Ausgerichtet</block>
  <block id="594b0fc1af44897ff4b26f2e6b866685" category="paragraph">Das folgende Beispiel zeigt eine Ausrichtungsüberprüfung einer einzelnen LUN mit einer einzelnen Partition.</block>
  <block id="dc2c18402c86861702fc1d94a6495ac3" category="paragraph">Erstellen Sie zunächst die Partition, die alle auf dem Laufwerk verfügbaren Partitionen verwendet.</block>
  <block id="adff8cc6319e96d2685fd082a5aa043c" category="paragraph">Die Ausrichtung kann mathematisch mit folgendem Befehl überprüft werden:</block>
  <block id="4bc7aba328a710bb7d0935cf830634aa" category="paragraph">Die Ausgabe zeigt an, dass die Einheiten 512 Byte betragen, und der Beginn der Partition ist 32 Einheiten. Dies sind insgesamt 32 x 512 = 16,834 Byte, was ein ganzes Vielfaches von 4-KB-WAFL-Blöcken ist. Diese Partition ist korrekt ausgerichtet.</block>
  <block id="dd343941469b5360af52eb1b94fe5de6" category="paragraph">Führen Sie die folgenden Schritte durch, um die korrekte Ausrichtung zu überprüfen:</block>
  <block id="7d84e72acd05d0c93d99e414f5b092b5" category="list-text">Identifizieren Sie die UUID (Universally Unique Identifier) der LUN.</block>
  <block id="92af2a93f00a6297c490ba0be5fd7a8a" category="list-text">Geben Sie die Node-Shell auf dem ONTAP-Controller ein.</block>
  <block id="5274579d5eff6fe6d1e8ecbf54e84993" category="list-text">Starten Sie statistische Sammlungen auf der im ersten Schritt identifizierten Ziel-UUID.</block>
  <block id="52df0a2ea976123bf02330300b2392e3" category="list-text">Führen Sie einige I/O-Vorgänge aus Es ist wichtig, die zu verwenden<block ref="3c908d68ba53922b92c5595b72fa011c" prefix=" " category="inline-code"></block> Argument, um sicherzustellen, dass I/O synchron und nicht gepuffert ist.</block>
  <block id="fac8a5b490ea29eca93ec213d79e6ff2" category="admonition">Seien Sie sehr vorsichtig mit diesem Befehl. Umkehren der<block ref="39c8942e1038872a822c0dc75eedbde3" prefix=" " category="inline-code"></block> Und<block ref="8bf8854bebe108183caeb845c7676ae4" prefix=" " category="inline-code"></block> Argumente zerstören Daten.</block>
  <block id="4f7dce34a21e3de727f3e3ad05e6e7d8" category="list-text">Stoppen Sie die Statistiken, und zeigen Sie das Alignment-Histogramm an. Alle I/O-Vorgänge sollten sich im befinden<block ref="c6bd178b372b0ddd17fff48819badc6a" prefix=" " category="inline-code"></block> Bucket-Modul zur Angabe von I/O, die an einer 4-KB-Blockgrenze ausgerichtet ist</block>
  <block id="5df81374c01d1b7c20fe8cb3883117eb" category="section-title">Falsch Ausgerichtet</block>
  <block id="5ff266dadf965b3c304513f516a13c12" category="paragraph">Im folgenden Beispiel wird eine falsch ausgerichtete I/O angezeigt:</block>
  <block id="25be03b87e6a5d8170ce85b16ea506ab" category="list-text">Erstellen Sie eine Partition, die nicht an einer 4-KB-Grenze ausgerichtet ist. Dies ist kein Standardverhalten auf modernen Betriebssystemen.</block>
  <block id="9879c10d67b41984cae0992340d157f0" category="list-text">Die Partition wurde mit einem 33-Sektor-Offset anstelle der Standardeinstellung 32 erstellt. Wiederholen Sie den in beschriebenen Vorgang <block ref="9eef0931337736367767200cf12a7482" category="inline-link-macro-rx"></block>. Das Histogramm wird wie folgt angezeigt:</block>
  <block id="4adda0e871000c2b13a4faef6ce4e21b" category="paragraph">Die Fehlausrichtung ist klar. Die I/O fällt meist in das* <block ref="66c8d76cad709856ccec680cab8ab35a" prefix="*" category="inline-code"></block> Bucket, der dem erwarteten Offset entspricht. Bei der Erstellung der Partition wurde sie 512 Byte weiter in das Gerät verschoben als der optimierte Standardwert, was bedeutet, dass das Histogramm durch 512 Byte versetzt wird.</block>
  <block id="b53cb977228ac351c16dfacc3c427a99" category="paragraph">Darüber hinaus der<block ref="20e637b3ddd562732de038fba736c7ee" prefix=" " category="inline-code"></block> Die Statistik ist ein Wert ungleich Null, was bedeutet, dass I/O-Vorgänge ausgeführt wurden, die keinen gesamten 4-KB-Block aufgefüllt haben.</block>
  <block id="d3d92f87c5235ad11c8bc69e85fb2fd0" category="section-title">Wiederherstellungsprotokollierung</block>
  <block id="162b54d51a30629d78e153f8da201780" category="paragraph">Die hier erläuterten Verfahren gelten für Datendateien. Oracle Redo- und Archivprotokolle weisen unterschiedliche I/O-Muster auf. Beispielsweise ist die Wiederherstellungsprotokollierung ein kreisförmiges Überschreiben einer einzelnen Datei. Wenn die standardmäßige 512-Byte-Blockgröße verwendet wird, sehen die Schreibstatistiken in etwa wie folgt aus:</block>
  <block id="d36dbaa617441d3308f5a9b50cb6f5ca" category="paragraph">Die I/O-Vorgänge werden auf alle Histogramm-Buckets verteilt, dies stellt jedoch keine Performance-Sorge dar. Extrem hohe Redo-Protokollierungsraten können jedoch von der Verwendung einer 4-KB-Blockgröße profitieren. In diesem Fall ist es wünschenswert, dass die LUNs für die Wiederherstellungsprotokollierung ordnungsgemäß ausgerichtet sind. Dies ist jedoch für eine gute Performance nicht so wichtig wie die Datendateiausrichtung.</block>
  <block id="f64f1c647516f5a47c00be152fdbf488" category="summary">Oracle und veraltete NFSv3-Sperren</block>
  <block id="91d9710c9fee248ae3e9c4b810ae704f" category="doc">Veraltete NFSv3-Sperren und Oracle-Datenbanken</block>
  <block id="3f9e1e3abd12ad7445baea4b681b9ceb" category="paragraph">Wenn ein Oracle-Datenbankserver abstürzt, kann es beim Neustart zu Problemen mit veralteten NFS-Sperren kommen. Dieses Problem ist vermeidbar, indem Sie sorgfältig auf die Konfiguration der Namensauflösung auf dem Server achten.</block>
  <block id="288ebefc25180862eb0448b786b1b9fc" category="paragraph">Dieses Problem tritt auf, weil das Erstellen einer Sperre und das Löschen einer Sperre zwei leicht unterschiedliche Methoden der Namensauflösung verwenden. Es sind zwei Prozesse beteiligt: Der Network Lock Manager (NLM) und der NFS-Client. Der NLM verwendet<block ref="e5caaf154dfeed411b9eec65b903a22a" prefix=" " category="inline-code"></block> Um den Hostnamen zu ermitteln, während der<block ref="d49331f31f40041ebcee19fca74fd9d4" prefix=" " category="inline-code"></block> Prozessanwendungen<block ref="330c4316ae6124616389eb1ca9912f7a" prefix=" " category="inline-code"></block>. Diese Hostnamen müssen übereinstimmen, damit das Betriebssystem veraltete Sperren ordnungsgemäß löschen kann. Beispielsweise sucht der Host nach Sperren, die Eigentum von sind<block ref="c7169a6dd344d0f0a38071a1262e4973" prefix=" " category="inline-code"></block>, Aber die Schlösser wurden vom Host als registriert<block ref="0c32c65f5ac66d0bdb4e63bd5fde7f75" prefix=" " category="inline-code"></block>. Wenn<block ref="330c4316ae6124616389eb1ca9912f7a" prefix=" " category="inline-code"></block> Gibt nicht denselben Wert zurück wie<block ref="5c020b5bb8d1ce1ace51c2a2f4c06fc2" prefix=" " category="inline-code"></block>, Dann ist der Sperrvorgang nicht erfolgreich.</block>
  <block id="19b9a1f540971d74c69042125bab2abc" category="paragraph">Mit dem folgenden Beispielskript wird überprüft, ob die Namensauflösung vollständig konsistent ist:</block>
  <block id="ee04b3fa3b28391874763596275e09c9" category="paragraph">Wenn<block ref="b64c6f211add16fd66ac17ef14c2a2b4" prefix=" " category="inline-code"></block> Stimmt nicht überein<block ref="4040592cec1880aa70936989f05e7c31" prefix=" " category="inline-code"></block>, Veraltete Sperren sind wahrscheinlich. Dieses Ergebnis zeigt beispielsweise ein potenzielles Problem auf:</block>
  <block id="2b500e5914ea5a219ade17dea0808f51" category="paragraph">Die Lösung wird normalerweise durch Ändern der Reihenfolge gefunden, in der Hosts in angezeigt werden<block ref="ad942c725cd0cae65ca4c63717ec464c" prefix=" " category="inline-code"></block>. Nehmen wir beispielsweise an, dass die Hosts-Datei diesen Eintrag enthält:</block>
  <block id="22b58ec1cec48707dfc018e6e216e966" category="paragraph">Um dieses Problem zu beheben, ändern Sie die Reihenfolge, in der der vollständig qualifizierte Domänenname und der kurze Hostname angezeigt werden:</block>
  <block id="e357ccd0745db58f22ea5c0947b613ee" category="paragraph"><block ref="330c4316ae6124616389eb1ca9912f7a" prefix="" category="inline-code"></block> Gibt nun den Short zurück<block ref="c7169a6dd344d0f0a38071a1262e4973" prefix=" " category="inline-code"></block> Host-Name, der mit der Ausgabe von übereinstimmt<block ref="4040592cec1880aa70936989f05e7c31" prefix=" " category="inline-code"></block>. Sperren werden somit nach einem Serverabsturz automatisch gelöscht.</block>
  <block id="547b870352d8464aadbe7bee63d6f3d1" category="summary">Einführung in die Datenbankvirtualisierung</block>
  <block id="ea4c55be196897a16d86999f5c16d582" category="doc">Einheitliche</block>
  <block id="4a478889a2e46bee771126a78eda2911" category="paragraph">Die Virtualisierung von Datenbanken mit VMware ESX, Oracle OVM oder KVM wird für NetApp-Kunden, die sich für die Virtualisierung selbst für ihre geschäftskritischsten Datenbanken entschieden haben, immer häufiger eingesetzt.</block>
  <block id="0f976e587b1e7af0949904e76d91384b" category="paragraph">In den Support-Richtlinien für Virtualisierung gibt es viele falsche Annahmen, insbesondere für VMware Produkte. Tatsächlich ist es nicht ungewöhnlich zu hören, dass Oracle keine Virtualisierung unterstützt. Diese Vorstellung ist falsch und führt zu verpassten Virtualisierungsmöglichkeiten. Oracle Doc ID 249212.1 behandelt bekannte Probleme in einer Oracle-Umgebung und gibt auch die Unterstützung für RAC an.</block>
  <block id="02ea3d7754e6bc1c99ff77393e49e373" category="paragraph">Ein Kunde mit einem Oracle unbekannten Problem wird möglicherweise gebeten, das Problem auf physischer Hardware zu reproduzieren. Ein Oracle Kunde, der eine brandneue Version eines Produkts ausführt, möchte möglicherweise wegen der Möglichkeit einer neuen Fehlererkennung keine Virtualisierung verwenden. Für Virtualisierungskunden, die allgemein verfügbare Produktversionen verwenden, war diese Situation jedoch in der Praxis kein Problem.</block>
  <block id="9e28dbd7a4f5940eeaf6d3893c5c4b1f" category="section-title">Storage-Präsentation</block>
  <block id="8fdbc6d55014a06c15b9f130e5bedd12" category="paragraph">Kunden, die eine Virtualisierung ihrer Datenbanken in Erwägung ziehen, sollten ihre Storage-Entscheidungen basierend auf ihren Geschäftsanforderungen treffen. Dies ist zwar eine allgemein zutreffende Aussage für alle IT-Entscheidungen, ist jedoch besonders für die Virtualisierung wichtig, da die Größe und der Umfang der Projekte erheblich variieren.</block>
  <block id="6cf53ad2948792abdf4a8668365b8396" category="paragraph">Es gibt vier grundlegende Optionen für die Storage-Präsentation:</block>
  <block id="151ae53a4100e0a6e83bde4d78083f81" category="list-text">Vom iSCSI-Initiator gemanagte iSCSI-LUNs auf der VM, nicht der Hypervisor</block>
  <block id="73014dc1e7381cfd107ba79742a873e3" category="list-text">NFS-Dateisysteme, die von der VM gemountet werden, kein Virtual Machine Disk (VMDK)</block>
  <block id="810f0004f0e8e215c676ac0621d5836b" category="list-text">Hypervisor-Datastores</block>
  <block id="8e2a0eba3eaebd64066d020ab225dd78" category="paragraph">Vermeiden Sie in der Regel die Verwendung von Datastores für Oracle-Dateien. Diese Empfehlung hat viele Gründe:</block>
  <block id="98b171e836c6656f9cf88835666c6345" category="list-text">*Transparenz.* Wenn eine VM Eigentümer ihrer Dateisysteme ist, ist es einfacher für einen Datenbank-Administrator oder einen Systemadministrator, die Quelle der Dateisysteme für ihre Daten zu identifizieren.</block>
  <block id="ec6a3b593d5584a2e15651852e384082" category="list-text">*Performance.* Tests haben gezeigt, dass es einen Performance-Effekt gibt, wenn alle I/O über einen Hypervisor-Datastore geleitet werden.</block>
  <block id="47464ddf615c138c6c06d3bfea555b2d" category="list-text">*Verwaltbarkeit.* Wenn eine VM Eigentümer ihrer Dateisysteme ist, wirkt sich die Verwendung oder Nichtnutzung einer Hypervisor-Schicht auf die Verwaltbarkeit aus. Die gleichen Verfahren für die Bereitstellung, das Monitoring, die Datensicherung usw. können über den gesamten Bestand hinweg eingesetzt werden, einschließlich sowohl virtualisierter als auch nicht virtualisierter Umgebungen.</block>
  <block id="3d04d7019fbc0d27880dcc5c0881f87b" category="list-text">*Stabilität und Fehlerbehebung.* Wenn eine VM über ihre Dateisysteme verfügt, sind die Bereitstellung einer guten, stabilen Leistung und Problembehandlung viel einfacher, da der gesamte Speicher-Stack auf der VM vorhanden ist. Die einzige Rolle des Hypervisors besteht darin, FC- oder IP-Frames zu transportieren. Wenn ein Datastore in einer Konfiguration enthalten ist, wird die Konfiguration durch die Einführung eines weiteren Satzes von Timeouts, Parametern, Protokolldateien und potenziellen Bugs erschwert.</block>
  <block id="36f9cea3dc0f65698a9fbe15460591c1" category="list-text">*Portabilität.* Wenn eine VM Eigentümer ihrer Dateisysteme ist, wird der Prozess des Verschiebens einer Oracle-Umgebung viel einfacher. Dateisysteme können problemlos zwischen virtualisierten und nicht virtualisierten Gastsystemen verschoben werden.</block>
  <block id="cb90f9e52412940f028394174f31ec2f" category="list-text">*Vendor Lock-in.* Nachdem die Daten in einem Datastore platziert wurden, wird es sehr schwierig, einen anderen Hypervisor zu verwenden oder die Daten aus der virtualisierten Umgebung zu nehmen.</block>
  <block id="4308dde96d1bdae6ac436a611c834331" category="list-text">*Snapshot-Aktivierung.* in manchen Fällen können Backups in einer virtualisierten Umgebung wegen der relativ begrenzten Bandbreite zum Problem werden. So kann beispielsweise ein 10-GbE-Trunk mit vier Ports ausreichen, um die täglichen Performance-Anforderungen vieler virtualisierter Datenbanken zu unterstützen. Ein solcher Trunk wäre jedoch nicht ausreichend, um Backups mit RMAN oder anderen Backup-Produkten durchzuführen, die ein Streaming einer vollständigen Kopie der Daten erfordern.</block>
  <block id="872c95c8713fd14a0bef21fe92a55ab7" category="paragraph">Durch die Verwendung von Filesystemen, die sich im Besitz von VMs befinden, können Snapshot-basierte Backups und Restores einfacher genutzt werden. Ein Dateisystem, das sich im Besitz von VMs befindet, lädt die Durchführung von Backups auf das Storage-System. Die Hypervisor-Konfiguration muss nicht allein zur Unterstützung der Bandbreiten- und CPU-Anforderungen im Backup-Fenster überdimensioniert werden.</block>
  <block id="3522f960cdbaf08c375bd70214f8db2f" category="admonition">*NetApp empfiehlt* die Vermeidung der Platzierung von Oracle-Daten auf einem Datastore, um optimale Performance und Verwaltbarkeit zu erreichen. Verwenden Sie vom Gast gemanagte Dateisysteme wie NFS- oder iSCSI-Dateisysteme oder mit RDMs.</block>
  <block id="f114856edc6cd8d6a9add5ec3f67656f" category="section-title">Paravirtualisierte Treiber</block>
  <block id="beeb10ceee6c9aabe178fb51edea7d22" category="paragraph">Für eine optimale Leistung ist die Verwendung paravirtualisierter Netzwerktreiber von entscheidender Bedeutung. Wenn ein Datastore verwendet wird, ist ein paravirtualisierter SCSI-Treiber erforderlich. Ein paravirtualisierter Gerätetreiber ermöglicht es einem Gast, sich tiefer in den Hypervisor zu integrieren, im Gegensatz zu einem emulierten Treiber, bei dem der Hypervisor mehr CPU-Zeit damit verbringt, das Verhalten physischer Hardware nachzuahmen.</block>
  <block id="59b3d62404749c3e899b7e4c9ee10146" category="paragraph">Die Performance der meisten Datenbanken wird durch Storage eingeschränkt. Daher fällt die zusätzliche Latenz, die durch ein Netzwerk oder einen SCSI-Treiber entsteht, besonders auf. Der NetApp Kundensupport ist auf viele Leistungsbeschwerden gestoßen, die durch die Installation paravirtualisierter Treiber behoben wurden. Bei einem Machbarkeitsnachweis für Kunden zeigten Datenbanken eine bessere Performance unter ESX als bei derselben Hardware, die wie beim Bare Metal lief. Die Tests waren sehr I/O-intensiv und der Performance-Unterschied wurde durch die Verwendung der paravirtualisierten ESX Netzwerktreiber zugeschrieben.</block>
  <block id="4e27b04a271416c5701a99234f8a23e6" category="admonition">*NetApp empfiehlt* immer paravirtualisierte Netzwerktreiber und SCSI-Treiber zu verwenden.</block>
  <block id="7c5996fc15a24ce96b30160b60ac2b96" category="section-title">RAM überschreiben</block>
  <block id="5bccdd812c4af1cb5b9e36ddce656b60" category="paragraph">Das Überschreiben von RAM bedeutet, mehr virtualisierten RAM auf verschiedenen Hosts zu konfigurieren, als auf der physischen Hardware vorhanden ist. Dies kann zu unerwarteten Leistungsproblemen führen. Bei der Virtualisierung einer Datenbank dürfen die zugrunde liegenden Blöcke des Oracle SGA nicht durch den Hypervisor in den Storage getauscht werden. Dies führt zu äußerst instabilen Performance-Ergebnissen.</block>
  <block id="31db92967e891f0a122e0329d819842e" category="admonition">*NetApp empfiehlt*, einen Hypervisor nicht so zu konfigurieren, dass Oracle SGA-Blöcke ausgetauscht werden können.</block>
  <block id="be493f1fc0b02ae45602c7c13f7b5dc7" category="summary">TR-4792 unterstützt die Verwendung von NetApp HCI 615C für 3D-Grafik-Workloads in einer VMware Horizon-Umgebung mit NVIDIA-GPUs (Graphics Processing Units) und Virtualisierungssoftware.</block>
  <block id="ff1d278a485c443dc5d8fc9f10f1a702" category="doc">NetApp HCI for Virtual Desktop Infrastructure mit VMware Horizon 7 – stärken Sie Ihre Power-User mit 3D-Grafiken</block>
  <block id="e3162938e0d7b1bbc74111cc5b5871c5" category="paragraph">TR-4792 enthält Anweisungen zur Verwendung des NetApp H615C Computing-Nodes für 3D-Grafik-Workloads in einer VMware Horizon-Umgebung mit NVIDIA-GPUs (Graphics Processing Units) und Virtualisierungssoftware. Er enthält außerdem die Ergebnisse der vorläufigen Tests von SPECviewperf 13 für den H615C.</block>
  <block id="1de37c09602b46db5de57a946efe2768" category="paragraph"><block ref="1de37c09602b46db5de57a946efe2768" category="inline-link-macro-rx"></block></block>
  <block id="5ed492cbbbf7e6d167035a7c10478daa" category="summary">Das VMware Endbenutzer-Computing mit NetApp HCI ist eine validierte Best-Practice Datacenter-Architektur zur Implementierung virtueller Desktop Workloads im Enterprise-Maßstab.</block>
  <block id="36f00397200c227ebfe56599e7bafcd5" category="doc">NVA-1129-DESIGN: VMware End-User Computing mit NetApp HCI und NVIDIA GPUs</block>
  <block id="52940073ac3f539b3c6d9ac1e41d5f06" category="paragraph">Das VMware Endbenutzer-Computing mit NetApp HCI ist eine validierte Best-Practice Datacenter-Architektur zur Implementierung virtueller Desktop Workloads im Enterprise-Maßstab. Dieses Dokument beschreibt das Architekturdesign und Best Practices für eine zuverlässige und risikofreie Implementierung der Lösung im Produktionsskala.</block>
  <block id="8a36e2f35bf4a10959caf61f15d8df63" category="paragraph"><block ref="8a36e2f35bf4a10959caf61f15d8df63" category="inline-link-macro-rx"></block></block>
  <block id="b4a3c2c985fcfc0d0e59c8d9c3259eb0" category="doc">NVA-1129-DEPLOY: VMware Endbenutzer-Computing mit NetApp HCI und NVIDIA-GPUs</block>
  <block id="8b3f1e47da9509d2edf2f21012c6ec7e" category="paragraph">VMware End-User Computing with NetApp HCI ist eine vorab validierte, Best Practice Datacenter-Architektur zur Implementierung virtueller Desktop Workloads auf Enterprise-Niveau. In diesem Dokument wird beschrieben, wie Sie die Lösung im Produktionsskala zuverlässig und risikofrei bereitstellen</block>
  <block id="ba999af3664a8f6c5b43a92bc11de64a" category="paragraph"><block ref="ba999af3664a8f6c5b43a92bc11de64a" category="inline-link-macro-rx"></block></block>
  <block id="85864e2699dfaceb7f8d1f85448939fe" category="doc">NVA-1132-DESIGN: VMware Endbenutzer-Computing mit NetApp HCI</block>
  <block id="8c40c45c2332a47a83ae257f42af2331" category="paragraph"><block ref="8c40c45c2332a47a83ae257f42af2331" category="inline-link-macro-rx"></block></block>
  <block id="93b94e62ad8cb02a1d1a7b0944a5445d" category="summary">Dieses Dokument beschreibt die Produktsicherheit für ONTAP Tools für VMware vSphere.</block>
  <block id="57a033c33a8be6110be46b2914cc4989" category="doc">Verwendung von VVols mit ONTAP</block>
  <block id="69556d50c944e0a07ade0bea62f078a3" category="paragraph">Für die Verwendung von VVols mit ONTAP muss die VASA Provider Software als Bestandteil der virtuellen ONTAP Tools für die VMware vSphere Appliance integriert sein.</block>
  <block id="5e484430124a3d64541b75bbf3c8f529" category="paragraph">Zu den ONTAP-Tools gehören außerdem vCenter-UI-Erweiterungen, REST-API-Server, Storage Replication Adapter für VMware Site Recovery Manager, Monitoring- und Host-Konfigurationstools sowie eine Reihe von Berichten, mit denen Sie Ihre VMware-Umgebung besser managen können.</block>
  <block id="21247c4392dc3c243f693dbf5b762553" category="section-title">Produkte und Dokumentation</block>
  <block id="4fc5e15c4dc0d227bc5f8f26e4337083" category="paragraph">Mit der ONTAP FlexClone Lizenz (in ONTAP One enthalten) und der ONTAP Tools Appliance sind nur die zusätzlichen Produkte erforderlich, um VVols in Verbindung mit NetApp ONTAP zu verwenden. Die neuesten Versionen der ONTAP Tools werden als einzige vereinheitlichte Appliance bereitgestellt und auf ESXi ausgeführt. Sie bieten die Funktionen von ehemals drei verschiedenen Appliances und Servern. Bei VVols ist es wichtig, die vCenter UI-Erweiterungen der ONTAP Tools oder REST-APIs als allgemeine Managementtools und Benutzeroberflächen für ONTAP Funktionen mit vSphere zusammen mit dem VASA Provider, der bestimmte VVols Funktionen bereitstellt, zu verwenden. Die SRA Komponente ist für herkömmliche Datastores enthalten, doch VMware Site Recovery Manager verwendet keine SRA für VVols. Stattdessen werden neue Services in SRM 8.3 und höher implementiert, bei denen der VASA-Provider für die VVols-Replizierung genutzt wird.</block>
  <block id="bf03408d75f93f6e28c07c3c2300b98a" category="section-title">ONTAP nutzt die VASA Provider Architektur unter Verwendung von iSCSI oder FCP</block>
  <block id="94ef809dc16e728151bda996f8b4f8aa" category="inline-image-macro">ONTAP Tools VASA Provider Architektur,240</block>
  <block id="d78de3410d86d345a548abdf67aff375" category="paragraph"><block ref="d78de3410d86d345a548abdf67aff375" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5e5421e75636200787a4449a2cdaa1f1" category="section-title">Produktinstallation</block>
  <block id="3ef3033a2b9a744a1e4e7e93fa01f909" category="paragraph">Bei Neuinstallationen implementieren Sie die virtuelle Appliance in Ihrer vSphere Umgebung. Aktuelle Versionen der ONTAP Tools werden sich automatisch bei Ihrem vCenter registrieren und VASA Provider standardmäßig aktivieren. Zusätzlich zu den ESXi-Host- und vCenter-Server-Informationen benötigen Sie auch die IP-Adresskonfigurationsdetails für die Appliance. Wie bereits erwähnt, muss für VASA Provider die Lizenz ONTAP FlexClone bereits auf allen ONTAP Clustern installiert sein, die Sie für VVols verwenden möchten. Die Appliance verfügt über einen integrierten Watchdog, um die Verfügbarkeit zu gewährleisten. Als Best Practice sollte sie mit VMware High Availability und optional mit Fault Tolerance-Funktionen konfiguriert werden. Weitere Informationen finden Sie in Abschnitt 4.1. Installieren oder verschieben Sie die ONTAP Tools Appliance oder vCenter Server Appliance (VCSA) nicht auf VVols Storage, da dies verhindern kann, dass die Appliances neu gestartet werden.</block>
  <block id="6a5c862f634c8967f7246f42eb9de6e1" category="paragraph">In-Place-Upgrades von ONTAP Tools werden über die ISO-Datei für Upgrades unterstützt, die auf der NetApp Support Website (NSS) zum Download zur Verfügung steht. Befolgen Sie die Anweisungen des Bereitstellungs- und Setup-Handbuchs, um die Appliance zu aktualisieren.</block>
  <block id="3c07c9b4b562a16890d9fee571f0441e" category="inline-link">Leitfaden zur Dimensionierung für ONTAP Tools für VMware vSphere</block>
  <block id="e4e51979718d88ce483f9477be981a76" category="paragraph">Informationen zur Dimensionierung Ihrer virtuellen Appliance und zum Verständnis der Konfigurationsbeschränkungen finden Sie in diesem Knowledge Base-Artikel:<block ref="a75738ed95b0811ed0edd1b8ef0d9568" category="inline-link-rx"></block></block>
  <block id="72333dadacbc964761fb14f718f6d411" category="section-title">Produktdokumentation</block>
  <block id="e0644c46fdc2ced2c094f7db15e15a8a" category="paragraph">Die folgende Dokumentation ist verfügbar, um Sie bei der Implementierung von ONTAP Tools zu unterstützen.</block>
  <block id="09e308ed60d47b80b6cd16eb233f1bb9" category="inline-link">Für die vollständige Dokumentation Repository&amp;amp;#44; besuchen Sie diesen Link zu docs.netapp.com</block>
  <block id="7f21741a70426baea3ee41488da86af4" category="paragraph"><block ref="56b49132b20e341764c8aa067751e8a5" category="inline-link-rx"></block></block>
  <block id="be11c74c1dd7f307bb80183a90dc2067" category="section-title">Los geht's</block>
  <block id="7d0ee6fed10d3d4e5c9ee496729ab519" category="inline-link">Versionshinweise</block>
  <block id="2645deadffb8af180b8a35da3d034ad8" category="list-text"><block ref="2645deadffb8af180b8a35da3d034ad8" category="inline-link-rx"></block></block>
  <block id="b1555cd6358e57b76c72e343dbe31846" category="inline-link">Erfahren Sie mehr über ONTAP Tools für VMware vSphere</block>
  <block id="a0aaeda90fe2ef02fba791bc7c35645c" category="list-text"><block ref="a0aaeda90fe2ef02fba791bc7c35645c" category="inline-link-rx"></block></block>
  <block id="e695b432b77d6bddfcb785c76f5e5442" category="inline-link">ONTAP-Tools Schnellstartanleitung</block>
  <block id="324b0410f22fb210bbf88e1ee7e97428" category="list-text"><block ref="324b0410f22fb210bbf88e1ee7e97428" category="inline-link-rx"></block></block>
  <block id="3d7fe3e43f9f24fffe5ed0d546d12f13" category="inline-link">Implementierung von ONTAP Tools</block>
  <block id="354336d78d1f0a156dcd5221d341dfd0" category="list-text"><block ref="354336d78d1f0a156dcd5221d341dfd0" category="inline-link-rx"></block></block>
  <block id="a2fa58344be7fbd9a2be0320a8df0f77" category="inline-link">Upgrade von ONTAP-Tools</block>
  <block id="33a77e1014f1325d6ba19639a6c95d48" category="list-text"><block ref="33a77e1014f1325d6ba19639a6c95d48" category="inline-link-rx"></block></block>
  <block id="21e2a89d708329706ec6ed3fc989a1f6" category="section-title">Verwenden Sie ONTAP-Tools</block>
  <block id="91a9cfdbaaa44e0a9ad72e92533f763f" category="inline-link">Bereitstellung herkömmlicher Datastores</block>
  <block id="f27fe8f858d8a91950e214753b95722c" category="list-text"><block ref="f27fe8f858d8a91950e214753b95722c" category="inline-link-rx"></block></block>
  <block id="fc7d7e475ac8c3868d7426bb41df9b09" category="inline-link">Bereitstellung von VVols Datastores</block>
  <block id="0c2552c3930f472b2d120f30d7aa0415" category="list-text"><block ref="0c2552c3930f472b2d120f30d7aa0415" category="inline-link-rx"></block></block>
  <block id="317bbf73ff27c5f981628c8fb83ebf22" category="inline-link">Konfigurieren Sie die rollenbasierte Zugriffssteuerung</block>
  <block id="644ae78061acbb2254be4de3ea454b06" category="list-text"><block ref="644ae78061acbb2254be4de3ea454b06" category="inline-link-rx"></block></block>
  <block id="48bc2d028cb2a507ef974230ca3ba793" category="inline-link">Konfigurieren Sie die Remote-Diagnose</block>
  <block id="fc0330812838aba14025bd70d41b943d" category="list-text"><block ref="fc0330812838aba14025bd70d41b943d" category="inline-link-rx"></block></block>
  <block id="641e9457539249e880725760f91d5ee2" category="inline-link">Konfigurieren Sie Hochverfügbarkeit</block>
  <block id="5027a18a60c68e05df84cd699af74497" category="list-text"><block ref="5027a18a60c68e05df84cd699af74497" category="inline-link-rx"></block></block>
  <block id="04edeb5424c826c14a69edb777edf395" category="section-title">Sicherung und Management von Datenspeichern</block>
  <block id="e17534281670c5ea4e8d55420a63c98f" category="inline-link">Sicherung herkömmlicher Datastores</block>
  <block id="c8ac931d575d89c007212a35c8dde74c" category="list-text"><block ref="8f91d2113ff32de18906bad1cd446b0d" category="inline-link-rx"></block> Mit SRM</block>
  <block id="bff05cbbc19cad2bd10b9fe25dc34a1b" category="inline-link">Sicherung von auf VVols basierenden Virtual Machines</block>
  <block id="710b15d782f0c2c0411066b86644a12d" category="list-text"><block ref="7741c74d7508dc983fa4af0dff0bdda1" category="inline-link-rx"></block> Mit SRM</block>
  <block id="5267febc97a2cc385cc5c73995dc64df" category="inline-link">Überwachen Sie herkömmliche Datenspeicher und Virtual Machines</block>
  <block id="bac3b262bb348a54f9986c2b5dbf6024" category="list-text"><block ref="bac3b262bb348a54f9986c2b5dbf6024" category="inline-link-rx"></block></block>
  <block id="3123ece3c3b36f605758cb0c9a28f904" category="inline-link">Überwachen Sie VVols Datastores und Virtual Machines</block>
  <block id="75c07b623699e1947d011983a7823584" category="list-text"><block ref="75c07b623699e1947d011983a7823584" category="inline-link-rx"></block></block>
  <block id="73751ced5959ea3089346b01d42dde76" category="paragraph">Zusätzlich zur Produktdokumentation gibt es möglicherweise Artikel aus der Support Knowledgebase, die hilfreich sein könnten.</block>
  <block id="23bd7442fd1cd75655289cc3a38dd825" category="inline-link">Durchführen einer Disaster Recovery für VASA Provider</block>
  <block id="a2dd1381618efc2cd3834a883a0d779d" category="list-text"><block ref="a2dd1381618efc2cd3834a883a0d779d" category="inline-link-rx"></block></block>
  <block id="dd5138e8a4207a5b2fde43b411a4b5e1" category="section-title">VASA Provider Dashboard</block>
  <block id="6da01a643ea28efe37fa2d6fd06a634b" category="paragraph">Vasa Provider umfasst ein Dashboard mit Performance- und Kapazitätsinformationen für einzelne VVols VMs. Diese Informationen stammen direkt von ONTAP für die vVol Dateien und LUNs, einschließlich Latenz, IOPS, Durchsatz und Uptime für die Top 5 VMs sowie Latenz und IOPS für die Top 5 Datastores. Bei Verwendung von ONTAP 9.7 oder höher ist sie standardmäßig aktiviert. Es kann bis zu 30 Minuten dauern, bis die ersten Daten abgerufen und im Dashboard angezeigt werden.</block>
  <block id="9b78e1fecb2bcc40733f2180691c7507" category="section-title">ONTAP Tools VVols Dashboard</block>
  <block id="4adf016da96258b45a1cf762298729b5" category="inline-image-macro">ONTAP Tools VVols Dashboard,400</block>
  <block id="73c1e14ddf3f32984f869ac3f122b2ca" category="paragraph"><block ref="73c1e14ddf3f32984f869ac3f122b2ca" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cd47dd01745339787e4c7300389401f2" category="section-title">Best Practices In Sich Vereint</block>
  <block id="9ae938622297e9d4b14dd0006a8f0bf4" category="paragraph">*Grenzen*</block>
  <block id="b4f52a4fd0b07c9d904b95fc98a1cd45" category="inline-link">Konfigurationsmaxima</block>
  <block id="bc8259e306c73b2969e7ac6297000e64" category="paragraph">ONTAP unterstützt im Allgemeinen VVols-Limits, die durch VMware definiert sind (siehe veröffentlicht<block ref="a6efdd9b1a19df6105024b4869e0582b" category="inline-link-rx"></block>). In der folgenden Tabelle sind bestimmte ONTAP-Limits für Größe und Anzahl von VVols zusammengefasst. Prüfen Sie immer das<block ref="bb9c67b5a4c15a85b5e6aa6c9afd0285" category="inline-link-rx"></block> Für aktualisierte Grenzwerte für Anzahl und Größe der LUNs und Dateien.</block>
  <block id="9b7ad553354519b31ec860eef39e5f6b" category="paragraph">*ONTAP VVols Grenzen*</block>
  <block id="130b78bfd6c9b050a912fec77e285e3f" category="cell">Kapazität/Funktion</block>
  <block id="6231ad61105cd983d3f0042762d3233d" category="cell">SAN (SCSI oder NVMe-of)</block>
  <block id="75d4e7871261a858356a58d682ab71de" category="cell">Maximale VVols-Größe</block>
  <block id="9cfd7100738cee4daf7acd5e01d31e14" category="cell">62 tib*</block>
  <block id="9a728251ad1e90577975ae9395374772" category="cell">Maximale Anzahl VVols pro FlexVol Volume</block>
  <block id="021bbc7ee20b71134d53e20206bd6feb" category="cell">1024</block>
  <block id="46ba990c143630f55072434a6ea958c0" category="cell">2 Milliarden</block>
  <block id="cdbcf58620f0b4b0bbf3291386a99407" category="cell">Maximale Anzahl VVols pro ONTAP Node</block>
  <block id="342264031889898ec1a553b4dd58d98c" category="cell">Bis zu 12,288**</block>
  <block id="659e5faa0bdb08327ba0719230e95be2" category="cell">50 Milliarden</block>
  <block id="43b49f27d93c6f55f54a68e8983d5479" category="cell">Maximale Anzahl VVols pro ONTAP-Paar</block>
  <block id="3941694d19c2d1fc406f055ab62cb9eb" category="cell">Bis zu 24,576**</block>
  <block id="d6b3e65f296fd23975dd6f1a915c4b22" category="cell">Maximale Anzahl von VVols pro ONTAP Cluster</block>
  <block id="2702ff8627a3990fc940d6f53463925e" category="cell">Bis zu 98,304**</block>
  <block id="4f0c25d6c688cf50460d11fecaa97fa8" category="cell">Keine spezifische Cluster-Beschränkung</block>
  <block id="855ecc47bb0d239e1fdf6fee84e24c75" category="cell">Maximale QoS-Objekte (gemeinsam genutzte Richtliniengruppe und individuelle VVols Service-Level)</block>
  <block id="26890bd9dcb27c05f1ab5bcc859501b8" category="cell">12,000 bis ONTAP 9.3; 40,000 mit ONTAP 9.4 und höher</block>
  <block id="0e38f856cb713ce9eea79fa1c6b7dc32" category="list-text">Größenbeschränkung auf Basis von ASA Systemen oder AFF und FAS Systemen mit ONTAP 9.12.1P2 und höher</block>
  <block id="d27c43bb3cdcbfa3852bb91192ffb849" category="list-text">Die Anzahl der SAN-VVols (NVMe-Namespaces oder LUNs) variiert je nach Plattform. Prüfen Sie immer das<block ref="bb9c67b5a4c15a85b5e6aa6c9afd0285" category="inline-link-rx"></block> Für aktualisierte Grenzwerte für Anzahl und Größe der LUNs und Dateien.</block>
  <block id="72e0ee397942f7233122887584f94b8b" category="paragraph">Die Verwendung von ONTAP VVols mit vSphere ist einfach und folgt den veröffentlichten vSphere-Methoden (siehe Arbeiten mit virtuellen Volumes unter vSphere-Speicher in der VMware-Dokumentation für Ihre Version von ESXi). Nachfolgend finden Sie einige weitere Vorgehensweisen, die Sie in Verbindung mit ONTAP in Betracht ziehen sollten.</block>
  <block id="83583580d98b69cb8317f9b285f3c8df" category="cell">*Verwenden Sie ONTAP-Tools für VMware vSphere UI-Erweiterungen oder REST-APIs zur Bereitstellung von VVols-Datastores* *und Protokollendpunkten.*</block>
  <block id="9507d4f97aceb8d05fc962dd53f082af" category="cell">VVols Datastores können über die allgemeine vSphere Schnittstelle erstellt werden, aber mithilfe von ONTAP Tools werden automatisch bei Bedarf Protokollendpunkte erstellt und FlexVol Volumes anhand von ONTAP Best Practices und unter Einhaltung der definierten Storage-Funktionsprofile erstellt. Klicken Sie einfach mit der rechten Maustaste auf den Host/Cluster/Datacenter und wählen Sie dann „_ONTAP Tools_“ und „_Provision Datastore_“ aus. Wählen Sie dann im Assistenten einfach die gewünschten VVols Optionen aus.</block>
  <block id="e8d5f9dc0bff953a9e59755813c7e8bf" category="cell">*Speichern Sie die ONTAP Tools Appliance oder vCenter Server Appliance (VCSA) niemals auf einem VVols Datastore, den sie verwalten.*</block>
  <block id="c6ac0465bff03857ee851d98f6bd782b" category="cell">Dies kann zu einer „Hühnchen- und Eiersituation“ führen, wenn Sie die Appliances neu starten müssen, da sie nicht in der Lage sind, während sie neu starten ihre eigenen VVols abzuheben. Sie können sie auf einem VVols Datastore speichern, der von verschiedenen ONTAP Tools und einer vCenter Implementierung gemanagt wird.</block>
  <block id="ab8d352870fb5334773c7177d3d5dcd1" category="cell">*Vermeiden Sie VVols-Vorgänge über verschiedene ONTAP-Versionen hinweg.*</block>
  <block id="8b2bcef781b7e1f6d64739147d50aae7" category="cell">Unterstützte Storage-Funktionen wie QoS, Personality und mehr haben sich in verschiedenen Versionen des VASA Providers verändert, einige sind von der ONTAP Version abhängig. Die Verwendung verschiedener Versionen in einem ONTAP-Cluster oder das Verschieben von VVols zwischen Clustern mit unterschiedlichen Versionen können zu unerwartetem Verhalten oder Compliance-Alarmen führen.</block>
  <block id="b2da0eca57c759eff034e6fe26f153e6" category="cell">*Zonen Sie Ihre Fibre Channel Fabric vor der Verwendung von NVMe/FC oder FCP für VVols.*</block>
  <block id="cd7bf0e1e61341c1aa3fa23401af8a27" category="inline-image-macro">Zoning mit einem Initiator durchgeht vier Nodes,400</block>
  <block id="51591d05b7e084ba8e5ae7f63172177e" category="inline-link">_TR-4080 Best Practices for Modern SAN ONTAP 9_</block>
  <block id="c1723e6a0e1d3dd28232b33e0cb6e61d" category="inline-link">_TR-4684 Implementierung und Konfiguration moderner SANs mit NVMe-of_</block>
  <block id="9a36c8f0464a7ffce114044f1859c7ff" category="cell">* Planen Sie Ihre Unterstützung FlexVols nach Ihren Bedürfnissen.*</block>
  <block id="03d2e894fa9a05efefa4e8d6b2008a19" category="cell">Es ist durchaus wünschenswert, mehrere Backup-Volumes zum VVols-Datastore hinzuzufügen, um den Workload über das ONTAP-Cluster zu verteilen, verschiedene Richtlinienoptionen zu unterstützen oder die Anzahl der zulässigen LUNs oder Dateien zu erhöhen. Wenn jedoch eine maximale Storage-Effizienz erforderlich ist, platzieren Sie alle Ihre Backup Volumes auf einem einzigen Aggregat. Wenn eine maximale Klon-Performance erforderlich ist, ziehen Sie die Verwendung eines einzelnen FlexVol Volumes in Erwägung und halten Ihre Vorlagen- oder Content Library im selben Volume. Der VASA Provider verlagert viele VVols Storage-Vorgänge auf ONTAP, einschließlich Migration, Klonen und Snapshots. Wenn dies in einem einzelnen FlexVol Volume geschieht, werden platzsparende Klone von Dateien verwendet und stehen so gut wie sofort zur Verfügung. Wenn dies über FlexVol Volumes hinweg durchgeführt wird, sind die Kopien schnell verfügbar und verwenden Inline-Deduplizierung und -Komprimierung. Allerdings kann eine maximale Storage-Effizienz erst dann wiederhergestellt werden, wenn Hintergrundjobs auf Volumes mithilfe von Deduplizierung und Komprimierung im Hintergrund ausgeführt werden. Je nach Quelle und Ziel kann die Effizienz beeinträchtigt werden.</block>
  <block id="80b15469535d95a1690f308427545c7e" category="cell">*Speicherfähigkeitsprofile (SCPs) einfach halten.*</block>
  <block id="33e2905cb722c14575a9bff81ba78b39" category="cell">Vermeiden Sie die Angabe von Funktionen, die nicht erforderlich sind, indem Sie sie auf beliebig festlegen. Dadurch werden Probleme beim Auswählen oder Erstellen von FlexVol-Volumes minimiert. Wenn bei VASA Provider 7.1 und älteren Versionen beispielsweise die Komprimierung mit der SCP-Standardeinstellung „Nein“ beibehalten wird, wird versucht, die Komprimierung selbst auf einem AFF-System zu deaktivieren.</block>
  <block id="5a6d5fdddf6fbd82f1952b532b03c9ef" category="cell">*Verwenden Sie die Standard-SCPs als Beispielvorlagen, um Ihre eigenen zu erstellen.*</block>
  <block id="ee3cbda1c3c4a14ae024478c7ada6d11" category="cell">*Befolgen Sie alle Best Practices für Protokolle.*</block>
  <block id="6a2c1ac1da51eca0c1a65afffab8dfab" category="inline-image-macro">Netzwerkkonfiguration mit VVols über NFS v3.500</block>
  <block id="6cacb3f1edd09835a2ad07d72f488e2a" category="paragraph">Seit über zwei Jahrzehnten ist die NetApp ONTAP Software eine der führenden Storage-Lösungen für VMware vSphere Umgebungen und wird kontinuierlich mit innovativen Funktionen erweitert, die nicht nur zur Vereinfachung des Managements, sondern auch zu Kostensenkungen beitragen.</block>
  <block id="918febfed3d070cf1250909e5cdcf31d" category="paragraph">Dieses Dokument behandelt die ONTAP Funktionen für VMware vSphere Virtual Volumes (VVols), einschließlich der neuesten Produktinformationen und Anwendungsfälle sowie Best Practices und andere Informationen, um die Implementierung zu optimieren und Fehler zu reduzieren.</block>
  <block id="c7448b194ba68bddce48f1d11d5d7db7" category="admonition">Diese Dokumentation ersetzt zuvor veröffentlichte technische Berichte _TR-4400: VMware vSphere Virtual Volumes (VVols) durch NetApp ONTAP_</block>
  <block id="d30f04665be7a6d9663004b1b5e61a9a" category="paragraph">Andere Dokumente wie Leitfäden und Kompatibilitätslisten werden durch Best Practices ergänzt. Sie werden basierend auf Labortests und umfassenden praktischen Erfahrungen der NetApp Ingenieure und Kunden entwickelt. Es handelt sich hierbei unter Umständen nicht nur um geeignete oder unterstützte Praktiken, sondern im Allgemeinen um die einfachsten Lösungen, die die Anforderungen der meisten Kunden erfüllen.</block>
  <block id="b010d2e253827dbb44b7ba4e1332e24e" category="admonition">Dieses Dokument wurde mit neuen VVols-Funktionen aus vSphere 8.0 Update 1 aktualisiert, die von der Version 9.12 der ONTAP Tools unterstützt werden.</block>
  <block id="cc713c330b9c4e00d3ed7233bc54a889" category="section-title">Virtual Volumes (VVols) – Übersicht</block>
  <block id="64f0863a7fb5f52a7ac6a911e1ad6862" category="paragraph">NetApp begann 2012 die Zusammenarbeit mit VMware zur Unterstützung von vSphere APIs for Storage Awareness (VASA) für vSphere 5. Dieser frühe VASA Provider ermöglichte die Definition von Storage-Funktionen in einem Profil, das zur Filterung von Datastores bei der Bereitstellung und zur Überprüfung der Einhaltung der Richtlinie anschließend verwendet werden konnte. Im Laufe der Zeit wurden neue Funktionen hinzugefügt, um eine stärkere Automatisierung der Bereitstellung zu ermöglichen. Zudem wurden Virtual Volumes oder VVols hinzugefügt, bei denen individuelle Storage-Objekte für Dateien von Virtual Machines und Virtual Disks verwendet werden. Zu diesen Objekten gehören LUNs, Dateien und jetzt auch vSphere 8. NVMe namespaces.NetApp arbeitete eng mit VMware als Referenzpartner für VVols zusammen, die im Jahr 2015 für vSphere 6 veröffentlicht wurden, und erneut als Design-Partner für VVols, die NVMe over Fabrics in vSphere 8 verwenden. NetApp erweitert VVols kontinuierlich, um die Vorteile der neuesten Funktionen von ONTAP zu nutzen.</block>
  <block id="cbf0aa9daeb855e4eace1a3bdc474ce2" category="paragraph">Es gibt mehrere Komponenten, die zu beachten sind:</block>
  <block id="e2f6b83160ea0712fbc59dd84410c4b2" category="cell">*VASA Provider*</block>
  <block id="919601826e1d58bccaaab76d787871d2" category="cell">Dies ist die Softwarekomponente, die die Kommunikation zwischen VMware vSphere und dem Speichersystem übernimmt. Bei ONTAP wird VASA Provider in einer Appliance ausgeführt, bekannt als ONTAP Tools für VMware vSphere (kurz ONTAP Tools). Die ONTAP Tools enthalten außerdem ein vCenter Plug-in, einen Storage Replication Adapter (SRA) für VMware Site Recovery Manager und REST-API-Server zum Erstellen Ihrer eigenen Automatisierung. Sobald ONTAP Tools bei vCenter konfiguriert und registriert sind, besteht kaum noch Bedarf für eine direkte Interaktion mit dem ONTAP System, da sich Ihre Storage-Anforderungen nahezu vollständig über die vCenter UI oder ÜBER REST-API-Automatisierung managen lassen.</block>
  <block id="05ad8543ff165c6b8cd0cc5e976d3245" category="cell">*Protokollendpunkt (PE)*</block>
  <block id="3b2cd9018385f55c53c9a8b756df8bb5" category="cell">Der Protokollendpunkt ist ein Proxy für I/O zwischen den ESXi Hosts und dem VVols Datastore. ONTAP VASA Provider erstellt diese automatisch, entweder eine Protokollendpunkt-LUN (4 MB Größe) pro FlexVol Volume des VVols Datastores oder ein NFS-Bereitstellungspunkt pro NFS-Schnittstelle (LIF) auf dem Storage-Node, der ein FlexVol Volume im Datastore hostet. Der ESXi-Host mountet diese Protokollendpunkte direkt statt einzelner vVol-LUNs und Dateien mit virtuellen Laufwerken. Die Protokollendpunkte müssen nicht verwaltet werden, da sie vom VASA Provider zusammen mit den erforderlichen Schnittstellengruppen oder Exportrichtlinien automatisch erstellt, gemountet, unmountet und gelöscht werden.</block>
  <block id="d3f051e8316cfd36651af1e65be24a75" category="cell">*Virtual Protocol Endpoint (VPE)*</block>
  <block id="71afca0aa1a505ea2ac3ce5a1a681549" category="paragraph">Neu in vSphere 8 ist bei Verwendung von NVMe over Fabrics (NVMe-of) mit VVols, das Konzept eines Protokollendpunkts in ONTAP nicht mehr relevant. Stattdessen wird ein virtueller PE automatisch vom ESXi-Host für jede ANA-Gruppe instanziiert, sobald die erste VM eingeschaltet ist. ONTAP erstellt automatisch ANA-Gruppen für jedes vom Datenspeicher verwendete FlexVol Volume.</block>
  <block id="8202498953d2ebcf9968c37a7e47f4f6" category="paragraph">Ein weiterer Vorteil bei der Nutzung von NVMe-of für VVols besteht darin, dass vom VASA Provider keine Bind-Anfragen erforderlich sind. Stattdessen verarbeitet der ESXi-Host die vVol-Bindungsfunktion intern basierend auf dem VPE. Dies verringert die Möglichkeit, dass ein vVol BIND-Ansturm den Service beeinträchtigt.</block>
  <block id="70532c0374111d897ef1176b34b6396c" category="inline-link">NVMe und Virtual Volumes</block>
  <block id="50ec55042a7f4e8c2c66219ac096cfb3" category="inline-link">VMware.com</block>
  <block id="113c9d4e642d1ba4cc469267fb7fd0de" category="paragraph">Weitere Informationen finden Sie unter<block ref="f8d477cd77073d731aafe4f52026608a" category="inline-link-rx"></block> Ein<block ref="1f1565cca975c4a703345d21e7f273b8" category="inline-link-rx"></block></block>
  <block id="61def0b14af00df4eb90bcd79d858a8b" category="cell">*Datastore des virtuellen Volumes*</block>
  <block id="b945cda41d7a84e7152e09343a17cbe6" category="cell">Der Virtual Volume Datastore ist eine logische Datastore-Darstellung eines VVols-Containers, der von einem VASA Provider erstellt und gemanagt wird. Der Container ist ein Pool an Storage-Kapazität, der aus den vom VASA Provider gemanagten Storage-Systemen bereitgestellt wird. ONTAP Tools unterstützen die Zuweisung mehrerer FlexVol Volumes (auch als Backup Volumes bezeichnet) einem einzelnen VVols-Datastore. Diese VVols Datastores können über mehrere Nodes in einem ONTAP Cluster verteilt werden. Dabei werden Flash- und Hybrid-Systeme mit unterschiedlichen Funktionen kombiniert. Der Administrator kann neue FlexVol Volumes mithilfe des Bereitstellungsassistenten oder DER REST-API erstellen oder vorab erstellte FlexVol Volumes für die Storage-Sicherung auswählen, sofern diese verfügbar sind.</block>
  <block id="c25d2cc7c6540f6ac98af67455eecc39" category="cell">*Virtual Volumes (VVols)*</block>
  <block id="9664cdf7951789389813facac649fec1" category="cell">VVols sind die Dateien und Festplatten der Virtual Machines, die tatsächlich im VVols Datastore gespeichert sind. Der Begriff vVol (Singular) bezieht sich auf eine einzelne spezifische Datei, LUN oder Namespace. ONTAP erstellt NVMe-Namespaces, LUNs oder Dateien, je nachdem, welches Protokoll der Datastore verwendet. Es gibt mehrere unterschiedliche Typen von VVols. Die gängigsten sind Konfiguration (Metadatendateien), Daten (virtuelle Festplatte oder VMDK) und Swap (das beim Einschalten der VM erstellt wird). VVols, die durch die Verschlüsselung von VMware VM geschützt sind, haben einen anderen Typ. Die VMware VM-Verschlüsselung sollte nicht mit der ONTAP-Volume- oder Aggregatverschlüsselung verwechselt werden.</block>
  <block id="937251054fa0c1a7b946f8928cc857b9" category="section-title">Richtlinienbasiertes Management</block>
  <block id="34d2b7d8b570ede7a638d070656b7b81" category="paragraph">VMware vSphere APIs for Storage Awareness (VASA) erleichtern es VM-Administratoren, alle erforderlichen Storage-Funktionen zu nutzen, um VMs bereitzustellen, ohne mit ihrem Storage-Team interagieren zu müssen. Vor VASA konnten VM-Administratoren VM-Storage-Richtlinien definieren, mussten dann aber gemeinsam mit ihren Storage-Administratoren geeignete Datastores ermitteln – oft anhand der Dokumentation oder von Namenskonventionen. Mit VASA können vCenter Administratoren mit den entsprechenden Berechtigungen eine Reihe von Storage-Funktionen definieren, mit denen vCenter Benutzer dann VMs bereitstellen können. Durch die Zuordnung zwischen VM-Storage-Richtlinie und Datastore-Storage-Funktionsprofil kann in vCenter eine Liste kompatibler Datastores zur Auswahl angezeigt werden. Außerdem können andere Technologien wie Aria (ehemals vRealize) Automation oder Tanzu Kubernetes Grid aktiviert werden, um automatisch Storage aus einer zugewiesenen Richtlinie auszuwählen. Dieser Ansatz wird als richtlinienbasiertes Storage-Management bezeichnet. Während Storage-Funktionsprofile und -Richtlinien auch bei herkömmlichen Datastores verwendet werden können, konzentrieren wir uns hier auf VVols Datastores.</block>
  <block id="631bdc7de6608fd57c3fa0b397c3c26f" category="paragraph">Es gibt zwei Elemente:</block>
  <block id="a156a7f38a3727ce705b5466eb11e0bf" category="cell">*Storage Capability Profile (SCP)*</block>
  <block id="43a258e66ca875fa9c5d3e35e06ba2b7" category="cell">Ein Storage-Funktionsprofil (Storage Capability Profile, SCP) ist eine Form von Storage-Vorlage. Damit können vCenter Administratoren festlegen, welche Storage-Funktionen benötigt werden, ohne dass ein Verständnis für das Management dieser Funktionen in ONTAP erforderlich ist. Mit Hilfe einer Vorlage können Administratoren problemlos Storage-Services auf konsistente und vorhersehbare Weise bereitstellen. Zu den in einem SCP beschriebenen Funktionen zählen Performance, Protokolle, Storage-Effizienz und weitere Funktionen. Die spezifischen Funktionen sind je nach Version unterschiedlich. Sie werden mit dem Menü ONTAP Tools für VMware vSphere in der vCenter UI erstellt. SIE können AUCH REST-APIs zum Erstellen von SCPs verwenden. Sie können manuell durch Auswahl einzelner Funktionen erstellt oder automatisch aus vorhandenen (herkömmlichen) Datenspeichern generiert werden.</block>
  <block id="8f50a0757d99fe5dd0df8d19478d4921" category="cell">*VM-Speicherrichtlinie*</block>
  <block id="f99c5cf9298b040025bd3dfe966cb86e" category="cell">VM Storage-Richtlinien werden in vCenter unter Richtlinien und Profile erstellt. Erstellen Sie für VVols mithilfe von Regeln des NetApp VVols Storage-Typ-Providers ein Regelwerk. ONTAP Tools bietet einen vereinfachten Ansatz, da Sie ein SCP einfach auswählen können, anstatt Sie zur Angabe einzelner Regeln zu zwingen.</block>
  <block id="5dda8b04866334dc92ee08001b15701a" category="paragraph">Wie oben erwähnt, kann die Verwendung von Richtlinien zur Vereinfachung der Bereitstellung von Volumes beitragen. Wählen Sie einfach eine entsprechende Richtlinie aus. VASA Provider zeigt VVols-Datastores an, die diese Richtlinie unterstützen, und platziert das vVol in einem individuellen, konformen FlexVol Volume (Abbildung 1).</block>
  <block id="2ce0d6ec59cca7e0b6e0bdc389301e63" category="section-title">Bereitstellung der VM mithilfe der Storage-Richtlinie</block>
  <block id="e0795f8b847058e171dec5a519757ece" category="image-alt">Implementierung einer Virtual Machine mithilfe der Storage-Richtlinie</block>
  <block id="f0d0f0a6174a5a9dde27782042e22ccf" category="paragraph">Sobald eine VM bereitgestellt ist, prüft der VASA Provider weiterhin die Compliance und alarmiert den VM-Administrator mit einem Alarm in vCenter, wenn das Backup-Volume nicht mehr mit der Richtlinie konform ist (Abbildung 2).</block>
  <block id="941431bc1cecb0ec5e89e78e9a5a96fc" category="section-title">Einhaltung von VM-Storage-Richtlinien</block>
  <block id="bfd6dec22a6a1724ff1b67f1f289cdfc" category="image-alt">Einhaltung der Virtual Machine Storage-Richtlinien</block>
  <block id="e08bc5b354c3e8058003a662e0f7cade" category="section-title">NetApp VVols Unterstützung</block>
  <block id="234ad0324c313ec05d0fa6fe8d430967" category="paragraph">NetApp ONTAP unterstützt die VASA Spezifikation seit der ersten Version im Jahr 2012. Während andere NetApp Storage-Systeme VASA unterstützen, konzentriert sich dieses Dokument auf die derzeit unterstützten Versionen von ONTAP 9.</block>
  <block id="7b02ea300aef2e0bff0d7f6111053284" category="section-title">NetApp ONTAP</block>
  <block id="4d53a8e49ac64213ffccdd970a35171e" category="paragraph">Neben ONTAP 9 auf AFF, ASA und FAS Systemen unterstützt NetApp VMware-Workloads auf ONTAP Select, Amazon FSX für NetApp ONTAP mit VMware Cloud auf AWS, Azure NetApp Files mit der Lösung Azure VMware, Cloud Volumes Service mit Google Cloud VMware Engine und NetApp Private Storage in Equinix, Die spezifische Funktionalität kann jedoch je nach Dienstanbieter und verfügbarer Netzwerkverbindung variieren. Es ist auch möglich, von vSphere Gasts auf Daten zuzugreifen, die in diesen Konfigurationen sowie auf Cloud Volumes ONTAP gespeichert sind.</block>
  <block id="9fe1fd556b933358881222d5c3da127c" category="paragraph">Zum Zeitpunkt der Veröffentlichung sind Hyperscaler-Umgebungen nur auf herkömmliche NFS v3-Datastores beschränkt. Daher sind VVols nur mit lokalen ONTAP Systemen oder Cloud-vernetzten Systemen verfügbar, die die gesamten Funktionen von On-Premises-Systemen bereitstellen, z. B. von NetApp Partnern und Service-Providern auf der ganzen Welt.</block>
  <block id="274bc582ca884fc158ea9ac9f79f9067" category="inline-link">ONTAP Produktdokumentation</block>
  <block id="5ca60fe92dec435059ba5acefa4ce2c9" category="paragraph">_Weitere Informationen zu ONTAP finden Sie unter<block ref="8a9b15dc18a16e0b1acfa438e27f6aa6" category="inline-link-rx"></block>_</block>
  <block id="3dffa984dadf9ff0006ee9cebd3b04b9" category="inline-link">TR-4597</block>
  <block id="9a03bb7ec5329e35d98c7b12b63c4df0" category="paragraph">_Weitere Informationen zu den Best Practices von ONTAP und VMware vSphere finden Sie unter<block ref="fc9815e7b1405959c49ad47e9a23e3a5" category="inline-link-rx"></block>_</block>
  <block id="d3fb76da5fbbcd6fa32e40910b5b9a47" category="section-title">Vorteile der Verwendung von VVols mit ONTAP</block>
  <block id="d0f004282063136e91d76d1d43d7c95f" category="paragraph">Als VMware 2015 die VVols-Unterstützung mit VASA 2.0 einführte, bezeichnete das Unternehmen das System als „ein Integrations- und Management-Framework zur Bereitstellung eines neuen Betriebsmodells für externen Storage (SAN/NAS)“. Dieses Betriebsmodell bietet zusammen mit ONTAP Storage mehrere Vorteile.</block>
  <block id="6a74f7c0a9021e009a9c030e54084978" category="paragraph">Wie in Abschnitt 1.2 beschrieben, ermöglicht richtlinienbasiertes Management die Bereitstellung und das Management von VMs anhand von vordefinierten Richtlinien. Dies bietet verschiedene Vorteile FÜR IT-Abläufe:</block>
  <block id="e0eb51b6d319e14c2fbfc1f628021a26" category="list-text">*Beschleunigung.* durch ONTAP Tools muss der vCenter Administrator keine Tickets mehr für die Storage-Bereitstellung beim Storage Team öffnen. ONTAP-Tools RBAC-Rollen in vCenter und im ONTAP System ermöglichen jedoch unabhängigen Teams (z. B. Storage-Teams) oder unabhängigen Aktivitäten desselben Teams, indem bei Bedarf der Zugriff auf bestimmte Funktionen eingeschränkt wird.</block>
  <block id="3f4dbd6687bd0d55bf69fe5fdd0137c4" category="list-text">*Intelligentere Bereitstellung.* die Funktionen des Storage-Systems können über die VASA APIs zugänglich gemacht werden. So können Workflows für die Bereitstellung von erweiterten Funktionen profitieren, ohne dass der VM-Administrator ein Verständnis für das Management des Storage-Systems benötigt.</block>
  <block id="a13fcc9220d042cae454e9ac073636ca" category="list-text">*Schnellere Bereitstellung.* verschiedene Storage-Funktionen können in einem einzelnen Datastore unterstützt und anhand der VM-Richtlinie automatisch für eine VM ausgewählt werden.</block>
  <block id="eb4c052226108afebf26e670208b9a55" category="list-text">*Vermeiden von Fehlern.* Storage- und VM-Richtlinien werden vorab entwickelt und bei Bedarf angewendet, ohne dass bei jeder Bereitstellung einer VM Storage angepasst werden muss. Wenn sich die Storage-Funktionen von den festgelegten Richtlinien abdriften, werden Compliance-Alarme ausgelöst. Wie bereits erwähnt, ist die Erstbereitstellung durch SCPs vorhersehbar und wiederholbar, wobei die korrekte Platzierung durch die Verwendung von VM-Speicherrichtlinien auf den SCPs gewährleistet ist.</block>
  <block id="9c520768a1d84268417335cf19a423b9" category="list-text">*Besseres Kapazitätsmanagement.* VASA und ONTAP Tools ermöglichen es, bei Bedarf die Storage-Kapazität bis zur induvialen Aggregatebene anzuzeigen und bei niedrigem Kapazitätsbedarf mehrere Alarmebenen bereitzustellen.</block>
  <block id="f9878e32fdf258284c007eaae38773cd" category="section-title">Granulares VM-Management auf dem modernen SAN</block>
  <block id="7e673a7c12cc256f29bcd7b2028d9d5a" category="paragraph">SAN-Storage-Systeme mit Fibre Channel und iSCSI wurden als erste von VMware für ESX unterstützt, allerdings fehlten ihnen die Managementmöglichkeiten individueller VM-Dateien und Festplatten aus dem Storage-System. Stattdessen werden LUNs bereitgestellt und VMFS managt die einzelnen Dateien. Dadurch wird es für das Storage-System schwierig, die Storage-Performance, das Klonen und den Schutz einzelner VMs direkt zu managen. VVols bieten Storage-Granularität, die Kunden, die NFS-Storage bereits nutzen, mit den robusten, hochperformanten SAN-Funktionen von ONTAP.</block>
  <block id="25a46370807e0eab0dfe3853abfb9b6e" category="paragraph">Mit vSphere 8 und ONTAP Tools für VMware vSphere 9.12 und höher sind nun dieselben granularen Steuerelemente, die von VVols für ältere SCSI-basierte Protokolle verwendet werden, in dem modernen Fibre-Channel-SAN unter Verwendung von NVMe over Fabrics verfügbar, um noch höhere Performance im großen Maßstab zu ermöglichen. Mit vSphere 8.0 Update 1 ist es jetzt möglich, eine umfassende End-to-End-NVMe-Lösung mit VVols zu implementieren, ohne dass eine I/O-Verschiebung im Hypervisor-Storage-Stack erforderlich ist.</block>
  <block id="f61f57f748f5f0b52c7f11f1f1bd43f0" category="section-title">Bessere Auslagerungsmöglichkeiten</block>
  <block id="911fa02c34dda38cd69be06e524ed9d0" category="inline-link">Effizienz-Garantie</block>
  <block id="3170031d77f241bc872afcb490c0a806" category="paragraph">VAAI bietet zwar eine Vielzahl an Operationen, die auf Storage verlagert werden, doch bestehen einige Lücken, die vom VASA Provider behoben werden. SAN VAAI kann keine von VMware gemanagten Snapshots in das Storage-System auslagern. NFS VAAI kann über VM gemanagte Snapshots auslagern, aber es gibt Einschränkungen, bei denen eine VM mit nativen Storage-Snapshots platziert wird. Da VVols individuelle LUNs, Namespaces oder Dateien für Virtual-Machine-Festplatten verwenden, kann ONTAP die Dateien oder LUNs schnell und effizient klonen, um VM-granulare Snapshots zu erstellen, die keine Delta-Dateien mehr benötigen. NFS VAAI unterstützt zudem nicht das verlagern von Klonvorgängen bei Migrationen mit heißem (eingeschaltetem) Storage vMotion. Die VM muss ausgeschaltet sein, um bei Verwendung von VAAI mit herkömmlichen NFS-Datastores das verlagern der Migration zu ermöglichen. Der VASA Provider in ONTAP ermöglicht nahezu sofortige, Storage-effiziente Klone für heiße und kalte Migrationen. Zudem unterstützt er nahezu sofortige Kopien für Volume-übergreifende Migrationen von VVols. Aufgrund dieser enormen Vorteile hinsichtlich der Storage-Effizienz können Sie die VVols Workloads unter dem optimal nutzen<block ref="9d1af7a9d4f98887e53c1a9bedbce044" category="inline-link-rx"></block> Programm. Auch wenn Volume-übergreifende Klone mit VAAI nicht Ihren Anforderungen entsprechen, werden Sie wahrscheinlich aufgrund der Verbesserungen bei den Kopien mit VVols eine geschäftliche Herausforderung bewältigen können.</block>
  <block id="a8567b4dc683947384ef2e1dd0fc6ac1" category="section-title">Häufige Anwendungsfälle für VVols</block>
  <block id="48e535b80538b088fd868fde9372715c" category="paragraph">Neben diesen Vorteilen sehen wir auch folgende häufige Anwendungsfälle für vVol Storage:</block>
  <block id="441f01ec38e91fad1b235a0e7422a178" category="list-text">*Bedarfsgesteuerte Bereitstellung von VMs*</block>
  <block id="bd652a918164d8fa5176b5f9b92c2e61" category="list-text">Private Cloud oder Service-Provider-IaaS.</block>
  <block id="fddccd9595370687015a5ab02bcff60f" category="list-text">Automatisierung und Orchestrierung über die Aria (ehemals vRealize) Suite, OpenStack usw.</block>
  <block id="4fbc1141a40f5259e3ab1545de52b1ea" category="list-text">*First Class Disks (FCDs)*</block>
  <block id="e83f2e4e8676ee8faac4d6af599fd7e7" category="list-text">Persistente VMware Tanzu Kubernetes Grid [TKG] Volumes.</block>
  <block id="b2b81490f2245d3d566e0ccc6a29cfc2" category="list-text">Bereitstellung von Amazon EBS-ähnlichen Services über unabhängiges VMDK Lifecycle Management</block>
  <block id="2511e4e8cbb72027ae20f24008d4b939" category="list-text">*On-Demand Bereitstellung temporärer VMs*</block>
  <block id="eeb1044cc319a5d53503e45dbf762291" category="list-text">Labore für Test und Entwicklung</block>
  <block id="858d314810762abccaa7baf230e3dc18" category="list-text">Schulungsumgebungen</block>
  <block id="ab7bbc294bf0f0354980a3014e8f4219" category="section-title">Gemeinsame Vorteile mit VVols</block>
  <block id="ccd6ea8c57e93a5401d07aab9c60f371" category="paragraph">Wenn VVols so eingesetzt werden, wie in den oben genannten Anwendungsfällen, bieten sie folgende spezifische Verbesserungen:</block>
  <block id="13491b3af50183642ea0035b2d1f95f9" category="list-text">Klone werden schnell innerhalb eines einzelnen Volumes oder über mehrere Volumes in einem ONTAP Cluster hinweg erstellt – ein Vorteil im Vergleich zu herkömmlichen VAAI-fähigen Klonen. Außerdem sind sie Storage-effizient. Klone innerhalb eines Volumes nutzen ONTAP-Datei-Klone, die wie FlexClone Volumes sind und speichern nur Änderungen aus der Quell-vVol-Datei/LUN/Namespace. Dadurch werden langfristige VMs für Produktions- oder andere Applikationszwecke schnell erstellt, benötigen nur minimalen Speicherplatz und profitieren vom Schutz auf VM-Ebene (durch das NetApp SnapCenter Plug-in für VMware vSphere, von VMware gemanagte Snapshots oder VADP-Backup) und Performance-Management (mit ONTAP QoS).</block>
  <block id="1c21847cdc5616af138ba0c03aad7adb" category="list-text">VVols stellen die ideale Storage-Technologie dar, wenn ein TKG mit vSphere CSI verwendet wird und separate Storage-Klassen und Kapazitäten bereitstellt, die vom vCenter Administrator gemanagt werden.</block>
  <block id="d5f068caef73978a5483badd927a7e98" category="list-text">Amazon EBS-ähnliche Services können über FCDs bereitgestellt werden, da eine FCD-VMDK, wie der Name schon andeutet, eine erstklassige Antwort in vSphere ist und einen Lebenszyklus hat, der unabhängig von den VMs gemanagt werden kann, an die es angeschlossen werden kann.</block>
  <block id="7e7040600922b2a78715f856613a3c08" category="doc">Sicherung von VVols</block>
  <block id="de92c927f248723e4668aec459709995" category="section-title">VASA Provider High Availability</block>
  <block id="f4d4cb8868f07cad16bd7de7e36c5201" category="paragraph">NetApp VASA Provider wird als Teil der virtuellen Appliance zusammen mit dem vCenter Plug-in und REST API-Server (ehemals Virtual Storage Console [VSC]) und Storage Replication Adapter ausgeführt. Wenn der VASA Provider nicht verfügbar ist, werden VMs mit VVols weiterhin ausgeführt. Es können jedoch keine neuen VVols-Datastores erstellt werden. VVols können nicht über vSphere erstellt oder gebunden werden. Das bedeutet, dass VMs mit VVols nicht eingeschaltet werden können, da vCenter die Erstellung des Swap-vVol nicht anfordern kann. Außerdem können ausgeführte VMs vMotion nicht für die Migration zu einem anderen Host verwenden, da die VVols nicht an den neuen Host gebunden werden können.</block>
  <block id="3958bf41787d7fcc6a9f8dd9348c947f" category="paragraph">VASA Provider 7.1 und höher unterstützen neue Funktionen, damit die Services bei Bedarf verfügbar sind. Sie umfasst neue Watchdog-Prozesse zur Überwachung von VASA Provider und integrierten Datenbankdiensten. Wenn ein Fehler erkannt wird, werden die Protokolldateien aktualisiert und die Dienste dann automatisch neu gestartet.</block>
  <block id="1acc458c695b0d3dfbf588309801fda2" category="paragraph">Der weitere Schutz muss vom vSphere-Administrator mithilfe derselben Verfügbarkeitsfunktionen konfiguriert werden, die auch zum Schutz anderer geschäftskritischer VMs vor Fehlern in Software, Host-Hardware und Netzwerk verwendet werden. Es ist keine zusätzliche Konfiguration für die virtuelle Appliance erforderlich, um diese Funktionen nutzen zu können. Konfigurieren Sie sie einfach mit dem Standard-vSphere-Ansatz. Sie wurden getestet und werden von NetApp unterstützt.</block>
  <block id="ff43afff832597ff45e5abeab2826ccf" category="inline-link">Dokumentation zu ONTAP Tools für VMware vSphere (Konfiguration von Hochverfügbarkeit für ONTAP Tools)</block>
  <block id="d516ca4c9c18446a82d9fc9ee85bd955" category="paragraph">VSphere High Availability lässt sich leicht konfigurieren, um eine VM auf einem anderen Host im Host-Cluster bei einem Ausfall neu zu starten. VSphere Fault Tolerance bietet eine höhere Verfügbarkeit, indem eine sekundäre VM erstellt wird, die kontinuierlich repliziert wird und an jedem beliebigen Punkt übernommen werden kann. Weitere Informationen zu diesen Funktionen finden Sie im<block ref="b6d78cbf1d5afb52929c529b32a350ad" category="inline-link-rx"></block>, Sowie VMware vSphere Dokumentation (suchen Sie nach vSphere Verfügbarkeit unter ESXi und vCenter Server).</block>
  <block id="97ba24d475ff6fdc7743099992cc301f" category="paragraph">ONTAP Tools VASA Provider sichert die VVols Konfiguration automatisch in Echtzeit auf gemanagten ONTAP Systemen, auf denen die VVols Informationen innerhalb der FlexVol Volume-Metadaten gespeichert sind. Sollte die ONTAP Tools Appliance aus irgendeinem Grund nicht mehr verfügbar sein, können Sie schnell und einfach eine neue Appliance implementieren und die Konfiguration importieren. Weitere Informationen zu den Schritten zur Wiederherstellung von VASA Provider finden Sie in diesem KB-Artikel:</block>
  <block id="6799b6ec743f9159edf3b43790210a11" category="inline-link">So führen Sie eine VASA Provider Disaster Recovery - Resolution Guide durch</block>
  <block id="9462790a7557a7eb2fe9daad4b875817" category="paragraph"><block ref="9462790a7557a7eb2fe9daad4b875817" category="inline-link-rx"></block></block>
  <block id="029a7740ecd792264454f9dbe194e980" category="section-title">VVols Replizierung</block>
  <block id="c7b26217fd0c9041b6f779a0f669de5c" category="paragraph">Viele ONTAP Kunden replizieren ihre herkömmlichen Datastores auf sekundäre Storage-Systeme mithilfe von NetApp SnapMirror. Bei einem Ausfall stellen sie dann mithilfe des Sekundärsystems individuelle VMs oder einen kompletten Standort wieder her. In den meisten Fällen verwenden Kunden hierfür ein Software Tool, z. B. ein Backup Software-Produkt wie das NetApp SnapCenter Plug-in für VMware vSphere oder eine Disaster Recovery-Lösung wie Site Recovery Manager von VMware (zusammen mit dem Storage Replication Adapter in ONTAP Tools).</block>
  <block id="bc6303e4538280b1b01d45a5f7d20039" category="paragraph">Diese Anforderung an ein Software-Tool ist für das Management der VVols Replizierung noch wichtiger. Einige Aspekte können durch native Funktionen gemanagt werden (beispielsweise werden durch VMware gemanagte Snapshots von VVols auf ONTAP verlagert, bei denen schnelle, effiziente Datei- oder LUN-Klone verwendet werden), doch ist allgemeine Orchestrierung für das Management der Replizierung und Recovery erforderlich. Metadaten zu VVols werden sowohl durch ONTAP als auch durch den VASA Provider geschützt, für die Nutzung an einem sekundären Standort ist jedoch eine zusätzliche Verarbeitung erforderlich.</block>
  <block id="c6a26835eb364bad22b16cb127b74135" category="paragraph">Die ONTAP Tools 9.7.1 unterstützen in Verbindung mit der VMware Site Recovery Manager (SRM) Version 8.3 zusätzlich die Orchestrierung von Disaster Recovery und Migrations-Workflows mithilfe der NetApp SnapMirror Technologie.</block>
  <block id="2803a799fd66056eff404a17ba640c2b" category="paragraph">In der ersten Version der SRM-Unterstützung mit ONTAP Tools 9.7.1 war es erforderlich, FlexVols vorab zu erstellen und die SnapMirror Sicherung zu aktivieren, bevor sie als Backup-Volumes für einen VVols-Datastore verwendet werden konnten. Ab ONTAP Tools 9.10 wird dieser Prozess nicht mehr benötigt. Sie können jetzt vorhandene Backup Volumes um SnapMirror Schutz erweitern und Ihre VM-Storage-Richtlinien aktualisieren, um von richtlinienbasiertem Management mit Disaster Recovery, Migrationorchestrierung und Automatisierung, integriert in SRM, zu profitieren.</block>
  <block id="8142fcf496d02a58ce02a17558db863e" category="paragraph">Derzeit ist VMware SRM die einzige von NetApp unterstützte Lösung für Disaster Recovery und Migrationsautomatisierung für VVols. ONTAP Tools überprüfen die Existenz eines SRM 8.3 oder eines höheren Servers, der bei vCenter registriert ist, bevor Sie die VVols Replizierung aktivieren können. Es ist zwar möglich, die REST-APIs der ONTAP Tools zur Erstellung eigener Services zu nutzen.</block>
  <block id="7d8e8eced8d8b1a50f20640ffb5d363a" category="section-title">VVols Replizierung mit SRM</block>
  <block id="4d30574e6d5bc9a71718858eeb30774c" category="inline-image-macro">VVols Replizierung mit SRM,300</block>
  <block id="5844b0ec1ad8db5185ec67effeb9a7b7" category="paragraph"><block ref="5844b0ec1ad8db5185ec67effeb9a7b7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c95aede1de7a41511c9d962deba49054" category="section-title">MetroCluster-Unterstützung</block>
  <block id="3f15bb720adb42bd521a2ce1cb3a2974" category="paragraph">ONTAP Tools können zwar keine MetroCluster-Umschaltung auslösen, doch es unterstützt NetApp MetroCluster Systeme für VVols, die Volumes in einer einheitlichen vSphere Metro Storage Cluster (vMSC) Konfiguration sichern. Die Umschaltung eines MetroCluster-Systems erfolgt auf normale Weise.</block>
  <block id="cde16c5ee89c209c821e120caf65bb81" category="paragraph">NetApp SnapMirror Business Continuity (SM-BC) kann zwar auch als Basis für eine vMSC Konfiguration verwendet werden, wird jedoch derzeit nicht mit VVols unterstützt.</block>
  <block id="c859f5cd725cb2d1b163e4b066bede9a" category="paragraph">In diesen Leitfäden finden Sie weitere Informationen über NetApp MetroCluster:</block>
  <block id="e5e0fb3ae5564674a6548ade7c601578" category="inline-link">_TR-4689 MetroCluster IP Lösungsarchitektur und Design_</block>
  <block id="e64de4e49a37e62ff7f8c37e859bbeb9" category="paragraph"><block ref="e64de4e49a37e62ff7f8c37e859bbeb9" category="inline-link-rx"></block></block>
  <block id="0229efec9dc9b9a7fdf144b025157176" category="inline-link">TR-4705 NetApp MetroCluster Lösungsarchitektur und Design_</block>
  <block id="6aee4b78ffdfaf193918978472d660a7" category="paragraph"><block ref="6aee4b78ffdfaf193918978472d660a7" category="inline-link-rx"></block></block>
  <block id="876341bac548f230eb390348e8b075ad" category="inline-link">_VMware KB 2031038 VMware vSphere Unterstützung mit NetApp MetroCluster_</block>
  <block id="5e68486fffeebad2ed145408dc250367" category="paragraph"><block ref="5e68486fffeebad2ed145408dc250367" category="inline-link-rx"></block></block>
  <block id="50c323f7050912164118ba47eab75888" category="section-title">VVols Backup-Übersicht</block>
  <block id="6751e706567f4773c4f3138b4de51a0f" category="paragraph">Für die Sicherung von VMs gibt es verschiedene Ansätze, beispielsweise die Verwendung von Backup-Agenten in Gastbetrieben, das Anhängen von VM-Datendateien an einen Backup-Proxy oder die Verwendung definierter APIs wie VMware VADP. VVols können über dieselben Mechanismen geschützt werden, und viele NetApp Partner unterstützen VM-Backups, einschließlich VVols.</block>
  <block id="416d27c872769e934ac8a49ec98ccb53" category="paragraph">Wie bereits erwähnt, werden von VMware vCenter gemanagte Snapshots in platzsparende und schnelle ONTAP Datei-/LUN-Klone ausgelagert. Diese können für schnelle, manuelle Backups verwendet werden, sind aber von vCenter auf maximal 32 Snapshots beschränkt. Sie können vCenter verwenden, um Snapshots zu erstellen und bei Bedarf zurückzusetzen.</block>
  <block id="8f3d5ae5bd7d8922841975ccd84b8526" category="paragraph">Ab dem SnapCenter Plug-in für VMware vSphere (SCV) 4.6 wird in Verbindung mit den ONTAP Tools 9.10 und höher die Unterstützung für absturzkonsistentes Backup und Recovery von VVols-basierten VMs unterstützt. Dabei werden ONTAP FlexVol Volume Snapshots mit Unterstützung für SnapMirror und SnapVault-Replizierung verwendet. Pro Volume werden bis zu 1023 Snapshots unterstützt. SCV kann mithilfe von SnapMirror mit einer Mirror-Vault-Richtlinie auch mehr Snapshots mit längerer Aufbewahrung auf sekundären Laufwerken speichern.</block>
  <block id="1429a9379faa8e82f8b198e93eebdf61" category="paragraph">Die Unterstützung für vSphere 8.0 wurde mit SCV 4.7 eingeführt, wobei eine isolierte lokale Plug-in-Architektur verwendet wurde. Die Unterstützung für vSphere 8.0U1 wurde zu SCV 4.8 hinzugefügt, wodurch die neue Remote-Plug-in-Architektur vollständig umgestellt wurde.</block>
  <block id="de1d77d00dae616276b6ceb6296a18f2" category="section-title">VVols Backup mit SnapCenter Plug-in für VMware vSphere</block>
  <block id="02f41838319aab980999b60967d7fd53" category="paragraph">Mit NetApp SnapCenter können Sie nun auf Tags und/oder Ordnern basierende Ressourcengruppen für VVols erstellen und so automatisch die Vorteile der auf ONTAP FlexVol basierenden Snapshots für VVols basierte VMs nutzen. So können Sie Backup- und Recovery-Services definieren, die VMs automatisch bei der dynamischen Bereitstellung in Ihrer Umgebung sichern.</block>
  <block id="4549a2943666c4815098331d30a872da" category="paragraph">Das SnapCenter Plug-in für VMware vSphere wird als Standalone-Appliance implementiert, die als vCenter-Erweiterung registriert und über die vCenter UI oder ÜBER REST-APIs zur Automatisierung von Backup- und Recovery-Services gemanagt wird.</block>
  <block id="26e2418d177df1dddb008e455ce28752" category="section-title">Architektur von SnapCenter</block>
  <block id="3b345c0fb5d2f0451ef84d991b21dcac" category="inline-image-macro">Architektur von SnapCenter,300</block>
  <block id="af9bca7d8452705ba7f607cd036dba01" category="paragraph"><block ref="af9bca7d8452705ba7f607cd036dba01" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c32197281aa44f57ae568a9a42c7b3b6" category="paragraph">Da zum Zeitpunkt dieses Schreibens die anderen SnapCenter-Plug-ins VVols noch nicht unterstützen, konzentrieren wir uns in diesem Dokument auf das eigenständige Implementierungsmodell.</block>
  <block id="6750052f2c0fb06d80a8efd7cb871190" category="paragraph">Da SnapCenter ONTAP FlexVol Snapshots verwendet, wird kein Overhead auf vSphere platziert. Es gibt auch keine Performance-Einbußen, wie man bei herkömmlichen VMs mit von vCenter gemanagten Snapshots sehen könnte. Da die SCV-Funktionalität über REST-APIs zugänglich ist, wird die Erstellung automatisierter Workflows mit Tools wie VMware Aria Automation, Ansible, Terraform und nahezu jedem anderen Automatisierungs-Tool, das standardmäßige REST-APIs verwenden kann, erleichtert.</block>
  <block id="0c889d77d71512ceb7241bd0f6d6ca23" category="inline-link">Übersicht ÜBER REST-APIs</block>
  <block id="35eab4195b135718da016e20979f9031" category="paragraph">Informationen zu SnapCenter-REST-APIs finden Sie unter<block ref="33852d6f529e96c0b816da3945bcb1e5" category="inline-link-rx"></block></block>
  <block id="4ee2d383554981f4ea8eff4f35db6832" category="inline-link">SnapCenter Plug-in für VMware vSphere REST-APIs</block>
  <block id="63ae61e98eec102c39264a819a3c522e" category="paragraph">Informationen zum SnapCenter Plug-in für VMware vSphere REST-APIs finden Sie unter<block ref="40a6c7462de67e21480b7a31e406f8f9" category="inline-link-rx"></block></block>
  <block id="bdf03d5c2a7086b6c916dc96d06a0a6c" category="paragraph">Die folgenden Best Practices unterstützen Sie dabei, die Vorteile Ihrer SnapCenter Implementierung optimal zu nutzen.</block>
  <block id="60af6a4208b610da54a63a7e3658d5a5" category="list-text">SCV unterstützt sowohl vCenter Server RBAC als auch ONTAP RBAC und umfasst vordefinierte vCenter Rollen, die automatisch für Sie erstellt werden, wenn das Plug-in registriert ist. Sie finden weitere Informationen zu den unterstützten Typen von RBAC<block ref="a8ef9d6a500bd8288101245a3828ddb1" category="inline-link-rx"></block></block>
  <block id="0ed0835259b5b8c4b0f0910e7bfe2b17" category="list-text">Verwenden Sie die vCenter-Benutzeroberfläche, um den Zugriff auf das Konto mit den geringsten Berechtigungen mithilfe der beschriebenen vordefinierten Rollen zuzuweisen<block ref="17b3487f3493b9c198e03f92348bfca0" category="inline-link-rx"></block>.</block>
  <block id="d53326766687d6bc7fa2e28ee177e809" category="list-text">Wenn Sie SCV mit SnapCenter-Server verwenden, müssen Sie die Rolle _SnapCenterAdmin_ zuweisen.</block>
  <block id="61ba6cb0b6021c205d41ed7f6fc1eb71" category="list-text">ONTAP RBAC bezieht sich auf das Benutzerkonto, das zum Hinzufügen und Managen der vom SCV verwendeten Speichersysteme verwendet wird. Die rollenbasierte Zugriffssteuerung von ONTAP gilt nicht für VVols-basierte Backups. Erfahren Sie mehr über ONTAP RBAC und SCV<block ref="e4e865178d3962f87ac5cef3d6d68942" category="inline-link-rx"></block>.</block>
  <block id="1c89ba258526186ea0ec98325b61371b" category="list-text">Replizieren Sie Backup-Datensätze auf ein zweites System und verwenden Sie SnapMirror für vollständige Replikate der Quell-Volumes. Wie bereits erwähnt, können Sie auch Mirror-Vault Richtlinien für die längerfristige Aufbewahrung von Backup-Daten unabhängig von den Quell-Volume Snapshot Aufbewahrungseinstellungen verwenden. Beide Mechanismen werden durch VVols unterstützt.</block>
  <block id="9792eeb3b91469abf77746b005d82d77" category="list-text">Da SCV außerdem ONTAP-Tools für VMware vSphere für VVols Funktionen erfordert, prüfen Sie immer das NetApp Interoperabilitäts-Matrix-Tool (IMT), ob die jeweilige Version kompatibel ist</block>
  <block id="71c989bd68059e2ddfa4200c60b736c7" category="list-text">Wenn Sie eine VVols-Replizierung mit VMware SRM verwenden, sollten Sie Ihre Richtlinien-RPO und Backup-Zeitplan beachten</block>
  <block id="604eb779cbb9af378f7bda71633b5b31" category="list-text">Backup-Richtlinien auf Aufbewahrungseinstellungen erstellen, die die in Ihrem Unternehmen definierten Recovery Point Objectives (RPOs) erfüllen</block>
  <block id="067ff91a08d3ff453b59d81993b96182" category="list-text">Konfigurieren Sie Benachrichtigungseinstellungen für Ihre Ressourcengruppen, um über den Status der Backups informiert zu werden (siehe Abbildung 10 unten).</block>
  <block id="c3add00693172bbbb4dd864bf0ad9116" category="section-title">Benachrichtigungsoptionen für Ressourcengruppen</block>
  <block id="c728df76dc3609672a7969e320e39e32" category="inline-image-macro">Benachrichtigungsoptionen für Ressourcengruppen,300</block>
  <block id="45281309785094533b5880fe6d0fd1ea" category="paragraph"><block ref="45281309785094533b5880fe6d0fd1ea" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6eae9510711f8df8f55a15e1761875d9" category="section-title">Erste Schritte mit SCV mit diesen Dokumenten</block>
  <block id="235a656535515ab3518937c09836e60d" category="inline-link">Erfahren Sie mehr über das SnapCenter Plug-in für VMware vSphere</block>
  <block id="79eb02d2a96cc634df87bec5bd511bbe" category="paragraph"><block ref="79eb02d2a96cc634df87bec5bd511bbe" category="inline-link-rx"></block></block>
  <block id="04e7bb0411c1c8f56ca4fc8000c62ad8" category="inline-link">Implementieren Sie das SnapCenter Plug-in für VMware vSphere</block>
  <block id="d4ba0aa084ae1145248006481c881d29" category="paragraph"><block ref="d4ba0aa084ae1145248006481c881d29" category="inline-link-rx"></block></block>
  <block id="231cf4c70d866b616c21baddaeed0696" category="doc">Fehlerbehebung</block>
  <block id="87e6f97c8ec2f31df616ef84401ffaf4" category="paragraph">Es stehen mehrere Ressourcen zur Fehlerbehebung mit zusätzlichen Informationen zur Verfügung.</block>
  <block id="9d2169c1c2855b78a7aeaa4f42d27dc7" category="section-title">NetApp Support Website</block>
  <block id="ed9018b2e8611a3d2c03bb6a205b9715" category="inline-link">ONTAP Tools für VMware vSphere</block>
  <block id="890eb741924c425abbb11e4618560181" category="paragraph">Neben einer Vielzahl von Knowledgebase Artikeln zu NetApp Virtualisierungsprodukten bietet die NetApp Support-Website auch eine praktische Landing Page für das<block ref="6e90053136fd326e5d581844ca21966d" category="inline-link-rx"></block> Produkt. Dieses Portal bietet Links zu Artikeln, Downloads, technischen Berichten und Diskussionen zu VMware Lösungen in der NetApp Community. Sie ist verfügbar unter:</block>
  <block id="fff460b039580a1bd42725a397b4c8be" category="inline-link">NetApp Support Site_</block>
  <block id="897515b5a8a03f8d5cbed44fd47ef9f3" category="paragraph"><block ref="897515b5a8a03f8d5cbed44fd47ef9f3" category="inline-link-rx"></block></block>
  <block id="4020fd07f5ee2361dd23956e6a334ffd" category="paragraph">Weitere Dokumentation zur Lösung finden Sie hier:</block>
  <block id="503a41e1e31e362793f7e86af9102c41" category="inline-link">_NetApp Lösungen für Virtualisierung_</block>
  <block id="33d455bce1363bad4500664eb6208860" category="paragraph"><block ref="33d455bce1363bad4500664eb6208860" category="inline-link-rx"></block></block>
  <block id="baf17f6d2396be5fd3676baf863a331f" category="section-title">Fehlerbehebung Für Produkte</block>
  <block id="9d6d7fa1a5253698556ac2b0cda2207d" category="paragraph">Die verschiedenen Komponenten von ONTAP Tools wie vCenter Plug-in, VASA Provider und Storage Replication Adapter sind im NetApp Dokumenten-Repository zusammengefasst. Jedes hat jedoch einen separaten Unterabschnitt der Wissensdatenbank und kann spezifische Fehlerbehebungsverfahren haben. Diese betreffen die häufigsten Probleme, die mit dem VASA Provider auftreten können.</block>
  <block id="ae2a93a809929192ecc7b468f234af84" category="section-title">Probleme BEI DER VASA Provider-UI</block>
  <block id="92a2b5cb9c6906035c2864fa225e1940" category="inline-link">Artikel</block>
  <block id="69aecee18a55993c779487758eb051cc" category="paragraph">Gelegentlich stößt der vCenter vSphere Web Client auf Probleme mit den Serenity-Komponenten, wodurch die Menüelemente VASA Provider for ONTAP nicht angezeigt werden. Weitere Informationen finden Sie unter Beheben von Problemen bei der Registrierung von VASA Provider im Implementierungsleitfaden oder in dieser Knowledgebase<block ref="c8979f1604396ce5570d07774ba255f0" category="inline-link-rx"></block>.</block>
  <block id="03cc611b90575ea37b55959adaa1c754" category="section-title">VVols Datastore-Bereitstellung schlägt fehl</block>
  <block id="281b890be0e8280eea1aebb82de90961" category="paragraph">Gelegentlich treten bei der Erstellung des VVols-Datastores bei vCenter-Services möglicherweise eine Zeitlang aus. Um sie zu korrigieren, starten Sie den vmware-sps-Service neu und mounten Sie den VVols-Datastore über die vCenter-Menüs (Storage &gt; New Datastore) neu. Dies wird durch die fehlgeschlagenen VVols Datastore-Bereitstellung mit vCenter Server 6.5 im Administrationshandbuch abgedeckt.</block>
  <block id="3152add163cd8aaf116a259d85ebf8fb" category="section-title">Das Aktualisieren von Unified Appliance schlägt fehl, um ISO zu mounten</block>
  <block id="ffaa56a3f5a1157f2eb3955773bb41da" category="paragraph">Aufgrund eines Fehlers in vCenter kann das zur Aktualisierung der Unified Appliance von einem Release auf das nächste verwendete ISO möglicherweise nicht mounten. Wenn das ISO mit der Appliance in vCenter verbunden werden kann, befolgen Sie den Prozess in dieser Knowledgebase<block ref="9839383ed04f777c0132b57ad0cb14ac" category="inline-link-rx"></block> Zu beseitigen.</block>
  <block id="cacba1b456347ce8f32c7f5ed0d81e64" category="doc">Implementierung von VVols Storage</block>
  <block id="4adcd8d9323839ff088dc4f8f0bdcce2" category="paragraph">Zum Erstellen von VVols Storage für Ihre VMs sind verschiedene Schritte erforderlich.</block>
  <block id="2a5f3dc8d46246216b293c9e41979269" category="paragraph">Die ersten beiden Schritte sind für eine bestehende vSphere-Umgebung, die ONTAP für herkömmliche Datastores verwendet, möglicherweise nicht erforderlich. Möglicherweise verwenden Sie bereits ONTAP Tools für das Management, die Automatisierung und die Berichterstellung mit Ihrem VMFS- oder herkömmlichen NFS-basierten Storage. Diese Schritte werden im folgenden Abschnitt näher erläutert.</block>
  <block id="841db3655338a0c3dc36cf2761bfdafd" category="list-text">Storage Virtual Machine (SVM) und deren Protokollkonfiguration erstellen. Sie wählen zwischen NVMe/FC, NFSv3, NFSv4.1, iSCSI, FCP oder eine Kombination dieser Optionen. Sie können entweder die Assistenten von ONTAP System Manager oder die Cluster Shell-Befehlszeile verwenden.</block>
  <block id="10818a8ad4f650a48d78d728278d4cb3" category="list-text">Mindestens eine LIF pro Node für jede Switch-/Fabric-Verbindung. Als Best Practice sollten Sie mindestens zwei pro Node für FCP-, iSCSI- oder NVMe-basierte Protokolle erstellen.</block>
  <block id="612705dd95888cdc6345d01c93c84c39" category="list-text">Derzeit können Volumes erstellt werden, doch es ist einfacher, sie vom Assistenten „_Provisioning Datastore_“ erstellen zu lassen. Die einzige Ausnahme von dieser Regel ist, wenn Sie eine VVols Replizierung mit VMware Site Recovery Manager verwenden möchten. Die Einrichtung solcher FlexVol Volumes mit bestehenden SnapMirror Beziehungen ist einfacher. Beachten Sie, dass QoS auf keinen Volumes für VVols aktiviert wird, da diese über SPBM und ONTAP Tools gemanagt werden sollen.</block>
  <block id="16421df834af873175559b678c2b3cd9" category="list-text">Implementieren Sie ONTAP Tools für VMware vSphere mit der von der NetApp Support-Website heruntergeladenen OVA.</block>
  <block id="8bdb69b5934ff84bbaafd84585965a90" category="list-text">Konfigurieren Sie ONTAP Tools für Ihre Umgebung.</block>
  <block id="dd07accb290c9c1e3900692630a70767" category="list-text">Fügen Sie den ONTAP-Cluster zu den ONTAP-Tools unter _Storage Systems_ hinzu</block>
  <block id="731ce7392ae254e2050191ae92cafb14" category="list-text">ONTAP Tools und SRA unterstützen zwar Anmeldedaten auf Cluster- und SVM-Ebene, doch unterstützt der VASA Provider nur Zugangsdaten auf Cluster-Ebene für Storage-Systeme. Dies liegt daran, dass viele der für VVols verwendeten APIs nur auf Cluster-Ebene verfügbar sind. Wenn Sie daher VVols verwenden möchten, müssen Sie die ONTAP-Cluster mit den Anmeldedaten für den Cluster-Umfang hinzufügen.</block>
  <block id="869ce78032d85111f09ceb58bdb59a36" category="list-text">Wenn sich Ihre ONTAP-Daten-LIFs in unterschiedlichen Subnetzen von Ihren VMkernel-Adaptern befinden, müssen Sie die VMkernel-Adapter-Subnetze zur Liste der ausgewählten Subnetze im Einstellungsmenü der ONTAP-Tools hinzufügen. Standardmäßig sichern ONTAP Tools Ihren Storage-Datenverkehr nur durch lokalen Subnetzzugriff.</block>
  <block id="5a6d084090f063797fc6b863d2817d98" category="list-text">Die ONTAP Tools enthalten mehrere vordefinierte Richtlinien, die verwendet werden können oder sehen <block ref="434866eb159632a70c4db034544336ef" category="inline-xref-macro-rx"></block> Anleitung zum Erstellen von SCPs.</block>
  <block id="ef51190e4c839596248fc4173ed12a3c" category="list-text">Verwenden Sie das Menü „_ONTAP Tools_“ in vCenter, um den Assistenten „_Provisioning Datastore_“ zu starten.</block>
  <block id="66edaf6f622057aeadab950977c1f3e8" category="list-text">Geben Sie einen aussagekräftigen Namen ein, und wählen Sie das gewünschte Protokoll aus. Sie können auch eine Beschreibung des Datastore angeben.</block>
  <block id="d22d6de0c8f11375907a1c10d8d0f251" category="list-text">Wählen Sie einen oder mehrere SCPs aus, die vom VVols-Datastore unterstützt werden sollen. Dadurch werden alle ONTAP-Systeme herausgefiltert, die nicht mit dem Profil übereinstimmen. Wählen Sie in der Ergebnisliste den gewünschten Cluster und die gewünschte SVM aus.</block>
  <block id="6a016a18a0c20e3b805cd9b8e713fb3e" category="list-text">Verwenden Sie den Assistenten, um neue FlexVol-Volumes für jeden der angegebenen SCPs zu erstellen, oder verwenden Sie vorhandene Volumes, indem Sie das entsprechende Optionsfeld auswählen.</block>
  <block id="2527effe721902a77755b8d628fdad93" category="list-text">Erstellen Sie VM-Richtlinien für jedes SCP, das im Datastore verwendet wird, über das Menü „_Policies and Profiles_“ in der vCenter UI.</block>
  <block id="642dadaf5095b4c11730dca0ffcb0d27" category="list-text">Wählen Sie den Storage-Regelsatz „NetApp.Clustered.Data.ONTAP.VP.vvol“ aus. Der Storage-Regelsatz „NetApp.Clustered.Data.ONTAP.VP.VASA10“ gilt für die SPBM-Unterstützung bei Datastores ohne VVols</block>
  <block id="c9565e0957e6e02cf12aef618bd30c3f" category="list-text">Beim Erstellen einer VM-Speicherrichtlinie geben Sie das Storage Capability Profile nach Namen an. Sie können in diesem Schritt auch die SnapMirror Richtlinienabstimmung über die Registerkarte „Replication“ und über die Registerkarte „Tags“ konfigurieren. Beachten Sie, dass Tags bereits erstellt werden müssen, um ausgewählt werden zu können.</block>
  <block id="af70f7acdeed8e2a702372f9bc85d960" category="list-text">Erstellen Sie Ihre VMs, indem Sie unter Select Storage die VM Storage Policy und kompatiblen Datenspeicher auswählen.</block>
  <block id="3db9849d9f30bfc6e05c4e0b36d28848" category="section-title">Migration von VMs von herkömmlichen Datastores auf VVols</block>
  <block id="7be42b7840cc093ce6d05a247df8e63d" category="paragraph">Die Migration von VMs von herkömmlichen Datastores in einen VVols Datastore ist nicht komplizierter als das Verschieben von VMs zwischen herkömmlichen Datastores. Wählen Sie einfach die VM(s) aus, dann Migrate aus der Liste der Aktionen und dann einen Migrationstyp von _change Storage only_ aus. Migrationsvorgänge werden für SAN VMFS zu VVols Migrationen mit vSphere 6.0 und höher verlagert, jedoch nicht von NAS VMDKs zu VVols.</block>
  <block id="58f2a764a13ec89d3c5ead5343e75637" category="section-title">Verwalten von VMs mithilfe von Richtlinien</block>
  <block id="4b746813f1085683be4f71c8affea233" category="paragraph">Um die Storage-Bereitstellung mit richtlinienbasiertem Management zu automatisieren, müssen wir</block>
  <block id="10b68fb9cbee818a044f91644423640c" category="list-text">Definieren Sie mit Storage Capability Profiles (SCPs) die Funktionen des Speichers (ONTAP-Knoten und FlexVol-Volume).</block>
  <block id="2e415dc7a6f21b4fd03f963858c9f680" category="list-text">Erstellen Sie VM-Storage-Richtlinien, die den definierten SCPs zugeordnet sind.</block>
  <block id="67c819108c4ef294ac28a51197046dfc" category="paragraph">NetApp hat die Funktionen und die Zuordnung ab VASA Provider 7.2 vereinfacht, wobei die Verbesserungen in späteren Versionen fortgeführt werden. Dieser Abschnitt konzentriert sich auf diesen neuen Ansatz. Frühere Versionen unterstützten eine größere Anzahl von Funktionen und erlaubten die individuelle Zuordnung zu Storage-Richtlinien, allerdings wird dieser Ansatz nicht mehr unterstützt.</block>
  <block id="0bd86c4955ab0bdce52b49644ce9396d" category="section-title">Funktionen des Storage-Funktionsprofils nach ONTAP-Tools</block>
  <block id="4a6af8a6e216dcc53a63f04143c13222" category="cell">*SCP-Fähigkeit*</block>
  <block id="048424cc97a54b673c837ee7d4c19de0" category="cell">*Fähigkeitswerte*</block>
  <block id="098e77f7c5d9e0c2ad5454817edf0767" category="cell">*Release-Unterstützung*</block>
  <block id="28f44037af103f0c930309365629f8ef" category="cell">*Hinweise*</block>
  <block id="d031377688b064b729a0cc60fb7fbbff" category="cell">*Komprimierung*</block>
  <block id="cc6aee5037bdc5b051433a266ec7d4a3" category="cell">Ja, Nein, Alle</block>
  <block id="7778bddb1c205e9f74d08bd30be0aca3" category="cell">Obligatorisch für AFF ab 7.2.</block>
  <block id="221baf8ad30299306e725e4fb395bf34" category="cell">*Deduplizierung*</block>
  <block id="6868f879256c802b106616a006671848" category="cell">M andatory für AFF in 7.2 und später.</block>
  <block id="504897d4a6b59afadffd3cf9e5d3ea85" category="cell">*Verschlüsselung*</block>
  <block id="95fddd53c531d6efe15e3ac7ace1d9eb" category="cell">7.2 und höher</block>
  <block id="b3870ec121aeafa2e7ca8cb3894c0e3a" category="cell">Wählt/erstellt ein verschlüsseltes FlexVol-Volume. ONTAP-Lizenz erforderlich.</block>
  <block id="e2dcc78cf70dac34550234c95443ac37" category="cell">*Maximale IOPS*</block>
  <block id="b78a981cc40fc4e66208bf5ee6d1a1eb" category="cell">&lt;number&gt;</block>
  <block id="130b32bc15d3fbe6d2e80ecda94135cc" category="cell">7.1 und später, aber Unterschiede</block>
  <block id="c0f84018aff4ff4a1cf4012a8b82e509" category="cell">Aufgeführt unter QoS Policy Group für 7.2 und höher. Siehe <block ref="8fdd8868d80d04eecf1b4189862f536c" category="inline-xref-macro-rx"></block> Finden Sie weitere Informationen.</block>
  <block id="993c56850c1da5de36e798b0c5a72513" category="cell">* Persönlichkeit*</block>
  <block id="8485fa08bf8c556b7b2275349d11eb05" category="cell">A FF, FAS</block>
  <block id="c0acd03e8ba6b951b8c6dff3e95b9560" category="cell">FAS beinhaltet auch andere nicht-All Flash FAS Systeme wie beispielsweise ONTAP Select. AFF umfasst ASA.</block>
  <block id="dce365633ffb688b7532470dfaf4e118" category="cell">*Protokoll*</block>
  <block id="7cff0b96b4a6467ea880f49dd365a81f" category="cell">NFS, NFS 4.1, iSCSI, FCP, NVMe/FC, Alle</block>
  <block id="be18de5e88c84ba55eeb5bc42cca4c0d" category="cell">7.1 und früher, 9.10 und höher</block>
  <block id="cfca0bc0c0b481555ba52be1f4e21da6" category="cell">7.2-9.8 ist effektiv "jede". Ebenfalls ab 9.10, wo NFS 4.1 und NVMe/FC in die ursprüngliche Liste aufgenommen wurden.</block>
  <block id="3dd301ae5682df79e8687ead5b6a3ddf" category="cell">*Speicherplatzreserve (Thin Provisioning)*</block>
  <block id="03868a080fbf4cdbc006da45e13cfad7" category="cell">Dünn, Dick, (Beliebig)</block>
  <block id="0a74dc1caf6ce891d5cbd3878cae2221" category="cell">Alle, aber Unterschiede</block>
  <block id="4b370bcc260aa96e343bbb24d3af2cc5" category="cell">7.1 und früher als Thin Provisioning bezeichnet, wodurch auch beliebige Werte zulässig sind. Genannt Space Reserve in 7.2. Alle Releases sind standardmäßig Thin.</block>
  <block id="40e2e283d064264dd51846580adb367d" category="cell">*Tiering-Richtlinie*</block>
  <block id="06b815f81a7e7aceb1489e3888fb9534" category="cell">Beliebig, Keine, Snapshot, Automatisch</block>
  <block id="00917abc35f0d57db6562a886997c4e8" category="cell">Verwendet für FabricPool - erfordert AFF oder ASA mit ONTAP 9.4 oder höher. Nur Snapshot ist empfohlen, wenn eine lokale S3 Lösung wie NetApp StorageGRID nicht verwendet wird.</block>
  <block id="ffb0d092d584c15937dfacd5be3c684a" category="section-title">Erstellen Von Storage-Funktionsprofilen</block>
  <block id="ad0b6bb809400347fc4806f18385015c" category="paragraph">NetApp VASA Provider verfügt über mehrere vordefinierte SCPs. Neue SCPs können manuell über die vCenter UI oder über die Automatisierung mit REST-APIs erstellt werden. Durch das Angeben von Funktionen in einem neuen Profil, das Klonen eines vorhandenen Profils oder das automatische Generieren von Profilen aus bestehenden herkömmlichen Datastores. Dies erfolgt über die Menüs unter ONTAP Tools. Verwenden Sie _Storage Capability Profiles_, um ein Profil zu erstellen oder zu klonen, und _Storage Mapping_, um ein Profil automatisch zu generieren.</block>
  <block id="62351556db3b0f6f13da226ca3e2df24" category="section-title">Storage-Funktionen für ONTAP Tools 9.10 und höher</block>
  <block id="14b49e2a6b56b1177a77be03a29dfc83" category="inline-image-macro">„Storage-Funktionen für ONTAP Tools 9.10 und höher“.300</block>
  <block id="2a53cbcd07a15d9f13f0cc630c7cc44d" category="paragraph"><block ref="2a53cbcd07a15d9f13f0cc630c7cc44d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="12bb128f53dfaac0a251798e4b4e6954" category="paragraph"><block ref="12bb128f53dfaac0a251798e4b4e6954" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4e6d46028a015a7f3860fc8fdf214b3c" category="paragraph"><block ref="4e6d46028a015a7f3860fc8fdf214b3c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="64ca5ade59a3a7351134cf0db3a8e06a" category="paragraph"><block ref="64ca5ade59a3a7351134cf0db3a8e06a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2c8f597441425c22b4ae09f872f8bcc4" category="paragraph"><block ref="2c8f597441425c22b4ae09f872f8bcc4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fd59d4e26c472ef1e14cadb688283604" category="paragraph"><block ref="fd59d4e26c472ef1e14cadb688283604" category="inline-image-macro-rx" type="image"></block></block>
  <block id="049b6d7b78dd8ffebadb5a0be2261637" category="paragraph">*Erstellen von VVols Datastores*
Nachdem die erforderlichen SCPs erstellt wurden, können sie auch zur Erstellung des VVols-Datastores (und optional auch FlexVol Volumes für den Datastore) verwendet werden. Klicken Sie mit der rechten Maustaste auf den Host, das Cluster oder das Datacenter, auf dem Sie den VVols-Datastore erstellen möchten, und wählen Sie dann _ONTAP Tools_ &gt; _Provisioning Datastore_ aus. Wählen Sie einen oder mehrere SCPs aus, die vom Datastore unterstützt werden sollen, und wählen Sie dann aus vorhandenen FlexVol Volumes aus bzw. stellen Sie neue FlexVol Volumes für den Datastore bereit. Geben Sie schließlich das Standard-SCP für den Datastore an, das für VMs verwendet wird, für die kein durch die Richtlinie angegebenes SCP angegeben ist, sowie für Swap-VVols (diese erfordern keinen hochperformanten Storage).</block>
  <block id="a4332a81dbc3a9888be608dea640cd3d" category="section-title">Erstellen von VM-Storage-Richtlinien</block>
  <block id="80f789420db66cc767606f2432667d32" category="paragraph">VM-Storage-Richtlinien managen in vSphere optionale Funktionen wie Storage I/O Control oder vSphere Encryption. Sie werden auch zusammen mit VVols verwendet, um spezifische Storage-Funktionen auf die VM anzuwenden. Verwenden Sie den Storage-Typ „NetApp.Clustered.Data.ONTAP.VP.vvol“ und die Regel „ProfileName“, um mithilfe der Richtlinie ein bestimmtes SCP auf VMs anzuwenden. Ein Beispiel hierfür mit den ONTAP Tools VASA Provider finden Sie unter Link:ontap.HTML#Best Practices[Beispiel für eine Netzwerkkonfiguration mit VVols über NFS v3]. Regeln für Storage „NetApp.Clustered.Data.ONTAP.VP.VASA10“ sollen mit Datastores ohne VVols verwendet werden.</block>
  <block id="b4f6f65777757af7630fae901718e51e" category="paragraph">Frühere Versionen sind ähnlich, aber wie in erwähnt <block ref="68072d20e775e4558feadbec7ba8f768" category="inline-xref-macro-rx"></block>, Ihre Optionen variieren.</block>
  <block id="136cc0f714cd085d732d263ed60f95b7" category="paragraph">Sobald die Storage-Richtlinie erstellt wurde, kann sie verwendet werden, wenn neue VMs bereitgestellt werden, wie in dargestellt <block ref="4ed4bde8f4b7355ad6a00fef761d7ba6" category="inline-link-macro-rx"></block>. Richtlinien zur Nutzung von Performance-Management-Funktionen mit VASA Provider 7.2 finden Sie in <block ref="8fdd8868d80d04eecf1b4189862f536c" category="inline-xref-macro-rx"></block>.</block>
  <block id="52896487a6472798e1d6cbc9a95ec51e" category="section-title">Erstellen der Richtlinie für den VM-Storage mit ONTAP Tools VASA Provider 9.10</block>
  <block id="c0c5e719ad5439106e5a00588402f206" category="inline-image-macro">„Erstellung der VM Storage-Richtlinien mit ONTAP Tools VASA Provider 9.10„.300</block>
  <block id="378e30f2a60dc28c4afc9ae4f11a39e1" category="paragraph"><block ref="378e30f2a60dc28c4afc9ae4f11a39e1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="95ac22478e141fde0d2878c71530a13a" category="section-title">Performance Management mit ONTAP Tools 9.10 und höher</block>
  <block id="c153012a9aa13e8ed8ce3f3e471a70b4" category="list-text">ONTAP Tools 9.10 verwendet einen eigenen Algorithmus für optimierte Platzierung, um ein neues vVol im besten FlexVol Volume in einem VVols Datastore zu platzieren. Die Platzierung basiert auf dem angegebenen SCP und übereinstimmenden FlexVol-Volumes. Dadurch wird sichergestellt, dass der Datastore und der zugrunde liegende Storage die angegebenen Performance-Anforderungen erfüllen können.</block>
  <block id="e65bde48b0a84fcc60d957de90c3a128" category="list-text">Wenn sich Funktionen für die Performance wie Min. Und Max. Ändern, muss die spezifische Konfiguration entsprechend verändert werden.</block>
  <block id="c43f1c590aab42b849ee038e863a567d" category="list-text">*Min und Max IOPS* können in einem SCP angegeben und in einer VM Policy verwendet werden.</block>
  <block id="404e0fefd61512a9f144586382a62641" category="list-text">Wenn Sie die IOPS im SCP ändern, wird die QoS auf den VVols erst geändert, wenn die VM-Richtlinie bearbeitet und dann auf die VMs angewendet wird, die sie verwenden (siehe <block ref="2358041c73953300d39d98366deee80d" category="inline-xref-macro-rx"></block>). Oder erstellen Sie ein neues SCP mit den gewünschten IOPS und ändern Sie die Richtlinie, um es zu verwenden (und erneut auf VMs anzuwenden). Im Allgemeinen wird empfohlen, einfach separate SCPs und VM-Storage-Richtlinien für verschiedene Service-Ebenen zu definieren und einfach die VM-Storage-Richtlinie für die VM zu ändern.</block>
  <block id="0e05d638b7a9c7a5c32e6c22679eeb82" category="list-text">AFF- und FAS-Persönlichkeiten haben unterschiedliche IOPS-Einstellungen. Sowohl Min. Als auch Max. Sind auf AFF verfügbar. Nicht-All Flash FAS Systeme können jedoch nur die IOPS-Maximaleinstellungen verwenden.</block>
  <block id="97659fa3c3a5aaf088f6020a38faf086" category="list-text">In einigen Fällen muss ein vVol nach einer Richtlinienänderung (entweder manuell oder automatisch durch VASA Provider und ONTAP) migriert werden:</block>
  <block id="81c975fc79a19102fa04ad9c49f7538b" category="list-text">Einige Änderungen erfordern keine Migration (wie beispielsweise eine Änderung der maximalen IOPS, die sofort auf die VM angewendet werden kann, wie oben beschrieben).</block>
  <block id="a426b56f86a12c200f3484efb990e81f" category="list-text">Wenn die Richtlinienänderung nicht vom aktuellen FlexVol Volume unterstützt werden kann, in dem das vVol gespeichert ist (beispielsweise unterstützt die Plattform die angeforderte Verschlüsselungs- oder Tiering-Richtlinie nicht), müssen Sie die VM manuell in vCenter migrieren.</block>
  <block id="7de504873f20af5c8ce6dadd2f79b29a" category="list-text">ONTAP-Tools erstellen individuelle QoS-Richtlinien ohne gemeinsame Nutzung mit derzeit unterstützten Versionen von ONTAP. Daher erhält jede einzelne VMDK eine eigene IOPS-Zuweisung.</block>
  <block id="63a33ddbd2c3ccd2daac06020248049f" category="section-title">Erneutes Anwenden der VM-Speicherrichtlinie</block>
  <block id="d0f5986c3378364e5cb0eda0e98fd0fd" category="inline-image-macro">„VM-Speicherrichtlinie neu anwendet.300</block>
  <block id="2a8c2026166e178134c7e19c2f4a2c15" category="paragraph"><block ref="2a8c2026166e178134c7e19c2f4a2c15" category="inline-image-macro-rx" type="image"></block></block>
  <block id="50b6e1c7f2e81842d993d8ce88acc979" category="summary">ONTAP unterstützt alle maßgeblichen Storage-Protokolle für die Virtualisierung, beispielsweise iSCSI, Fibre Channel (FC), Fibre Channel over Ethernet (FCoE) oder Non-Volatile Memory Express over Fibre Channel (NVMe/FC) für SAN-Umgebungen sowie NFS (v3 und v4.1) und SMB oder S3 für Gastverbindungen. Die Kunden können die für ihre Umgebung am besten geeigneten Protokolle auswählen und sie nach Bedarf in einem einzigen System kombinieren.</block>
  <block id="ee8cc65cae83009c275cd4748f4c58ae" category="doc">Virtualisierungstools für ONTAP</block>
  <block id="0894f8dfb7dd501a78dc2416b7b90c2a" category="paragraph">NetApp bietet verschiedene Standalone-Softwaretools, die gemeinsam mit ONTAP und vSphere für das Management Ihrer virtualisierten Umgebung verwendet werden können.</block>
  <block id="236e1a1bf6abf86968baf738af47b78c" category="paragraph">Die folgenden Tools sind ohne Aufpreis in der ONTAP Lizenz enthalten. In Abbildung 1 sehen Sie eine Darstellung, wie diese Tools in Ihrer vSphere Umgebung zusammenarbeiten.</block>
  <block id="f364e3337f5237c93d7b5439c82d444b" category="paragraph">Die ONTAP Tools für VMware vSphere sind eine Reihe von Tools, die ONTAP Storage zusammen mit vSphere verwenden. Das vCenter Plug-in, ehemals Virtual Storage Console (VSC), vereinfacht Storage-Management- und Effizienzfunktionen, verbessert die Verfügbarkeit und senkt die Storage-Kosten und den Betriebsaufwand – sei es bei SAN oder NAS. Dieses Plug-in nutzt Best Practices für die Bereitstellung von Datastores und optimiert ESXi Hosteinstellungen für NFS- und Block-Storage-Umgebungen. Bei all diesen Vorteilen empfiehlt NetApp, bei der Verwendung von vSphere mit Systemen mit ONTAP Software diese ONTAP Tools als Best Practice zu verwenden. Sie umfasst eine Server-Appliance, Erweiterungen der Benutzeroberfläche für vCenter, VASA Provider und Storage Replication Adapter. Nahezu alles in ONTAP Tools lässt sich mithilfe einfacher REST-APIs automatisieren – auch mit den meisten modernen Automatisierungs-Tools nutzbar.</block>
  <block id="0b266371a133b176a2ee883ccf72b46c" category="list-text">*VCenter UI Extensions.* die UI-Erweiterungen der ONTAP-Tools vereinfachen die Arbeit von Betriebsteams und vCenter Administratoren durch die Verwendung benutzerfreundlicher, kontextabhängiger Menüs zum Managen von Hosts und Storage, Informations-Portlets und nativen Alarmfunktionen direkt in der vCenter-Benutzeroberfläche für optimierte Workflows.</block>
  <block id="e08c666b5127e745f8aacbacfce37dcf" category="list-text">*VASA Provider für ONTAP.* der VASA Provider für ONTAP unterstützt das VMware vStorage APIs for Storage Awareness (VASA) Framework. Er wird im Rahmen von ONTAP Tools für VMware vSphere als eine einzelne virtuelle Appliance zur einfachen Implementierung bereitgestellt. VASA Provider verbindet vCenter Server mit ONTAP und erleichtert so die Bereitstellung und das Monitoring von VM-Storage. Es aktiviert die Unterstützung und das Management von Storage-Funktionsprofilen für VMware Virtual Volumes (VVols) und die VVols Performance für einzelne VMs sowie Alarme für die Monitoring-Kapazität und -Compliance mit den Profilen.</block>
  <block id="1c7bb8764fc089dda8481678ad1ea0b5" category="list-text">*Storage Replication Adapter.* SRA wird zusammen mit VMware Site Recovery Manager (SRM) zum Management der Datenreplizierung zwischen Produktions- und Disaster-Recovery-Standorten sowie zum unterbrechungsfreien Testen der DR-Replikate verwendet. Diese Software hilft bei der Automatisierung der Erkennungs-, Recovery- und Sicherungsaufgaben. Sie enthält sowohl eine SRA Server-Appliance als auch SRA Adapter für den Windows SRM Server und eine SRM Appliance.</block>
  <block id="a1c13ec555198266776a3a7b904810dd" category="paragraph">In der folgenden Abbildung sind die ONTAP Tools für vSphere dargestellt.</block>
  <block id="f7e876d450acee7c9ed7b18438440fb2" category="paragraph"><block ref="f7e876d450acee7c9ed7b18438440fb2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="dd55e255500b9ec15305dc69dfa0e15b" category="section-title">NFS-Plug-in für VMware VAAI</block>
  <block id="4fbfd4c228f22ff3f2841908e853d895" category="paragraph">Das NetApp NFS Plug-in für VMware VAAI ist ein Plug-in für ESXi Hosts, mit dem diese VAAI Funktionen mit NFS-Datastores unter ONTAP verwenden können. Es unterstützt den Copy-Offload für Klonvorgänge, die Speicherplatzreservierung für Thick Virtual Disk Files und Snapshot Offload. Die Verlagerung von Kopiervorgängen in den Storage erfolgt nicht unbedingt schneller, sorgt aber dafür, dass die Anforderungen an die Netzwerkbandbreite reduziert werden und Host-Ressourcen wie CPU-Zyklen, Puffer und Warteschlangen verlagert werden. Sie können das Plug-in mithilfe von ONTAP Tools für VMware vSphere auf ESXi Hosts oder, sofern unterstützt, vSphere Lifecycle Manager (vLCM) installieren.</block>
  <block id="00cdd3f66e02711548cf72d579ec0df8" category="summary">Mit SnapCenter können Sie Backup-Richtlinien erstellen, die auf mehrere Jobs angewendet werden können. In diesen Richtlinien können ein Zeitplan, die Aufbewahrung, die Replizierung und andere Funktionen definiert werden. Damit ist es weiterhin möglich, optional VM-konsistente Snapshots auszuwählen und dadurch die Fähigkeit des Hypervisors auszuschöpfen, das I/O vor dem Erstellen eines VMware Snapshots stillzulegen.</block>
  <block id="f1d1eddd608fe98b6fa2bc3436ce81d0" category="doc">Richtlinienbasiertes Storage-Management und VVols</block>
  <block id="2bdce8d6813e7a3d93783119529cf146" category="paragraph">VMware vSphere APIs for Storage Awareness (VASA) erleichtern einem Storage-Administrator die Konfiguration von Datastores mit klar definierten Funktionen. Der VM-Administrator kann sie zudem im Bedarfsfall jederzeit nutzen, um VMs bereitzustellen, ohne dass eine Interaktion stattfinden muss.</block>
  <block id="871db14a81b3510676400538c6f07073" category="paragraph">Eine genauere Betrachtung dieses Ansatzes lohnt sich für Sie, wenn Sie feststellen möchten, wie er Ihre Storage-Virtualisierungsvorgänge optimieren und Ihnen viele banale Arbeiten ersparen kann.</block>
  <block id="ad0bd815b4fb6f01acc94f160af3dca7" category="paragraph">Vor VASA konnten VM-Administratoren VM-Storage-Richtlinien definieren, mussten dann aber gemeinsam mit dem Storage-Administrator geeignete Datastores ermitteln – oft anhand der Dokumentation oder von Namenskonventionen. Mit VASA kann der Storage-Administrator eine Reihe von Storage-Funktionen definieren, darunter Performance, Tiering, Verschlüsselung und Replizierung. Ein Satz von Funktionen für ein Volume oder eine Gruppe von Volumes wird als Storage-Funktionsprofil (Storage Capability Profile, SCP) bezeichnet.</block>
  <block id="44d75bdf4feecabe2de10427870ae623" category="paragraph">Das SCP unterstützt die minimale und/oder maximale QoS für die Daten-VVols einer VM. Minimale QoS wird nur auf AFF Systemen unterstützt. ONTAP Tools für VMware vSphere umfassen ein Dashboard, in dem die granulare VM-Performance und logische Kapazität für VVols auf ONTAP Systemen angezeigt werden.</block>
  <block id="4240fa68f6d9919e6d039c4038175025" category="paragraph">In der folgenden Abbildung sind die ONTAP Tools für das Dashboard von VMware vSphere 9.8 VVols dargestellt.</block>
  <block id="d3fcb217aa8b45eb8a95f8958c1f7746" category="paragraph"><block ref="d3fcb217aa8b45eb8a95f8958c1f7746" category="inline-image-macro-rx" type="image"></block></block>
  <block id="50e0e66922b3b12510a128829d1fdc70" category="paragraph">Nachdem ein Storage-Funktionsprofil definiert wurde, können damit anhand der Storage-Richtlinie, in der die entsprechenden Anforderungen angegeben sind, VMs bereitgestellt werden. Durch die Zuordnung zwischen der VM-Storage-Richtlinie und dem Datastore-Storage-Funktionsprofil kann in vCenter eine Liste kompatibler Datastores zur Auswahl angezeigt werden. Dieser Ansatz wird als richtlinienbasiertes Storage-Management bezeichnet.</block>
  <block id="794b6e2fc393d40a552fc58975920cb0" category="paragraph">VASA stellt die Technologie bereit, mit der der Storage abgefragt und eine Reihe von Storage-Funktionen an vCenter zurückgegeben werden können. VASA Provider stellen die Übersetzung zwischen den Storage-System-APIs und -Konstrukten einerseits und den von vCenter erkannten VMware APIs bereit. NetApp VASA Provider für ONTAP wird als Teil der ONTAP Tools für die VMware vSphere Appliance VM angeboten. Das vCenter Plug-in bietet die Schnittstelle zum Bereitstellen und Managen von vVol Datastores und bietet die Möglichkeit, Storage-Funktionsprofile zu definieren.</block>
  <block id="dad160104969c39365dd2cd4c98dd300" category="inline-link">TR-4400</block>
  <block id="79f0d5feb7ec25a16c407f3f585eabb2" category="paragraph">ONTAP unterstützt sowohl VMFS als auch NFS vVol Datastores. Bei gemeinsamer Verwendung von VVols und SAN-Datastores profitieren Sie von einigen der Vorteile von NFS, beispielsweise von Granularität auf VM-Ebene. Im Folgenden werden einige der zu berücksichtigende Best Practices beschrieben. Weitere Informationen finden Sie unter<block ref="4f23d4db151ca74200684ac8aef53fed" category="inline-link-rx"></block>:</block>
  <block id="bd490c925219bcb312338a370589bf70" category="list-text">Ein vVol Datastore kann aus mehreren FlexVol Volumes auf mehreren Cluster-Nodes bestehen. Den einfachsten Ansatz stellt ein einzelner Datastore dar, selbst wenn die Volumes unterschiedliche Funktionen haben. SPBM stellt sicher, dass ein kompatibles Volume für die VM verwendet wird. Die Volumes müssen allerdings alle einer einzigen ONTAP SVM angehören und es muss über ein einziges Protokoll auf sie zugegriffen werden. Für jedes Protokoll reicht eine logische Schnittstelle pro Node aus. Es empfiehlt sich nicht, mehrere ONTAP Versionen in einem einzelnen vVol Datastore zu nutzen, da sich die Storage-Funktionen in verschiedenen Versionen unter Umständen unterscheiden.</block>
  <block id="0cc956d6da91fefae9dad9b2c8c9519b" category="list-text">Verwenden Sie die ONTAP Tools für VMware vSphere Plug-in, um vVol Datastores zu erstellen und zu managen. Neben dem Management des Datastores und dessen Profil erstellt es bei Bedarf automatisch einen Protokollendpunkt für den Zugriff auf die VVols. Falls LUNs verwendet werden, werden LUN-Protokollendpunkte (PES) mit LUN-IDs ab 300 zugeordnet. Vergewissern Sie sich, dass die erweiterte Systemeinstellung des ESXi-Hosts aktiviert ist<block ref="ce913b4e625461a33f54f9e4ac38c2d7" prefix=" " category="inline-code"></block> Ermöglicht eine LUN-ID-Nummer, die über 300 liegt (Standard ist 1,024). Wählen Sie diesen Schritt aus: ESXi Host in vCenter, dann Registerkarte „Configure“ und suchen Sie<block ref="ce913b4e625461a33f54f9e4ac38c2d7" prefix=" " category="inline-code"></block> In der Liste der erweiterten Systemeinstellungen.</block>
  <block id="fac85f355a1eb47127ef1b94e7603924" category="list-text">Installieren oder migrieren Sie VASA Provider, vCenter Server (Appliance oder Windows basierte Version) oder ONTAP Tools für VMware vSphere selbst nicht auf einem VVols Datastore, da diese dann voneinander abhängen. Im Falle eines Stromausfalls oder einer anderen Störung im Datacenter könnten Sie sie dann nur begrenzt managen.</block>
  <block id="dd76252ea7a50def2a98f218cb1505b4" category="inline-link">KB-Artikel</block>
  <block id="15ef75dd3d20b8278c16cd01a708e13e" category="list-text">Sichern Sie die VASA Provider VM in regelmäßigen Abständen. Erstellen Sie mindestens stündlich Snapshots des herkömmlichen Datastores, der VASA Provider umfasst. Weitere Informationen zum Sichern und Wiederherstellen von VASA Provider finden Sie in diesem Abschnitt<block ref="9d642870dca1748c69f7aa0b6fb95a89" category="inline-link-rx"></block>.</block>
  <block id="2d2d2e356f9ab117b7d2a58d42cc5988" category="paragraph">In der folgenden Abbildung werden die VVols Komponenten angezeigt.</block>
  <block id="6aadcb77504dae1dbfed2e4d1c969158" category="paragraph"><block ref="6aadcb77504dae1dbfed2e4d1c969158" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7be2e69e5d19c282db8d81c60a51c862" category="summary">Auf dieser Seite werden die Best Practices zur Implementierung einer NetApp ONTAP Storage-Lösung in einer VMware vSphere Umgebung beschrieben.</block>
  <block id="d3ba101543fc97ba1dd9272c87bf65da" category="doc">Virtual Volumes (VVols) und richtlinienbasiertes Storage-Management (SPBM)</block>
  <block id="25e09c324ad3c89ee3aa01454fce14cd" category="section-title">Über VVols und SPBM</block>
  <block id="a42f13867ea459821488608dc4d1b7c4" category="paragraph">NetApp war schon früh als Design-Partner von VMware an der Entwicklung von vSphere Virtual Volumes (VVols) beteiligt und stellte architekturspezifischen Input und frühzeitig Unterstützung für VVols und VMware vSphere APIs for Storage Awareness (VASA) bereit. Durch diesen Ansatz wurde VMFS nicht nur granulares VM-Storage-Management ermöglicht, sondern auch die Automatisierung der Storage-Bereitstellung durch Storage Policy Based Management (SPBM) unterstützt.</block>
  <block id="ce09fc365ce48a9d89c0fdb5222c3909" category="paragraph">SPBM bietet ein Framework, das als Abstraktionsebene zwischen den für Ihre Virtualisierungsumgebung verfügbaren Storage-Services und den über Richtlinien bereitgestellten Storage-Elementen dient. Storage-Architekten können mit diesem Ansatz Storage-Pools mit unterschiedlichen Funktionen entwerfen, die von VM-Administratoren einfach genutzt werden können. Administratoren können die Workload-Anforderungen von Virtual Machines an die bereitgestellten Storage Pools anpassen, wodurch verschiedene Einstellungen pro VM oder Virtual Disk granular kontrolliert werden können.</block>
  <block id="2902acda09b9786460c2dd928a2d8f1a" category="paragraph">Bei VVols ist ONTAP eine der führenden Lösungen in der Storage-Branche, da es Hunderttausende VVols in einem einzigen Cluster unterstützt. Anbieter von Enterprise-Arrays und kleineren Flash-Arrays hingegen unterstützen gerade einmal mehrere Tausend VVols pro Array. Zudem bringt NetApp mit neuen Funktionen bei der Unterstützung von VVols 3.0 die Weiterentwicklung des granularen VM-Managements voran.</block>
  <block id="fda9c21a4aefd4a1f42ad0b195e6ef0a" category="inline-link">TR-4400: VMware vSphere Virtual Volumes with ONTAP</block>
  <block id="69173613658292fc2adeb513b12f29ca" category="admonition">Weitere Informationen zu VMware vSphere Virtual Volumes, SPBM und ONTAP finden Sie unter<block ref="354226c2546b1aed39f1c0c484e6a98a" category="inline-link-rx"></block>.</block>
  <block id="4f46fffb0ac7017fd2b42c10d6aa03fc" category="paragraph">Zu den größten Stärken von ONTAP für vSphere zählt, dass Sie Ihre VMs sichern und schnell wiederherstellen können und dass Sie diese Funktion mit dem SnapCenter Plug-in für VMware vSphere einfach in vCenter managen können.</block>
  <block id="61823c0f572643e0ce2e4edcb74cae51" category="paragraph">Mit Snapshots können Sie ohne Auswirkungen auf die Performance schnell Kopien Ihrer VMs oder Datastores erstellen und diese dann zur längerfristigen externen Datensicherung mit SnapMirror an ein sekundäres System senden. Durch diesen Ansatz werden der Storage-Platzbedarf und die Netzwerkbandbreite minimiert, da nur geänderte Informationen gespeichert werden.</block>
  <block id="0aef2da721f0ab14676f8d6ffb9e7e8c" category="inline-link">Empfehlenswert</block>
  <block id="022e604112aa3d1870f0da5e7806f48b" category="paragraph">Mit SnapCenter können Sie Backup-Richtlinien erstellen, die auf mehrere Jobs angewendet werden können. In diesen Richtlinien können ein Zeitplan, die Aufbewahrung, die Replizierung und andere Funktionen definiert werden. Damit ist es weiterhin möglich, optional VM-konsistente Snapshots auszuwählen und dadurch die Fähigkeit des Hypervisors auszuschöpfen, das I/O vor dem Erstellen eines VMware Snapshots stillzulegen. Aufgrund der Performance-Auswirkungen von VMware Snapshots werden diese jedoch im Allgemeinen nicht empfohlen, es sei denn, Sie müssen das Gast-Betriebssystem stilllegen. Verwenden Sie stattdessen Snapshots für die allgemeine Sicherung und Applikationstools wie SnapCenter Plug-ins, um transaktionsorientierte Daten – beispielsweise SQL Server oder Oracle Daten – zu sichern. Diese Snapshots unterscheiden sich von den VMware (Konsistenz-)Snapshots und sind für längerfristigen Schutz geeignet.  VMware Snapshots sind nur<block ref="75f5ad475d959e2ecb55267e1a9a54f1" category="inline-link-rx"></block> Für den kurzfristigen Einsatz aufgrund von Performance und anderen Auswirkungen.</block>
  <block id="26aae91a7d92b32a60b1fbc86c29ee81" category="paragraph">Diese Plug-ins bieten erweiterte Funktionen zur Sicherung von Datenbanken in physischen und virtuellen Umgebungen. Bei vSphere können Sie sie zur Sicherung von SQL Server oder Oracle Datenbanken heranziehen, in denen die Daten in RDM-LUNs, direkt mit dem Gastbetriebssystem verbundenen iSCSI-LUNs oder VMDK-Dateien in VMFS oder NFS-Datastores gespeichert werden. Mit den Plug-ins können unterschiedliche Typen von Datenbank-Backups angegeben, Online- oder Offline-Backups unterstützt und neben Protokolldateien auch Datenbankdateien gesichert werden. Zusätzlich zum Backup und Recovery unterstützen die Plug-ins auch das Klonen von Datenbanken zu Entwicklungs- oder Testzwecken.</block>
  <block id="1556ba0bf6ea4783cda0ff40e96f0265" category="paragraph">Die folgende Abbildung zeigt ein Beispiel für die Implementierung von SnapCenter.</block>
  <block id="54ee9d8cd5db70a761321f3e7d168445" category="paragraph"><block ref="54ee9d8cd5db70a761321f3e7d168445" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6c1bef29e8dc34a00e17b06c221d5efe" category="paragraph">Falls Sie erweiterte Disaster-Recovery-Funktionen nutzen möchten, sollten Sie in Betracht ziehen, NetApp SRA für ONTAP mit VMware Site Recovery Manager zu kombinieren. Dadurch wird die Replizierung von Datastores an einen DR-Standort unterstützt. Darüber hinaus werden unterbrechungsfreie Tests in der DR-Umgebung ermöglicht, indem die replizierten Datastores geklont werden. Das Recovery nach einem Ausfall und die erneute Sicherung der Produktion nach Behebung des Ausfalls wurden durch die in SRA integrierte Automatisierung ebenfalls vereinfacht.</block>
  <block id="650062685b0df8284f1b87f62fa3f9f3" category="inline-link">TR-4128</block>
  <block id="886a3fd32ec402d87ea2b090f8f701b2" category="paragraph">Um ein Höchstmaß an Hochverfügbarkeit zu gewährleisten, ziehen Sie eine VMware vSphere Metro Storage Cluster (vMSC) Konfiguration mit NetApp MetroCluster in Erwägung. VMSC ist eine von VMware zertifizierte Lösung mit einer Kombination aus synchroner Replizierung und Array-basiertem Clustering. Sie bietet dieselben Vorteile wie ein Hochverfügbarkeits-Cluster, ist aber zum Schutz vor Standortausfällen auf separate Standorte verteilt. NetApp MetroCluster bietet kostengünstige Konfigurationen für die synchrone Replizierung mit transparentem Recovery nach dem Ausfall einer einzelnen Storage-Komponente sowie Recovery mit nur einem Befehl im Falle eines Standortausfalls. VMSC wird in ausführlicher beschrieben<block ref="737e6eedc4568d5bb72c6a6cf1fe681a" category="inline-link-rx"></block>.</block>
  <block id="d336a329d910c32fb90337a372f596fc" category="summary">Seit fast zwei Jahrzehnten ist die NetApp ONTAP Software eine der führenden Storage-Lösungen für VMware vSphere Umgebungen und wird kontinuierlich mit innovativen Funktionen erweitert, die nicht nur zur Vereinfachung des Managements, sondern auch zu Kostensenkungen beitragen. Dieses Dokument bietet eine Einführung in die ONTAP Lösung für vSphere sowie in die neuesten Produktinformationen und Best Practices zur Optimierung der Implementierung, Risikominderung und Vereinfachung des Managements.</block>
  <block id="92515b597b8c0784d6000b89ee47c5fd" category="doc">Unified Storage</block>
  <block id="8b02311a9d2f587eb4c447455c3df68f" category="paragraph">Systeme mit ONTAP Software sind auf mehrere signifikante Arten vereinheitlicht.</block>
  <block id="7242358e2514a48e7044717140cacb4b" category="paragraph">Dieser Ansatz bezog sich ursprünglich auf die Unterstützung von NAS- und SAN-Protokollen auf einem Storage-System. ONTAP ist dabei weiterhin eine der führenden Plattformen für SAN und bietet in Bezug auf NAS die ursprünglichen Stärken.</block>
  <block id="4947dc197f31edea82b3fdab9dc68fdc" category="paragraph">Eine Storage Virtual Machine (SVM) ist logisch aufgebaut, um Client-Zugriff auf Systeme zu ermöglichen, auf denen die ONTAP Software ausgeführt wird. SVMs können Daten gleichzeitig über mehrere Datenzugriffsprotokolle über logische Schnittstellen (Logical Interfaces, LIFs) bereitstellen. SVMs ermöglichen den Datenzugriff auf Dateiebene über NAS-Protokolle wie CIFS und NFS sowie den Datenzugriff auf Blockebene über SAN-Protokolle wie iSCSI, FC/FCoE und NVMe. SVMs können Daten sowohl für SAN- als auch für NAS-Clients unabhängig gleichzeitig bereitstellen.</block>
  <block id="d6154a0901f9ca6bb5d8fb15c113581e" category="paragraph"><block ref="d6154a0901f9ca6bb5d8fb15c113581e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3c46d272642e0999c025f67e9de315c9" category="paragraph">Bei vSphere könnte dieser Ansatz auch für ein einheitliches System für Virtual Desktop Infrastructure (VDI) in Kombination mit einer virtuellen Serverinfrastruktur (VSI) stehen. Systeme mit ONTAP Software sind bei VSI in der Regel kostengünstiger als herkömmliche Enterprise-Arrays, bieten zugleich aber fortschrittliche Storage-Effizienzfunktionen, mit denen Sie im selben System auch VDI gerecht werden können. ONTAP vereint außerdem eine Reihe von Storage-Medien – von SSDs bis SATA – und kann diese problemlos in die Cloud erweitern. Auf diese Weise müssen Sie nicht ein Flash-Array für Performance-Zwecke, ein SATA-Array für Archive und separate Systeme für die Cloud erwerben. Sie alle sind in ONTAP integriert.</block>
  <block id="e9e0f5f2c513c7138ea70b4c929d6fef" category="inline-link">Storage-Virtualisierung</block>
  <block id="54c9439ad8fb4842a5a86c34d2401e36" category="admonition">Weitere Informationen zu SVMs, Unified Storage und Client-Zugriff finden Sie unter<block ref="2843f934dec816d79f9c394ad0533c28" category="inline-link-rx"></block> Im Dokumentationszentrum ONTAP 9.</block>
  <block id="400cc516a4a40acd605aef2cfd4ba4c0" category="doc">VMware Storage Distributed Resource Scheduler</block>
  <block id="6e210af5c49ef2b81c06b57f989ed5c6" category="paragraph">VMware Storage Distributed Resource Scheduler (SDRS) ist eine Funktion von vSphere, die VMs auf Storage basierend auf der aktuellen I/O-Latenz und der Speicherplatznutzung platziert.</block>
  <block id="e7649bfbacc438bf8e20ba3564db4bdd" category="paragraph">Danach werden die VM oder VMDKs unterbrechungsfrei zwischen den Datastores in einem Datastore-Cluster (auch Pod genannt) verschoben und es wird der beste Datastore ausgewählt, in dem die VM oder die VMDKs im Datastore-Cluster platziert werden sollen. Ein Datastore-Cluster ist eine Sammlung ähnlicher Datastores, die aus Sicht des vSphere Administrators in einer einzigen Verbrauchseinheit aggregiert werden.</block>
  <block id="5735cfd4d72f50fd28717ac30361b503" category="paragraph">Wenn Sie SDRS mit den NetApp ONTAP Tools für VMware vSphere verwenden, müssen Sie zuerst einen Datastore mit dem Plug-in erstellen, vCenter verwenden, um das Datastore-Cluster zu erstellen und dann den Datastore hinzufügen. Nach der Erstellung des Datastore-Clusters können diesem direkt aus dem Assistenten für die Datastore-Bereitstellung auf der Seite „Details“ weitere Datastores hinzugefügt werden.</block>
  <block id="b028cce2007c32457c41f20d2954c0c2" category="paragraph">Weitere ONTAP Best Practices für SDRS:</block>
  <block id="d11eff5be5178b7ba95b06270611ffc8" category="list-text">Alle Datastores im Cluster sollten denselben Storage-Typ (beispielsweise SAS, SATA oder SSD) verwenden. Zudem sollte es sich bei allen entweder um VMFS oder NFS-Datastores handeln und sie sollten dieselben Replizierungs- und Sicherungseinstellungen aufweisen.</block>
  <block id="76db7ce67615bbc16da685df79ed0aa9" category="list-text">Sie sollten SDRS eventuell im Standardmodus (manuell) verwenden. Mit diesem Ansatz können Sie die Empfehlungen prüfen und entscheiden, ob Sie sie anwenden oder nicht. Beachten Sie diese Auswirkungen von VMDK Migrationen:</block>
  <block id="97f4ed95cb52bb29629002a25cb5039f" category="list-text">Wenn VMDKs VON SDRS zwischen Datastores verschoben werden, gehen sämtliche Speicherersparnisse durch ONTAP Klone oder Deduplizierung verloren. Sie können die Deduplizierung erneut ausführen, um diese Einsparungen zurückzugewinnen.</block>
  <block id="38f492286c3edf236c76e993ce0f0bf2" category="list-text">Nachdem SDRS die VMDKs verschoben hat, empfiehlt NetApp, die Snapshots im Quell-Datastore neu zu erstellen, da der Speicherplatz andernfalls von der verschobenen VM gesperrt wird.</block>
  <block id="09a99cbc4fb85d10c7af970e79032a05" category="list-text">Die Verschiebung von VMDKs zwischen Datastores im selben Aggregat bietet nur wenige Vorteile. Zudem sind andere Workloads, die das Aggregat möglicherweise teilen, FÜR SDRS nicht sichtbar.</block>
  <block id="09b616c445ab7efa8240062532e526e4" category="doc">VMware vSphere mit ONTAP –</block>
  <block id="48e29772cebbf1133d022577e278d5c1" category="admonition">Diese Dokumentation ersetzt zuvor veröffentlichte technische Berichte _TR-4597: VMware vSphere for ONTAP_</block>
  <block id="bfa7e7fc7c6bf4cc4e4c5c74b09763eb" category="paragraph">Andere Dokumente wie Leitfäden und Kompatibilitätslisten werden durch Best Practices ergänzt. Sie werden basierend auf Labortests und umfassenden praktischen Erfahrungen der NetApp Ingenieure und Kunden entwickelt. Es handelt sich hierbei unter Umständen nicht nur um die einzigen unterstützten Praktiken, die in jeder Umgebung funktionieren. Im Allgemeinen sind sie aber die einfachsten Lösungen, die die Anforderungen der meisten Kunden erfüllen.</block>
  <block id="9ed4a475dd3705157a9fed8811f63ce2" category="inline-link">NetApp Interoperabilitäts-Matrix-Tool</block>
  <block id="e08175c6fa64cba68719dea85ebd9d34" category="inline-link">VMware Compatibility Guide</block>
  <block id="c7e9d53e7f1a53451fa25cb6340fbf6f" category="paragraph">Der Schwerpunkt dieses Dokuments liegt auf den Funktionen der neuesten Versionen von ONTAP (9.x), die unter vSphere 7.0 oder höher ausgeführt werden. Siehe<block ref="37aa2814221d042697a27bc81e148f64" category="inline-link-rx"></block> Und<block ref="e1593898142109fc8cd8025356d3f312" category="inline-link-rx"></block> Finden Sie Details zu bestimmten Versionen.</block>
  <block id="74587fa4ad90f8713c0446529a3670e0" category="section-title">Warum ONTAP für vSphere?</block>
  <block id="a110ecc6d4ce7014019c560e5fedf572" category="paragraph">Zehntausende Kunden haben sich für ONTAP als Storage-Lösung für vSphere entschieden. Dafür gibt es viele Gründe, beispielsweise ein Unified-Storage-System, das sowohl SAN- als auch NAS-Protokolle unterstützt, robuste Datensicherungsfunktionen mittels platzsparender Snapshots und eine Fülle von Tools, die Sie beim Management von Applikationsdaten unterstützen. Wenn Sie ein Storage-System getrennt vom Hypervisor verwenden, können Sie viele Funktionen verlagern und Ihre Investitionen in vSphere Host-Systeme optimal nutzen. Hierdurch wird sichergestellt, dass Ihre Host-Ressourcen schwerpunktmäßig für Applikations-Workloads verwendet werden. Darüber hinaus werden zufällige Auswirkungen auf die Performance von Applikationen aufgrund des Storage-Betriebs vermieden.</block>
  <block id="0f50acddbdbb9aa9712a471f2276e655" category="paragraph">Die Kombination von ONTAP und vSphere ermöglicht Kosteneinsparungen für Host-Hardware und VMware Software. Schützen Sie Ihre Daten außerdem zu geringeren Kosten mit konstant hoher Performance. Da virtualisierte Workloads mobil sind, können Sie mit Storage vMotion verschiedene Ansätze nutzen, um VMs auf VMFS-, NFS- oder VVols-Datastores zu verschieben. Und das alles auf ein und demselben Storage-System.</block>
  <block id="90977175b761542615a11f2b96cc4cbd" category="paragraph">Im Folgenden sind wichtige Faktoren aufgeführt, die heutzutage von Kunden wertvoll sind:</block>
  <block id="442c1f0ac31c3d71b638125e0a8b51da" category="list-text">*Unified Storage.* Systeme mit ONTAP Software sind auf mehrere signifikante Arten vereinheitlicht. Dieser Ansatz bezog sich ursprünglich auf NAS- und SAN-Protokolle. ONTAP ist dabei weiterhin eine der führenden Plattformen für SAN und bietet in Bezug auf NAS die ursprünglichen Stärken. Bei vSphere könnte dieser Ansatz auch für ein einheitliches System für Virtual Desktop Infrastructure (VDI) in Kombination mit einer virtuellen Serverinfrastruktur (VSI) stehen. Systeme mit ONTAP Software sind bei VSI in der Regel kostengünstiger als herkömmliche Enterprise-Arrays, bieten zugleich aber fortschrittliche Storage-Effizienzfunktionen, mit denen Sie im selben System auch VDI gerecht werden können. ONTAP vereint außerdem eine Reihe von Storage-Medien – von SSDs bis SATA – und kann diese problemlos in die Cloud erweitern. Auf diese Weise müssen Sie nicht ein Flash-Array für Performance-Zwecke, ein SATA-Array für Archive und separate Systeme für die Cloud erwerben. Sie alle sind in ONTAP integriert.</block>
  <block id="0ce37df1cd9b66a2abde8244f17fc051" category="list-text">*Auf virtuellen Volumes und richtlinienbasiertem Storage-Management.* NetApp war bereits früh als Designpartner von VMware an der Entwicklung von vSphere Virtual Volumes (VVols) beteiligt und stellte architekturspezifischen Input und frühzeitig Unterstützung für VVols und VMware vSphere APIs for Storage Awareness (VASA) bereit. Durch diesen Ansatz wurde nicht nur das granulare VM-Storage-Management in VMFS integriert, sondern auch die Automatisierung der Storage-Bereitstellung durch richtlinienbasiertes Management unterstützt. Storage-Architekten können mit diesem Ansatz Storage-Pools mit unterschiedlichen Funktionen entwerfen, die von VM-Administratoren einfach genutzt werden können. ONTAP ist einer der führenden Anbieter von vVol Storage-Lösungen in der Storage-Branche, da es Hunderttausende VVols in einem einzigen Cluster unterstützt. Anbieter von Enterprise-Arrays und kleineren Flash-Arrays hingegen unterstützen gerade einmal mehrere Tausend VVols pro Array. Zudem bringt NetApp mit neuen Funktionen bei der Unterstützung von VVols 3.0 die Weiterentwicklung des granularen VM-Managements voran.</block>
  <block id="9eeea06a6a7f860f801343c04af5d7d2" category="list-text">*Storage-Effizienz.* Obwohl NetApp als erster Anbieter Deduplizierung für Produktions-Workloads bereitgestellt hat, war diese Innovation weder die erste noch die letzte in diesem Bereich. Es begann mit Snapshots, einem platzsparenden Datensicherungsmechanismus ohne Auswirkungen auf die Performance, sowie mit FlexClone Technologie, bei der sofort Lese-/Schreibkopien von VMs für die Produktion und die Nutzung von Backups erstellt werden können. Danach stellte NetApp Inline-Funktionen bereit, darunter Deduplizierung, Komprimierung und Zero-Block-Deduplizierung, mit denen sich der Storage kostspieliger SSDs maximal ausschöpfen lässt. Zuletzt wurde ONTAP um die Möglichkeit erweitert, kleinere I/O-Vorgänge und Dateien durch Data-Compaction in einen Festplattenblock zu packen. Dank der Kombination dieser Funktionen verzeichnen Kunden Einsparungen im Verhältnis von bis zu 5:1 für VSI und von bis zu 30:1 für VDI.</block>
  <block id="bb73602f3344c326a7b63c94db24362a" category="list-text">*Hybrid Cloud.* ob in der Private Cloud vor Ort, in einer Public-Cloud-Infrastruktur oder in einer Hybrid Cloud, die das Beste der beiden Lösungen vereint – ONTAP Lösungen helfen Ihnen, Ihre Data Fabric zur Optimierung und zum Optimieren des Datenmanagements aufzubauen. Den Anfang machen hochperformante All-Flash-Systeme, die dann für die Datensicherung und das Cloud-Computing mit Festplatten- oder Cloud-Storage-Systemen gekoppelt werden. Zur Kostenoptimierung und Vermeidung einer Anbieterbindung stehen hierbei Azure, AWS, IBM oder Google Clouds zur Auswahl. Bei Bedarf kann die erweiterte Unterstützung für OpenStack und Containertechnologien genutzt werden. NetApp bietet darüber hinaus Cloud-basiertes Tiering und Archivierungstools (SnapMirror Cloud, Cloud Backup Service und Cloud Sync) sowie Storage-Systeme (FabricPool) für ONTAP, um die Betriebskosten zu senken und die große Reichweite der Cloud auszuschöpfen.</block>
  <block id="7a61ec7965eebc0b5486cb78f096c770" category="list-text">* Und mehr.* Nutzen Sie die extreme Performance von NetApp AFF A-Series Arrays, um Ihre virtualisierte Infrastruktur zu beschleunigen und gleichzeitig die Kosten im Griff zu haben. Mit horizontal skalierbaren ONTAP Clustern profitieren Sie bei der Wartung, bei Upgrades und selbst beim kompletten Ersatz Ihres Storage-Systems von einem durchgängig unterbrechungsfreien Betrieb. Daten im Ruhezustand werden mit NetApp Verschlüsselungsfunktionen ohne zusätzliche Kosten geschützt. Durch fein abgestimmte Quality-of-Service- Funktionen stellen Sie sicher, dass die Performance den geschäftlichen Service-Levels entspricht. Sie alle sind Bestandteil des umfangreichen Funktionsbereichs, das in ONTAP, der branchenführenden Software für das Enterprise-Datenmanagement, enthalten ist.</block>
  <block id="6104c8ef7be4222a76596ab6a22bb422" category="doc">Empfohlene ESXi Host-Einstellungen und andere ONTAP Einstellungen</block>
  <block id="0416d04b345b434b120840c30ddaf0a1" category="paragraph">NetApp hat für ESXi Hosts einen Satz von Einstellungen für Multipathing und HBA-Zeitüberschreitungen entwickelt, um auf der Grundlage eigener Tests für das richtige Verhalten bei ONTAP zu sorgen. Diese Einstellungen lassen sich mit ONTAP Tools für VMware vSphere problemlos konfigurieren. Klicken Sie im Übersichtskonsole im Portlet „Host-Systeme“ auf „Einstellungen bearbeiten“ oder klicken Sie in vCenter mit der rechten Maustaste auf den Host und navigieren Sie zu „ONTAP-Tools“ &gt; „Empfohlene Werte festlegen“. Im Folgenden sind die derzeit empfohlenen Hosteinstellungen für die Version 9.8 angegeben.</block>
  <block id="678582eb0cbbe0e063e618d230b63223" category="cell">*Hosteinstellung*</block>
  <block id="dfe49b73bd7e747701b49f9ed21ea2d6" category="cell">*Von NetApp empfohlener Wert*</block>
  <block id="edceae57d92287f4f6200f94d3259cd0" category="cell">*Neustart Erforderlich*</block>
  <block id="dc3a6955a23583876d020db0f6b80d4d" category="cell">*ESXi Advanced Configuration*</block>
  <block id="73663d0d00956f0632e4ae75d811d53f" category="cell">VMFS3.HardwareAcceleratLocking</block>
  <block id="59b1aceaef0203fdc32e11df232b16e6" category="cell">Standard beibehalten (1)</block>
  <block id="bafd7322c6e97d25b6299b5d6fe8920b" category="cell">Nein</block>
  <block id="1b50110aedae4d8d2043a4eb9beb20af" category="cell">VMFS3.EnableBlockDelete</block>
  <block id="5d1b81f1885499e392018ebd7124ad37" category="inline-link-macro">VMware KB 2007427</block>
  <block id="3aca64366573d9850e0148ce2a38164c" category="cell">Behalten Sie die Standardeinstellung (0) bei, können sie jedoch bei Bedarf geändert werden.
Weitere Informationen finden Sie unter <block ref="68c2cf0ecb6a1c6abaf6e56c035d5866" category="inline-link-macro-rx"></block></block>
  <block id="316084648bbafe451240702bd19c6ee9" category="cell">VMFS3.EnableVMFS6Entmappen</block>
  <block id="befd90cd01403237f6fdf296822efbee" category="inline-link-macro">VMware vSphere APIs – Array-Integration (VAAI)</block>
  <block id="e385d2442208cc1e23ca841b1f217380" category="cell">Standard beibehalten (1)
Weitere Informationen finden Sie unter <block ref="d124e203790e5f214a195f69cd068c6d" category="inline-link-macro-rx"></block></block>
  <block id="571cc1d48c6d1ff3cf7e3a54cb035753" category="cell">*NFS-Einstellungen*</block>
  <block id="c3b49a515dd0046685e06092642aa139" category="cell">NET.TcpipHeapSize</block>
  <block id="875f6b98e20edfecb56f9013d00987f6" category="cell">VSphere 6.0 oder höher: Auf 32 einstellen.
Alle anderen NFS-Konfigurationen: Auf 30 einstellen</block>
  <block id="93cba07454f06a4a960172bbd6e2a435" category="cell">Ja.</block>
  <block id="504e96cc79e7efe30a8271cea152d9d1" category="cell">NET.TcpipHeapMax</block>
  <block id="a8af33a99dd728969fd947da27a2f69f" category="cell">Sind die meisten vSphere 6.X Versionen auf 512 MB eingestellt.
Stellen Sie auf 1024 MB für 6.5U3, 6.7U3 und 7.0 oder höher ein.</block>
  <block id="5f1e7b6431061565550e292d05c73588" category="cell">MaxVolumes: NFS</block>
  <block id="e787d5b0d643685421632a1af3914963" category="cell">VSphere 6.0 oder höher: Auf 256 einstellen
Alle anderen NFS-Konfigurationen: Auf 64 einstellen.</block>
  <block id="3058676a1cf088aa4a73312ac36f2a58" category="cell">NFS41.MaxVolumes</block>
  <block id="62c07f94c64184ee5d530e4c0917093f" category="cell">VSphere 6.0 oder höher: Auf 256 einstellen.</block>
  <block id="e18600af98c17fae10fdba0dc89979ed" category="cell">NFS.MaxQueueDepth^1^</block>
  <block id="be7707fa525d0124489c9fe3072f78de" category="cell">VSphere 6.0 oder höher: Auf 128 einstellen</block>
  <block id="18e1fb6924459470760771b20ab0c379" category="cell">NFS.HeartbeatMaxFailures</block>
  <block id="138989cbe5dd3a4997662e0f65c17878" category="cell">Alle NFS-Konfigurationen: Auf 10 einstellen</block>
  <block id="1aa26eb281359ba3b9a9a4b83a09ed46" category="cell">HeartbeatFrequency NFS.HeartbeatFrequency</block>
  <block id="7ea6e8664542e3beb1aea10425efb4db" category="cell">Alle NFS-Konfigurationen: Auf 12 einstellen</block>
  <block id="eb4182715f8cde98563dc59ea36461d3" category="cell">HeartbeatTimeout NFS.HeartbeatTimeout</block>
  <block id="45aa5481fa55802a29a96aefd2f5dab1" category="cell">Alle NFS-Konfigurationen: Auf 5 einstellen.</block>
  <block id="54a08b15243d9078d3b5a47f8242da6f" category="cell">SunRPC.MaxConnPerIP</block>
  <block id="9a9ccbecb3f315797ff8e709d85a0e18" category="cell">VSphere 7.0 oder höher: Auf 128 einstellen.</block>
  <block id="c0b3fd5512c2093847f753f398290f30" category="cell">*FC/FCoE-Einstellungen*</block>
  <block id="2e556ad678160413b32dcca55c7d1f5f" category="cell">Pfadauswahl-Richtlinie</block>
  <block id="fb62337a3ef32f4701b639339a4ceb33" category="cell">Wenn FC-Pfade mit ALUA verwendet werden: Auf RR (Round Robin) einstellen. Alle anderen Konfigurationen: Auf FIXED einstellen.
Wenn Sie diesen Wert auf RR einstellen, ist für alle aktiven/optimierten Pfade ein besserer Lastausgleich möglich.
Der Wert FIXED wird für ältere Konfigurationen ohne ALUA verwendet und verhindert Proxy-I/O-Vorgänge Er trägt also dazu bei, dass I/O-Vorgänge bei einem HA-Paar in einer Umgebung, in der Data ONTAP im 7-Mode ausgeführt wird, nicht auf den anderen Node verlagert werden</block>
  <block id="117704664d6cada78ac3107380f63d23" category="cell">Disk.QFullSampleSize</block>
  <block id="0e82e1f81de2159b0e9bee0b7be00dc9" category="cell">Alle Konfigurationen: Auf 32 einstellen.
Durch die Festlegung dieses Wertes werden I/O-Fehler verhindert.</block>
  <block id="f66a3c183f0e736240b77f8b755c880e" category="cell">Disk.QFullThreshold</block>
  <block id="bdd8c1d08eabb5e1923ed8f0c4b10ba4" category="cell">Alle Konfigurationen: Auf 8 einstellen.
Durch die Festlegung dieses Wertes werden I/O-Fehler verhindert.</block>
  <block id="19c08de7404551288e1274186e039ef4" category="cell">Emulex FC-HBA-Zeitüberschreitungen</block>
  <block id="b4dbfc2d52627e923cbb563a31ff756d" category="cell">Standardwert verwenden.</block>
  <block id="d46cddda4da7ec11f17472d11df95b68" category="cell">QLogic FC-HBA-Zeitüberschreitungen</block>
  <block id="19b5aaf3e2cb86809996ca63a2a416b0" category="cell">*ISCSI-Einstellungen*</block>
  <block id="2aa077454308383f1e82025427cd7362" category="cell">Alle iSCSI-Pfade: Auf RR (Round Robin) einstellen.
Wenn Sie diesen Wert auf RR einstellen, ist für alle aktiven/optimierten Pfade ein besserer Lastausgleich möglich.</block>
  <block id="0340eb1bcbfc6cd3c62b8a878d8d643b" category="cell">Alle Konfigurationen: Auf 32 einstellen.
Durch die Festlegung dieses Wertes werden I/O-Fehler verhindert</block>
  <block id="891c10448731ad57490b9a932dabfff8" category="inline-link-macro">VMware KB 86331</block>
  <block id="2c572e3c397fe100b075a09359c9cc23" category="admonition">1 - die erweiterte NFS-Konfigurationsoption MaxQueueDepth funktioniert möglicherweise nicht wie vorgesehen bei der Verwendung von VMware vSphere ESXi 7.0.1 und VMware vSphere ESXi 7.0. Bitte referenzieren <block ref="861055760f3cd527823fd34a49459992" category="inline-link-macro-rx"></block> Finden Sie weitere Informationen.</block>
  <block id="fb55ee99c04280ac638757869929785d" category="paragraph">ONTAP-Tools legen beim Erstellen von ONTAP FlexVol Volumes und LUNs bestimmte Standardeinstellungen fest:</block>
  <block id="3f7502a5f109d7a73706aba1c0741a4b" category="cell">*ONTAP-Tool*</block>
  <block id="485577e97e8efcd504fc8e8b13e613f1" category="cell">*Standardeinstellung*</block>
  <block id="5938fe448c8661febcef3f4e779e3adb" category="cell">Snapshot-Reserve (-percent-Snapshot-space)</block>
  <block id="cfcd208495d565ef66e7dff9f98764da" category="cell">0</block>
  <block id="7218aec62575561a6de1cae8d5658390" category="cell">Fraktionale Reserve (-fractional-Reserve)</block>
  <block id="3a7e09ff0fa38663ffe6d91324ea75d9" category="cell">Aktualisierung der Zugriffszeit (-atime-Update)</block>
  <block id="f8320b26d30ab433c5a54546d21f414c" category="cell">Falsch</block>
  <block id="e93200d5b0d16915bf04236790544b2f" category="cell">Minimales Vorauslesen (-min-readahead)</block>
  <block id="c877d89702fdd14e51b02028a20c7d07" category="cell">Geplante Snapshots</block>
  <block id="fd18465573ec21a6218982055981f6b1" category="cell">Storage-Effizienz</block>
  <block id="00d23a76e43b46dae9ec7aa9dcbebb32" category="cell">Aktiviert</block>
  <block id="f65fd63b63c9e9f25bf6bc141e83de34" category="cell">Volume-Garantie</block>
  <block id="c2410aebdf425dabcc65e546e506b03e" category="cell">Keine (Thin Provisioning)</block>
  <block id="f97c03bf3e9580446d70d479f5aad1e0" category="cell">Automatische Volumengröße</block>
  <block id="d89f4f8b1d7c18847b88b46142f61535" category="cell">Vergrößern_verkleinern</block>
  <block id="ace72ec54e17777d27eb8bdb9d57e782" category="cell">LUN-Speicherplatzreservierung</block>
  <block id="b9f5c797ebbf55adccdd8539a65a0241" category="cell">Deaktiviert</block>
  <block id="514aa7792a71ab4ab677eb2385131aae" category="cell">Zuweisung von LUN-Speicherplatz</block>
  <block id="dbe1e98b00264bd496095ed5c95f9350" category="section-title">Multipath-Einstellungen für die Performance</block>
  <block id="de9f44b08eec22d6b405acff2c925d56" category="paragraph">Obwohl NetApp derzeit nicht durch verfügbare ONTAP-Tools konfiguriert ist, empfiehlt es folgende Konfigurationsoptionen:</block>
  <block id="840731ae1cb9e4b23e19f645ab018b6f" category="inline-link">2069356</block>
  <block id="5073fc9da327263a7db04fd449991e6a" category="list-text">In hochperformanten Umgebungen oder bei Tests der Performance mit einem einzelnen LUN-Datastore sollte die Einstellung der Lastverteilung für die Round-Robin (VMW_PSP_RR) Path Selection Policy (PSP) von der standardmäßigen IOPS-Einstellung 1000 auf einen Wert 1 geändert werden. Siehe VMware KB<block ref="f3f4762788a6845119bdb5b9c9179bda" category="inline-link-rx"></block> Finden Sie weitere Informationen.</block>
  <block id="1ea3eb55b985cf75e100607ee8bd935d" category="inline-link">Pfadauswahl-Plug-ins und -Richtlinien</block>
  <block id="249afbf456bd04d574e8d362d5bf133c" category="list-text">In vSphere 6.7 Update 1 hat VMware einen neuen Lastausgleichsmechanismus für das Round Robin PSP System eingeführt. Bei der Auswahl des optimalen Pfads für I/O berücksichtigt die neue Option die I/O-Bandbreite und die Pfadlatenz Möglicherweise profitieren Sie von der Verwendung in Umgebungen mit nicht äquivalenter Pfadkonnektivität. So können Sie beispielsweise mehr Netzwerk-Hops auf einem Pfad als auf einem anderen verwenden oder ein NetApp All SAN Array System nutzen. Siehe<block ref="f5ecc69f2970e2e9c8638ad278ec38f7" category="inline-link-rx"></block> Finden Sie weitere Informationen.</block>
  <block id="01d954fb2edbf283d121f0651b04de83" category="section-title">Zusätzliche Dokumentation</block>
  <block id="40db5019ed68654f4eb2cf21ec5021db" category="inline-link">Verwenden Sie VMware vSphere 7.x mit ONTAP</block>
  <block id="30d85838b9488ee908d075559c8978cd" category="inline-link">Verwenden Sie VMware vSphere 8.x mit ONTAP</block>
  <block id="000c9205416c1ea85f6841a7ca379c17" category="inline-link">Für NVMe-of finden Sie weitere Details unter NVMe-of Host Configuration for ESXi 7.x with ONTAP</block>
  <block id="5a27e6dbe6279e323aec51d205b2b455" category="inline-link">Für NVMe-of finden Sie weitere Details unter NVMe-of Host Configuration for ESXi 8.x with ONTAP</block>
  <block id="842acd8b4932f6c9329df8e0fefe8b9b" category="paragraph">Für FCP und iSCSI mit vSphere 7 finden Sie weitere Details unter<block ref="f3eae508de4d3c1748a9c65337197b21" category="inline-link-rx"></block>
Für FCP und iSCSI mit vSphere 8 finden Sie weitere Details unter<block ref="3f8db75ee0177b85df9cdf31ddb51abe" category="inline-link-rx"></block>
Für NVMe-of mit vSphere 7 finden Sie weitere Informationen unter<block ref="6c040a6e611e78bb9d0ad92946e613ea" category="inline-link-rx"></block>
Für NVMe-of mit vSphere 8 finden Sie weitere Informationen unter<block ref="030788e4c7bbe3137759b534ea62d7d9" category="inline-link-rx"></block></block>
  <block id="99a66df20e19a8e18fae37a7f714750a" category="doc">Klonen von VMs und Datastores</block>
  <block id="2438f6a80b933cf058ad052d26ac0703" category="paragraph">Durch das Klonen eines Storage-Objekts können Sie schnell Kopien für andere Zwecke erstellen, beispielsweise zum Provisionieren weiterer VMs, für Backup- und Recovery-Vorgänge usw.</block>
  <block id="fe12a277656562082ad50b980c227a84" category="paragraph">In vSphere können Sie VMs, virtuelle Festplatten, vVol oder Datastores klonen. Nach dem Klonen kann das betreffende Objekt weiter angepasst werden. Dies geschieht häufig durch einen automatisierten Prozess. VSphere unterstützt sowohl vollständige Klone als auch Linked Clones, bei denen Änderungen separat vom ursprünglichen Objekt verfolgt werden.</block>
  <block id="883a97a36ab0c59ec785b03161a1cc32" category="paragraph">Linked Clones eignen sich sehr gut, um Speicherplatz zu sparen, aber sie erhöhen die Menge der I/O-Vorgänge, die vSphere für die VM verarbeitet. Dies wirkt sich auf die Performance der betreffenden VM und vielleicht auch des gesamten Hosts aus. Aus diesem Grund nutzen NetApp Kunden häufig Klone, die auf Storage-Systemen basieren, um das Beste aus beiden Welten zu erhalten: Effiziente Storage-Nutzung und höhere Performance.</block>
  <block id="17e1a153b5d05c5a642c93ba9ce3c6de" category="paragraph">In der folgenden Abbildung ist das Klonen von ONTAP dargestellt.</block>
  <block id="8ee3cd3dba25fb32f1bc38cb528ac998" category="paragraph"><block ref="8ee3cd3dba25fb32f1bc38cb528ac998" category="inline-image-macro-rx" type="image"></block></block>
  <block id="76ee7355875ad5e9f56186ff7da961f6" category="paragraph">Das Klonen kann – in der Regel auf VM-, vVol oder Datastore-Ebene – durch mehrere Verfahren auf Systeme mit ONTAP Software verlagert werden. Hierzu zählen:</block>
  <block id="d957242cd67db8ffccec78d93c14449d" category="list-text">VVols, die den NetApp vSphere APIs for Storage Awareness (VASA) Provider verwenden.  ONTAP Klone unterstützen von vCenter gemanagte vVol Snapshots, die platzsparend sind und bei der Erstellung und Löschung eine minimale I/O-Auswirkung haben.  VMs können auch mit vCenter geklont werden. Sie werden dann auch zu ONTAP verlagert, sei es innerhalb eines einzelnen Datastores/Volumes oder zwischen Datastores/Volumes.</block>
  <block id="059e5a6b7f963e9876ba0129dc1b667d" category="list-text">VSphere Klone und Migration mit vSphere APIs – Array Integration (VAAI). VM-Klonvorgänge können in SAN- und NAS-Umgebungen zu ONTAP verlagert werden (NetApp stellt ein ESXi Plug-in zur Aktivierung von VAAI für NFS bereit).  VSphere verlagert den Betrieb nur auf „kalte“ (ausgeschalteten) VMs in einem NAS-Datastore, während Vorgänge auf heißen VMs (Klonen und Storage vMotion) ebenfalls für SAN verlagert werden. ONTAP nutzt je nach Quelle, Ziel und installierten Produktlizenzen den effizientesten Ansatz. Diese Funktion wird auch von VMware Horizon View unterstützt.</block>
  <block id="a603c207c7b5801942ff108502676c12" category="list-text">SRA (wird mit VMware Site Recovery Manager verwendet). Hier werden Klone zum unterbrechungsfreien Testen der Recovery des DR-Replikats herangezogen.</block>
  <block id="bb300d356d258c084dbe5da2ca367e08" category="list-text">Backup und Recovery mit NetApp Tools wie SnapCenter. Mit VM-Klonen werden Backup-Vorgänge sichergestellt. Darüber hinaus können VM-Backups gemountet werden, so dass einzelne Dateien kopiert / zurückgesichert werden können.</block>
  <block id="524b5b8bc03312baeafbea86df667c4b" category="paragraph">Verlagerte ONTAP Klone können durch VMware, NetApp und Drittanbietertools aufgerufen werden. Zu ONTAP verlagerte Klone haben mehrere Vorteile. Sie sind in den meisten Fällen platzsparend, da sie nur für Änderungen am Objekt Storage benötigen. Es entstehen keine zusätzlichen Performance-Einbußen, wenn sie gelesen und geschrieben werden, und in einigen Fällen wird die Performance durch die Freigabe von Blöcken in High-Speed-Caches erhöht. Zudem verlagern sie CPU-Zyklen und Netzwerk-I/O-Vorgänge vom ESXi Server. Die Verlagerung von Kopien in einen herkömmlichen Datastore, bei dem ein FlexVol Volume verwendet wird, kann mit einer Lizenzierung von FlexClone schnell und effizient sein. Kopien zwischen FlexVol Volumes sind jedoch unter Umständen langsamer. Wenn Sie VM-Vorlagen als Klonquelle bereithalten, sollten Sie sie in Betracht ziehen, sie im Datastore-Volume zu platzieren (Ordner oder Inhaltsbibliotheken zur Organisation dieser Klone einsetzen), um schnelle, platzsparende Klone zu erstellen.</block>
  <block id="f3968368501d882b3969da59138db6e2" category="paragraph">Zum Klonen eines Datastores können Sie ein Volume oder eine LUN auch direkt in ONTAP klonen. Mithilfe der FlexClone Technologie kann bei NFS-Datastores ein gesamtes Volume geklont und der Klon anschließend aus ONTAP exportiert und von ESXi als weiterer Datastore gemountet werden. Bei VMFS Datastores kann in ONTAP eine LUN innerhalb eines Volumes oder das gesamte Volume (einschließlich einer oder mehrerer darin enthaltener LUNs) geklont werden. Eine LUN, die ein VMFS enthält, muss einer ESXi Initiatorgruppe zugeordnet und dann von ESXi neu signiert werden, damit sie gemountet und als regulärer Datastore verwendet werden kann. Ein geklontes VMFS kann für einige temporäre Anwendungsfällte ohne erneute Signatur gemountet werden. Nachdem ein Datastore geklont wurde, können die darin enthaltenen VMs registriert, neu konfiguriert und angepasst werden, als wären sie einzeln geklonte VMs.</block>
  <block id="2d506b6088a383ccf08479b0f80c0ff4" category="paragraph">In einigen Fällen kann das Klonen durch zusätzliche lizenzierte Funktionen wie SnapRestore für Backups oder FlexClone optimiert werden. Diese Lizenzen sind oft in Lizenz-Bundles ohne zusätzliche Kosten enthalten. Für vVol Klonvorgänge und zur Unterstützung gemanagter Snapshots eines vVol (die vom Hypervisor zu ONTAP verlagert werden) ist eine FlexClone Lizenz erforderlich. Durch eine FlexClone Lizenz können auch bestimmte VAAI basierte Klone optimiert werden, wenn sie in einem Datastore/Volume verwendet werden. Dabei werden sofortige platzsparende Kopien anstelle von Blockkopien erstellt.  Sie wird zudem von SRA beim Testen der Recovery eines DR-Replikats sowie von SnapCenter für Klonvorgänge und zum Durchsuchen von Backup-Kopien zum Wiederherstellen einzelner Dateien genutzt.</block>
  <block id="5dd57c2a315d3af44c2eb40eefc47111" category="doc">Netzwerkkonfiguration</block>
  <block id="2b6203f34def274ff7424bf1d64a9bca" category="paragraph">Wenn Sie vSphere mit Systemen mit ONTAP Software verwenden, ist die Konfiguration von Netzwerkeinstellungen einfach und erfolgt ähnlich wie andere Netzwerkkonfigurationen.</block>
  <block id="66507f357c74ee12194270cfe053b98d" category="paragraph">Folgende Punkte sind dabei zu berücksichtigen:</block>
  <block id="b3752ab8dec37db2e30f4bf37fbdc112" category="list-text">Separater Storage-Netzwerk-Traffic aus anderen Netzwerken. Ein separates Netzwerk kann mithilfe eines dedizierten VLANs oder separater Switches für Storage eingerichtet werden. Falls im Storage-Netzwerk physische Pfade wie Uplinks geteilt werden, sind eventuell QoS oder zusätzliche Uplink-Ports erforderlich, um eine ausreichende Bandbreite sicherzustellen. Stellen Sie keine direkte Verbindung zwischen Hosts und Storage her. Verwenden Sie Switches, um redundante Pfade zu verwenden und VMware HA ohne Eingriff von Microsoft HA zu arbeiten.</block>
  <block id="7c4904daaa282388097ad83bf382e1a5" category="list-text">Jumbo Frames können genutzt werden, sofern dies gewünscht ist und von Ihrem Netzwerk unterstützt wird, insbesondere bei Verwendung von iSCSI. Vergewissern Sie sich bei ihrem Einsatz, dass sie auf allen Netzwerkgeräten, VLANs etc. Im Pfad zwischen Storage und dem ESXi Host gleich konfiguriert sind. Anderenfalls kann es zu Performance- oder Verbindungsproblemen kommen. Auf dem virtuellen ESXi Switch, dem VMkernel Port, sowie den physischen Ports oder den Interface Groups muss für jeden ONTAP Node auch jeweils dieselbe MTU festgelegt sein.</block>
  <block id="8b6e7f43d1d697e8f99164f0aa2ab1b6" category="inline-link">TR-4182</block>
  <block id="3745abd352adaa2cdec42c798060eef6" category="list-text">NetApp empfiehlt eine Deaktivierung der Netzwerk- Flusssteuerung nur an den Cluster-Netzwerkports innerhalb eines ONTAP Clusters. Für die übrigen Netzwerkports, die für Daten-Traffic verwendet werden, gibt NetApp im Hinblick auf Best Practices keine weiteren Empfehlungen. Diese Ports sollten Sie nach Bedarf aktivieren oder deaktivieren. Siehe<block ref="bdfb81665a0ef86d871a52c0e6ebc591" category="inline-link-rx"></block> Für mehr Hintergrund zur Flusssteuerung.</block>
  <block id="730a8287f758961d602b1b050bbe2751" category="list-text">Wenn ESXi und ONTAP Storage-Arrays mit Ethernet-Storage-Netzwerken verbunden werden, empfiehlt NetApp, die Ethernet-Ports, mit denen diese Systeme verbunden werden, mit der Cisco PortFast Funktion oder als Rapid Spanning Tree Protocol (RSTP)-Edge-Ports zu konfigurieren. NetApp empfiehlt die Aktivierung der Spanning Tree PortFast Trunk-Funktion in Umgebungen mit Verwendung der Cisco PortFast Funktion und 802.1Q VLAN-Trunking entweder für den ESXi Server oder für die ONTAP Storage-Arrays.</block>
  <block id="ac4976538e1fc8726f77afc202561afc" category="list-text">Für die Link-Aggregation empfiehlt NetApp die folgenden Best Practices:</block>
  <block id="301c77ecc6cdfa6ebde6c8164cffae0c" category="list-text">Verwenden Sie Switches, die die Link-Aggregation von Ports in zwei separaten Switch-Chassis durch einen Ansatz mit einer Multi-Chassis-Link-Aggregationsgruppe wie Virtual PortChannel (vPC) von Cisco unterstützen.</block>
  <block id="19d137845c7f6687c99b386dfad0aa97" category="list-text">Deaktivieren Sie LACP für mit ESXi verbundene Switch Ports, es sei denn, Sie verwenden dvSwitches ab 5.1 mit konfiguriertem LACP.</block>
  <block id="30254a2bb3e4b3b958b06d08c724e7db" category="list-text">Erstellen Sie mit LACP Link-Aggregate für ONTAP Storage-Systeme mit dynamischen Multimode-Schnittstellengruppen mit IP-Hash.</block>
  <block id="d608421cceb8e4c584a2a32d9127879e" category="list-text">Verwenden Sie eine IP-Hash-Teaming-Richtlinie für ESXi.</block>
  <block id="2432030fc6183a1a6c52cf5e93f3e9ae" category="paragraph">Die folgende Tabelle enthält eine Zusammenfassung der Netzwerkkonfigurationselemente sowie Angaben dazu, wo die Einstellungen angewendet werden.</block>
  <block id="7d74f3b92b19da5e606d737d339a9679" category="cell">Element</block>
  <block id="1aa66ef3a8e34a7a538960a80d2e1e31" category="cell">ESXi</block>
  <block id="bbc155fb2b111bf61c4f5ff892915e6b" category="cell">Switch</block>
  <block id="6c3a6944a808a7c0bbb6788dbec54a9f" category="cell">Knoten</block>
  <block id="0b7e67b6cdcf0432b624d53588d520fb" category="cell">SVM</block>
  <block id="75ba8d70e3692ba200f0e0df37b4d2ae" category="cell">IP-Adresse</block>
  <block id="ee6c0f25c2881cc69947a2ef23be5b8c" category="cell">VMkernel</block>
  <block id="e11f298a5bd5344d2d975b5157c27b69" category="cell">Nein**</block>
  <block id="d6f0876f76c273b8962b749c36153157" category="cell">Link-Aggregation</block>
  <block id="fabd320b3b2249377e53e93099e27657" category="cell">Virtueller Switch</block>
  <block id="b1b40427c8eb8d0a083ddb16e250325b" category="cell">Nein*</block>
  <block id="9881f82f0dd89588831f9d1682bd5492" category="cell">VLAN</block>
  <block id="5fc0d231160fa9650ea5c877f146bbe6" category="cell">VMkernel und VM-Portgruppen</block>
  <block id="39a3e05f380e583ae2887c79c7443f11" category="cell">Flusskontrolle</block>
  <block id="220071ab44b426f80ef21f1c552c363c" category="cell">NIC</block>
  <block id="6f2c08412f489e52a17a30217f50b3c1" category="cell">Spanning Tree</block>
  <block id="4b1c0df98ba3f3d1681c3c3dbdc97746" category="cell">MTU (für Jumbo Frames)</block>
  <block id="7d6feaf896df4a937157d4ee5b91f4e1" category="cell">Virtueller Switch und VMkernel Port (9000)</block>
  <block id="0110e50bd8629573701e73a4ba8b056f" category="cell">Ja (auf Maximalwert eingestellt)</block>
  <block id="061ff5255adf00e4ae68469f43a7bf55" category="cell">Ja (9000)</block>
  <block id="bcc0e5a3e08cd34e80692195d056b06d" category="cell">Failover-Gruppen</block>
  <block id="a4d1a66a448e327c12d3e287098a31d5" category="cell">Ja (erstellen)</block>
  <block id="465d5674eb6808b997037470f4dace73" category="cell">Ja (auswählen)</block>
  <block id="ba78d695573c8d4f1205452c675fa539" category="paragraph">*SVM-LIFs werden mit Ports, Schnittstellengruppen oder VLAN-Schnittstellen verbunden, die über VLAN-, MTU- und andere Einstellungen verfügen. Diese Einstellungen werden jedoch nicht auf SVM-Ebene gemanagt.</block>
  <block id="50ecdab93bf5a2f1bfb4cd8f81b9bd3d" category="paragraph">**Diese Geräte haben eigene IP-Adressen für das Management, aber diese Adressen werden nicht im Zusammenhang mit ESXi Storage Networking verwendet.</block>
  <block id="efd0bde36323238fec688b9cdf0c75a3" category="section-title">SAN (FC, FCoE, NVMe/FC, iSCSI), RDM</block>
  <block id="29cdd488736a6111699f7348320bbed7" category="paragraph">Mit vSphere gibt es drei Methoden, blockbasierten Speicher zu nutzen:</block>
  <block id="8982d243303f9d1a8c2470b7d55278e6" category="list-text">Mit VMFS Datastores</block>
  <block id="9a0098c8c1be287e8d1da1aaf3bd2e59" category="list-text">Mit Raw Device Mapping (RDM)</block>
  <block id="93e209176746ac6f25c618631a02643b" category="list-text">Auf diese LUN wird von einem Software-Initiator aus einem VM-Gastbetriebssystem zugegriffen und gesteuert</block>
  <block id="c25dc676ca39a05ee6067ac9a50dbce0" category="paragraph">VMFS ist ein hochperformantes geclustertes Filesystem, das Datastores bereitstellt, bei denen es sich um Shared-Storage-Pools handelt. VMFS Datastores können mit LUNs konfiguriert werden, auf die über FC, iSCSI, FCoE oder NVMe Namespaces zugegriffen wird, auf die das NVMe/FC-Protokoll zugegriffen wird. Bei VMFS können alle ESX Server in einem Cluster gleichzeitig auf herkömmliche LUNs zugreifen. Die maximale LUN-Größe beträgt bei ONTAP im Allgemeinen 16 TB; daher wird ein VMFS 5 Datastore mit einer maximalen Größe von 64 TB (siehe erste Tabelle in diesem Abschnitt) aus vier 16-TB-LUNs erstellt (alle SAN-Array-Systeme unterstützen die maximale VMFS-LUN-Größe von 64 TB). Da die ONTAP LUN-Architektur keine kleinen individuellen „Queue Depths“ aufweist, sind VMFS Datastores in ONTAP relativ problemlos in einem höheren Maße skalierbar gegenüber herkömmlichen Array-Architekturen.</block>
  <block id="43f67f108e50dab0978a343603cbfec9" category="paragraph">VSphere umfasst integrierte Unterstützung für mehrere Pfade zu Storage-Geräten. Dieses Verfahren wird als natives Multipathing (NMP) bezeichnet. NMP kann den Storage-Typ für unterstützte Storage-Systeme erkennen und den NMP-Stack automatisch so konfigurieren, dass die Funktionen des verwendeten Storage-Systems unterstützt werden.</block>
  <block id="6bf646772584de04f877d166e564b5ff" category="paragraph">Sowohl NMP als auch NetApp ONTAP unterstützen Asymmetric Logical Unit Access (ALUA) zur Ermittlung optimierter und nicht optimierter Pfade. In ONTAP folgt ein ALUA-optimierter Pfad auf einen direkten Datenpfad. Dabei wird ein Zielport auf dem Node verwendet, der die LUN hostet, auf die zugegriffen wird. ALUA ist sowohl in vSphere als auch in ONTAP standardmäßig aktiviert. NMP erkennt das ONTAP Cluster als ALUA-fähig und verwendet ein ALUA Storage-Array-Plug-in <block ref="d4f7bd3bf4872a2f8cd0cbe400fb23d0" prefix="(" category="inline-code"></block>) Und wählt das Plug-in zur Auswahl des Round-Robin-Pfads aus <block ref="4646bb781f9a95f64c182af129e43c7c" prefix="(" category="inline-code"></block>).</block>
  <block id="b284ee628d89c3e804c4def2a90f0520" category="paragraph">ESXi 6 unterstützt bis zu 256 LUNs und insgesamt bis zu 1,024 Pfade zu LUNs. Alle über diese Grenzen hinausgehenden LUNs oder Pfade werden von ESXi nicht erkannt. Ausgehend von dieser maximalen Anzahl an LUNs lässt das Pfadlimit vier Pfade pro LUN zu. In einem größeren ONTAP Cluster ist es möglich, dass das Pfadlimit vor dem LUN-Limit erreicht wird. Zur Beseitigung dieser Beschränkung unterstützt ONTAP ab Version 8.3 die selektive LUN-Zuordnung (Selective LUN Map, SLM).</block>
  <block id="8466b1e5abb4751e931c5feb1af4e469" category="inline-link">TR-4080</block>
  <block id="e9e7de5d01d51034d9114fd8f16c9144" category="paragraph">SLM beschränkt die Nodes, die Pfade an eine bestimmte LUN weitergeben. Eine Best Practice von NetApp sieht mindestens eine logische Schnittstelle (Logical Interface, LIF) pro Node pro SVM und die Verwendung von SLM vor, um die Pfade zu begrenzen, die an den Node weitergegeben werden, der die LUN und deren HA-Partner hostet. Es sind zwar noch andere Pfade vorhanden, doch werden diese standardmäßig nicht weitergegeben. Die weitergegebenen Pfade können mit den Node-Argumenten zum Hinzufügen oder Entfernen der Berichterstellung in SLM geändert werden. Beachten Sie, dass in Versionen vor 8.3 erstellte LUNs alle Pfade weitergeben. Sie müssen geändert werden, damit nur die Pfade zum Hosting-HA-Paar weitergegeben werden. Weitere Informationen zu SLM finden Sie im Abschnitt 5.9 von<block ref="c6b12416d518b4689065ffe16afe88db" category="inline-link-rx"></block>. Um die für eine LUN verfügbaren Pfade weiter zu reduzieren, kann auch die frühere Portsatzmethode verwendet werden. Portsätze tragen dazu bei, die Anzahl der sichtbaren Pfade zu verringern, durch die Initiatoren in einer Initiatorgruppe LUNs ausfindig machen können.</block>
  <block id="4157f0c23fc104508f492dc846f187f3" category="list-text">SLM ist standardmäßig aktiviert. Sofern Sie keine Portsätze verwenden, ist keine weitere Konfiguration erforderlich.</block>
  <block id="597f1433ad810b3b86c7ae0f8f95afa8" category="list-text">Für LUNs, die vor Data ONTAP 8.3 erstellt wurden, wenden Sie SLM manuell an, indem Sie die ausführen<block ref="886fd385b633a0746a8a08f8f00c67cd" prefix=" " category="inline-code"></block> Befehl, um die LUN-Nodes für die Berichterstellung zu entfernen und den LUN-Zugriff auf den LUN-Eigentümer-Node und seinen HA-Partner zu beschränken.</block>
  <block id="43919b4d4d6d446ed498e26bff62db84" category="paragraph">Blockprotokolle (iSCSI, FC und FCoE) greifen mithilfe von LUN-IDs und Seriennummern sowie mit eindeutigen Namen auf LUNs zu. FC und FCoE verwenden weltweite Namen (WWNNs und WWPNs) und iSCSI verwendet qualifizierte iSCSI-Namen (IQNs). Der Pfad zu LUNs innerhalb des Storage hat für die Blockprotokolle keine Bedeutung und wird nirgendwo im Protokoll angegeben. Daher muss ein Volume, das nur LUNs enthält, nicht intern gemountet werden. Zudem ist für Volumes, die in Datastores verwendete LUNs enthalten, kein Verbindungspfad erforderlich. Das NVMe-Subsystem in ONTAP funktioniert ähnlich.</block>
  <block id="ed0e76ed86e852bd7317a09d856ec4e8" category="paragraph">Weitere Best Practices, die berücksichtigt werden sollten:</block>
  <block id="93586ad57931e0f16fff61cdba9d77df" category="list-text">Vergewissern Sie sich, dass für jede SVM auf jedem Node im ONTAP Cluster eine logische Schnittstelle (LIF) erstellt wird, um maximale Verfügbarkeit und Mobilität zu gewährleisten. Als Best Practice empfiehlt sich für ONTAP SANs die Verwendung von zwei physischen Ports und LIFs pro Node, einer für jede Fabric. Mit ALUA werden Pfade geparst und aktive optimierte (direkte) Pfade im Gegensatz zu aktiven nicht optimierten Pfaden identifiziert. ALUA wird für FC, FCoE und iSCSI verwendet.</block>
  <block id="b3cebb7381bddbabb1e950a46d264190" category="list-text">Nutzen Sie für iSCSI-Netzwerke mehrere VMkernel Netzwerkschnittstellen für verschiedene Subnetze mit NIC-Teaming, wenn mehrere virtuelle Switches vorhanden sind. Darüber hinaus können Sie mehrere physische NICs nutzen, die mit mehreren physischen Switches verbunden sind, um Hochverfügbarkeit und einen höheren Durchsatz bereitzustellen. Die folgende Abbildung zeigt ein Beispiel für Multipath-Konnektivität. Konfigurieren Sie in ONTAP entweder eine Single-Mode-Schnittstellengruppe für Failover mit zwei oder mehr Links, die mit zwei oder mehreren Switches verbunden sind, oder nutzen Sie LACP oder eine andere Link-Aggregationstechnologie mit Multimode-Schnittstellengruppen, um Hochverfügbarkeit und die Vorteile der Link-Aggregation bereitzustellen.</block>
  <block id="2968b9f3c141bf23bc73d0e6e15a174a" category="list-text">Wenn das Challenge-Handshake Authentication Protocol (CHAP) in ESXi für die Zielauthentifizierung verwendet wird, muss es auch in ONTAP über die CLI konfiguriert werden <block ref="199c9b970eacf1c35d84a383b7ceb210" prefix="(" category="inline-code"></block>) Oder mit System Manager (bearbeiten Sie die Initiatorsicherheit unter „Storage“ &gt; „SVMs“ &gt; „SVM-Einstellungen“ &gt; „Protocols“ &gt; „iSCSI“).</block>
  <block id="d31f2e075df4ca75ca0874fa08f74b12" category="list-text">Verwenden Sie ONTAP Tools für VMware vSphere, um LUNs und Initiatorgruppen zu erstellen und zu managen. Das Plug-in bestimmt automatisch die WWPNs von Servern und erstellt entsprechende Initiatorgruppen. Darüber hinaus konfiguriert er LUNs gemäß Best Practices und ordnet sie den richtigen Initiatorgruppen zu.</block>
  <block id="de78559e8aed2cd62fbf852f73dc58c2" category="inline-link">Kompatibilitätsmodus für physischen und virtuellen Modus</block>
  <block id="905221150fdd103b5241870a0a1f2c42" category="list-text">Setzen Sie RDMs mit Bedacht ein, da ihr Management schwieriger sein kann. Zudem verwenden sie auch Pfade, die wie bereits beschrieben beschränkt sind. ONTAP LUNs unterstützen beide<block ref="27e1f8e5a88cfbb2836b083145b004c9" category="inline-link-rx"></block> RDMs:</block>
  <block id="636da39a2033c6179a718983c5ce1222" category="inline-link">ONTAP NVMe/FC-Host-Konfigurationsleitfaden</block>
  <block id="81ef6507a13da5635951bc5b533deb59" category="inline-link">TR-4684</block>
  <block id="15483b0826bb9a4b11d1c89af2029c5c" category="list-text">Weitere Informationen zur Verwendung von NVMe/FC mit vSphere 7.0 finden Sie im hier<block ref="6b4ed262d14e47ef641cd57b65c32c38" category="inline-link-rx"></block> Und<block ref="7a29b2f31035a451d5b068728d2b79a7" category="inline-link-rx"></block>Die folgende Abbildung zeigt die Multipath-Konnektivität von einem vSphere Host zu einer ONTAP LUN.</block>
  <block id="f9fd9ea22ea7a2e8ec9e95254a449831" category="paragraph"><block ref="f9fd9ea22ea7a2e8ec9e95254a449831" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f2a693e1f056b96566c4551fcab418f2" category="paragraph">Bei vSphere können Kunden mithilfe von NFS-Arrays der Enterprise-Klasse gleichzeitigen Zugriff auf Datastores auf allen Nodes in einem ESXi Cluster ermöglichen. Wie im Abschnitt zu Datastores erwähnt, gibt es bei der Verwendung von NFS mit vSphere einige Vorteile im Hinblick auf Benutzerfreundlichkeit, Storage-Effizienz und Sichtbarkeit.</block>
  <block id="743fa5a7bc7d4ba215b096e34779d298" category="paragraph">Für die Verwendung von ONTAP NFS mit vSphere werden folgende Best Practices empfohlen:</block>
  <block id="c05061b6d3055b83136fa96cb38f0f9a" category="list-text">Verwenden einer einzelnen logischen Schnittstelle (LIF) für jede SVM auf jedem Node im ONTAP-Cluster Die bisherigen Empfehlungen eines LIF pro Datenspeicher sind nicht mehr erforderlich. Der direkte Zugriff (LIF und Datastore auf demselben Node) ist zwar am besten, aber indirekte Zugriffe müssen sich keine Sorgen machen, da die Performance-Auswirkungen im Allgemeinen minimal sind (Mikrosekunden).</block>
  <block id="7b997b3be9c993d49799dd9d71d8c3f6" category="list-text">VMware unterstützt NFSv3 seit VMware Infrastructure 3. VSphere 6.0 bietet zusätzlich Unterstützung für NFSv4.1 und ermöglicht damit einige erweiterte Funktionen wie Kerberos Sicherheit. In NFSv3 wird „Client-side locking“ verwendet, in NFSv4.1 „Server-side locking“. Ein ONTAP Volume kann zwar mit beiden Protokollen exportiert werden, doch ESXi kann nur durch ein Protokoll gemountet werden. Bei diesem Einzelprotokoll-Mounting ist jedoch nicht ausgeschlossen, dass ESXi Hosts denselben Datastore auch durch eine andere Version mounten. Denken Sie daran, die beim Mounten verwendete Protokollversion anzugeben, damit alle Hosts dieselbe Version und somit auch denselben Sperrungsstil anwenden. Verwenden Sie auf verschiedenen Hosts nicht unterschiedliche NFS-Versionen. Falls möglich, prüfen Sie mithilfe von Hostprofilen die Compliance.</block>
  <block id="ae4c5baa79e370d8f601cc7082f8123e" category="list-text">Da keine automatische Datastore-Konvertierung zwischen NFSv3 und NFSv4.1 stattfindet, erstellen Sie einen neuen Datastore für NFSv4.1 und migrieren Sie die VMs mithilfe von Storage vMotion zum neuen Datastore.</block>
  <block id="8065bff4940ae8d7161f926b0df47ac4" category="inline-link">NetApp Interoperabilitäts-Matrix-Tool</block>
  <block id="1479ddf58c038ab7d220ff734c74deaf" category="list-text">Weitere Informationen finden Sie in den Anmerkungen zur Interoperabilität von NFS v4.1<block ref="8813559f5b95abb5411182be29200aff" category="inline-link-rx"></block> Für bestimmte ESXi-Patch-Level, die zur Unterstützung erforderlich sind.</block>
  <block id="24aaa4a688e881fa13d31656a85d40a9" category="list-text">Zur Steuerung des Zugriffs durch vSphere Hosts kommen NFS-Exportrichtlinien zur Anwendung. Sie können eine Richtlinie für mehrere Volumes (Datastores) nutzen. Bei NFSv3 verwendet ESXi den Sicherheitsstil „sys“ (UNIX). Zur Ausführung von VMs ist dabei die Root-Mount-Option erforderlich. In ONTAP wird diese Option als Superuser bezeichnet. Wenn die Option Superuser verwendet wird, ist es nicht erforderlich, die anonyme Benutzer-ID anzugeben. Beachten Sie, dass Exportrichtlinien mit unterschiedlichen Werten für gelten<block ref="ea72d12ecaa06afdb0c8a3b15e485e95" prefix=" " category="inline-code"></block> Und<block ref="df809a941c1287d18c08bb5927b639dc" prefix=" " category="inline-code"></block> Die ONTAP-Tools können zu Problemen bei der SVM-Erkennung führen. Hier sehen Sie eine Beispielrichtlinie:</block>
  <block id="822366735aef72f1a9429ac86dda7338" category="list-text">Access Protocol: nfs3</block>
  <block id="69abbd5c7cd9c1b3828b9aa5a894ff47" category="list-text">Client Match Spec: 192.168.42.21</block>
  <block id="bd6cc42f9cd65cca72cbd56d2f4bf43d" category="list-text">RO-Zugriffsregel: Sys</block>
  <block id="581c470a5099548fc9865a4bab8761f8" category="list-text">RW Access Rule: Sys</block>
  <block id="0bbc71e6a4ea49af70dd616d3807e524" category="list-text">Anonyme UID</block>
  <block id="59d5d8c898df18115bd4ced36c6bc0de" category="list-text">Superuser: Sys</block>
  <block id="c184ce6b86d2e6fbf8681d61637c101b" category="list-text">Wenn das NetApp NFS-Plug-in für VMware VAAI verwendet wird, sollte das Protokoll auf eingestellt werden<block ref="2521ef5d58fc027d3121662b7d8f9ac2" prefix=" " category="inline-code"></block> Wenn die Regel für die Exportrichtlinie erstellt oder geändert wird. Damit der Copy-Offload funktioniert, wird das NFSv4-Protokoll benötigt und das Protokoll als angegeben<block ref="2521ef5d58fc027d3121662b7d8f9ac2" prefix=" " category="inline-code"></block> Beinhaltet automatisch sowohl die NFSv3- als auch die NFSv4-Versionen.</block>
  <block id="6670a317619282ec228a9ef492af0a76" category="list-text">NFS-Datastore-Volumes werden aus dem Root-Volume der SVM heraus verbunden. Daher muss ESXi zum Navigieren und Mounten von Datastore Volumes auch Zugriff auf das Root-Volume haben. Die Exportrichtlinie für das Root-Volume und für alle anderen Volumes, in denen die Verbindung des Datastore Volumes geschachtelt ist, muss eine oder mehrere Regeln für die ESXi Server einschließen, die ihnen schreibgeschützten Zugriff gewähren. Hier sehen Sie eine Beispielrichtlinie für das Root-Volume, bei der auch das VAAI Plug-in genutzt wird:</block>
  <block id="8c93fb3ff528165613797962f5a0ed9c" category="list-text">Access Protocol: nfs (schließt nfsv3 und NFSv4 ein)</block>
  <block id="80e6a4f964e826c69c1c62bd5ea67590" category="list-text">RW Access Rule: Never (höchste Sicherheit für Root-Volume)</block>
  <block id="f96625174b4a06d13267f9b0a5a96d59" category="list-text">Superuser: Sys (auch für Root-Volume mit VAAI erforderlich)</block>
  <block id="4c571520a8128d1692fc709ffbfb2b1e" category="list-text">Verwenden Sie ONTAP Tools für VMware vSphere (die wichtigste Best Practice):</block>
  <block id="b8d278c6184cb65727ca5ae729db92d7" category="list-text">Mit ONTAP Tools für VMware vSphere können Sie Datastores bereitstellen, da es das Management von Richtlinien für den Export automatisch vereinfacht.</block>
  <block id="23aa7b9aeed3fba2a1ec43e630313af7" category="list-text">Wählen Sie beim Erstellen von Datastores für VMware Cluster mithilfe des Plug-ins das Cluster anstelle eines einzelnen ESX Servers aus. Bei dieser Auswahl mountet der Datastore automatisch auf alle Hosts im Cluster.</block>
  <block id="e4e62770daaf9887c7868fbc8e248a4b" category="list-text">Wenden Sie mithilfe der Plug- in-Mount-Funktion vorhandene Datastores auf neue Server an.</block>
  <block id="928562eb576ed6ae31cb1a149d3e751a" category="list-text">Wenn Sie die ONTAP Tools nicht für VMware vSphere verwenden, verwenden Sie eine Exportrichtlinie für alle Server oder für jeden Server-Cluster, wo eine zusätzliche Zugriffs-Kontrolle erforderlich ist.</block>
  <block id="7bccab0fa4c0864835c645c9fde7ebf6" category="list-text">Obwohl ONTAP eine flexible Namespace-Struktur für Volumes bietet, in der Volumes mithilfe von Verbindungen in einer Baumstruktur angeordnet werden können, ist dieser Ansatz für vSphere nicht praktikabel. Für jede VM im Root-Verzeichnis des Datastores wird unabhängig von der Namespace-Hierarchie des Storage ein Verzeichnis erstellt. Daher besteht die Best Practice darin, den Verbindungspfad für Volumes für vSphere im Root-Volume der SVM zu erstellen. Dies entspricht auch der Art und Weise, wie ONTAP Tools für VMware vSphere Datastores bereitstellt. Ohne geschachtelte Verbindungspfade besteht bei Volumes zudem nur eine Abhängigkeit zum Root-Volume. Wenn ein Volume dann offline geschaltet oder sogar absichtlich zerstört wird, wirkt sich dies also nicht auf den Pfad zu den anderen Volumes aus.</block>
  <block id="ea6fc1288f1d3b21238d29ff28cb867a" category="list-text">Eine Blockgröße von 4 KB ist für NTFS-Partitionen auf NFS-Datenspeichern gut. In der folgenden Abbildung ist die Konnektivität eines vSphere Hosts zu einem ONTAP NFS-Datastore dargestellt.</block>
  <block id="16c864cb4f3b00c59e1124932e49f342" category="paragraph"><block ref="16c864cb4f3b00c59e1124932e49f342" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e54433644e830ed1503561b778e9ded4" category="paragraph">In der folgenden Tabelle sind NFS-Versionen und unterstützte Funktionen aufgeführt.</block>
  <block id="9fb9dac7513c7ef8452aade8a52ad40d" category="cell">Funktionen von vSphere</block>
  <block id="5b12ee0369243579651edca43ff65c85" category="cell">NFSv3</block>
  <block id="de841868c2911da76b8ae2da9fa3166d" category="cell">NFSv4.1</block>
  <block id="64e3cc476958b05086721cd6070004cf" category="cell">VMotion und Storage vMotion</block>
  <block id="05807e454c19f244770adae059b3c330" category="cell">Hochverfügbarkeit</block>
  <block id="45a75e44a713fdf94dbf1dbaa0749188" category="cell">Fehlertoleranz</block>
  <block id="f1e3446c69e4d87279ff7863482f9dcb" category="cell">DRS</block>
  <block id="6ca09f98e8925b2cb78bbf24eccc0186" category="cell">Hostprofile</block>
  <block id="ec8420797e3b089812499cce4047ded8" category="cell">Storage DRS</block>
  <block id="7c19bf1cbe62a87a42857ef0b4fe22ae" category="cell">Storage-I/O-Steuerung</block>
  <block id="56d43ad1a280ada5e16fd2960ae44b32" category="cell">SRM</block>
  <block id="d595c8f30866b71ea121ced5cde66b1d" category="cell">Virtual Volumes</block>
  <block id="6ad5114acf73f68a85c72f11646920cb" category="cell">Hardwarebeschleunigung (VAAI)</block>
  <block id="ad37ded9046268d8e5ea7cb253bb5dda" category="cell">Kerberos Authentifizierung</block>
  <block id="45701e6ef9bc09dca07f8f4abe661dc6" category="cell">Ja (Erweiterung mit vSphere 6.5 und höher zur Unterstützung von AES, krb5i)</block>
  <block id="76969a36155d2f41fc6cc3bd3faff244" category="cell">Multipathing-Unterstützung</block>
  <block id="8a18e0a50dc5755c294477cb16507a6c" category="doc">Flexgroups</block>
  <block id="b6cd969550b5501b0f62a149fb7964ce" category="paragraph">ONTAP 9.8 bietet zusätzliche Unterstützung für FlexGroup-Datastores in vSphere sowie für die ONTAP-Tools für VMware vSphere 9.8 Release.</block>
  <block id="f9ac230f370c7937167d25093c4ce9b9" category="paragraph">FlexGroup vereinfacht die Erstellung großer Datastores und erstellt automatisch eine Reihe von zusammengehörigen Volumes, um die maximale Performance eines ONTAP Systems zu erreichen. Nutzen Sie FlexGroup mit vSphere für einen einzelnen, skalierbaren vSphere Datastore, der die Leistungsfähigkeit eines vollständigen ONTAP-Clusters bietet.</block>
  <block id="6829bc8d3038be0130fd2b409ad5e560" category="paragraph">Neben umfangreichen Systemtests mit vSphere Workloads bietet ONTAP 9.8 auch einen neuen Offload-Mechanismus für FlexGroup Datastores. Hierbei wird eine verbesserte Kopier-Engine verwendet, um Dateien zwischen den Komponenten im Hintergrund zu kopieren, während der Zugriff auf Quelle und Ziel möglich ist. Mehrere Kopien verwenden sofort verfügbare, platzsparende Datei-Klone in einer Komponente, wenn diese je nach Skalierung benötigt werden.</block>
  <block id="760383437e8e5cbe4a2560753da783fb" category="paragraph">ONTAP 9.8 bietet darüber hinaus neue dateibasierte Performance-Metriken (IOPS, Durchsatz und Latenz) für FlexGroup-Dateien. Diese Kennzahlen können Sie auch in den ONTAP Tools für VMware vSphere Dashboard- und VM-Berichten ansehen. Die ONTAP Tools für VMware vSphere Plug-in ermöglichen Ihnen darüber hinaus die Festlegung von QoS-Regeln (Quality of Service) über eine Kombination aus dem Maximum und/oder dem Minimum von IOPS. Diese können über alle VMs in einem Datenspeicher oder individuell für bestimmte VMs hinweg festgelegt werden.</block>
  <block id="50783a97403d748762dff691da2d3723" category="paragraph">Im Folgenden finden Sie einige weitere NetApp Best Practices:</block>
  <block id="d190c5fcdf8146c1dd7aad1140be4e64" category="list-text">Nutzen Sie die Standardeinstellungen für die FlexGroup-Bereitstellung. Es empfiehlt sich zwar ONTAP-Tools für VMware vSphere, da sie die FlexGroup in vSphere erstellen und gemountet werden. Zudem ist ONTAP System Manager oder die Befehlszeile kann für spezielle Anforderungen verwendet werden. Verwenden Sie dann selbst die Standardwerte wie die Anzahl der zusammengehörigen Mitglieder pro Node, da dies bei vSphere getestet wurde.</block>
  <block id="9f3fa65c2cc36eabd2228b984c30c5e1" category="list-text">Beachten Sie bei der Dimensionierung eines FlexGroup-Datenspeichers, dass die FlexGroup aus mehreren kleineren FlexVol-Volumes besteht, die einen größeren Namespace erstellen. Daher muss die Größe des Datenspeichers bei der größten Virtual Machine mindestens das Achtfache betragen. Wenn Sie beispielsweise eine 6-TB-VM in Ihrer Umgebung haben, geben Sie der FlexGroup-Datenspeicher die Größe nicht kleiner als 48 TB an.</block>
  <block id="5fbee6b763967c822bb1e4a31665b11d" category="list-text">Erlauben Sie FlexGroup, den Datenspeicherplatz zu managen. Autosize und Elastic Sizing wurden mit vSphere Datastores getestet. Sollte der Datenspeicher annähernd die volle Kapazität erhalten, verwenden Sie ONTAP Tools für VMware vSphere oder ein anderes Tool, um die Größe des FlexGroup Volume zu ändern. Bei FlexGroup werden Kapazität und Inodes über die Komponenten hinweg ausgeglichen. So werden die Dateien in einem Ordner (VM) nach Möglichkeit der Kapazität auf dieselbe Komponente priorisiert.</block>
  <block id="b48b55db402c8085e1d333cad214232b" category="list-text">VMware und NetApp unterstützen derzeit keinen gemeinsamen Ansatz für Multipath-Netzwerke. Bei NFSv4.1 unterstützt NetApp pNFS, während VMware das Session-Trunking unterstützt. NFSv3 unterstützt nicht mehrere physische Pfade zu einem Volume. Bei FlexGroup mit ONTAP 9.8 empfehlen wir, die ONTAP-Tools für VMware vSphere beim Single Mount zu überlassen, da die Auswirkungen des indirekten Zugriffs in der Regel minimal (Mikrosekunden) sind. Es ist möglich, Round-Robin-DNS zu verwenden, um ESXi Hosts auf verschiedenen Nodes im FlexGroup über LIFs zu verteilen, allerdings müsste die FlexGroup ohne ONTAP-Tools für VMware vSphere erstellt und gemountet werden. Dann wären die Leistungsmanagementfunktionen nicht verfügbar.</block>
  <block id="f5f11bb6aa98d02453eca36d5d1d2e19" category="list-text">Die Unterstützung für FlexGroup vSphere Datastores wurde mit Version 9.8 auf bis zu 1500 VMs getestet.</block>
  <block id="f48591b3ae898f29a551a2995a7dcfe8" category="list-text">Nutzen Sie das NFS-Plug-in für VMware VAAI für den Offloaded Data Transfer. Beachten Sie, dass ONTAP während der Erweiterung des Klonens in einem FlexGroup Datastore keine wesentlichen Performance-Vorteile bietet gegenüber ESXi Hostkopien, wenn VMs zwischen FlexVol- und/oder FlexGroup-Volumes kopiert werden.</block>
  <block id="57a0d1deb8da99d321814990d26d21ed" category="list-text">Verwenden Sie ONTAP Tools für VMware vSphere 9.8, um die Performance von FlexGroup VMs mithilfe von ONTAP Kennzahlen (Dashboard- und VM-Berichte) zu überwachen und QoS auf einzelnen VMs zu managen. Diese Metriken sind derzeit nicht über ONTAP-Befehle oder APIs verfügbar.</block>
  <block id="ad971da24ec0a38449ebf31e4e2c9332" category="list-text">QoS (max./min. IOPS) kann auf einzelnen VMs oder auf allen VMs zu diesem Zeitpunkt in einem Datenspeicher festgelegt werden. Die Festlegung der QoS auf allen VMs ersetzt alle separaten Einstellungen pro VM. Einstellungen erweitern nicht auch künftig auf neue oder migrierte VMs. Sie können entweder QoS auf den neuen VMs festlegen oder QoS neu auf alle VMs im Datastore anwenden.</block>
  <block id="3c9d41390700cbdfb2c273f00df0d6fd" category="list-text">Das SnapCenter Plug-in für VMware vSphere Version 4.4 unterstützt Backup und Recovery von VMs in einem FlexGroup-Datenspeicher auf dem primären Storage-System. Während SnapMirror manuell für die Replizierung einer FlexGroup auf ein sekundäres System verwendet werden kann, verwaltet SCV 4.4 die sekundären Kopien nicht.</block>
  <block id="be0ec3d9251292dd856ea0924ecc6873" category="doc">Servicequalität (QoS)</block>
  <block id="f437881fa7e42bf0e4563bbec8176f81" category="paragraph">Systeme mit ONTAP Software nutzen die ONTAP Storage-QoS-Funktion, um den Durchsatz in Megabit pro Sekunde und/oder die Anzahl der I/O-Vorgänge pro Sekunde (IOPS) für unterschiedliche Storage-Objekte wie Dateien, LUNs, Volumes oder ganze SVMs zu beschränken.</block>
  <block id="8fdd6138f63aa45f1c51b48d9a01b19d" category="paragraph">Durchsatzbegrenzungen sind bei der Steuerung unbekannter Workloads oder von Test-Workloads vor der Implementierung nützlich, wenn sichergestellt werden soll, dass sie sich nicht auf andere Workloads auswirken. Sie können auch zur Beschränkung eines als problematisch identifizierten Workloads eingesetzt werden. Minimale Service-Level auf Basis der IOPS werden ebenfalls unterstützt, um SAN-Objekten in ONTAP 9.2 und NAS-Objekten in ONTAP 9.3 eine konsistente Performance bereitzustellen.</block>
  <block id="3e4a2dc31acddb628ba286d25b1bd36e" category="paragraph">Bei einem NFS-Datastore kann eine QoS-Richtlinie auf das gesamte FlexVol Volume oder auf einzelne VMDK-Dateien darin angewendet werden. Die QoS-Richtlinien können bei VMFS Datastores mit ONTAP LUNs auf das FlexVol Volume, das die LUNs enthält, oder auf einzelne LUNs angewendet werden, jedoch nicht auf einzelne VMDK-Dateien, weil ONTAP das VMFS Filesystem nicht erkennt. Bei Verwendung von VVols kann über das Storage-Funktionsprofil und die VM-Storage-Richtlinie für einzelne VMs die minimale und/oder maximale QoS festgelegt werden.</block>
  <block id="534ecd446aac2f9c809eef9064f44aab" category="paragraph">Die maximale QoS-Durchsatzbegrenzung für ein Objekt kann in Megabit pro Sekunde und/oder IOPS festgelegt werden. Wenn beide verwendet werden, wird das erste erreichte Limit von ONTAP durchgesetzt. Ein Workload kann mehrere Objekte umfassen. Auf einen oder mehrere Workloads kann eine QoS-Richtlinie angewendet werden. Wird eine Richtlinie auf mehrere Workloads angewendet, teilen diese das in der Richtlinie zulässige Gesamtlimit. Geschachtelte Objekte werden nicht unterstützt (so können beispielsweise nicht jede Datei in einem Volume eine eigene Richtlinie aufweisen). QoS-Mindestwerte können nur als IOPS angegeben werden.</block>
  <block id="040f184b126879657b253b6d258661d9" category="paragraph">Derzeit sind folgende Tools für das Management von ONTAP QoS-Richtlinien und deren Anwendung auf Objekte verfügbar:</block>
  <block id="de134183bea5df515a6756a539ce6f18" category="list-text">CLI VON ONTAP</block>
  <block id="6ad5e0a20f49ad6a370454bb3afc9a9e" category="list-text">ONTAP System Manager</block>
  <block id="8e23e05fc0865e950d6a3581e0dd8ce9" category="list-text">OnCommand Workflow-Automatisierung</block>
  <block id="5ecb6b24c169667ff1a176768115659e" category="list-text">Active IQ Unified Manager</block>
  <block id="8cc4e713850f67a131e9dbf8b997f61e" category="list-text">NetApp PowerShell Toolkit für ONTAP</block>
  <block id="fcdb48d0d22627e4910a8352c80bd87a" category="list-text">ONTAP-Tools für VMware vSphere VASA Provider</block>
  <block id="e6defd03e0f49585b6d47614713e97f7" category="paragraph">Beachten Sie folgende Vorgaben, wenn Sie eine QoS-Richtlinie auf eine VMDK in NFS anwenden:</block>
  <block id="10509998e8d4c4d7be30fc1d0b6b2a1e" category="list-text">Die Politik muss auf das angewendet werden<block ref="a1bb63c284b58c32f1afb554a12e3e9a" prefix=" " category="inline-code"></block> Die das tatsächliche Image des virtuellen Laufwerks enthält, nicht das<block ref="aa26c73336ecfd98ed727b3e249c7f90" prefix=" " category="inline-code"></block> (Deskriptordatei für virtuelle Festplatten) oder<block ref="092eb4dd2ca488962f4c22b3e8cc4ca0" prefix=" " category="inline-code"></block> (VM-Deskriptordatei).</block>
  <block id="2175e0e29bc4b213fa8b9c7afd591b6b" category="list-text">Wenden Sie keine Richtlinien auf andere VM-Dateien wie virtuelle Swap-Dateien an <block ref="aa33c3c1850a3f99cec7426e2c411d08" prefix="(" category="inline-code"></block>).</block>
  <block id="8230e9b5c1e9862fedb2c69f7cc5d3d1" category="list-text">Wenn Sie Dateipfade mithilfe des vSphere Webclients ermitteln („Datastore“ &gt; „Files“), denken Sie daran, dass dieser die Informationen der zusammenfasst<block ref="f149d7424e10a266ec998ca5b32b81bb" prefix=" " category="inline-code"></block> Und<block ref="4a78be158c13cd6b2dc2100a80bb7070" prefix=" " category="inline-code"></block> Und zeigt einfach eine Datei mit dem Namen des an<block ref="4a78be158c13cd6b2dc2100a80bb7070" prefix=" " category="inline-code"></block> Aber die Größe der<block ref="f149d7424e10a266ec998ca5b32b81bb" prefix=" " category="inline-code"></block>. Zusatz<block ref="4fc4e556dbb9dcede037ccd80fabd784" prefix=" " category="inline-code"></block> In den Dateinamen, um den richtigen Pfad zu erhalten.</block>
  <block id="1d4614aca13104c98d5d8cc2d415b941" category="paragraph">Wenn Sie eine QoS-Richtlinie einschließlich VMFS und RDM einer LUN zuweisen möchten, können Sie die ONTAP SVM (angezeigt als „vServer“), den LUN-Pfad und die Seriennummer auf der ONTAP Tools für VMware vSphere Startseite aus dem Menü „Storage Systems“ abrufen. Wählen Sie das Storage-System (SVM) und anschließend „Related Objects“ &gt; „SAN“ aus.  Verwenden Sie diesen Ansatz, wenn Sie die QoS mit einem der ONTAP Tools angeben.</block>
  <block id="cc97a1a52adc0bd6f188de1545eea887" category="paragraph">Die maximale und minimale QoS kann einer vVol-basierten VM mit ONTAP Tools für VMware vSphere oder Virtual Storage Console 7.1 und höher problemlos zugewiesen werden. Wenn Sie das Storage-Funktionsprofil für den vVol Container erstellen, geben Sie unter der Performance-Funktion einen IOPS-Wert für max und/oder min an und verweisen dann mit der Storage-Richtlinie der VM auf dieses Storage-Funktionsprofil. Verwenden Sie diese Richtlinie beim Erstellen der VM oder beim Anwenden der Richtlinie auf eine vorhandene VM.</block>
  <block id="421c9efa4ff1b039a5378be7bc1e2e49" category="paragraph">FlexGroup Datastores bieten erweiterte QoS-Funktionen, wenn ONTAP Tools für VMware vSphere 9.8 und höher verwendet werden. Sie können ganz einfach QoS für alle VMs in einem Datastore oder für bestimmte VMs festlegen. Weitere Informationen finden Sie im Abschnitt „FlexGroup“ dieses Berichts.</block>
  <block id="77bb2ba950959bd3f1c55da523ace0be" category="section-title">ONTAP QoS und VMware SIOC</block>
  <block id="b2e21dac6070ea83831ff6521a66a447" category="paragraph">ONTAP QoS und VMware vSphere Storage I/O Control (SIOC) sind Technologien, die sich gegenseitig ergänzen und die vSphere und Storage-Administratoren gemeinsam nutzen können, um die Performance von vSphere VMs zu managen, die auf Systemen mit ONTAP Software ausgeführt werden. Wie in der folgenden Tabelle zu sehen ist, hat jedes Tool seine eigenen Stärken. Aufgrund des unterschiedlichen Umfangs von VMware vCenter und ONTAP kann es sein, dass einige Objekte von einem System erkannt und gemanagt werden können, vom anderen jedoch nicht.</block>
  <block id="5ad234cb2cde4266195252a23ca7d84e" category="cell">Eigenschaft</block>
  <block id="b8b8d1ba8fa345f03438a90f29af5784" category="cell">ONTAP-QoS</block>
  <block id="c2a4cb962db2a4a6782b69864f0e411c" category="cell">VMware SIOC</block>
  <block id="aa628d5a66888444926b4dc042458200" category="cell">Wenn aktiv</block>
  <block id="688b10fcfff927dee65634e3b3636064" category="cell">Richtlinie ist immer aktiv</block>
  <block id="a981c4aa67c29ff2d36fc614d8b28808" category="cell">Aktiv, wenn ein Konflikt besteht (Datastore-Latenz über Schwellenwert)</block>
  <block id="f46e64a82c96db56f3d6657d4fb53f00" category="cell">Einheiten</block>
  <block id="878b4223bb85b95d8caf0429d9406cd5" category="cell">IOPS, MB/Sek.</block>
  <block id="3e189a34f422a141311dad231f9ad5b5" category="cell">IOPS, Freigaben</block>
  <block id="7367a0ec46339213625cbc77d56a9572" category="cell">Umfang von vCenter oder Applikation</block>
  <block id="1faff19290bb64ce8ff6bc1220496881" category="cell">Mehrere vCenter Umgebungen, andere Hypervisoren und Applikationen</block>
  <block id="1e664a3cc0ab109fcabcc81b488cebb1" category="cell">Einzelner vCenter Server</block>
  <block id="ebccc9f5c939841d86e5382988dfcc47" category="cell">QoS auf VM festlegen?</block>
  <block id="cddd0980ce99890d2ea90288f6b03117" category="cell">VMDK nur auf NFS</block>
  <block id="928629d8a2a889f5274cad9940a06da0" category="cell">VMDK auf NFS oder VMFS</block>
  <block id="305e85b992089534091855224f60cf75" category="cell">QoS auf LUN festlegen (RDM)?</block>
  <block id="e798014243cf5682e7fb3aaf4ee7cecf" category="cell">QoS auf LUN festlegen (VMFS)?</block>
  <block id="9cd021ea9d3c88de723fe9a2e50a2380" category="cell">QoS auf Volume festlegen (NFS-Datastore)?</block>
  <block id="c352b53c32380efcf4436926da6d0414" category="cell">QoS auf SVM festlegen (Mandant)?</block>
  <block id="5dad340ee8f9e8fa9b65bf86a9fd5341" category="cell">Richtlinienbasierter Ansatz?</block>
  <block id="b31c76176f26196c6379a9bcce212d99" category="cell">Ja – kann von allen Workloads in der Richtlinie geteilt oder vollständig auf jeden Workload in der Richtlinie angewendet werden.</block>
  <block id="1ff33557bad923d68973872cacf2e43a" category="cell">Ja, mit vSphere 6.5 und höher.</block>
  <block id="d5f1465492190ee9d30a09b36f64f4b7" category="cell">Lizenz erforderlich</block>
  <block id="4cec76d82991abd453484c23f7e3788a" category="cell">In ONTAP enthalten</block>
  <block id="6bb36803f4670824ff9ebdf665654829" category="cell">Enterprise Plus</block>
  <block id="d4d4b5b65bebf236590d70c702a6ba6b" category="paragraph">VMware Storage Distributed Resource Scheduler (SDRS) ist eine Funktion von vSphere, die VMs auf Storage basierend auf der aktuellen I/O-Latenz und der Speicherplatznutzung platziert. Danach werden die VM oder VMDKs unterbrechungsfrei zwischen den Datastores in einem Datastore-Cluster (auch Pod genannt) verschoben und es wird der beste Datastore ausgewählt, in dem die VM oder die VMDKs im Datastore-Cluster platziert werden sollen. Ein Datastore-Cluster ist eine Sammlung ähnlicher Datastores, die aus Sicht des vSphere Administrators in einer einzigen Verbrauchseinheit aggregiert werden.</block>
  <block id="01e838e1c124042f75adb374a81f72a6" category="paragraph">VMware vSphere APIs for Storage Awareness (VASA) erleichtern einem Storage-Administrator die Konfiguration von Datastores mit klar definierten Funktionen. Der VM-Administrator kann sie zudem im Bedarfsfall jederzeit nutzen, um VMs bereitzustellen, ohne dass eine Interaktion stattfinden muss. Eine genauere Betrachtung dieses Ansatzes lohnt sich für Sie, wenn Sie feststellen möchten, wie er Ihre Storage-Virtualisierungsvorgänge optimieren und Ihnen viele banale Arbeiten ersparen kann.</block>
  <block id="0ce8b0e3e0d7dc7f39c62fb74a28b3bf" category="section-title">Cloud-Migration und -Backup</block>
  <block id="4fe11b4a91ff38ec9933009a15dd5b0b" category="paragraph">Eine weitere Stärke von ONTAP ist die umfassende Unterstützung für die Hybrid Cloud, bei der Systeme in Ihrer Private Cloud vor Ort mit Public-Cloud-Funktionen vereint werden. Im Folgenden sind einige NetApp Cloud-Lösungen aufgeführt, die gemeinsam mit vSphere verwendet werden können:</block>
  <block id="e18ab5f123ad4ce169202479f07f3f0f" category="list-text">*Cloud Volumes.* NetApp Cloud Volumes Service für Amazon Web Services oder Google Cloud Platform und Azure NetApp Files für ANF bieten hochperformante, Multiprotokoll-gemanagte Storage-Services in führenden Public-Cloud-Umgebungen. Sie können direkt von den Gästen der VMware Cloud VM verwendet werden.</block>
  <block id="9625e7e8b7b951b4ac75beee0139b407" category="list-text">*Cloud Volumes ONTAP.* die NetApp Cloud Volumes ONTAP Datenmanagement-Software bietet Kontrolle, Schutz, Flexibilität und Effizienz für Ihre Unternehmensdaten in der gewünschten Cloud. Cloud Volumes ONTAP ist eine Cloud-native Datenmanagement-Software auf der Basis der Storage-Software NetApp ONTAP. Nutzen Sie diese Technologie zusammen mit Cloud Manager, um Cloud Volumes ONTAP Instanzen gemeinsam mit Ihren lokalen ONTAP Systemen zu implementieren und zu managen. Nutzen Sie erweiterte NAS- und iSCSI SAN-Funktionen mit einheitlichem Datenmanagement einschließlich Snapshots und SnapMirror Replizierung.</block>
  <block id="2a11701c0c01affc0ce96eb0d0c16ed9" category="list-text">*Cloud-Services.* Verwenden Sie Cloud Backup Service oder SnapMirror Cloud, um Daten mithilfe von Public-Cloud-Storage vor lokalen Systemen zu schützen. Cloud Sync hilft bei der Migration und bei der Synchronisierung Ihrer Daten in NAS-, Objektspeicher- und Cloud Volumes Service-Storage.</block>
  <block id="99c6c4d349151c1f4a6694e424aef741" category="inline-link">Speichern Sie mehr Snapshots Ihrer VMs</block>
  <block id="01fa297dbdab5aceb83a45a98161efe0" category="list-text">*FabricPool.* FabricPool bietet schnelles und einfaches Tiering für ONTAP Daten. Selten genutzte, „kalte“ Blöcke können zu einem Objektspeicher in Public Clouds oder zu einem privaten StorageGRID Objektspeicher migriert werden und beim erneuten Zugriff auf die ONTAP-Daten automatisch wieder abgerufen werden. Alternativ können Sie die Objekt-Tier als dritte Schutzebene für Daten verwenden, die bereits von SnapVault gemanagt werden. Dieser Ansatz kann Ihnen ermöglichen<block ref="60d027dbb3c3f076cbb70c6b246eb433" category="inline-link-rx"></block> Auf primären und/oder sekundären ONTAP-Storage-Systemen.</block>
  <block id="1a7072854c9dd945a98f4314b3f77408" category="list-text">*ONTAP Select.* mit softwaredefiniertem NetApp Storage erweitern Sie Ihre Private Cloud über das Internet auf Remote-Einrichtungen und Niederlassungen, in denen Sie ONTAP Select zur Unterstützung von Block- und Fileservices sowie denselben vSphere Datenmanagementfunktionen nutzen können, die Sie in Ihrem Unternehmens-Datacenter haben.</block>
  <block id="79aec220098057ef8c0e46281a45d6c2" category="paragraph">Ziehen Sie bei dem Entwurf Ihrer VM-basierten Applikationen zukünftige Cloud-Mobilität in Erwägung. Anstatt beispielsweise Applikations- und Datendateien gemeinsam zu platzieren, verwenden Sie einen separaten LUN- oder NFS-Export für die Daten. Damit können Sie VM und Daten getrennt zu Cloud-Services migrieren.</block>
  <block id="af63597853dc0983258c8f86a12aae0b" category="section-title">Verschlüsselung für vSphere Daten</block>
  <block id="63a07ab9352c9297cea3894d6cd41c3f" category="paragraph">Heute besteht eine wachsende Nachfrage, Daten im Ruhezustand durch Verschlüsselung zu sichern. Obwohl der Schwerpunkt anfänglich auf Informationen im Finanz- und Gesundheitswesen lag, gibt es ein zunehmendes Interesse an der Sicherung sämtlicher Informationen – seien sie in Dateien, Datenbanken oder in anderen Datentypen gesichert.</block>
  <block id="f131c8f285a9ebc44140235877aecbe5" category="paragraph">Systeme mit ONTAP Software vereinfachen die Sicherung sämtlicher Daten durch Verschlüsselung im Ruhezustand. NetApp Storage Encryption (NSE) verwendet Self-Encrypting Drives mit ONTAP, um SAN- und NAS-Daten zu sichern. NetApp bietet darüber hinaus NetApp Volume Encryption und NetApp Aggregate Encryption als einen einfachen, softwarebasierten Ansatz zur Verschlüsselung von Volumes auf Festplattenlaufwerken. Für diese Softwareverschlüsselung sind keine speziellen Festplatten oder externen Schlüsselmanager erforderlich. Es ist für ONTAP Kunden kostenlos verfügbar. Sie können ein Upgrade durchführen und mit der Nutzung von IT beginnen, ohne dass es zu Unterbrechungen für Ihre Clients oder Applikationen kommt. Außerdem sind sie gemäß FIPS 140-2 Level 1 Standard validiert, einschließlich Onboard Key Manager.</block>
  <block id="937a352e0f824ff55e4cd50c8e3b051e" category="paragraph">Für die Sicherung der Daten virtualisierter Applikationen unter VMware vSphere gibt es verschiedene Ansätze. Einer besteht darin, die Daten mit Software innerhalb der VM auf der Ebene des Gastbetriebssystems zu sichern. Alternativ dazu unterstützen neuere Hypervisoren wie vSphere 6.5 jetzt auch Verschlüsselung auf VM-Ebene. Die NetApp Softwareverschlüsselung ist jedoch eine einfache und bietet folgende Vorteile:</block>
  <block id="6eda79cc710edc32583cf567b00e7672" category="list-text">*Keine Auswirkung auf die virtuelle Server-CPU.* in einigen virtuellen Server-Umgebungen ist jeder verfügbare CPU-Zyklus für ihre Anwendungen erforderlich, aber Tests haben ergeben, dass bei Verschlüsselung auf Hypervisor-Ebene bis zu 5x CPU-Ressourcen benötigt werden. Selbst wenn die Verschlüsselungssoftware zur Verlagerung von Verschlüsselungs-Workloads den AES-NI Befehlssatz von Intel unterstützt (wie es bei der NetApp-Softwareverschlüsselung der Fall ist), ist dieser Ansatz aufgrund der Notwendigkeit neuer CPUs, die nicht mit älteren Servern kompatibel sind, unter Umständen nicht realisierbar.</block>
  <block id="6abee98aea26f85e6f0fe8d4db70f998" category="list-text">*Onboard Key Manager inbegriffen.* die NetApp Software-Verschlüsselung umfasst einen Onboard-Schlüsselmanager ohne zusätzliche Kosten und erleichtert den Einstieg ohne hochverfügbare Verschlüsselungsmanagement-Server, deren Erwerb und Nutzung ein hohes Maß an Komplexität mit sich bringt.</block>
  <block id="c216121021de8554d33503ef6616b256" category="list-text">*Keine Auswirkungen auf die Storage-Effizienz.* Storage-Effizienztechniken wie Deduplizierung und Komprimierung werden heute weit verbreitet und sind für eine kostengünstige Nutzung von Flash-Speicher von zentraler Bedeutung. Verschlüsselte Daten können in der Regel jedoch nicht dedupliziert oder komprimiert werden. Die Hardware- und Storage-Verschlüsselung von NetApp arbeitet auf niedrigerer Ebene und ermöglicht im Gegensatz zu anderen Ansätzen die vollständige Nutzung der branchenführenden NetApp Storage-Effizienzfunktionen.</block>
  <block id="5f9aa8333f218d1c21e67c8608a48672" category="list-text">*Einfache granulare Datastore-Verschlüsselung.* mit NetApp Volume Encryption erhält jedes Volume einen eigenen AES 256-Bit-Schlüssel. Wenn Sie diesen ändern müssen, müssen Sie dazu nur einen einzigen Befehl ausführen. Dieser Ansatz eignet sich ideal, wenn Sie mehrere Mandanten haben oder für unterschiedliche Abteilungen oder Apps eine unabhängige Verschlüsselung nachweisen müssen. Diese Verschlüsselung wird auf Datastore-Ebene gemanagt, was viel einfacher ist als das Management einzelner VMs.</block>
  <block id="de2b3baa1cd4980c36e8bbf7c827ae0c" category="paragraph">Die ersten Schritte mit Softwareverschlüsselung sind ganz einfach. Nach der Installation der Lizenz konfigurieren Sie einfach das Onboard-Verschlüsselungsmanagement, indem Sie eine Passphrase angeben und dann entweder ein neues Volume erstellen oder ein Storage-seitiges Volume verschieben, um die Verschlüsselung zu aktivieren. NetApp arbeitet daran, künftige Versionen seiner VMware Tools um zusätzliche integrierte Unterstützung von Verschlüsselungsfunktionen zu erweitern.</block>
  <block id="c95fa5b56a01e5c1a80c540c1ab1a750" category="paragraph">Active IQ Unified Manager bietet einen Überblick über die VMs in Ihrer virtuellen Infrastruktur und ermöglicht die Überwachung und Fehlerbehebung von Storage- und Performance-Problemen in Ihrer virtuellen Umgebung.</block>
  <block id="be75250c2f30870dc1e359b4ade2a767" category="paragraph">Eine typische Implementierung einer virtuellen Infrastruktur auf ONTAP setzt auf verschiedene Komponenten, die auf Computing-, Netzwerk- und Storage-Ebenen verteilt sind. Alle Performance-Einbußen bei einer VM-Applikation können aufgrund einer Kombination aus Latenzen auftreten, die bei den verschiedenen Komponenten auf den jeweiligen Ebenen auftreten.</block>
  <block id="d1734f6f2e65a1488896f74695db5254" category="paragraph">Der folgende Screenshot zeigt die Ansicht der virtuellen Active IQ Unified Manager Machines.</block>
  <block id="8aa017c9f67ad32dd7301ecf52b61d72" category="paragraph"><block ref="8aa017c9f67ad32dd7301ecf52b61d72" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2118336fa447fcc0f213cb8c40c516af" category="paragraph">Unified Manager stellt das zugrunde liegende Untersystem einer virtuellen Umgebung in einer topologischen Übersicht vor, um zu ermitteln, ob beim Computing-Node, Netzwerk oder Storage ein Latenzproblem aufgetreten ist. Die Ansicht zeigt außerdem das spezifische Objekt, das aufgrund der Performance-Verzögerung Korrekturmaßnahmen ergreifen und das zugrunde liegende Problem lösen kann.</block>
  <block id="d8a78b994fcd4e04901203a2e7bc6414" category="paragraph">Der folgende Screenshot zeigt die erweiterte AIQUM-Topologie.</block>
  <block id="e9659be2b7d3d69eccdb443ed2acec75" category="paragraph"><block ref="e9659be2b7d3d69eccdb443ed2acec75" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f02207fb26160d7e47cf5ea35d07df03" category="doc">Datenspeicher und Protokolle</block>
  <block id="ff53ee8001042abcefe5c912d0b5012f" category="section-title">VSphere Datastore- und Protokollfunktionen</block>
  <block id="af8dcb8c7a1e8b7e614e570806d8dcee" category="paragraph">Sieben Protokolle können für die Anbindung von VMware vSphere ESXi Hosts an ONTAP Systeme für Datastores genutzt werden:</block>
  <block id="a7c815fafe60ae637d38216fa6300395" category="list-text">FCP</block>
  <block id="14eae6ee278098bfad4f8a10fd6c1195" category="list-text">FCoE</block>
  <block id="26bcb9f1cb6f391f4b2c18e676bb458d" category="list-text">NVMe/FC</block>
  <block id="8b7c42123642e2e4ea7dd426aeb2de58" category="list-text">NVMe/TCP</block>
  <block id="e4e1c13bb0b14f6cb7608cbecea948ef" category="list-text">ISCSI</block>
  <block id="f7d773fd2896401c143676940bc001fc" category="list-text">NFS v3</block>
  <block id="0b99b245267ef194ca3b9f6e694b0983" category="list-text">NFS 4.1</block>
  <block id="cfa070ed8af17c3125cfd1530fbd387a" category="paragraph">FCP, FCoE, NVMe/FC, NVMe/TCP und iSCSI sind Blockprotokolle. VMware Datastores werden über das vSphere Virtual Machine File System (VMFS) gespeichert, um VMs innerhalb von ONTAP LUNs oder NVMe Namespaces zu speichern, die in einem ONTAP FlexVol Volume enthalten sind. Beachten Sie, dass VMware ab vSphere 7.0 keine Software FCoE mehr in Produktionsumgebungen unterstützt. NFS ist ein File-Protokoll. Hierbei werden die Datastores nicht zusätzlich mit VMFS formatiert. VMs laufen direkt auf dem ONTAP Volume. SMB (CIFS), iSCSI, NVMe/TCP oder NFS kann direkt aus einem Gastbetriebssystem für ONTAP genutzt werden.</block>
  <block id="2b19cb432f68f1ba3dc7b0f175a14778" category="inline-link">Maximalwerte für die VMware Konfiguration</block>
  <block id="f8ca1b19553d4c965e40e9eeb1eb5aca" category="paragraph">In der folgenden Tabelle sind die Funktionen herkömmlicher Datastores dargestellt ONTAP, die von vSphere unterstützt werden. Diese Informationen gelten nicht für VVols Datastores, sie gelten jedoch im Allgemeinen für vSphere 6.x bzw. neuere Versionen, bei denen unterstützte ONTAP Versionen verwendet werden. Sie können sich auch beraten<block ref="61b579b455015dfa2bbf16bf62f07f93" category="inline-link-rx"></block> Bestätigen Sie für bestimmte vSphere Versionen bestimmte Limits.</block>
  <block id="9da73946f1bc3be4a41898d06c9d2e8b" category="cell">Funktion/Feature</block>
  <block id="c982f804d02e2d7e937f125d2cac1024" category="cell">FC/FCoE</block>
  <block id="6151632541dcd80356c6c76b34d69d0c" category="cell">NVMe-of</block>
  <block id="520d0db389f362bf79ef56ca0af3dcab" category="cell">Formatieren</block>
  <block id="99a3142584ca8ad0a3afadeaa6f2ef69" category="cell">VMFS oder Raw Device Mapping (RDM)</block>
  <block id="26aae26f61844ac20ab7b04ba6f5c515" category="cell">VMFS oder RDM</block>
  <block id="18263a30df8afc60a733e59c60676ac0" category="cell">VMFS</block>
  <block id="382b0f5185773fa0f67a8ed8056c7759" category="cell">K. A.</block>
  <block id="8dc6d0c66219ddb809322c0d248e55e6" category="cell">Maximale Anzahl an Datastores oder LUNs</block>
  <block id="aa23f9914ce1939ea7a4d479edfdc915" category="cell">1024 LUNs pro Host</block>
  <block id="1af3b27207afc48a363629a315d76b59" category="cell">1024 LUNs pro Server</block>
  <block id="0705fd627c25b5fba17cd9a022ed7d72" category="cell">256 Namespeces pro Server</block>
  <block id="2774ddb6f193789c5d9a480b9e53a38d" category="cell">256 Halterungen
Standard-NFS. MaxVolumes ist 8. Erhöhen Sie mit den ONTAP Tools für VMware vSphere auf 256.</block>
  <block id="51c0dc217976e27de06e262947947a62" category="cell">Maximale Datastore-Größe</block>
  <block id="856c997f909830b8249756c07dc9452b" category="cell">64 TB</block>
  <block id="8e5d3a4b085389c59a1a7af7c4067a9b" category="cell">100 TB FlexVol Volume oder mehr mit FlexGroup Volume</block>
  <block id="b4fb1d41fedaec79072964cbb4d16e3d" category="cell">Maximale Datastore-Dateigröße</block>
  <block id="d10549beb2f7bd1e91e5ef8965edd84a" category="cell">62 TB</block>
  <block id="18301e675ce7d51c23071d7b135edbdc" category="cell">62 TB mit ONTAP 9.12.1P2 und höher</block>
  <block id="9aa56a79640231adaec83bc53e59c929" category="cell">Optimale „Queue depth“ pro LUN oder Filesystem</block>
  <block id="c7dfde106afbb4e1d55096403af252e0" category="cell">64-256</block>
  <block id="ca6e77250a239af7b4aed9a1ac058825" category="cell">Autonegotiation Ist Eingeschaltet</block>
  <block id="bad19bc2587cd465cab5cec5a13aa306" category="cell">Siehe NFS.MaxQueueDepth in<block ref="0391a4aaf03ed2bf80fb4efb215797d0" category="inline-link-rx"></block>.</block>
  <block id="edc5121cb9b42a76b718b8ece9d67437" category="paragraph">In der folgenden Tabelle sind die unterstützten Funktionen in Bezug auf VMware Storage aufgeführt.</block>
  <block id="6c1a84b789b54fd42511ce582be94d21" category="cell">VMotion</block>
  <block id="e95b58d02782c970bb339c6cc587ff39" category="cell">Storage vMotion</block>
  <block id="0486e0e3dc3e86859f43b6d8e32b8071" category="cell">VMware HA</block>
  <block id="8be6bd7f20474cbefdd496cb9fd495ca" category="cell">Storage Distributed Resource Scheduler (SDRS)</block>
  <block id="4244919a64848265426dfd82a14f8248" category="cell">VMware vStorage APIs for Data Protection (VADP)-fähige Backup-Software</block>
  <block id="28c2f8ab9cdbf296aa4261bc3c58ba0d" category="cell">Microsoft Cluster Service (MSCS) oder Failover Clustering in einer VM</block>
  <block id="01a9a3b8d0fcae3055dc91935e8ec6c6" category="cell">Ja*</block>
  <block id="aa7f77e663b832d5b0e544c5511e680c" category="cell">Nicht unterstützt</block>
  <block id="aa18abedec09bd4f85e612c307e2eaa6" category="cell">Fehlertoleranz</block>
  <block id="bfd52522de4ac6efd6f680e0e754eeb5" category="cell">Site Recovery Manager</block>
  <block id="d6407966cf588d8d78d4f7e65f1ea6fd" category="cell">Nur V3**</block>
  <block id="17d495427086fa21259b9df40b27e00a" category="cell">VMs (virtuelle Festplatten) mit Thin Provisioning</block>
  <block id="4ee7af004efef335d6a14c60ee758f5e" category="cell">Ja.
Diese Einstellung ist der Standard für alle VMs im NFS, wenn nicht VAAI verwendet wird.</block>
  <block id="13bc264ff420559de4156ec40980a4b9" category="cell">Natives VMware Multipathing</block>
  <block id="50ed43e1a7a22335069a344bc706b600" category="cell">Ja, Verwendung des neuen High Performance Plug-ins (HPP)</block>
  <block id="a06819d91a165d0491c5816c54b41234" category="paragraph">In der folgenden Tabelle werden die unterstützten ONTAP Storage-Managementfunktionen aufgeführt.</block>
  <block id="f8d61013f1a3bbf1342f4ced3279c7cf" category="cell">Datendeduplizierung</block>
  <block id="72167540968147afed9deb59f0e9fe00" category="cell">Einsparungen im Array</block>
  <block id="9a5473a6abaea16b736f096913a749be" category="cell">Einsparungen im Datastore</block>
  <block id="6cd880eabbec3488232c6cba3fbcf998" category="cell">Thin Provisioning</block>
  <block id="5caeb11c4ed379b808d7f7cdca7cfbf0" category="cell">Datenspeicher oder RDM</block>
  <block id="8a5227cc82d14862956938caffc1acf2" category="cell">Datenspeicher</block>
  <block id="b71ba22dcd42deceac87150206f7bd12" category="cell">Datenspeichergröße ändern</block>
  <block id="c6b792bfd7aac8067d36337e67d11545" category="cell">Erweitern Sie nur</block>
  <block id="29e23534878bb63341e0b689426b7fb0" category="cell">Vergrößerung, Autogrow und Verkleinerung</block>
  <block id="76021405cc62a4b8c542e7f65e3d24ed" category="cell">SnapCenter Plug-ins für Windows, Linux Applikationen (in Gast-BS)</block>
  <block id="c0b3c629432c82a9e8500242abb35eaf" category="cell">Monitoring und Host-Konfiguration mit ONTAP Tools für VMware vSphere</block>
  <block id="5a915a8215e9a66bcff0f034e8adff18" category="cell">Bereitstellung mit ONTAP Tools für VMware vSphere</block>
  <block id="6495c7cda42bf1b80bc1c2af6166ef58" category="paragraph">In der folgenden Tabelle sind die unterstützten Backup-Funktionen aufgeführt.</block>
  <block id="ad336d1fccea3e918d07055edac855a3" category="cell">ONTAP Snapshots</block>
  <block id="bf22a1b5bc2b72a75825094826a942de" category="cell">Durch replizierte Backups unterstütztes SRM</block>
  <block id="60d3f7d9f265eb34e826da352cb545be" category="cell">Volume SnapMirror</block>
  <block id="fabf31a57c142c986c5d88cb089b3d7b" category="cell">VDMK Image-Zugriff</block>
  <block id="40b655e79545b3922b8095be28d59428" category="cell">VADP fähige Backup-Software</block>
  <block id="8215e73d220182794dfbd75ad494c727" category="cell">VADP fähige Backup-Software, vSphere Client und vSphere Web Client Datastore-Browser</block>
  <block id="d7605580ecad0fcb4528789d74cdcad5" category="cell">VDMK-Zugriff auf Dateiebene</block>
  <block id="906ece32da286d6c4b323bc0d6443b7c" category="cell">VADP fähige Backup-Software, nur Windows</block>
  <block id="d17e2fa63a62622f88bf170612132383" category="cell">VADP fähige Backup-Software und Applikationen von Drittanbietern</block>
  <block id="4e3d259d82a536e12c5c9c948b62e26a" category="cell">NDMP-Granularität</block>
  <block id="90d45e02e50c81603c36a4e4ad3649d9" category="cell">Datastore oder VM</block>
  <block id="8339c514e73f5cced3b83d504d60441b" category="inline-link">Einrichtung für Windows Server Failover Clustering</block>
  <block id="45f7e6f7f6f0f4093754d7d48810e17f" category="paragraph">*NetApp empfiehlt für Microsoft Cluster die Verwendung von in-Guest iSCSI anstelle von Multiwriter-fähigen VMDKs in einem VMFS Datastore. Dieser Ansatz wird von Microsoft und VMware vollständig unterstützt. Er bietet mit ONTAP ein hohes Maß an Flexibilität (SnapMirror auf ONTAP Systeme vor Ort oder in der Cloud), lässt sich leicht konfigurieren und automatisieren und kann mit SnapCenter gesichert werden. In vSphere 7 wurde eine neue Clustered VMDK-Option hinzugefügt. Dies unterscheidet sich von VMDKs mit mehreren Schreibenden, die einen Datenspeicher benötigen, der über das FC-Protokoll bereitgestellt wird, für das die Unterstützung für geclusterte VMDK aktiviert ist. Weitere Einschränkungen sind möglich. VMware's ansehen<block ref="b158594c147457b5b6417413cb30f800" category="inline-link-rx"></block> Dokumentation für Konfigurationsrichtlinien.</block>
  <block id="e2bd40041a6472b580305ce9017b0b2e" category="paragraph">**Datastores mit NVMe-of und NFS v4.1 erfordern die vSphere Replizierung. Array-basierte Replizierung wird von SRM nicht unterstützt.</block>
  <block id="54b3e11ce37eaaa9884f4086e72dd2be" category="section-title">Auswahl eines Storage-Protokolls</block>
  <block id="4bbd62e7748dbf2416c644698342b5f9" category="paragraph">Systeme mit ONTAP Software unterstützen alle wichtigen Storage-Protokolle, sodass die Kunden das für ihre Umgebung am besten geeignete Protokoll auswählen können. Dies hängt von der vorhandenen und geplanten Netzwerkinfrastruktur und den Fähigkeiten der Mitarbeiter ab. Bei von NetApp durchgeführten Tests zeigten sich generell nur geringfügige Unterschiede zwischen Protokollen, die mit ähnlichen Übertragungsgeschwindigkeiten ausgeführt wurden. Daher empfiehlt es sich, den Schwerpunkt in erster Linie auf die Netzwerkinfrastruktur und die Fähigkeiten der Mitarbeiter und erst in zweiter Linie auf die ursprüngliche Protokoll-Performance zu legen.</block>
  <block id="0212b4e8bc965dcd8a7ff771dd96bf21" category="paragraph">Die folgenden Faktoren könnten bei Überlegungen zur Auswahl eines Protokolls hilfreich sein:</block>
  <block id="0425ddb6dbbe7f13280e19e1f925b0a8" category="list-text">*Gegenwärtige Kundenumgebung.* Obwohl IT-Teams normalerweise erfahren sind, um Ethernet IP-Infrastrukturen zu managen, sind nicht alle erfahren im Management einer FC SAN Fabric. Die Nutzung eines nicht auf Storage-Traffic ausgelegten dedizierten IP-Netzwerks ist jedoch unter Umständen keine gute Lösung. Berücksichtigen Sie Ihre vorhandene Netzwerkinfrastruktur, alle geplanten Optimierungen sowie die Fähigkeiten und die Verfügbarkeit von Mitarbeitern, die diese managen.</block>
  <block id="774f1348caf3e145710073eb634c4fa1" category="list-text">*Einfache Einrichtung.* über die Erstkonfiguration der FC-Fabric hinaus (zusätzliche Switches und Kabel, Zoning und die Verifizierung der Interoperabilität von HBA und Firmware) müssen Blockprotokolle auch LUNs erstellen und zuordnen sowie vom Gastbetriebssystem Erkennung und Formatierung vornehmen. Nach der Erstellung und dem Export der NFS-Volumes werden sie vom ESXi Host gemountet und sind dann betriebsbereit. Für NFS sind keine besonderen Hardwarequalifizierungen oder Firmware für das Management erforderlich.</block>
  <block id="bf5169ce5bb544313eaf17435f756da2" category="list-text">*Einfaches Management.* bei SAN-Protokollen sind bei Bedarf mehrere Schritte erforderlich, darunter das Vergrößern einer LUN, das erneute Erkennen der neuen Größe und das Anwachsen des Dateisystems). Obwohl eine LUN vergrößert werden kann, ist eine Reduzierung der Größe einer LUN nicht möglich. Auch das Recovery von ungenutztem Speicherplatz kann weiteren Aufwand bedeuten. NFS ermöglicht eine problemlose Größenanpassung, die durch das Storage-System automatisiert werden kann. SAN bietet über TRIM/UNMAP-Befehle des Gast-Betriebssystems eine Speicherplatzrückgewinnung, sodass Speicherplatz aus gelöschten Dateien an das Array zurückgegeben werden kann. Diese Art der Rückgewinnung von ungenutztem Speicherplatz ist bei NFS-Datenspeichern schwieriger.</block>
  <block id="530c759326761c6ac026b313985b255f" category="list-text">*Storage-Speicherplatztransparenz.* die Storage-Auslastung ist in NFS-Umgebungen in der Regel einfacher zu erkennen, da Thin Provisioning unmittelbare Einsparungen ermöglicht. In ähnlicher Form sind Einsparungen durch Deduplizierung und Klonen unmittelbar für andere VMs im selben Datastore oder für Storage-System-Volumes verfügbar. Die VM-Dichte ist typischerweise ebenfalls größer als in einem NFS-Datastore. Hierdurch können höhere Einsparungen bei der Deduplizierung sowie eine Senkung der Managementkosten erzielt werden, da weniger Datastores gemanagt werden müssen.</block>
  <block id="16ee928b12bc598bf52b0f312879ec95" category="section-title">Datenspeicher-Layout</block>
  <block id="b9890b64f7b9790ea1e078227efacfa2" category="paragraph">ONTAP Storage-Systeme bieten beim Erstellen von Datastores für VMs und virtuelle Festplatten ein hohes Maß an Flexibilität. Obwohl viele ONTAP Best Practices angewendet werden, wenn Datastores für vSphere mit VSC bereitgestellt werden (siehe Abschnitt) <block ref="ef37ab860d90e747aecd96bae9ce8d8d" category="inline-link-macro-rx"></block>), hier sind einige zusätzliche Richtlinien zu berücksichtigen:</block>
  <block id="b8c499c7b537f5bd4e51b0a6d6a1e9d0" category="list-text">Der Einsatz von vSphere mit ONTAP-NFS-Datastores sorgt für eine hochperformante, einfach zu managende Implementierung mit VM/Datastore-Verhältnissen, die mit blockbasierten Storage-Protokollen nicht erreicht werden können. Diese Architektur kann zu einer Verzehnfachung der Datastore-Dichte und einer damit korrelierenden Verringerung der Datastore-Anzahl führen. Obwohl ein größerer Datastore die Storage-Effizienz begünstigen und betriebliche Vorteile bieten ONTAP kann, sollten Sie mindestens vier Datastores (FlexVol Volumes) verwenden. Durch die Verteilung der Datastores auf die Controller kann so die bestmögliche Ausnutzung der Hardware gewährleistet werden. Mit diesem Ansatz können Sie auch Datastores mit unterschiedlichen Recovery-Richtlinien erstellen. Einige können je nach den geschäftlichen Anforderungen häufiger gesichert oder repliziert werden als andere. Da FlexGroup Volumes eine Skalierung pro Design durchführen, sind für mehrere Datastores nicht erforderlich.</block>
  <block id="e15ed0ec7af4278259b7618024b3e7ce" category="list-text">NetApp empfiehlt die Verwendung von FlexVol Volumes für die meisten NFS-Datastores. Ab ONTAP 9.8 werden FlexGroup Volumes auch für die Nutzung als Datastores unterstützt und für bestimmte Anwendungsfälle im Allgemeinen empfohlen. Andere ONTAP Storage-Container wie qtrees werden im Allgemeinen nicht empfohlen, da diese derzeit weder durch ONTAP Tools für VMware vSphere noch durch das NetApp SnapCenter Plug-in für VMware vSphere unterstützt werden. Indessen könnte die Implementierung von Datastores als mehrere qtrees in einem einzelnen Volume in hoch automatisierten Umgebungen nützlich sein, die von Kontingenten auf Datastore-Ebene oder VM-Dateiklonen profitieren können.</block>
  <block id="dc4d78be836807b32c7ef7f42028b1ef" category="list-text">Eine gute Größe für einen FlexVol Volume-Datastore liegt bei etwa 4 TB bis 8 TB. Diese Größe bildet einen guten Ausgleichspunkt im Hinblick auf Performance, einfaches Management und Datensicherung. Beginnen Sie mit einem kleinen Datastore (beispielsweise 4 TB) und vergrößern Sie diesen nach Bedarf (bis auf maximal 100 TB). Kleinere Datenspeicher lassen sich nach einem Backup oder nach einem Ausfall schneller wiederherstellen und können schnell im Cluster verschoben werden. Die automatische Größenanpassung von ONTAP kann sinnvoll sein, um das Volume bei wechselnder Speicherplatzbelegung automatisch zu vergrößern oder zu verkleinern. Der ONTAP Tools für die Bereitstellung von VMware vSphere Datastores verwendet Autosize standardmäßig für neue Datastores. Eine weitere Anpassung der Vergrößerungs- und Verkleinerungsschwellenwerte sowie der maximalen und minimalen Größe kann mit System Manager oder über die Befehlszeile erfolgen.</block>
  <block id="964a81e46088ae1cc6306072464a9d73" category="list-text">Alternativ können VMFS Datastores mit LUNs konfiguriert werden, auf die über FC, iSCSI oder FCoE zugegriffen wird. Bei VMFS können alle ESX Server in einem Cluster gleichzeitig auf herkömmliche LUNs zugreifen. VMFS Datastores können eine Größe von bis zu 64 TB haben und bestehen aus bis zu 32 2TB LUNs (VMFS 3) oder einer einzelnen 64-TB-LUN (VMFS 5). Die maximale LUN-Größe von ONTAP beträgt auf den meisten Systemen 16 TB und 128 TB auf All-SAN-Array-Systemen. Daher kann auf den meisten ONTAP Systemen ein VMFS 5 Datastore mit maximaler Größe aus vier 16-TB-LUNs erstellt werden. Für Workloads mit hohem I/O-Aufkommen und mehreren LUNs (bei High-End FAS oder AFF Systemen) können Performance-Vorteile zum Tragen kommen, allerdings werden diese durch das komplexere Management beim Erstellen, Managen und Sichern der Datastore-LUNs und ein erhöhtes Verfügbarkeitsrisiko ausgeglichen. NetApp empfiehlt im Allgemeinen, eine einzelne, große LUN für jeden Datastore zu verwenden. Und nur im Ausnahmefall, wenn größere Datastores mit über 16 TB gebraucht werden, mit Extends zu arbeiten. Analog zu dem NFS Ansatz, verteilen ONTAP Sie ebenfalls die Datastores über die Controller, um die bestmögliche Performance zu erzielen.</block>
  <block id="c74cab014e402128efd8102b941c0b0c" category="list-text">Ältere Gastbetriebssysteme (OS) mussten an das Storage-System angeglichen werden (Alignment), um die bestmögliche Performance und Storage-Effizienz zu erzielen. Bei modernen Betriebssystemen mit Anbieterunterstützung von Microsoft und Linux Distributoren wie Red hat sind jedoch keine Anpassungen mehr erforderlich, um die Filesystem-Partition mit den Blöcken des zugrunde liegenden Storage-Systems in einer virtuellen Umgebung zu alignen. Wenn Sie ein altes Betriebssystem verwenden, für das unter Umständen ein Alignment erforderlich ist, suchen Sie in der NetApp Support Knowledgebase nach Artikeln, in denen das Thema VM Alignment behandelt wird, oder fordern Sie bei einem NetApp Ansprechpartner für den Vertrieb oder für Partner ein Exemplar des technischen Berichts TR-3747 an.</block>
  <block id="8c761039ef4dd69451490b849ace1f82" category="list-text">Vermeiden Sie die Verwendung von Defragmentierungsprogrammen innerhalb des Gast-Betriebssystems, da dies keinen Performance-Vorteil bietet und die Speichereffizienz und Snapshot-Speicherplatznutzung beeinträchtigt. Zudem sollten Sie die Suchindizierung im Gastbetriebssystem für virtuelle Desktops deaktivieren.</block>
  <block id="14abb814748566a24367c4459a54840b" category="list-text">ONTAP ist eines der branchenweit führenden Unternehmen mit innovativen Storage-Effizienzfunktionen, mit denen Sie Ihren nutzbaren Festplattenspeicherplatz maximal ausschöpfen können. AFF Systeme sind durch Inline-Deduplizierung und -Komprimierung sogar noch effizienter. Die Daten werden über alle Volumes hinweg in einem Aggregat dedupliziert. Daher müssen zur Maximierung der Einsparungen keine ähnlichen Betriebssysteme und ähnlichen Applikationen in einem einzelnen Datastore mehr gruppieren.</block>
  <block id="446548f2b1301893641e29657fc7fe53" category="inline-link-macro">Oracle-Datenbanken auf ONTAP</block>
  <block id="9016fa494b85853dca561abb922d08d1" category="list-text">In einigen Fällen benötigen Sie eventuell nicht einmal einen Datastore. Um die beste Performance und ein optimales Management zu erzielen, sollten Sie für Applikationen mit hohem I/O-Aufkommen – beispielsweise für Datenbanken und bestimmte Applikationen – keinen Datastore verwenden. Hier sind „inguest“-Ansätze via NFS oder iSCSI in Erwägung zu ziehen, die vom Gastbetriebssystem verwaltet werden oder via Raw Device Mapping (RDM). Eine Anleitung zu bestimmten Applikationen finden Sie in den technischen Berichten von NetApp für die jeweilige Applikation. Beispiel: <block ref="30827df672931d7ec1b01fc09c87df4e" category="inline-link-macro-rx"></block> Ein Abschnitt zur Virtualisierung mit hilfreichen Details.</block>
  <block id="6cda576d2fd323c1a728b7ac67d6034f" category="list-text">Festplatten der ersten Klasse (oder verbesserte virtuelle Festplatten) ermöglichen über vCenter gemanagte Festplatten unabhängig von einer VM mit vSphere 6.5 und höher. Sie werden zwar primär durch API gemanagt, sind aber auch mit VVols nützlich, insbesondere bei dem Management mit OpenStack oder Kubernetes-Tools. Sie werden von ONTAP unterstützt sowie ONTAP Tools für VMware vSphere.</block>
  <block id="71318121439b39fdf872bb0bd57494f2" category="section-title">Datastore und VM-Migration</block>
  <block id="e8824ce2062c6d1fc536163f7b8940bd" category="paragraph">Wenn Sie VMs aus einem bestehenden Datastore in einem anderen Storage-System zu ONTAP migrieren, sollten Sie die folgenden Praktiken berücksichtigen:</block>
  <block id="73b729fbc964c7d78dd90b64aaaeb785" category="list-text">Verwenden Sie Storage vMotion, um den Großteil Ihrer Virtual Machines in ONTAP zu verschieben. Dieser Ansatz ermöglicht nicht nur einen unterbrechungsfreien Betrieb der VMs, sondern auch die Nutzung von ONTAP Storage-Effizienzfunktionen wie Inline-Deduplizierung und -Komprimierung zur Verarbeitung der Daten während der Migration. Es empfiehlt sich unter Umständen, mithilfe von vCenter Funktionen mehrere VMs aus der Bestandsliste auszuwählen und die Migration dann zu einem geeigneten Zeitpunkt zu planen (dazu klicken Sie mit gedrückter Strg-Taste auf „Actions“).</block>
  <block id="e512c890754c686d8deccac97d84a290" category="list-text">Sie können eine Migration auf geeignete Ziel-Datastores zwar genau planen, doch es ist oft einfacher, große Datenmengen zu migrieren und diese anschließend nach Bedarf zu organisieren. Vielleicht möchten Sie diesen Ansatz nutzen, um Ihre Migration in verschiedene Datastores zu steuern, wenn Sie spezielle Datensicherungsanforderungen, z. B. unterschiedliche Snapshot Zeitpläne, haben.</block>
  <block id="616b2180a0659911fed5aa758dba722c" category="list-text">Die meisten VMs und deren Storage können im Betrieb (eingeschalteter Zustand) migriert werden. Attached Storage (nicht im Datastore) – beispielsweise in Form von ISOs, LUNs oder NFS-Volumes – aus einem anderen Storage-System muss jedoch unter Umständen im ausgeschalteten Zustand migriert werden.</block>
  <block id="fbb88da5639930a05f510729e473a216" category="inline-link">TR-4534</block>
  <block id="096f2185af16e07c387a7fbe50df957a" category="list-text">Virtual Machines, bei denen eine präzisere Migration erforderlich ist, sind unter anderem Datenbanken und Applikationen mit Nutzung von Attached Storage. Bei diesen sollten Sie die Migration im Allgemeinen mit den Applikationstools managen. Für Oracle empfiehlt sich zur Migration der Datenbankdateien die Nutzung von Oracle-Tools wie RMAN oder ASM. Siehe<block ref="6b3f565e7a7ce633fa62f4114c295216" category="inline-link-rx"></block> Finden Sie weitere Informationen. Ganz ähnlich kommen für SQL Server entweder SQL Server Management Studio oder NetApp Tools wie SnapManager für SQL Server oder SnapCenter in Betracht.</block>
  <block id="09485b54473eee31422696bf0217d714" category="paragraph">Wenn Sie vSphere mit ONTAP verwenden, ist es eine Best Practice, die ONTAP Tools für VMware vSphere Plug-in (ehemals Virtual Storage Console) zu installieren und zu verwenden. Dieses vCenter Plug-in vereinfacht das Storage-Management, erhöht die Verfügbarkeit und senkt die Storage-Kosten und den Betriebsaufwand – sei es bei SAN oder bei NAS. Dieses Plug-in nutzt Best Practices für die Bereitstellung von Datastores und optimiert die ESXi Hosteinstellungen für Multipath- und HBA-Timeouts (diese sind in Anhang B beschrieben). Da es sich um ein vCenter Plug-in handelt, ist es für alle vSphere Webclients verfügbar, die eine Verbindung mit dem vCenter Server herstellen.</block>
  <block id="9fb2cc2ced88ce872ef16c37d8284360" category="paragraph">Das Plug-in hilft Ihnen auch bei der Nutzung anderer ONTAP Tools in vSphere Umgebungen. Damit können Sie das NFS-Plug-in für VMware VAAI installieren, das einen Copy-Offload zu ONTAP für VM-Klonvorgänge, eine Speicherplatzreservierung für Thick Virtual Disk Files und ONTAP Snapshot Offload ermöglicht.</block>
  <block id="2e0fa230911ceec131e12fe7c87fc01e" category="paragraph">Das Plug-in ist auch die Managementoberfläche für viele Funktionen von VASA Provider für ONTAP und unterstützt das richtlinienbasierte Storage-Management mit VVols. Nach der Registrierung von ONTAP Tools für VMware vSphere erstellen Sie damit Storage-Funktionsprofile, ordnen diesen Storage zu und stellen im Laufe der Zeit die Datastore-Compliance mit den Profilen sicher. Vasa Provider verfügt auch über eine Schnittstelle zum Erstellen und Managen von vVol Datastores.</block>
  <block id="9baea886f208a41896164d4ade5b3fde" category="paragraph">Im Allgemeinen empfiehlt NetApp zur Bereitstellung herkömmlicher und VVols Datastores die Verwendung der ONTAP Tools für die Schnittstelle VMware vSphere in vCenter, um die Einhaltung von Best Practices sicherzustellen.</block>
  <block id="6161d374e9022f89382fd63b4be15aa1" category="section-title">Allgemeines Networking</block>
  <block id="f0cd6847f2a7a0773ad0b58d0f9dc67d" category="paragraph">Wenn Sie vSphere mit Systemen mit ONTAP Software verwenden, ist die Konfiguration von Netzwerkeinstellungen einfach und erfolgt ähnlich wie andere Netzwerkkonfigurationen. Folgende Punkte sind dabei zu berücksichtigen:</block>
  <block id="c7949782ad094d3ffc126bee722642a3" category="list-text">Verwenden Sie Switches, die die Link-Aggregation von Ports in zwei separaten Switch-Chassis durch einen Ansatz mit einer Multi-Chassis-Link-Aggregationsgruppe wie Virtual PortChannel (vPC) von Cisco unterstützen.</block>
  <block id="9dc1904e0c3ace141704b477cd9b345d" category="inline-link">Netzwerkmanagement</block>
  <block id="68ecdb0d7a96e68318a53d12e9fab5b5" category="list-text">Erstellen Sie mit LACP Link-Aggregate für ONTAP Storage-Systeme mit dynamischen Multimode-Schnittstellengruppen mit Port- oder IP-Hash. Siehe<block ref="b87480ad0ff34784c4be1445a72a3aaf" category="inline-link-rx"></block> Für weitere Hinweise.</block>
  <block id="3b407fe7c9654197902b1dd26af6dc81" category="list-text">Verwenden Sie eine IP-Hash-Teaming-Richtlinie für ESXi bei Verwendung von statischer Link-Aggregation (z. B. EtherChannel) und Standard-vSwitches oder LACP-basierter Link-Aggregation mit vSphere Distributed Switches. Wenn die Link-Aggregation nicht verwendet wird, verwenden Sie stattdessen „Weiterleiten basierend auf der ursprünglichen virtuellen Port-ID“.</block>
  <block id="ee1ef6cf0f3971b44eb2abcac958fb8d" category="section-title">FlexGroup Volumes</block>
  <block id="bf985cdd1506d49ea0773c8997e0b723" category="paragraph">ONTAP 9.8 bietet zusätzlich Unterstützung für FlexGroup Volume Datastores in vSphere und unterstützt außerdem ONTAP Tools für VMware vSphere sowie ein SnapCenter Plug-in für VMware vSphere. FlexGroup vereinfacht die Erstellung großer Datastores und erstellt automatisch eine Reihe von zusammengehörigen Volumes, um die maximale Performance eines ONTAP Systems zu erreichen. Verwenden Sie FlexGroup zusammen mit vSphere, wenn Sie einen einzelnen, skalierbaren vSphere-Datastore mit der Leistung eines vollständigen ONTAP Clusters benötigen oder bei sehr umfangreichen Klon-Workloads von dem neuen FlexGroup Klonmechanismus profitieren möchten.</block>
  <block id="83bcea036e70c0f011b083b2325b7a4b" category="paragraph">Neben umfangreichen Systemtests mit vSphere Workloads bietet ONTAP 9.8 auch einen neuen Offload-Mechanismus für FlexGroup Datastores. Sie verwendet eine aktualisierte Kopie-Engine, die die ersten Klone verwendet, um einen lokalen Cache in jedem einzelnen Volume zu füllen. Dieser lokale Cache wird dann verwendet, um VM-Klone bei Bedarf schnell instanziieren zu können.</block>
  <block id="dd9bd4a686bdeb1c7f11dc3cd0cda75f" category="paragraph">Betrachten wir das folgende Szenario:</block>
  <block id="6b277580cb59b13790b36344e827e22f" category="list-text">Sie haben eine neue FlexGroup mit 8 Komponenten erstellt</block>
  <block id="32efd8b10cc3b73c344f4c7e6c4b741e" category="list-text">Das Cache-Zeitlimit für die neue FlexGroup ist auf 160 Minuten festgelegt</block>
  <block id="879f959734466d50681eae9b95e7e591" category="paragraph">In diesem Szenario sind die ersten 8 Klone vollständig vollständige Kopien anstatt lokale Dateiklone. Für jedes weitere Klonen dieser VM vor Ablauf der 160-Sekunden-Zeitüberschreitung wird die Datei-Klon-Engine innerhalb jeder Komponente nach dem Round-Robin-Verfahren verwendet, um nahezu sofortige Kopien zu erstellen, die gleichmäßig über die einzelnen Volumes verteilt sind.</block>
  <block id="b368b4dbd46dd778776d405dc46d2033" category="paragraph">Bei jedem neuen Klonjob, der ein Volume erhält, wird die Zeitüberschreitung zurückgesetzt. Wenn ein konstituierendes Volume in der Beispiel-FlexGroup vor dem Timeout keine Klonanforderung erhält, wird der Cache für diese bestimmte VM gelöscht und das Volume muss erneut ausgefüllt werden. Wenn sich auch die Quelle des ursprünglichen Klons ändert (z. B. Sie haben die Vorlage aktualisiert), wird der lokale Cache jeder Komponente ungültig, um Konflikte zu vermeiden. Der Cache kann an die Anforderungen Ihrer Umgebung angepasst werden.</block>
  <block id="0f98175ace2dd0d56e47961b22b2544b" category="paragraph">In Umgebungen, in denen Unternehmen nicht alle Vorteile des FlexGroup Cache ausschöpfen können, aber trotzdem schnelles standortübergreifendes Klonen benötigen, ist die Verwendung von VVols eine erwägen. Das Volume-übergreifende Klonen mit VVols erfolgt viel schneller als bei herkömmlichen Datastores und ist nicht auf einen Cache angewiesen.</block>
  <block id="189aae773e13462525f07e99fcd9e90f" category="inline-link">VAAI: Wie funktioniert Caching mit FlexGroup Volumes?</block>
  <block id="718103d957da7fb9e8210a49a85aedab" category="paragraph">Weitere Informationen zur Verwendung von FlexGroups mit VAAI finden Sie in diesem KB-Artikel:<block ref="23db52497ce446299e31ecc0b7572649" category="inline-link-rx"></block></block>
  <block id="eafcbe529f542610c50d02e4a2fffcd6" category="paragraph">ONTAP 9.8 bietet außerdem neue dateibasierte Performance-Metriken (IOPS, Durchsatz und Latenz) für FlexGroup Volume-Dateien, die über das Dashboard von ONTAP Tools für VMware vSphere sowie VM-Berichte eingesehen werden können. Die ONTAP Tools für VMware vSphere Plug-in ermöglichen Ihnen darüber hinaus die Festlegung von QoS-Regeln (Quality of Service) über eine Kombination aus dem Maximum und/oder dem Minimum von IOPS. Diese können über alle VMs in einem Datenspeicher oder individuell für bestimmte VMs hinweg festgelegt werden.</block>
  <block id="b8c631b88d7be5f1105be2f8c7ff3213" category="list-text">Verwenden Sie die Standardwerte für die FlexGroup Volume-Bereitstellung. Es empfiehlt sich zwar ONTAP-Tools für VMware vSphere, da sie die FlexGroup in vSphere erstellen und gemountet werden. Zudem ist ONTAP System Manager oder die Befehlszeile kann für spezielle Anforderungen verwendet werden. Verwenden Sie selbst dann Standardwerte wie die Anzahl der konstituierenden Mitglieder pro Node, da dies mit vSphere am gründlichsten getestet wurde. Indessen werden nicht-Standardeinstellungen wie das Ändern der Anzahl oder Platzierung von Bestandteilen immer noch vollständig unterstützt.</block>
  <block id="301593c45668093a7eb242d138c597a3" category="list-text">Bei der Größenbestimmung eines FlexGroup-basierten Datenspeichers beachten Sie, dass die FlexGroup aus mehreren kleineren FlexVol Volumes besteht, die einen größeren Namespace erstellen. Wenn Sie daher eine FlexGroup mit acht Komponenten verwenden, sollten Sie den Datenspeicher mindestens die achtfache Größe Ihrer größten Virtual Machine festlegen. Wenn Sie beispielsweise eine 6-TB-VM in Ihrer Umgebung haben, geben Sie der FlexGroup-Datenspeicher die Größe nicht kleiner als 48 TB an.</block>
  <block id="6d9993f47e7802210a05453f494513bf" category="list-text">VMware und NetApp unterstützen derzeit keinen gemeinsamen Ansatz für Multipath-Netzwerke. Bei NFSv4.1 unterstützt NetApp pNFS, während VMware das Session-Trunking unterstützt. NFSv3 unterstützt nicht mehrere physische Pfade zu einem Volume. Für FlexGroup mit ONTAP 9.8 empfiehlt sich als Best Practice, die FlexGroup von den ONTAP Tools für VMware vSphere erstellen zu lassen. Danach sollten Sie sie abmounten und mithilfe von Round Robin DNS neu einbinden, um die Last über den Cluster zu verteilen. ONTAP Tools verwenden beim Mounten von Datastores nur eine LIF. Nach dem erneuten Mounten des Datastore können ONTAP Tools zur Überwachung und zum Management verwendet werden.</block>
  <block id="04cc9e0b9478cc704d42735886027630" category="list-text">Nutzen Sie das NFS-Plug-in für VMware VAAI für den Offloaded Data Transfer. Beachten Sie, dass das Klonen innerhalb eines FlexGroup-Datastore verbessert wird, wie bereits erwähnt, aber ONTAP beim Kopieren von VMs zwischen FlexVol und/oder FlexGroup Volumes keine wesentlichen Performance-Vorteile gegenüber ESXi Hostkopien bietet. Berücksichtigen Sie daher beim Einsatz von VAAI oder FlexGroups Ihre Klon-Workloads. Die Änderung der Anzahl zusammengebender Volumes ist eine Möglichkeit zur Optimierung des FlexGroup-basierten Klonens. Ebenso wie die Anpassung der Cache-Zeitüberschreitung.</block>
  <block id="b9e0a0134c0815e50bb71d8dd7e367b6" category="list-text">QoS (max./min. IOPS) kann auf einzelnen VMs oder auf allen VMs zu diesem Zeitpunkt in einem Datenspeicher festgelegt werden. Die Festlegung der QoS auf allen VMs ersetzt alle separaten Einstellungen pro VM. Einstellungen erweitern nicht auch künftig auf neue oder migrierte VMs. Sie können entweder QoS auf den neuen VMs festlegen oder QoS neu auf alle VMs im Datastore anwenden. Auch folgen die QoS-Richtlinien von FlexGroup nicht der VM, wenn sie in einen anderen Datastore migriert werden. Dies steht im Gegensatz zu VVols, die ihre QoS-Richtlinieneinstellungen beibehalten können, wenn sie zu einem anderen Datastore migriert werden.</block>
  <block id="1133ff8355478000111c8b1969e32770" category="list-text">Das SnapCenter Plug-in für VMware vSphere Version 4.4 und höher unterstützt das Backup und die Recovery von VMs in einem FlexGroup Datastore auf dem primären Storage-System. SCV 4.6 bietet SnapMirror Unterstützung für FlexGroup-basierte Datastores.</block>
  <block id="ce4df831657d2621e80bbef9271c33cd" category="summary">Seit dem Übergang von der älteren virtuellen Appliance bieten ONTAP Tools zahlreiche neue Funktionen, höhere Limits und neue VVols Unterstützung.</block>
  <block id="45b1565c472fff4046d0f7ddbe1342f2" category="doc">Neue Funktionen mit SRM und ONTAP Tools</block>
  <block id="116d20fc387d73c8e4a86e7998913947" category="section-title">Aktuelle Versionen von vSphere und Site Recovery Manager</block>
  <block id="57359b8d2b77ce83f2e854fdd323377f" category="paragraph">Mit der Veröffentlichung von SRM 8.7 und höher sowie mit den Versionen 9.12 und höher von ONTAP Tools sind Sie nun in der Lage, VMs zu schützen, die auf VMware vSphere 8 Update 1 ausgeführt werden.</block>
  <block id="96ca6fcc2ffdab3c06d0875be8d4fe29" category="paragraph">NetApp verbindet seit nahezu zwei Jahrzehnten eine enge Partnerschaft mit VMware und ist bestrebt, die neuesten Versionen so schnell wie möglich zu unterstützen. Aktuelle Kombinationen der Software sind im NetApp Interoperabilitäts-Matrix-Tool (IMT) verfügbar.</block>
  <block id="4ada3eb5b908caaedb757052562dfcf5" category="inline-link-macro"><block ref="4ada3eb5b908caaedb757052562dfcf5" category="inline-link-rx"></block></block>
  <block id="0a0a2a299629bed81a283fcd3b7833e9" category="paragraph">Die NetApp IMT finden Sie unter <block ref="83e08b5e992bc41d59feec38bb24f26d" category="inline-link-macro-rx"></block>.</block>
  <block id="9d6e1631f68d52fd0f82222bf276cdc4" category="section-title">Unterstützung für VVols (und darum, warum Storage Policy Based Management (SPBM) wichtig ist, selbst mit SRM)</block>
  <block id="b0b7bc3c901f340c708b7560d1f2b7e1" category="paragraph">Ab Version 8.3 unterstützt SRM jetzt das auf Storage Policy Based Management (SPBM) der Replizierung mit VVols und Array-basierte Replizierung für Datastores mit iSCSI, FCP und NFS v3. Dazu wurde der SRM-Server aktualisiert und um einen neuen SRM VVols Provider-Service erweitert, der mit dem SMS-Service des vCenter Servers für VASA-bezogene Aufgaben kommuniziert.</block>
  <block id="4567f5576b4577c63b126cac3f6aa5fa" category="paragraph">Ein Vorteil dieser Architektur besteht darin, dass SRA nicht mehr benötigt wird, da alles mit VASA behandelt wird.</block>
  <block id="e04031e1cecdb6732f91d44b204dbcf3" category="paragraph">SPBM ist ein leistungsstarkes Tool in der vSphere Toolbox und bietet vereinfachte, vorhersehbare und konsistente Storage-Services für die Nutzung durch Automatisierungs-Frameworks in Private- und Hybrid-Cloud-Umgebungen. Im Grunde können Sie mit SPBM Serviceklassen definieren, die die Anforderungen Ihres vielfältigen Kundenstamms erfüllen. Mit SRM können Sie Ihren Kunden jetzt Replizierungsfunktionen für kritische Workloads bereitstellen, die eine robuste Disaster-Recovery-Orchestrierung und -Automatisierung erfordern.</block>
  <block id="1b6204fa76bd422416757c4e2d6187bd" category="paragraph">Beispiel für eine VVols-Architektur mit FCP oder iSCSI:</block>
  <block id="6f1ad7cac2af0e3b92a3936efc393a0e" category="paragraph"><block ref="6f1ad7cac2af0e3b92a3936efc393a0e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9abbd7aed7e9791d9c52e8e17f34a756" category="section-title">Unterstützung von Appliance-basierten SRM Servern</block>
  <block id="925c477f139cce0692e13946a7f75eac" category="paragraph">Photon OS-basierte SRM-Server werden jetzt zusätzlich zu älteren Windows-basierten Plattformen unterstützt.</block>
  <block id="62c2c4203aebe081ddbc6cdd489f8ad7" category="paragraph">Sie können nun SRA Adapter unabhängig vom bevorzugten SRM-Servertyp installieren.</block>
  <block id="7cb1700928c008eb817bc79250cc9002" category="section-title">IPv6 wird unterstützt</block>
  <block id="ea9aacd1495949730de8eeab11e66459" category="paragraph">IPv6 wird jetzt mit folgenden Einschränkungen unterstützt:</block>
  <block id="d6d7f3d43de975c07655ebba1936867a" category="list-text">VCenter 6.7 oder höher</block>
  <block id="eb26ee1a20fe3dbde98204ec8b3ab838" category="list-text">Nicht unterstützt mit SRM 8.2 (8.1, 8.3 und 8. 4 werden unterstützt)</block>
  <block id="918d32b75f0ab883abba3a8dc0c3ae8d" category="inline-link">Interoperabilitäts-Matrix-Tool</block>
  <block id="02e7e71042609d3158020ab7befe45c6" category="list-text">Prüfen Sie die<block ref="218f4ad7153f69cdc5467065434cd2f0" category="inline-link-rx"></block> Für die neuesten qualifizierten Versionen.</block>
  <block id="e887aed8f9c3dbecd37e8896d96b6637" category="section-title">Verbesserte Performance</block>
  <block id="2a71574e89a69c8218fbac3f604b5728" category="paragraph">Die betriebliche Performance ist eine wichtige Anforderung für die Ausführung von SRM-Aufgaben. Um die Anforderungen moderner RTOs und RPOs zu erfüllen, wurden für die SRA mit ONTAP Tools drei neue Verbesserungen hinzugefügt.</block>
  <block id="bd403c539a0c414afacd7477bf3d311f" category="list-text">*Unterstützung für gleichzeitige Reprotect-Vorgänge.* Diese Funktion wurde erstmals in SRA 9.7 eingeführt und ermöglicht die gleichzeitige Ausführung von Reprotect auf zwei oder mehr Recovery-Plänen. Dadurch verringert sich der Zeitaufwand für die erneute Sicherung von Datastores nach einem Failover oder einer Migration und bleibt innerhalb der RTO- und RPO-Parameter.</block>
  <block id="f63b947f655a5aee2cf69d4f30d7f96b" category="list-text">*ONTAP Tools 9.8 fügt einen neuen nur für NAS optimierten Modus hinzu.* Wenn Sie SVM-Scoped-Konten und Verbindungen zu ONTAP-Clustern mit nur NFS-basierten Datastores verwenden, können Sie nur für NAS optimierten Modus für Spitzen-Performance in unterstützten Umgebungen aktivieren.</block>
  <block id="c82379d922d9cdc55fa21affe9f9b8bf" category="list-text">*Die ONTAP Tools 9.12 bieten jetzt Unterstützung für die Funktion zur schnellen Resync von ONTAP.* Dies ermöglicht eine schnelle Resynkronisierung der Spiegel unter dem Aspekt, dass nach dem Prozess die Storage-Einsparungen neu berechnet werden müssen. Diese Funktion wird standardmäßig nicht verwendet, kann aber in großen Umgebungen aktiviert werden, in denen die herkömmliche Resynchronisierung zu lange dauert oder ein Timing-Out stattfindet.</block>
  <block id="4a4842d7448ef71eb69b013e560b18bb" category="section-title">Besser skalieren</block>
  <block id="26738e8d40ae8035805f13bdbf185c30" category="paragraph">Die ONTAP-Tools SRA unterstützt jetzt bei der Verwendung mit SRM 8.3 und höher bis zu 500 Schutzgruppen (PGS).</block>
  <block id="96cb4d41ca97bd9d3d446984d3170a57" category="paragraph">Eine lang erwartete und viel erwartete neue Funktion ist SnapMirror Synchronous (SM-S) mit ONTAP 9.5 und höher, die eine granulare Band RPO Datenreplizierungslösung für Ihre geschäftskritischen Anwendungen liefert. SM-S erfordert ONTAP-Tools 9.8 oder höher.</block>
  <block id="b9832b10a87d0c3793ed3b413ee1d839" category="section-title">REST-API-Unterstützung</block>
  <block id="0065ce57adc813187a8e9c640ba6223a" category="paragraph">Die SRA Serverkonfiguration kann jetzt durch REST-APIs gemanagt werden. Eine Swagger UI wurde hinzugefügt, um Sie beim Erstellen Ihrer Automatisierungs-Workflows zu unterstützen. Sie finden sie auf Ihrer ONTAP-Tools-Appliance unter<block ref="579ce3ee0a7c1521f3dce6a507ea64a0" prefix=" " category="inline-code"></block>.</block>
  <block id="dcaf091737df278b1b4bdd2e37c10a75" category="summary">Seit seiner Einführung ins moderne Datacenter im Jahr 2002 ist NetApp ONTAP eine der führenden Storage-Lösungen für VMware vSphere Umgebungen und wird kontinuierlich mit innovativen Funktionen erweitert, die das Management vereinfachen und gleichzeitig die Kosten senken.</block>
  <block id="0a0e655ee9ba6467857ebf014a268f29" category="doc">VMware Site Recovery Manager mit NetApp ONTAP</block>
  <block id="60398bdc931fc67a9b6d781434c3a15a" category="section-title">ONTAP für vSphere</block>
  <block id="5bdb12cbb14efa98a61e7c5e3b4de108" category="admonition">Diese Dokumentation ersetzt den zuvor veröffentlichten technischen Bericht _TR-4900: VMware Site Recovery Manager mit ONTAP_</block>
  <block id="7659430738ccf1c5b8c8084a4003c709" category="paragraph">Seit seiner Einführung ins moderne Datacenter im Jahr 2002 ist NetApp ONTAP eine der führenden Storage-Lösungen für VMware vSphere Umgebungen und wird kontinuierlich mit innovativen Funktionen erweitert, die das Management vereinfachen und gleichzeitig die Kosten senken. Dieses Dokument enthält eine Einführung in die ONTAP Lösung für VMware Site Recovery Manager (SRM), die branchenführende VMware Software für Disaster Recovery (DR), sowie in die neuesten Produktinformationen und Best Practices zur Optimierung der Bereitstellung, Risikominderung und Vereinfachung des fortlaufenden Managements.</block>
  <block id="e3445c3aa798f5ad98665e33d34dd952" category="paragraph">Andere Dokumente wie Leitfäden und Kompatibilitäts-Tools werden durch Best Practices ergänzt. Sie werden basierend auf Labortests und umfassenden praktischen Erfahrungen der NetApp Ingenieure und Kunden entwickelt. In einigen Fällen passen empfohlene Best Practices möglicherweise nicht zu Ihrer Umgebung. Sie sind jedoch im Allgemeinen die einfachsten Lösungen, die die Anforderungen der meisten Kunden erfüllen.</block>
  <block id="10b8f80c23f8a44dfa6b10ae56d7dbe9" category="paragraph">Der Schwerpunkt dieses Dokuments liegt auf den Funktionen der neuesten Versionen von ONTAP 9, die in Verbindung mit ONTAP-Tools für VMware vSphere 9.12 (einschließlich NetApp Storage Replication Adapter [SRA] und VASA Provider [VP]) sowie VMware Site Recovery Manager 8.7 verwendet werden.</block>
  <block id="c40f8c2af56356193284f6b46865d954" category="section-title">Vorteile von ONTAP mit SRM</block>
  <block id="36c28121fc6c9b02a38c0b6c92654e9a" category="paragraph">Die NetApp Datenmanagementplattformen auf der Basis von ONTAP Software sind eine der am weitesten verbreiteten Storage-Lösungen für SRM. Die Gründe hierfür sind vielfältig: Eine sichere, hochperformante, einheitliche Protokoll-Datenmanagementplattform (NAS und SAN zusammen), die branchenweit definierte Storage-Effizienz, Mandantenfähigkeit, Quality-of-Service-Kontrollen, Datensicherung mit platzsparenden Snapshots und Replizierung mit SnapMirror bietet. Dabei werden native Hybrid-Multi-Cloud-Integrationen für die Sicherung von VMware Workloads sowie eine Fülle von Automatisierungs- und Orchestrierungs-Tools blitzschnell verfügbar.</block>
  <block id="2242b80f4627736a48c4c9a36b7428f6" category="paragraph">Wenn Sie SnapMirror für die Array-basierte Replizierung nutzen, profitieren Sie von einer der bewährten und ausgereiftesten Technologien von ONTAP. Mit SnapMirror profitieren Sie von sicheren und hocheffizienten Datentransfers, wobei nur geänderte Datenblöcke kopiert werden, nicht die gesamten VMs oder Datastores. Selbst diese Blöcke profitieren von Platzeinsparungen wie Deduplizierung, Komprimierung und Data-Compaction. Moderne ONTAP Systeme verwenden jetzt versionsunabhängiges SnapMirror für die flexible Auswahl von Quell- und Ziel-Clustern. SnapMirror hat sich tatsächlich zu einem der leistungsstärksten Tools für Disaster Recovery entwickelt.</block>
  <block id="36b04390d6103d8075862e4b825a485e" category="paragraph">Ganz gleich, ob Sie herkömmliche NFS-, iSCSI- oder Fibre Channel-Attached Datastores verwenden (jetzt mit Unterstützung für VVols Datastores) – SRM bietet Ihnen einen robusten Erstanbieter, der die besten ONTAP Funktionen für Disaster Recovery oder Planung der Datacenter-Migration und -Orchestrierung nutzt.</block>
  <block id="5d111e8a6885460b43ecf1f7abb6377e" category="section-title">Wie SRM ONTAP 9 nutzt</block>
  <block id="16d4ec242c9f020f3a1fade311c776ed" category="paragraph">SRM nutzt die erweiterten Datenmanagement-Technologien von ONTAP Systemen. Die Integration mit ONTAP Tools für VMware vSphere, einer virtuellen Appliance mit drei Hauptkomponenten:</block>
  <block id="d54038ba1f2a04a5b5f26c96627ae3e7" category="list-text">Das vCenter Plug-in, ehemals Virtual Storage Console (VSC), vereinfacht Storage-Management- und Effizienzfunktionen, verbessert die Verfügbarkeit und senkt die Storage-Kosten und den Betriebsaufwand – sei es bei SAN oder NAS. Dieses Plug-in nutzt Best Practices für die Bereitstellung von Datastores und optimiert ESXi Hosteinstellungen für NFS- und Block-Storage-Umgebungen. Wegen all dieser Vorteile empfiehlt NetApp dieses Plug-in bei der Verwendung von vSphere bei Systemen mit ONTAP Software.</block>
  <block id="a106bb15d6dc2b11535ed4fefc81fbf4" category="list-text">Vasa Provider für ONTAP unterstützt das VMware vStorage APIs for Storage Awareness (VASA) Framework. VASA Provider verbindet vCenter Server mit ONTAP und erleichtert so die Bereitstellung und das Monitoring von VM-Storage. Es unterstützt die Unterstützung von VMware Virtual Volumes (VVols) und das Management von Storage-Funktionsprofilen (einschließlich VVols Replizierungsfunktionen) und der individuellen VM VVols Performance. Außerdem gibt es Alarme zur Überwachung der Kapazität und der Konformität mit den Profilen. In Verbindung mit SRM ermöglicht der VASA Provider for ONTAP Unterstützung für VVols basierte Virtual Machines, ohne dass ein SRA Adapter auf dem SRM Server installiert werden muss.</block>
  <block id="f2007951062862f5f0d593acbb23bcb4" category="list-text">SRA wird zusammen mit SRM eingesetzt, um die Replizierung von VM-Daten zwischen Produktions- und Disaster-Recovery-Standorten bei herkömmlichen VMFS- und NFS-Datenspeichern sowie zum unterbrechungsfreien Testen von DR-Replikaten zu managen. Diese Software hilft bei der Automatisierung der Erkennungs-, Recovery- und Sicherungsaufgaben. Sie enthält sowohl eine SRA Server-Appliance als auch SRA Adapter für den Windows SRM Server und die SRM Appliance.</block>
  <block id="8ccaa60ee78ecc93c4870b3b2ad15284" category="paragraph">Nachdem Sie die SRA Adapter auf dem SRM-Server zum Schutz von Datastores außerhalb von VVols sowie zur aktivierten VVols-Replizierung in den VASA Provider-Einstellungen installiert und konfiguriert haben, können Sie mit der Aufgabe beginnen, Ihre vSphere Umgebung für die Disaster Recovery zu konfigurieren.</block>
  <block id="0a1e25166326359cd5f50d0ab83e6a37" category="paragraph">SRA und VASA Provider bieten eine Befehlszeilenschnittstelle für den SRM Server zum Managen der ONTAP FlexVols, die Ihre VMware Virtual Machines (VMs) enthalten, sowie zur SnapMirror Replizierung, die sie sichern.</block>
  <block id="38db855935949f86c5db7bfe7d49873e" category="paragraph">Ab SRM 8.3 wurde ein neuer SRM VVols Provider-Kontrollpfad in den SRM Server eingeführt, der die IT in die Lage versetzt, mit dem vCenter Server und darüber hinaus ohne SRA mit dem VASA Provider zu kommunizieren. Auf diese Weise konnte der SRM Server eine wesentlich umfassendere Kontrolle über das ONTAP Cluster nutzen als bisher möglich, da VASA eine vollständige API für eine nahtlose Integration bietet.</block>
  <block id="1c27364cc3705aff403c6ef131c347ff" category="paragraph">SRM kann Ihren DR-Plan mithilfe der proprietären NetApp FlexClone Technologie unterbrechungsfrei testen, um nahezu sofortige Klone Ihrer geschützten Datenspeicher an Ihrem DR-Standort zu erstellen. SRM erstellt eine Sandbox-Umgebung für sichere Tests, damit sowohl Ihre Organisation als auch Ihre Kunden bei einem echten Ausfall geschützt sind. So können Ihre Unternehmen sicher sein, dass bei einem Ausfall ein Failover ausgeführt werden kann.</block>
  <block id="04a8f82007ed4bec45053912a49b6f85" category="paragraph">Bei einem echten Ausfall oder sogar einer geplanten Migration können Sie mit SRM alle Last-Minute-Änderungen am Datensatz über ein letztes SnapMirror Update senden (sofern Sie dies tun). Dann wird die Spiegelung unterbrochen und der Datenspeicher wird Ihren DR-Hosts gemountet. An diesem Punkt können Ihre VMs automatisch in beliebiger Reihenfolge gemäß Ihrer vorab geplanten Strategie hochgefahren werden.</block>
  <block id="b2560426a08ae6ceb167dad2bfb5e8ae" category="section-title">SRM mit ONTAP und anderen Anwendungsfällen: Hybrid Cloud und Migration</block>
  <block id="ed4c730bd8636c27d3eaa876c63b3d45" category="inline-link">NetApp Private Storage in Equinix</block>
  <block id="b422e05bc5c6f52208b66ff51d718b9d" category="paragraph">Durch Integration Ihrer SRM-Implementierung mit erweiterten Datenmanagement-Funktionen von ONTAP lassen sich im Vergleich zu lokalen Storage-Optionen deutlich bessere Skalierungs- und Performance-Möglichkeiten erzielen. Darüber hinaus bringt sie jedoch noch mehr die Flexibilität der Hybrid Cloud. Mit der Hybrid Cloud können Sie Geld sparen, indem Sie ungenutzte Datenblöcke des High-Performance-Arrays mittels FabricPool in den bevorzugten Hyperscaler verschieben, was ein lokaler S3-Speicher wie NetApp StorageGRID sein könnte. Außerdem können Edge-basierte Systeme mit softwaredefiniertem ONTAP Select oder Cloud-basierter DR mithilfe von Cloud Volumes ONTAP (CVO) oder verwendet werden<block ref="37a666d3a37f1c4a8c4c8dba379664a4" category="inline-link-rx"></block> Um einen vollständig integrierten Storage-, Networking- und Computing-Service-Stack in der Cloud zu erstellen, führt Amazon Web Services (AWS), Microsoft Azure und Google Cloud Platform (GCP) zum Vorteil.</block>
  <block id="87a7b114355b836acefe833c497611bb" category="paragraph">Anschließend könnten Sie dank FlexClone ein Test-Failover innerhalb des Datacenters eines Cloud-Service-Providers durchführen, bei einem Storage-Platzbedarf von nahezu null. Der Schutz Ihres Unternehmens ist jetzt günstiger als je zuvor.</block>
  <block id="12d0cbcf61df7df30bf9b020f6fbb051" category="paragraph">Mit SRM können auch geplante Migrationen durchgeführt werden, indem VMs mit SnapMirror effizient von einem Datacenter in ein anderes oder sogar innerhalb desselben Datacenters übertragen werden, unabhängig davon, ob es sich um Ihr eigenes Datacenter oder über eine beliebige Anzahl an Service Providern von NetApp Partnern handelt.</block>
  <block id="160f88ca0bed5b24e94c809f4e22f1e7" category="summary">In ONTAP 9 sind die physischen Komponenten eines Clusters für Cluster-Administratoren sichtbar, sind aber für die Applikationen und Hosts, die das Cluster nutzen, nicht direkt sichtbar.</block>
  <block id="89fafdb11a7e8cd8abebb1d4df053dad" category="doc">Replizierungstopologien</block>
  <block id="be01acd2f018d38f9446f06b99ee4a2a" category="paragraph">In ONTAP 9 sind die physischen Komponenten eines Clusters für Cluster-Administratoren sichtbar, sind aber für die Applikationen und Hosts, die das Cluster nutzen, nicht direkt sichtbar. Die physischen Komponenten stellen einen Pool mit gemeinsam genutzten Ressourcen bereit, anhand dessen die logischen Clusterressourcen erstellt werden. Applikationen und Hosts greifen ausschließlich über SVMs auf Daten zu, die Volumes und LIFs enthalten.</block>
  <block id="7758fc02779ee5917b0a09ee22b52221" category="paragraph">Jede NetApp SVM wird im VMware vCenter Site Recovery Manager als Array behandelt. SRM unterstützt bestimmte Array-to-Array (oder SVM-zu-SVM) Replizierungslayouts.</block>
  <block id="58c0b55a67f4331cc49b073a7183e06c" category="paragraph">Eine einzelne VM kann aus den folgenden Gründen keine Daten besitzen – Virtual Machine Disk (VMDK) oder RDM – auf mehr als einem SRM Array:</block>
  <block id="880aeda0b58c0b30120b6319ae5f3beb" category="list-text">SRM sieht nur die SVM, nicht einen individuellen physischen Controller.</block>
  <block id="6f55124e085dbeb640e4cb8ad2c97905" category="list-text">Eine SVM kann LUNs und Volumes steuern, die mehrere Nodes in einem Cluster umfassen.</block>
  <block id="39d9903201320a83d45d3b36d512f051" category="cell">Best Practices In Sich</block>
  <block id="d86019fe4ba86b184ac71cf24a22f0c6" category="cell">Bedenken Sie bei der Ermittlung von Supportmöglichkeiten diese Regel: Um eine VM mithilfe von SRM und der NetApp SRA zu schützen, müssen alle Bestandteile der VM nur auf einer SVM vorhanden sein. Diese Regel gilt sowohl für den geschützten Standort als auch für den Recovery-Standort.</block>
  <block id="2e4472d35f80aa8b7eca52ae3dd43dc6" category="section-title">Unterstützte SnapMirror Layouts</block>
  <block id="d070ad9d8397892aa7f317cbb9046661" category="paragraph">Die folgenden Abbildungen zeigen die Szenarien des SnapMirror Beziehungs-Layouts, die von SRM und SRA unterstützt werden. Jede VM in den replizierten Volumes besitzt die Daten auf nur einem SRM Array (SVM) an jedem Standort.</block>
  <block id="39d3085abe6ccb914d8535de8a5f3e37" category="paragraph"><block ref="39d3085abe6ccb914d8535de8a5f3e37" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1ae7670cf947a397bdf6a882fbcc912a" category="paragraph"><block ref="1ae7670cf947a397bdf6a882fbcc912a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="111d3212464dba203cbd675a0338dcbc" category="paragraph"><block ref="111d3212464dba203cbd675a0338dcbc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c5dc3a606b05b41db22793ed3c1a72db" category="paragraph"><block ref="c5dc3a606b05b41db22793ed3c1a72db" category="inline-image-macro-rx" type="image"></block></block>
  <block id="86cf5bd2bdb1b1d67f8f907f41099509" category="section-title">Unterstützte Array Manager-Layouts</block>
  <block id="aacc8f18d659f75715d91a983e872233" category="paragraph">Wenn Sie in SRM Array-basierte Replizierung (ABR) verwenden, werden Schutzgruppen auf ein einzelnes Array-Paar isoliert, wie im folgenden Screenshot dargestellt. In diesem Szenario<block ref="129864522ed0e4ac80f306ecfa130ef7" prefix=" " category="inline-code"></block> Und<block ref="ec87aa7f4c8e70a139fd988f87b6549f" prefix=" " category="inline-code"></block> Werden mit Peering durchgeführt<block ref="387d04b65848414d4697f145a3782f90" prefix=" " category="inline-code"></block> Und<block ref="58bdbfcb72c2dd3d883a7ca754443a4c" prefix=" " category="inline-code"></block> Am Recovery-Standort. Sie können jedoch nur eines der beiden Array-Paare auswählen, wenn Sie eine Schutzgruppe erstellen.</block>
  <block id="68a1b289711a591ed50627014cd01ce9" category="paragraph"><block ref="68a1b289711a591ed50627014cd01ce9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1ceb46f3e1c6c7995de4ec5f05601227" category="section-title">Nicht unterstützte Layouts</block>
  <block id="611b9b35ac984f20e6594baec9181dbf" category="paragraph">Nicht unterstützte Konfigurationen beinhalten Daten (VMDK oder RDM) auf mehreren SVMs, die sich im Besitz einer individuellen VM befinden. In den folgenden Abbildungen sind<block ref="df777c4d2477e55571925353ce589f7e" prefix=" " category="inline-code"></block> Kann aus dem Grund nicht für den Schutz mit SRM konfiguriert werden<block ref="df777c4d2477e55571925353ce589f7e" prefix=" " category="inline-code"></block> Verfügt über Daten auf zwei SVMs.</block>
  <block id="5c251a65e8394fbeaf104ba1a1cad2e1" category="paragraph"><block ref="5c251a65e8394fbeaf104ba1a1cad2e1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f5f5fe64e0e9d0ae7ce2a0777d0ccf62" category="paragraph"><block ref="f5f5fe64e0e9d0ae7ce2a0777d0ccf62" category="inline-image-macro-rx" type="image"></block></block>
  <block id="69851ac8c2fa81b32799efc8522798d5" category="paragraph">Jegliche Replizierungsbeziehungen, bei denen ein einzelnes NetApp Volume von einer Quell-SVM auf mehrere Ziele in derselben SVM oder in verschiedenen SVMs repliziert wird, werden als SnapMirror Fan-out bezeichnet. Fan-out wird mit SRM nicht unterstützt. In der folgenden Abbildung ist das Beispiel dargestellt.<block ref="df777c4d2477e55571925353ce589f7e" prefix=" " category="inline-code"></block> Kann nicht für den Schutz in SRM konfiguriert werden, da es mit SnapMirror an zwei verschiedenen Standorten repliziert wird.</block>
  <block id="688890bdbdfd2d73a05a09883f3c4b40" category="paragraph"><block ref="688890bdbdfd2d73a05a09883f3c4b40" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3f88384b0d5cdcdc25895c644126c1b0" category="section-title">SnapMirror Kaskadierung</block>
  <block id="7ebde774ad43c45667d5544308a6d688" category="paragraph">SRM unterstützt keine Kaskadierung von SnapMirror Beziehungen, bei denen ein Quell-Volume auf einem Ziel-Volume repliziert wird und das Ziel-Volume ebenfalls mit SnapMirror auf einem anderen Ziel-Volume repliziert wird. In dem in der folgenden Abbildung gezeigten Szenario kann SRM nicht für das Failover zwischen mehreren Standorten verwendet werden.</block>
  <block id="2990fc44e9ba827a397e96e1c278a02a" category="paragraph"><block ref="2990fc44e9ba827a397e96e1c278a02a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8bd15e818d377a0a5cf6ebc429555f79" category="section-title">SnapMirror und SnapVault</block>
  <block id="d440734d1f5d9c6e59aa97f7cbbcd525" category="paragraph">Die NetApp SnapVault Software ermöglicht festplattenbasierte Backups von Unternehmensdaten zwischen NetApp Storage-Systemen. SnapVault und SnapMirror können in derselben Umgebung nebeneinander bestehen. SRM unterstützt jedoch nur das Failover der SnapMirror Beziehungen.</block>
  <block id="7878dfbf4b6ad3bc60d095cf89d79202" category="admonition">Die NetApp SRA unterstützt das<block ref="e7d3e049f94ce3ff8a47f209f012173d" prefix=" " category="inline-code"></block> Richtlinientyp.</block>
  <block id="883e69a285ae2d5fd23c80cd29285804" category="paragraph">SnapVault wurde für ONTAP 8.2 von Grund auf neu aufgebaut. Obwohl frühere Benutzer von Data ONTAP 7-Mode Ähnlichkeiten finden sollten, wurden in dieser Version von SnapVault wesentliche Verbesserungen vorgenommen. Eine wichtige Verbesserung ist die Möglichkeit zur Wahrung der Storage-Effizienz von Primärdaten während der SnapVault Transfers.</block>
  <block id="9bc21373e0e299579a7ac86dcd4f513d" category="paragraph">Eine wichtige Architekturänderung ist, dass SnapVault in ONTAP 9 wie bei 7-Mode SnapVault auf Volume-Ebene repliziert, nicht auf qtree-Ebene. Bei diesem Setup muss die Quelle einer SnapVault Beziehung ein Volume sein, und das Volume muss auf sein eigenes Volume auf dem sekundären SnapVault System repliziert werden.</block>
  <block id="d447048519c85a2fb3bea0790cd109fb" category="paragraph">In einer Umgebung, in der SnapVault verwendet wird, werden auf dem primären Storage-System speziell benannte Snapshots erstellt. Je nach implementierter Konfiguration können die benannten Snapshots auf dem Primärsystem nach einem SnapVault-Zeitplan oder durch eine Anwendung wie NetApp Active IQ Unified Manager erstellt werden. Die benannten Snapshots, die auf dem Primärsystem erstellt werden, werden dann auf das SnapMirror Ziel repliziert und von dort auf das SnapVault Ziel archiviert.</block>
  <block id="5dd37b7cd36f7d38ba2e6a63c603be4c" category="paragraph">Ein Quell-Volume kann in einer Kaskadenkonfiguration erstellt werden, bei der ein Volume auf ein SnapMirror Ziel am DR-Standort repliziert wird und von dort aus auf ein SnapVault Ziel verlagert wird. Ein Quell-Volume kann auch in einer Fan-out-Beziehung erstellt werden, wobei ein Ziel ein SnapMirror Ziel ist und das andere Ziel eine SnapVault Ziel ist. SRA rekonfiguriert jedoch nicht automatisch die SnapVault-Beziehung neu, um das SnapMirror Ziel-Volume als Quelle für den Vault zu verwenden, wenn das SRM Failover oder eine Umkehrung der Replizierung stattfindet.</block>
  <block id="5bc66b9c84b3f7cc0b375e729376b68d" category="inline-link">TR-4015 SnapMirror Configuration Best Practice Guide für ONTAP 9.</block>
  <block id="0d510e96259254d285c6aaeb8458f45d" category="paragraph">Aktuelle Informationen zu SnapMirror und SnapVault für ONTAP 9 finden Sie unter<block ref="32e7c991f675bf983c547a2a174c2caf" category="inline-link-rx"></block></block>
  <block id="75f8a2d99eea9f336120aec69d8c1010" category="cell">Wenn in derselben Umgebung SnapVault und SRM eingesetzt werden, empfiehlt NetApp, eine Kaskadenkonfiguration von SnapMirror auf SnapVault zu verwenden, bei der SnapVault Backups normalerweise über das SnapMirror Ziel am DR-Standort ausgeführt werden. Bei einem Notfall kann der primäre Standort durch diese Konfiguration nicht mehr zugänglich sein. Indem das SnapVault Ziel am Recovery-Standort gehalten wird, können SnapVault Backups nach dem Failover neu konfiguriert werden, sodass SnapVault Backups weiterhin am Recovery-Standort ausgeführt werden können.</block>
  <block id="e082a67e3ddd7f4f92096536440cbb34" category="paragraph">In einer VMware Umgebung verfügt jeder Datenspeicher über eine universelle eindeutige Kennung (Universal Unique Identifier, UUID) und jede VM über eine eindeutige Managed Object ID (MOID). Diese IDs werden während Failover oder Failback durch SRM nicht gepflegt. Da Datastore-UIDs und VM-MOIDs beim Failover durch SRM nicht gepflegt werden, müssen nach dem SRM Failover alle Applikationen, die von diesen IDs abhängen, neu konfiguriert werden. Eine Beispielapplikation ist NetApp Active IQ Unified Manager, wo die SnapVault Replizierung mit der vSphere Umgebung koordiniert wird.</block>
  <block id="657a41cce55646ab17754ac1427970af" category="paragraph">Die folgende Abbildung zeigt die Kaskadenkonfiguration von SnapMirror auf SnapVault. Wenn sich das SnapVault Ziel am DR-Standort oder an einem tertiären Standort befindet, der nicht von einem Ausfall am primären Standort betroffen ist, kann die Umgebung neu konfiguriert werden, sodass Backups nach dem Failover fortgesetzt werden können.</block>
  <block id="b56afb9a43332c671116b9fa3d597867" category="paragraph"><block ref="b56afb9a43332c671116b9fa3d597867" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e068178460f103498576eac8ddb7fb82" category="paragraph">In der folgenden Abbildung wird die Konfiguration dargestellt, nachdem SRM die SnapMirror Replizierung zurück auf den primären Standort umgekehrt hat. Die Umgebung wurde außerdem neu konfiguriert, sodass SnapVault Backups von der jetzt SnapMirror Quelle durchgeführt werden. Bei dieser Einrichtung handelt es sich um eine Fan-out-Konfiguration für SnapMirror SnapVault.</block>
  <block id="0ffa07ffd89b136d0ed8f2ac5ebcabb8" category="paragraph"><block ref="0ffa07ffd89b136d0ed8f2ac5ebcabb8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b4607a4ee7e1830ab6ba0007df206956" category="paragraph">Nachdem SRM ein Failback und eine zweite Umkehrung der SnapMirror Beziehungen durchführt, sind die Produktionsdaten am primären Standort zurück. Die Daten werden jetzt auf dieselbe Weise gesichert wie vor dem Failover zum DR-Standort – über SnapMirror und SnapVault Backups.</block>
  <block id="63fd1f18d5d53fa97fd05a7fd96090b4" category="section-title">Verwendung von Qtrees in Site Recovery Manager-Umgebungen</block>
  <block id="2d88570ceb2de0d8699a068b0140454b" category="paragraph">Qtrees sind spezielle Verzeichnisse, die die Anwendung von Filesystem-Kontingenten für NAS ermöglichen. ONTAP 9 ermöglicht die Erstellung von qtrees und qtrees in Volumes, die mit SnapMirror repliziert werden. SnapMirror ermöglicht jedoch nicht die Replizierung einzelner qtrees oder Qtree-Level-Replikationen. Alle SnapMirror Replikation befindet sich nur auf Volume-Ebene. Aus diesem Grund empfiehlt NetApp die Verwendung von qtrees mit SRM nicht.</block>
  <block id="345cb3f040f9f7f3f1a4261ed260aa79" category="section-title">Gemischte FC- und iSCSI-Umgebungen</block>
  <block id="a60b166c2b69b4fdfbb733dc2193668a" category="paragraph">Mit den unterstützten SAN-Protokollen (FC, FCoE und iSCSI) bietet ONTAP 9 LUN-Services an, d. h. die Möglichkeit, LUNs zu erstellen und angebundenen Hosts zuzuweisen. Da das Cluster aus mehreren Controllern besteht, gibt es mehrere logische Pfade, die von Multipath I/O zu einer beliebigen einzelnen LUN gemanagt werden. Auf den Hosts wird mithilfe des Asymmetric Logical Unit Access (ALUA) der optimale Pfad zu einer LUN ausgewählt und für den Datentransfer aktiviert. Wenn sich der optimierte Pfad zu einer LUN ändert (z. B. weil das zugehörige Volume verschoben wird), erkennt ONTAP 9 diese Änderung automatisch und passt sich unterbrechungsfrei an. Wenn der optimierte Pfad nicht mehr verfügbar ist, kann ONTAP ohne Unterbrechungen zu einem anderen verfügbaren Pfad wechseln.</block>
  <block id="b9921ac732e72656bc2836f83bb09522" category="paragraph">VMware SRM und NetApp SRA unterstützen die Nutzung des FC-Protokolls an einem Standort und das iSCSI-Protokoll am anderen Standort. Eine Kombination aus FC-Attached Datastores und iSCSI-Attached Datastores wird jedoch auf demselben ESXi Host oder auf verschiedenen Hosts im selben Cluster nicht unterstützt. Diese Konfiguration wird mit SRM nicht unterstützt, da SRM während des SRM Failover oder des Test-Failovers alle FC- und iSCSI-Initiatoren in den ESXi-Hosts in der Anforderung enthält.</block>
  <block id="fccd44a96243e459128798803dca70aa" category="cell">SRM und SRA unterstützen gemischte FC- und iSCSI-Protokolle zwischen den geschützten und den Recovery-Standorten. Allerdings sollte jeder Standort nur mit einem Protokoll, entweder FC oder iSCSI, konfiguriert werden, nicht mit beiden Protokollen am selben Standort. Wenn FC- und iSCSI-Protokolle am selben Standort konfiguriert werden müssen, empfiehlt NetApp, dass einige Hosts iSCSI verwenden und andere Hosts FC verwenden. NetApp empfiehlt in diesem Fall außerdem die SRM-Ressourcenzuordnung, damit die VMs für das Failover in eine Gruppe von Hosts oder die andere konfiguriert werden.</block>
  <block id="963739e9818c0bf4d8959b5cdf6a7956" category="summary">Der Workflow in SRM unterscheidet sich deutlich, wenn VVols Replizierung mit dem verwendet wird, was mit SRA und herkömmlichen Datastores verwendet wird.</block>
  <block id="56687c1a324f03f5d1429500efea710e" category="doc">Fehlerbehebung bei SRM bei Nutzung der VVols-Replizierung</block>
  <block id="14acf40cbe69d8682b4c844ac7fbf7f6" category="paragraph">Der Workflow in SRM unterscheidet sich deutlich, wenn VVols Replizierung mit dem verwendet wird, was mit SRA und herkömmlichen Datastores verwendet wird. Zum Beispiel gibt es kein Konzept für Array-Manager. So,<block ref="0ec64480a9620a1430c0ae1b6603ea01" prefix=" " category="inline-code"></block> Und<block ref="ba6c59072f543cb828e47d5bac560371" prefix=" " category="inline-code"></block> Befehle werden nie gesehen.</block>
  <block id="ef74d715544e3b067a6bec3218ac5044" category="paragraph">Bei der Fehlerbehebung sind die neuen Workflows zu verstehen, die im Folgenden aufgeführt sind:</block>
  <block id="47f0942d341ee10381b2eff35089d75d" category="list-text">QueryReplicationPeer: Ermittelt die Replikationsvereinbarungen zwischen zwei Fehlerdomänen.</block>
  <block id="136a299aae29998a147852cb0cba5b4a" category="list-text">QueryFaultDomain: Ermittelt die Fehlerdomäne-Hierarchie.</block>
  <block id="c071098c5df923c31f6245e4db2f3861" category="list-text">QueryReplicationGroup: Ermittelt die in den Quell- oder Zieldomänen vorhandenen Replikationsgruppen.</block>
  <block id="792cfe9ad3a3dc8528080a262e92989a" category="list-text">SyncReplicationGroup: Synchronisiert die Daten zwischen Quelle und Ziel.</block>
  <block id="39afb1e1e3b180a6230e07bb8571667e" category="list-text">QueryPointInTimeReplica: Ermittelt die Point-in-Time-Replikate auf einem Ziel.</block>
  <block id="9fb25fe2ff084dc9ccfb99eaccba7212" category="list-text">TestFailoverReplicationGroupStart: Startet Test Failover.</block>
  <block id="bd4e1dacaca4c37a53b5286b6ae0239d" category="list-text">TestFailoverReplicationGroupStop: Beendet das Test-Failover.</block>
  <block id="887f376a43cf9de1d6e14a8d69e588f6" category="list-text">PromoteReplicationGroup: Fördert eine Gruppe, die sich derzeit in der Produktion befindet.</block>
  <block id="17ab16c5c0786ff381e6a085318bad9b" category="list-text">PreparreFailoverReplicationGroup: Bereitet sich auf eine Notfallwiederherstellung vor.</block>
  <block id="665dd64ebcc4016bda94e0e8020d8c8e" category="list-text">Failover ReplicationGroup: Durchführung einer Disaster Recovery</block>
  <block id="6936cf00e30b7cd4421225113a023c3e" category="list-text">ReverseReplicateGroup: Initiiert Reverse-Replikation.</block>
  <block id="61ac8950a043e6998b458d4f8171154c" category="list-text">QueryMatchingContainer: Sucht Container (zusammen mit Hosts oder Replikationsgruppen), die eine Bereitstellungsanfrage mit einer bestimmten Richtlinie erfüllen können.</block>
  <block id="05c9efdc056d2af4640bc441ab61b53a" category="list-text">QueryResourceMetadaten: Ermittelt die Metadaten aller Ressourcen des VASA Providers, kann die Ressourcenauslastung als Antwort auf die queryMatchingContainer-Funktion zurückgegeben werden.</block>
  <block id="01fa56986f885c588b1be8c206623de8" category="paragraph">Der häufigste Fehler bei der Konfiguration der VVols-Replizierung ist das Erkennen der SnapMirror Beziehungen. Dies geschieht, weil die Volumes und SnapMirror Beziehungen außerhalb der ONTAP Tools-Ansicht erstellt werden. Daher empfiehlt es sich, immer sicherzustellen, dass die SnapMirror Beziehung vollständig initialisiert ist und dass Sie an beiden Standorten eine erneute Bestandsaufnahme in ONTAP Tools ausführen, bevor Sie versuchen, einen replizierten VVols Datastore zu erstellen.</block>
  <block id="3e4627f6667f830baceaaf35890b575a" category="summary">Sehen Sie sich die folgenden Dokumente und/oder Websites an, um mehr über die in diesem Dokument beschriebenen Informationen zu erfahren.</block>
  <block id="092bf78f9c97ba171b8232ddff585392" category="doc">Weitere Informationen</block>
  <block id="7d5b957cd473f6eaf5ad335a9c63c4ff" category="paragraph">Sehen Sie sich die folgenden Dokumente und/oder Websites an, um mehr über die in diesem Dokument beschriebenen Informationen zu erfahren:</block>
  <block id="ccc4b678df8ad6453b7f71661f118ae1" category="inline-link"><block ref="ccc4b678df8ad6453b7f71661f118ae1" category="inline-link-rx"></block></block>
  <block id="b17e2a7e5f42c90b40de5971850339ae" category="list-text">TR-4597: VMware vSphere für ONTAP
<block ref="5938ff9651f6c5e53544676ba8504afc" category="inline-link-rx"></block></block>
  <block id="7d9ee37e3155d571b441d63bcbc54709" category="inline-link"><block ref="7d9ee37e3155d571b441d63bcbc54709" category="inline-link-rx"></block></block>
  <block id="52c629361849219069b336f56f1556d0" category="list-text">TR-4400: VMware vSphere Virtual Volumes with ONTAP
<block ref="b7bf139d6051615d8c8e01b6b63dacc3" category="inline-link-rx"></block></block>
  <block id="18df8e05a5400abd9d0980b1c5bc9ef3" category="list-text">TR-4015 SnapMirror Configuration Best Practice Guide für ONTAP 9
<block ref="e361bd9d6f7b20da762bc23fcb3d09c2" category="inline-link-rx"></block></block>
  <block id="cbe2f6eb2a73f4a2c871a06264f10dc7" category="inline-link"><block ref="cbe2f6eb2a73f4a2c871a06264f10dc7" category="inline-link-rx"></block></block>
  <block id="249b98331fa56dc46bf6ba51dc6c39d5" category="list-text">RBAC Benutzer-Creator für ONTAP
<block ref="6b15b91279acfce2bbee060bdb17db43" category="inline-link-rx"></block></block>
  <block id="c88037eb28ae3cceb0e32c2cd3c322d7" category="inline-link"><block ref="c88037eb28ae3cceb0e32c2cd3c322d7" category="inline-link-rx"></block></block>
  <block id="1a57e0f74e725c1a5e2d53b4d4b4460d" category="list-text">ONTAP Tools für VMware vSphere Ressourcen
<block ref="80c496cd9ab75e5683007d8f66ca6fbf" category="inline-link-rx"></block></block>
  <block id="9aa6e8f8fac5c131e5924ee033660d29" category="inline-link"><block ref="9aa6e8f8fac5c131e5924ee033660d29" category="inline-link-rx"></block></block>
  <block id="91a48e1708df22b7464bced79c745ad2" category="list-text">VMware Site Recovery Manager - Dokumentation
<block ref="92ad802ced4838839b492be6d0bf427d" category="inline-link-rx"></block></block>
  <block id="c9dd6bad4c7d561872f2e2d498a990bf" category="inline-link">Interoperabilitäts-Matrix-Tool (IMT)</block>
  <block id="97cd1357ea4a16b44bd9e360127a1a9d" category="paragraph">Siehe<block ref="99cfde592e1d7fa7832b186d73ee4002" category="inline-link-rx"></block> Überprüfen Sie auf der NetApp Support-Website, ob die in diesem Dokument angegebenen Produktversionen und Funktionen in Ihrer IT-Umgebung unterstützt werden. Das NetApp IMT definiert die Produktkomponenten und -Versionen, die für von NetApp unterstützte Konfigurationen verwendet werden können. Die dort angezeigten Ergebnisse basieren auf der spezifischen Infrastruktur des jeweiligen Kunden bzw. auf den technischen Daten der in dieser Infrastruktur enthaltenen Komponenten.</block>
  <block id="1f82b18dcba5f32a085bc502cdd0c6b7" category="summary">Mit ONTAP sorgt das Konzept der Storage Virtual Machine (SVM) für eine strenge Segmentierung in sicheren mandantenfähigen Umgebungen.</block>
  <block id="7520e12a140ccf3de279fe2fd48889e4" category="doc">Best Practices für die Implementierung</block>
  <block id="1b4574c516231b685bb37b013b789b06" category="section-title">SVM-Layout und Segmentierung für SMT</block>
  <block id="446e04546ec0567eeeeef8e07368ab40" category="paragraph">Mit ONTAP sorgt das Konzept der Storage Virtual Machine (SVM) für eine strenge Segmentierung in sicheren mandantenfähigen Umgebungen. SVM-Benutzer auf einer SVM können nicht auf Ressourcen einer anderen SVM zugreifen bzw. diese managen. Auf diese Weise können Sie die ONTAP Technologie nutzen, indem Sie separate SVMs für verschiedene Geschäftseinheiten erstellen, die ihre eigenen SRM Workflows im selben Cluster managen, um eine größere Storage-Effizienz zu erzielen.</block>
  <block id="f98c1d223f34b2fdaf90eab1a3bc6a25" category="paragraph">Erwägen Sie die Verwaltung von ONTAP mit SVM-Scoped-Konten und SVM-Management-LIFs, um nicht nur die Sicherheitskontrolle zu verbessern, sondern auch die Performance zu verbessern. Die Performance ist bei der Nutzung von Verbindungen mit SVM-Umfang höher, da der SRA nicht erforderlich ist, alle Ressourcen eines gesamten Clusters – einschließlich physischer Ressourcen – zu verarbeiten. Stattdessen müssen sie nur die logischen Ressourcen verstehen, die zu der jeweiligen SVM abstrahiert sind.</block>
  <block id="849d4d5e8a5d5b2747d8375d2ec03b29" category="paragraph">Nur bei der Verwendung von NAS-Protokollen (kein SAN-Zugriff) können Sie sogar den neuen NAS-optimierten Modus nutzen, indem Sie den folgenden Parameter einstellen (beachten Sie, dass der Name so ist, da SRA und VASA dieselben Backend-Services in der Appliance nutzen):</block>
  <block id="05f551a655f40911851a53ba0c721997" category="list-text">Melden Sie sich am Bedienfeld unter an<block ref="501a3478972ee5e3d6f109bdc0514bdc" prefix=" " category="inline-code"></block> Und klicken Sie auf webbasierte CLI-Schnittstelle.</block>
  <block id="b0cc185c73ca964d1429a601551c68f5" category="list-text">Führen Sie den Befehl aus<block ref="4f35e9b3adeccfaf0287d002b134221c" prefix=" " category="inline-code"></block>.</block>
  <block id="5f7e35f90689bef91afe9f01257c61ac" category="list-text">Führen Sie den Befehl aus<block ref="aa610e3ab4e5162f432950793f30a387" prefix=" " category="inline-code"></block>.</block>
  <block id="ba2a1e4d95dc56709260e82cca20a789" category="list-text">Führen Sie den Befehl aus<block ref="6d83e9fce5e947159c3c34b9f499e80e" prefix=" " category="inline-code"></block>.</block>
  <block id="2d14ca751c8ce5a724606e4f75f02c50" category="section-title">Implementieren von ONTAP-Tools und Überlegungen für VVols</block>
  <block id="fa3a193f1892cf0f45f4a95a35aa3c4b" category="paragraph">Falls Sie SRM mit VVols verwenden möchten, müssen Sie den Storage mit Anmeldedaten für den Cluster-Umfang und einer Cluster-Management-LIF managen. Der Grund dafür ist, dass VASA Provider die zugrunde liegende physische Architektur verstehen muss, um die für VM Storage-Richtlinien erforderlichen Richtlinien erfüllen zu können. Wenn Sie beispielsweise eine Richtlinie haben, die All-Flash-Storage erfordert, muss der VASA Provider in der Lage sein, zu sehen, welche All-Flash-Systeme sind.</block>
  <block id="31d279d1cc3bc5a4281567ba697f678d" category="paragraph">Eine weitere Best Practice bei der Implementierung besteht darin, Ihre ONTAP Tools Appliance niemals auf einem VVols Datastore zu speichern, den sie managen. Dies kann dazu führen, dass Sie den VASA Provider nicht einschalten können, da Sie die Swap-vVol für die Appliance nicht erstellen können, da die Appliance offline ist.</block>
  <block id="97399fb37deca0d463aa5c7dc8d064a6" category="section-title">Best Practices für das Management von ONTAP 9 Systemen</block>
  <block id="18f8b81b7fb7ea92f333e127583df17c" category="paragraph">Wie bereits erwähnt, können Sie ONTAP Cluster mit Anmeldedaten im Cluster oder SVM-Umfang und Management-LIFs managen. Um die optimale Performance zu erzielen, sollten Sie immer dann die Verwendung von VVols in Betracht ziehen, wenn Sie über den SVM-Umfang verfügen. Dabei sollten Sie sich jedoch einigen Anforderungen bewusst sein und dass einige Funktionen verloren gehen.</block>
  <block id="fec05e53ca7d96aaf3e4c1a1b2502bea" category="list-text">Das Standard-vsadmin SVM-Konto verfügt nicht über die erforderliche Zugriffsebene, um ONTAP-Tools-Aufgaben durchzuführen. Daher müssen Sie ein neues SVM-Konto erstellen.</block>
  <block id="d508cbe8ee8a3aa0f975b96403baf33c" category="list-text">Wenn Sie ONTAP 9.8 oder höher verwenden, empfiehlt NetApp die Erstellung eines RBAC-Kontos mit den geringsten Berechtigungen über das Benutzermenü von ONTAP System Manager sowie die JSON-Datei, die auf der ONTAP Tools-Appliance unter verfügbar ist<block ref="137f8d4bb89dcc34c3bfe48f2a61c95e" prefix=" " category="inline-code"></block>. Verwenden Sie Ihr Administratorpasswort, um die JSON-Datei herunterzuladen. Diese Option kann für SVM oder Konten mit Cluster-Umfang verwendet werden.</block>
  <block id="a7a83b5e4f375c0585588b9c7ff92219" category="inline-link">NetApp Support Site Tool</block>
  <block id="fdfe9ba9104df6a32fff0f859291ea3c" category="paragraph">Wenn Sie ONTAP 9.6 oder eine frühere Version verwenden, sollten Sie das RUC-Tool (RBAC User Creator) verwenden, das im verfügbar ist<block ref="bdbf96c18cf8ac76d01fba7057b81b87" category="inline-link-rx"></block>.</block>
  <block id="ea7a3d08d55dc3e8ecf89d2a5d5e302d" category="list-text">Da die vCenter UI Plug-in, VASA Provider und SRA Server vollständig integrierte Services sind, müssen Sie den SRA-Adapter in SRM um Storage ebenso ergänzen wie in der vCenter UI für ONTAP-Tools. Andernfalls erkennt der SRA-Server möglicherweise nicht die Anfragen, die von SRM über den SRA-Adapter gesendet werden.</block>
  <block id="b473de4177eeaa79a66448798a446db3" category="list-text">Die NFS-Pfadprüfung wird bei der Verwendung der SVM-Scoped-Anmeldedaten nicht durchgeführt. Der Grund dafür ist, dass der physische Standort logisch von der SVM abstrahiert ist. Dies stellt jedoch keine Sorge mehr dar, da bei der Verwendung von indirekten Pfaden nicht mehr deutliche Performance-Einbußen bei modernen ONTAP Systemen auftreten.</block>
  <block id="6e62430b92a7c5a0b8512436b163a10d" category="list-text">Es werden möglicherweise keine Aggregat-Platzeinsparungen aufgrund von Storage-Effizienz gemeldet.</block>
  <block id="93d86aa51e0909549d1b1210f887aef3" category="list-text">Wenn unterstützt, können Spiegelungen zur Lastverteilung nicht aktualisiert werden.</block>
  <block id="647d380b52e259fe7ed2e2582bc54b27" category="list-text">Die EMS-Protokollierung wird möglicherweise nicht auf ONTAP Systemen durchgeführt, die mit den Anmeldedaten im Umfang des SVM-Service gemanagt werden.</block>
  <block id="c5cd657df037c277c37216b73efb0b08" category="summary">Wenn möglich, verwenden Sie immer ONTAP Tools, um Datenspeicher und Volumes bereitzustellen. Damit stellen wir sicher, dass Volumes, Verbindungspfade, LUNs, Initiatorgruppen, Exportrichtlinien Und andere Einstellungen sind kompatibel konfiguriert.</block>
  <block id="d3b26e9021e83573a3d2a9050400a33a" category="doc">Best Practices für betriebliche Prozesse</block>
  <block id="4d15db58f26b374b36c283df6b5a5fc1" category="paragraph">SRM unterstützt iSCSI, Fibre Channel und NFS Version 3 mit ONTAP 9 bei Nutzung der Array-basierten Replizierung über SRA. SRM unterstützt nicht die Array-basierte Replizierung für NFS Version 4.1 mit herkömmlichen oder VVols-Datastores.</block>
  <block id="61f54ceeb0338787a2ee2d801cbc62cd" category="paragraph">Zur Bestätigung der Konnektivität überprüfen Sie immer, ob Sie einen neuen Testdatenspeicher am DR-Standort vom Ziel-ONTAP-Cluster aus mounten und wieder mounten können. Testen Sie jedes Protokoll, das Sie für die Datastore-Konnektivität verwenden möchten. Eine Best Practice besteht darin, mit ONTAP-Tools Ihren Testdatenspeicher zu erstellen, da dies die gesamte Datastore-Automatisierung gemäß den Anweisungen von SRM erfolgt.</block>
  <block id="0ac3e8abbf45a28af68d22b0f59a973e" category="paragraph">SAN-Protokolle sollten für jeden Standort homogen sein. Sie können NFS und SAN mixen, aber die SAN-Protokolle sollten nicht innerhalb eines Standorts gemischt werden. Beispielsweise können Sie FCP in Seite A und iSCSI in Standort B verwenden Sie sollten FCP und iSCSI nicht an Standort A verwenden Der Grund hierfür: Der SRA erstellt nicht gemischte Initiatorgruppen am Recovery-Standort, und SRM filtert nicht die Initiatorliste, die den SRA gegeben wurde.</block>
  <block id="150f8d9d5018ff00285d9aa158451d7b" category="paragraph">Frühere Anleitungen sollten LIF zu Datenlokalität erstellen. Das heißt, mounten Sie immer einen Datenspeicher mit einer LIF auf dem Node, der physisch Eigentümer des Volume ist. In modernen Versionen von ONTAP 9 ist das nicht mehr erforderlich. Sofern möglich und im Rahmen der Zugangsdaten für den Cluster-Umfang festgelegt werden, wählen die ONTAP Tools nach wie vor den Lastausgleich zwischen lokalen LIFs für die Daten aus. Eine Hochverfügbarkeit oder Performance ist jedoch nicht erforderlich.</block>
  <block id="62a631034cae40cfcee909c69c12c5b3" category="paragraph">NetApp ONTAP 9 kann so konfiguriert werden, dass Snapshots automatisch entfernt werden, um die Uptime aufrechtzuerhalten, falls ein Speicherplatz nicht ausreicht, wenn Autosize nicht in der Lage ist, eine ausreichende Notfallkapazität zur Verfügung zu stellen. In der Standardeinstellung für diese Funktion werden die von SnapMirror erstellten Snapshots nicht automatisch gelöscht. Wenn SnapMirror Snapshots gelöscht werden, kann NetApp SRA die Replizierung für das betroffene Volume nicht rückgängig machen und erneut synchronisieren. Um zu verhindern, dass ONTAP SnapMirror Snapshots löscht, konfigurieren Sie die Funktion für automatisches Löschen von Snapshots für den Versuch.</block>
  <block id="63b6c8d5e17ef7185a34c4ddd86f9d19" category="inline-link-macro">Automatisches Vergrößern oder Verkleinern von Volumes</block>
  <block id="a1874a28c8389c5c687d10167e80dc1f" category="paragraph">Die automatische Volume-Größe sollte auf festgelegt werden<block ref="4d200fce73a8e1cc965cfc2c43343824" prefix=" " category="inline-code"></block> Für Volumes mit SAN-Datastores und<block ref="d89f4f8b1d7c18847b88b46142f61535" prefix=" " category="inline-code"></block> Für NFS-Datastores. Weitere Informationen zu <block ref="ebd664f1c7cf128a3758282775d35e72" category="inline-link-macro-rx"></block>.</block>
  <block id="e401bd7c98141814eaf5528ddb318da6" category="section-title">Storage Policy Based Management (SPBM) und VVols</block>
  <block id="3077a08ffed60acebf18d37874130d44" category="paragraph">Ab SRM 8.3 wird der Schutz von VMs mit VVols Datastores unterstützt. SnapMirror Zeitpläne werden über den VASA Provider VM-Storage-Richtlinien ausgesetzt, wenn die VVols Replizierung im Einstellungsmenü der ONTAP Tools aktiviert ist, wie in den folgenden Screenshots dargestellt.</block>
  <block id="399c1894baf71c0529aa0fba66ea18fb" category="paragraph">Im folgenden Beispiel wird die Unterstützung der VVols Replizierung gezeigt.</block>
  <block id="b180e7f35111dca8acd6c56cdbcabb3e" category="paragraph"><block ref="b180e7f35111dca8acd6c56cdbcabb3e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="be41c3baf700984021c43e2e6b661b0a" category="paragraph">Der folgende Screenshot zeigt ein Beispiel zu SnapMirror Zeitplänen, die im Assistenten zur Erstellung von VM-Storage-Richtlinien angezeigt werden.</block>
  <block id="43c130b36e9e2b3d61409aa974f89fc7" category="paragraph"><block ref="43c130b36e9e2b3d61409aa974f89fc7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f6292d9eb6ea467a3c3560a65b7f63b5" category="paragraph">Der ONTAP VASA Provider unterstützt den Failover auf unterschiedlichen Storage. So kann beispielsweise ein Failover des Systems von ONTAP Select an einem Edge-Standort auf ein AFF System im Core-Datacenter durchgeführt werden. Unabhängig von Ähnlichkeit zum Storage müssen Sie für VM Storage-Richtlinien immer Storage-Richtlinien-Zuordnungen und Reverse-Mappings konfigurieren, damit die Services am Recovery-Standort die Erwartungen und Anforderungen erfüllen. Der folgende Screenshot zeigt ein Beispiel für eine Richtlinienzuordnung.</block>
  <block id="783a951245ce43eb84161804072a38c6" category="paragraph"><block ref="783a951245ce43eb84161804072a38c6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1eb90dc8f7adfd00c74af3b815e2ac15" category="section-title">Erstellung replizierter Volumes für VVols-Datastores</block>
  <block id="18231879821321e0aed7de84fe876766" category="paragraph">Im Gegensatz zu älteren VVols-Datastores müssen replizierte VVols Datastores von Anfang an bei aktivierter Replizierung erstellt werden. Dabei müssen sie Volumes verwenden, die vorab auf den ONTAP Systemen mit SnapMirror Beziehungen erstellt wurden. Hierfür sind vorab-Konfigurationen wie Cluster-Peering und SVM-Peering erforderlich. Diese Aktivitäten sollten von Ihrem ONTAP-Administrator ausgeführt werden, da hierdurch die Zuständigkeiten zwischen denen, die die ONTAP-Systeme über mehrere Standorte hinweg managen, und denen, die in erster Linie für den vSphere-Betrieb verantwortlich sind, streng getrennt werden.</block>
  <block id="0a8c8293003bf411817ef3cedf18a2a9" category="paragraph">Dafür muss der vSphere Administrator eine neue Anforderung erfüllen. Da Volumes außerhalb der ONTAP Tools erstellt werden, ist es nicht bekannt, dass die Änderungen, die Ihr ONTAP-Administrator bis zur regelmäßigen planmäßigen Neuerfassungszeit vorgenommen hat. Daher ist es eine Best Practice, immer wieder neu zu ermitteln, wenn Sie eine Volume- oder SnapMirror Beziehung erstellen, die mit VVols verwendet werden soll. Klicken Sie einfach mit der rechten Maustaste auf den Host oder Cluster und wählen Sie die NetApp ONTAP Tools &gt; Aktualisieren von Host- und Speicherdaten aus, wie im folgenden Screenshot dargestellt.</block>
  <block id="dd5e006520a09e3975e52f6fb8991fd2" category="paragraph"><block ref="dd5e006520a09e3975e52f6fb8991fd2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="550d51e15336d4a33bcbb0f26a6810f7" category="paragraph">Bei VVols und SRM ist Vorsicht geboten. Niemals geschützte und ungesicherte VMs in demselben VVols Datastore zusammen Der Grund dafür: Wenn Sie SRM für das Failover an Ihrem DR-Standort verwenden, werden nur die VMs, die Teil der Sicherungsgruppe sind, in die DR online geschaltet. Wenn Sie die Sicherung rückgängig machen (das SnapMirror aus der DR wieder in die Produktionsumgebung verschieben), können die VMs, die nicht Failover waren, überschrieben werden und wertvolle Daten enthalten.</block>
  <block id="6d717f70d89096b731dfc63d7a1379e1" category="section-title">Allgemeines zu Array-Paaren</block>
  <block id="6dd3f3008fe81f402905b00c8dca007c" category="paragraph">Für jedes Array-Paar wird ein Array-Manager erstellt. Zusammen mit SRM und ONTAP Tools erfolgt die Kopplung jedes Arrays mit dem Umfang einer SVM, auch wenn Cluster-Anmeldedaten verwendet werden. So können Sie DR-Workflows zwischen Mandanten segmentieren, basierend auf den ihnen zugewiesenen SVMs. Sie können mehrere Array-Manager für ein bestimmtes Cluster erstellen und sie können asymmetrisch sein. Sie können Fan-out oder Fan-in zwischen verschiedenen ONTAP 9 Clustern. So können beispielsweise SVM-A und SVM-B auf Cluster-1 und damit auf SVM-C auf Cluster-2, SVM-D auf Cluster-3 oder umgekehrt genutzt werden.</block>
  <block id="2219228418c053eb593ce0a1f318da47" category="paragraph">Wenn Sie Array-Paare in SRM konfigurieren, sollten Sie sie immer in SRM auf die gleiche Weise hinzufügen, wie Sie sie den ONTAP Tools hinzugefügt haben. Das bedeutet, dass sie denselben Benutzernamen, dasselbe Passwort und dieselbe Management-LIF verwenden müssen. Diese Anforderung stellt sicher, dass SRA ordnungsgemäß mit dem Array kommuniziert. Der folgende Screenshot veranschaulicht, wie ein Cluster in ONTAP-Tools angezeigt wird und wie es zu einem Array Manager hinzugefügt werden kann.</block>
  <block id="7ec48584a43ed8a9b1dda55398d97cf4" category="paragraph"><block ref="7ec48584a43ed8a9b1dda55398d97cf4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3b34135c8c4d2b14ceb7ebf595f00193" category="section-title">Allgemeines zu Replikationsgruppen</block>
  <block id="6be59afd3c8bb91501f55a7e77ebe794" category="paragraph">Replikationsgruppen enthalten logische Sammlungen von virtuellen Maschinen, die zusammen wiederhergestellt werden. Mit den ONTAP Tools VASA Provider werden automatisch Replikationsgruppen für Sie erstellt. Da die ONTAP SnapMirror Replizierung auf Volume-Ebene stattfindet, befinden sich alle VMs in einem Volume in derselben Replizierungsgruppe.</block>
  <block id="94a20f06626561800313d9472f9d9769" category="paragraph">Es gibt mehrere Faktoren, die bei Replizierungsgruppen berücksichtigt werden müssen und die Art und Weise, wie VMs über FlexVol Volumes verteilt werden. Durch die Gruppierung ähnlicher VMs in demselben Volume kann die Storage-Effizienz bei älteren ONTAP Systemen erhöht werden, bei denen es keine Deduplizierung auf Aggregatebene gibt. Durch Gruppierung wird jedoch die Größe des Volumes erhöht und die Parallelität der Volume I/O verringert. Moderne ONTAP Systeme bieten ein optimales Gleichgewicht aus Performance und Storage-Effizienz, indem VMs über FlexVol Volumes im selben Aggregat verteilt werden. Dadurch werden die Deduplizierung auf Aggregatebene genutzt und die I/O-Parallelisierung über mehrere Volumes hinweg verbessert. Sie können VMs in den Volumes zusammen wiederherstellen, da eine (nachfolgend erläutert) Sicherungsgruppe mehrere Replizierungsgruppen enthalten kann. Der Nachteil dieses Layouts besteht darin, dass Blöcke mehrmals über das Netzwerk übertragen werden können, da die Aggregat-Deduplizierung bei Volume SnapMirror nicht berücksichtigt wird.</block>
  <block id="c727c1020d3128dd7495a6e3e6f23736" category="paragraph">Eine letzte Überlegung für Replikationsgruppen besteht darin, dass jede von Natur aus eine logische Konsistenzgruppe ist (nicht zu verwechseln mit SRM-Konsistenzgruppen). Das liegt daran, dass alle VMs im Volume mithilfe desselben Snapshots zusammen übertragen werden. Wenn Sie also VMs haben, die stets konsistent sein müssen, sollten Sie sie in der gleichen FlexVol speichern.</block>
  <block id="9f8a350a2113ea4be6b4e5e5112514a3" category="section-title">Allgemeines zu Schutzgruppen</block>
  <block id="df77671ab2743af7f1d1457c200eb12c" category="paragraph">Sicherungsgruppen definieren VMs und Datastores in Gruppen, die am geschützten Standort zusammen wiederhergestellt werden. Am geschützten Standort befinden sich die VMs, die in einer Schutzgruppe konfiguriert sind, im normalen Steady-State-Betrieb. Es ist wichtig zu beachten, dass eine Schutzgruppe nicht mehrere Array-Manager umfassen kann, obwohl SRM möglicherweise mehrere Array-Manager für eine Schutzgruppe anzeigt. Aus diesem Grund sollten Sie VM-Dateien nicht über Datastores auf unterschiedlichen SVMs verteilen.</block>
  <block id="b148467d645c3613c1c7a2607764c515" category="section-title">Recovery-Pläne sprechen</block>
  <block id="fd28cd9834ad3aa213c4fec2881064b5" category="paragraph">Recovery-Pläne legen fest, welche Schutzgruppen im gleichen Prozess wiederhergestellt werden. Mehrere Sicherungsgruppen können im selben Recovery-Plan konfiguriert werden. Um darüber hinaus mehr Optionen für die Ausführung von Recovery-Plänen zu aktivieren, kann eine einzige Sicherungsgruppe in mehreren Recovery-Plänen enthalten sein.</block>
  <block id="77aa84394124509e5e4006dcfd18789f" category="paragraph">Durch Recovery-Pläne können SRM-Administratoren Recovery-Workflows definieren, indem VMs einer Prioritätsgruppe von 1 (hoch) bis 5 (niedrig) zugewiesen werden, wobei 3 (mittel) standardmäßig verwendet wird. Innerhalb einer Prioritätsgruppe können VMs für Abhängigkeiten konfiguriert werden.</block>
  <block id="6d72567442b1f361e3c0e89cbc7dfd6a" category="paragraph">So könnte Ihr Unternehmen beispielsweise über eine geschäftskritische Tier-1-Applikation für seine Datenbank auf einen Microsoft SQL Server zurückgreifen. Sie entscheiden also, Ihre VMs in Prioritätsgruppe 1 einzufügen. Innerhalb der Prioritätsgruppe 1 beginnen Sie mit der Planung des Auftrages der Dienste. Sie möchten wahrscheinlich, dass Ihr Microsoft Windows Domain Controller vor Ihrem Microsoft SQL Server hochgefahren wird, was vor Ihrem Anwendungsserver online sein müsste, usw. Sie würden all diese VMs zur Prioritätsgruppe hinzufügen und dann die Abhängigkeiten einstellen, da Abhängigkeiten nur innerhalb einer bestimmten Prioritätsgruppe gelten.</block>
  <block id="030d749269f8866de516a551b0286001" category="paragraph">NetApp empfiehlt besonders, mit Ihren Applikationsteams zusammenarbeiten zu müssen, um die Reihenfolge der für ein Failover-Szenario erforderlichen Operationen zu ermitteln und die Recovery-Pläne entsprechend zu erstellen.</block>
  <block id="cebb1167d3e78885137c837f0abf8026" category="section-title">Testen Sie den Failover</block>
  <block id="2772828493452c4a2ff21f8b2b66a1a7" category="paragraph">Als Best Practice empfiehlt es sich, immer einen Test-Failover durchzuführen, wenn die Konfiguration eines geschützten VM Storage geändert wird. So wird sichergestellt, dass Sie bei einem Notfall darauf vertrauen können, dass Site Recovery Manager Services innerhalb des erwarteten RTO-Ziels wiederherstellen kann.</block>
  <block id="6ae8acfc86f5df3426d525fb95767506" category="paragraph">NetApp empfiehlt zudem, die Funktion der in Gast-Applikationen gelegentlich zu bestätigen, insbesondere nach der Neukonfiguration von VM-Storage.</block>
  <block id="bd47371bcd8b3d08d6b4b15481b08d93" category="paragraph">Wenn ein Test-Recovery-Vorgang ausgeführt wird, wird auf dem ESXi Host für die VMs ein privates Test-Bubble-Netzwerk erstellt. Dieses Netzwerk wird jedoch nicht automatisch mit physischen Netzwerkadaptern verbunden und bietet daher keine Verbindung zwischen den ESXi Hosts. Um die Kommunikation zwischen VMs zu ermöglichen, die während des DR-Tests auf verschiedenen ESXi Hosts ausgeführt werden, wird ein physisches privates Netzwerk zwischen den ESXi Hosts am DR-Standort erstellt. Um zu überprüfen, ob das Testnetzwerk privat ist, kann das Testblasennetzwerk physisch oder mittels VLANs oder VLAN-Tagging getrennt werden. Dieses Netzwerk muss von dem Produktionsnetzwerk getrennt werden, da die VMs wiederhergestellt werden und nicht mit IP-Adressen im Produktionsnetzwerk platziert werden können, die mit den tatsächlichen Produktionssystemen kollidieren können. Nach dem Erstellen eines Recovery-Plans in SRM kann das erstellte Testnetzwerk als privates Netzwerk ausgewählt werden, um die VMs mit während des Tests zu verbinden.</block>
  <block id="2be58fc410ddf2ba9c350135a617944a" category="paragraph">Nachdem der Test validiert und nicht mehr erforderlich ist, führen Sie eine Bereinigung durch. Bei der Durchführung der Bereinigung werden die geschützten VMs in ihren Ausgangszustand zurückversetzt und der Recovery-Plan wird auf den Status „bereit“ zurückgesetzt.</block>
  <block id="6f07b53963ee80903f0f13654de2cc3a" category="section-title">Überlegungen zum Failover</block>
  <block id="9d33d94019b4a595a1ea232926a4da1b" category="paragraph">Wenn es um Failover an einem Standort zusätzlich zur in diesem Leitfaden beschriebenen Reihenfolge geht, müssen noch einige weitere Aspekte berücksichtigt werden.</block>
  <block id="74abdd5cb502cd65bcf1d7ca484ab0c2" category="paragraph">Ein Problem, mit dem Sie möglicherweise zu kämpfen haben, ist die Netzwerkunterschiede zwischen den Standorten. In einigen Umgebungen können am primären Standort und am DR-Standort dieselben Netzwerk-IP-Adressen verwendet werden. Diese Fähigkeit wird als Stretched Virtual LAN (VLAN) oder Stretched Network Setup bezeichnet. Andere Umgebungen müssen möglicherweise unterschiedliche Netzwerk-IP-Adressen (z. B. in unterschiedlichen VLANs) am primären Standort relativ zum DR-Standort verwenden.</block>
  <block id="9b8890fe5b1ab29543118b12a7bd0a07" category="inline-link-macro">NSX-T-Optionen mit SRM</block>
  <block id="25154023650451d6cc971fc54bff8898" category="paragraph">VMware bietet verschiedene Möglichkeiten zur Lösung dieses Problems. Netzwerkvirtualisierungstechnologien wie VMware NSX-T Data Center abstrahieren den gesamten Netzwerk-Stack von Ebene 2 bis 7 von der Betriebsumgebung und ermöglichen so portablere Lösungen. Weitere Informationen zu <block ref="3e6a2bd8e1acf69d423b7944c6543271" category="inline-link-macro-rx"></block>.</block>
  <block id="2ef005587879f8a16a4d999c1dd71630" category="paragraph">SRM ermöglicht es Ihnen auch, die Netzwerkkonfiguration einer VM wie das Recovery zu ändern. Diese Neukonfiguration umfasst Einstellungen wie IP-Adressen, Gateway-Adresse und DNS-Server-Einstellungen. Verschiedene Netzwerkeinstellungen, die bei der Wiederherstellung auf einzelne VMs angewendet werden, können in den Einstellungen einer VM der Eigenschaft im Recovery-Plan angegeben werden.</block>
  <block id="b56336aa967325217297d8725b64eb0b" category="inline-link-macro">VMware Dokumentation</block>
  <block id="d32598436410006707b2ad1d79395f02" category="paragraph">Um SRM so zu konfigurieren, dass verschiedene Netzwerkeinstellungen auf mehrere VMs angewendet werden können, ohne die Eigenschaften der einzelnen im Recovery-Plan bearbeiten zu müssen, stellt VMware ein Tool namens dr-ip-Customizer bereit. Informationen zur Verwendung dieses Dienstprogramms finden Sie unter <block ref="837c7339284b78d4fd5550c5d0fb1a68" category="inline-link-macro-rx"></block>.</block>
  <block id="3c8c527afa8ce5009c8f707f7fd4fabf" category="section-title">Schützen</block>
  <block id="3b496038cb575fc404f8b0783e570f7a" category="paragraph">Nach einem Recovery wird der Recovery-Standort zum neuen Produktionsstandort. Da der Recovery-Vorgang die SnapMirror Replizierung ausbrach, ist der neue Produktionsstandort nicht vor zukünftigen Ausfällen geschützt. Als Best Practice wird empfohlen, den neuen Produktionsstandort unmittelbar nach dem Recovery auf einen anderen Standort zu schützen. Wenn der ursprüngliche Produktionsstandort betriebsbereit ist, kann der VMware Administrator den ursprünglichen Produktionsstandort als neuen Recovery-Standort zum Schutz des neuen Produktionsstandorts verwenden und damit die Richtung des Schutzes umkehren. Repschutz ist nur bei nicht-katastrophalen Ausfällen verfügbar. Daher müssen die ursprünglichen vCenter Server, ESXi Server, SRM Server und entsprechenden Datenbanken irgendwann wiederhergestellt werden können. Falls diese nicht verfügbar sind, müssen eine neue Schutzgruppe und ein neuer Recovery-Plan erstellt werden.</block>
  <block id="2bf236f8aceaaff2b305848df524c42e" category="paragraph">Ein Failback-Vorgang ist im Grunde ein Failover in eine andere Richtung als zuvor. Als Best Practice überprüfen Sie, ob der ursprüngliche Standort wieder zu akzeptablen Funktionsstufen zurückkehrt, bevor Sie ein Failback durchführen, oder, anders ausgedrückt, ein Failover zum ursprünglichen Standort durchführen. Falls der ursprüngliche Standort weiterhin kompromittiert wird, sollten Sie ein Failback verzögern, bis der Ausfall ausreichend behoben ist.</block>
  <block id="cb03753531bad31391d7156433b98ae6" category="paragraph">Eine weitere Failback Best Practice besteht darin, immer einen Test-Failover auszuführen, nachdem der erneute Schutz abgeschlossen und bevor das endgültige Failback durchgeführt wurde. Dadurch wird sichergestellt, dass die vorhandenen Systeme am ursprünglichen Standort den Betrieb abschließen können.</block>
  <block id="900a3b65ea54b6dcff72ed0d6ac66fdf" category="section-title">Wiederherstellung der Originalseite</block>
  <block id="2a0c13d7b927063987bf931a141f2662" category="paragraph">Nach dem Failback sollten Sie mit allen Beteiligte bestätigen, dass ihre Services wieder normal sind, bevor Sie erneut den Schutz starten.</block>
  <block id="12d059a2c7519f2e3497b30a71121503" category="paragraph">Wenn eine erneute Sicherung nach dem Failback ausgeführt wird, befindet sich die Umgebung im Wesentlichen in dem Zustand, in dem sie sich zu Beginn befand. Die SnapMirror Replizierung wird erneut vom Produktionsstandort zum Recovery-Standort ausgeführt.</block>
  <block id="7ab9df3e4e38ca227c1b48b0f6740675" category="section-title">Aktivitäten zur sicheren Entwicklung</block>
  <block id="1a79eb278bc02ebdbd2ab32925e316f6" category="paragraph">Das Software-Engineering mit NetApp ONTAP Tools für VMware vSphere nutzt folgende sichere Entwicklungsaktivitäten:</block>
  <block id="39e5fc9eb192f011ab14dae6c2974c4e" category="list-text">*Threat Modeling.* der Zweck der Bedrohungsmodellierung ist es, Sicherheitslücken in einem Feature, einer Komponente oder einem Produkt frühzeitig im Lebenszyklus der Softwareentwicklung zu entdecken. Ein Bedrohungsmodell ist eine strukturierte Darstellung aller Informationen, die die Sicherheit einer Anwendung beeinflussen. Im Wesentlichen ist es ein Blick auf die Anwendung und ihre Umgebung durch die Linsen der Sicherheit.</block>
  <block id="9f16ab3a50bca32d19c4729319035c8d" category="list-text">*Dynamic Application Security Testing (DAST).* Diese Technologie wurde entwickelt, um gefährdete Bedingungen für Anwendungen im laufenden Zustand zu erkennen. DAST testet die freigesetzten HTTP- und HTML-Schnittstellen von Web-enable-Anwendungen.</block>
  <block id="267bed0525e4dab477e4c24ca5a1794e" category="list-text">*Codewährung von Drittanbietern.* im Rahmen der Softwareentwicklung mit Open-Source-Software (OSS) müssen Sie Sicherheitslücken schließen, die mit jedem OSS in Ihr Produkt integriert werden könnten. Dies ist ein fortdauernde Bemühung, da bei einer neuen OSS-Version möglicherweise jederzeit eine neu entdeckte Sicherheitsanfälligkeit gemeldet wird.</block>
  <block id="db7bc87c89c1ee76d313865a32fc0e06" category="list-text">*Schwachstellenscans.* Zweck der Schwachstellenanalyse ist es, häufige und bekannte Sicherheitslücken in NetApp Produkten zu erkennen, bevor diese bei den Kunden freigegeben werden.</block>
  <block id="1a4c104571630526efc77b84e82380fe" category="list-text">*Penetrationstest.* Penetrationstest ist der Prozess, um ein System, eine Web-Anwendung oder ein Netzwerk zu bewerten, um Sicherheitslücken zu finden, die von einem Angreifer ausgenutzt werden könnten. Penetrationstests (Penetrationstests) bei NetApp werden von einer Gruppe genehmigter und vertrauenswürdiger Drittanbieter durchgeführt. Ihr Testumfang umfasst die Einleitung von Angriffen gegen eine Anwendung oder Software ähnlich wie feindliche Eindringlinge oder Hacker mit ausgereiften Methoden oder Tools zur Ausbeutung.</block>
  <block id="7e98fc3ea1ec077cfd1727a58e9c9020" category="section-title">Produktsicherheitsfunktionen</block>
  <block id="85d61648687f15050da0b86741b90358" category="paragraph">Die NetApp ONTAP Tools für VMware vSphere umfassen die folgenden Sicherheitsfunktionen in jeder Version.</block>
  <block id="dff88c2ef0b49b09246ffd6f9ec55195" category="list-text">*Anmeldebanner* SSH ist standardmäßig deaktiviert und erlaubt nur einmalige Anmeldungen, wenn sie über die VM-Konsole aktiviert sind. Das folgende Anmeldebanner wird angezeigt, nachdem der Benutzer einen Benutzernamen in die Anmeldeaufforderung eingegeben hat:</block>
  <block id="399875025e8e96cc13102a4dd72f2434" category="paragraph">*WARNUNG:* der unerlaubte Zugriff auf dieses System ist verboten und wird gesetzlich verfolgt. Durch den Zugriff auf dieses System erklären Sie sich damit einverstanden, dass Ihre Maßnahmen überwacht werden können, wenn eine unbefugte Nutzung vermutet wird.</block>
  <block id="2d8330ed99c80a842ffbd1362e038e5e" category="paragraph">Nachdem der Benutzer die Anmeldung über den SSH-Kanal abgeschlossen hat, wird der folgende Text angezeigt:</block>
  <block id="677528ad13d460c058ac50e8a62092cf" category="list-text">*Rollenbasierte Zugriffssteuerung (Role Based Access Control, RBAC).* ONTAP Tools verfügen über zwei Arten von RBAC-Steuerungsoptionen:</block>
  <block id="ac38773d017495a97d5b88f242578cb8" category="list-text">Native vCenter Server-Berechtigungen</block>
  <block id="c2e2fce3a995f59900d7afbbe58683f5" category="inline-link">Dieser Link</block>
  <block id="31cedac82fef311cb790a12f96897223" category="list-text">Spezifische Berechtigungen für vCenter Plug-in Weitere Informationen finden Sie unter<block ref="e5f6920797dbff91ef59367270a82669" category="inline-link-rx"></block>.</block>
  <block id="5d32469f8a65b884a8f70abf95fe485a" category="list-text">*Verschlüsselte Kommunikationskanäle.* Alle externen Kommunikation erfolgt über HTTPS mit Version 1.2 von TLS.</block>
  <block id="600d4f98483fae8e58054f976d7e0c0e" category="list-text">*Minimal Port Exposure.* nur die benötigten Ports sind an der Firewall geöffnet.</block>
  <block id="0406f8902379502d1eba01f043c232b7" category="paragraph">In der folgenden Tabelle werden die Details zum offenen Anschluss beschrieben.</block>
  <block id="69fc9fe9cbb7709e97a433352aecf77d" category="cell">TCP v4/v6-Port #</block>
  <block id="02674a4ef33e11c879283629996c8ff8" category="cell">Richtung</block>
  <block id="86408593c34af77fdd90df932f8b5261" category="cell">Funktion</block>
  <block id="0c95054981de037de06e544a52eb3613" category="cell">8143</block>
  <block id="a8e6fe5b9e68f30a146cefebaa7edcc3" category="cell">Eingehend</block>
  <block id="d16c4afdc5f340936b747baf91efc843" category="cell">HTTPS-Verbindungen für REST-API</block>
  <block id="5bd529d5b07b647a8863cf71e98d651a" category="cell">8043</block>
  <block id="1f4deeb2f64336d4ff65ea3d2b4ffe2f" category="cell">HTTPS-Verbindungen</block>
  <block id="cb4b69eb9bd10da82c15dca2f86a1385" category="cell">9060</block>
  <block id="5852f8019b572f4cdef5bab783fa799f" category="cell">HTTPS-Verbindungen
Wird für SOAP-über-https-Verbindungen verwendet
Dieser Port muss geöffnet werden, damit ein Client eine Verbindung zum ONTAP Tools API-Server herstellen kann.</block>
  <block id="b6d767d2f8ed5d21a44b0e5886680cb9" category="cell">22</block>
  <block id="f4e339608b243f9b57b78ffaf061b498" category="cell">SSH (standardmäßig deaktiviert)</block>
  <block id="d82d678e9583c1f5f283ec56fbf1abb7" category="cell">9080</block>
  <block id="ef34781e03f49b5db5dd8fa267c4c41b" category="cell">HTTPS-Verbindungen - VP und SRA - nur interne Verbindungen von Loopback</block>
  <block id="a44ba9086b2b83ccf2baf7c678723449" category="cell">9083</block>
  <block id="fe01ac95967cd8cb5f5b5669b685277a" category="cell">HTTPS-Verbindungen – VP und SRA
Wird für SOAP-über-https-Verbindungen verwendet</block>
  <block id="abea47ba24142ed16b7d8fbf2c740e0d" category="cell">1162</block>
  <block id="4a0724da5c6f4e4817663ae822550800" category="cell">VP SNMP-Trap-Pakete</block>
  <block id="5cce8dede893813f879b873962fb669f" category="cell">1527</block>
  <block id="91c15b8eb529bf2100c10383d1010a1e" category="cell">Nur zur internen Nutzung</block>
  <block id="60135f95267c6e0711bf5a2858dfff2f" category="cell">Derby-Datenbank-Port, nur zwischen diesem Computer und sich selbst, externe Verbindungen nicht akzeptiert -- nur interne Verbindungen</block>
  <block id="13f3cf8c531952d72e5847c4183e6910" category="cell">443</block>
  <block id="1ef2b5426b0824e93e33753fa87ddbf5" category="cell">Bidirektional</block>
  <block id="e4b8a8d8761aab7733e317b585d5d606" category="cell">Wird für Verbindungen zu ONTAP-Clustern verwendet</block>
  <block id="bf6184406d1e18fffc86ecf770fbb391" category="inline-link">kb-Artikel</block>
  <block id="fedac49792829de4ff38fcf7a3846faa" category="list-text">*Unterstützung für Zertifizierungsstelle (CA) signierte Zertifikate.* ONTAP Tools für VMware vSphere unterstützt CA signierte Zertifikate. Siehe das<block ref="0903a062b2072644a9b744a7fece4216" category="inline-link-rx"></block> Finden Sie weitere Informationen.</block>
  <block id="9fca19988370da2a459b24505e9d23d5" category="list-text">*Audit Logging.* Supportpakete können heruntergeladen werden und sind äußerst detailliert. Die ONTAP Tools protokollieren alle Benutzer-Login- und -Abmeldeaktivitäten in einer separaten Protokolldatei. VASA API-Aufrufe werden in einem dedizierten VASA Audit Log (Local cxf.log) protokolliert.</block>
  <block id="7d60a2806aedd934b75cce55d6693689" category="list-text">*Passwortrichtlinien.* folgende Kennwortrichtlinien werden befolgt:</block>
  <block id="f82f7513742f08b9d2784923213bdc75" category="list-text">Passwörter werden nicht in Protokolldateien protokolliert.</block>
  <block id="83040c348e071499488a8128db207545" category="list-text">Passwörter werden nicht im Klartext kommuniziert.</block>
  <block id="bc319862df3312f423a50fece7730db9" category="list-text">Während des Installationsvorgangs selbst werden Passwörter konfiguriert.</block>
  <block id="853c2ea85b86882d0ea73b606a9800a4" category="list-text">Der Passwortverlauf ist ein konfigurierbarer Parameter.</block>
  <block id="b3d3877bc96752ae50a409c72597d47a" category="list-text">Das Mindestalter des Kennworts ist auf 24 Stunden festgelegt.</block>
  <block id="fb0bdec50022a37424a405b53da7c9c8" category="list-text">Die Felder für das Kennwort werden automatisch ausgefüllt.</block>
  <block id="3a04f054be8ad983ea82fd5079519810" category="list-text">ONTAP-Tools verschlüsselt alle gespeicherten Anmeldeinformationen mithilfe von SHA256 Hashing.</block>
  <block id="46e61d6e7c848d43ddcede8efd36c3d8" category="doc">SnapCenter Plug-in VMware vSphere</block>
  <block id="ae9e79ac4b60eba67cf1c7508417b42c" category="paragraph">Das NetApp SnapCenter Plug-in für VMware vSphere nutzt folgende sichere Entwicklungsaktivitäten:</block>
  <block id="b25a1098aff7d0c5ee590f1e1a114bb9" category="list-text">*Dynamic Application Security Testing (DAST).* Technologien, die entwickelt wurden, um gefährdete Bedingungen für Anwendungen in ihrem laufenden Zustand zu erkennen. DAST testet die freigesetzten HTTP- und HTML-Schnittstellen von Web-enable-Anwendungen.</block>
  <block id="6cc1fee6b4fc48755d78e93170bbed93" category="list-text">*Codewährung von Drittanbietern.* im Rahmen der Entwicklung von Software und der Verwendung von Open-Source-Software (OSS) ist es wichtig, Sicherheitslücken zu beheben, die mit OSS verbunden sein könnten, die in Ihr Produkt integriert wurden. Dies ist ein kontinuierlicher Aufwand, da bei der Version der OSS-Komponente eine neu entdeckte Sicherheitsanfälligkeit jederzeit gemeldet wird.</block>
  <block id="87bd0fb9b4198f33535e0e1888a809f5" category="list-text">*Penetrationstest.* Penetrationstest ist der Prozess, um ein System, eine Web-Anwendung oder ein Netzwerk zu evaluieren, um Sicherheitslücken zu finden, die von einem Angreifer ausgenutzt werden könnten. Penetrationstests (Penetrationstests) bei NetApp werden von einer Gruppe genehmigter und vertrauenswürdiger Drittanbieter durchgeführt. Ihr Testumfang umfasst die Einleitung von Angriffen gegen eine Anwendung oder Software wie feindliche Eindringlinge oder Hacker mit ausgereiften Exploitationsmethoden oder -Tools.</block>
  <block id="e3a3be4b4b04c5e0b6a5f1b5ea388380" category="list-text">*Product Security Incident Response Aktivität.* Sicherheitslücken werden sowohl intern als auch extern entdeckt und können ein ernsthaftes Risiko für NetAppâ €™s Ruf darstellen, wenn sie nicht rechtzeitig angesprochen werden. Zur Erleichterung dieses Prozesses meldet ein PSIRT (Product Security Incident Response Team) die Sicherheitsanfälligkeiten und verfolgt diese.</block>
  <block id="e91db3b3278f7bd95cc704d74c5c9597" category="paragraph">Das NetApp SnapCenter Plug-in für VMware vSphere umfasst die folgenden Sicherheitsfunktionen in jeder Version:</block>
  <block id="4abd7d1d5d223683d3346671efb7e89c" category="list-text">*Eingeschränkter Shell-Zugriff.* SSH ist standardmäßig deaktiviert, und einmalige Anmeldungen sind nur erlaubt, wenn sie über die VM-Konsole aktiviert sind.</block>
  <block id="8c264fa5ca2c588d960d98bd30cbc897" category="list-text">*Zugangswarnung im Anmeldebanner.* das folgende Anmeldebanner wird angezeigt, nachdem der Benutzer einen Benutzernamen in die Anmeldeaufforderung eingegeben hat:</block>
  <block id="0d6633ada3a9803e206b2359d859e892" category="paragraph">Nachdem der Benutzer die Anmeldung über den SSH-Kanal abgeschlossen hat, wird die folgende Ausgabe angezeigt:</block>
  <block id="83e463bb73b12d9ca6e419327073c8a4" category="list-text">*Rollenbasierte Zugriffssteuerung (Role Based Access Control, RBAC).* NetApp ONTAP Tools verfügen über zwei Arten von RBAC-Steuerelementen:</block>
  <block id="b883bf79639dfce77e395b8458ee69e4" category="list-text">Native vCenter Server-Berechtigungen.</block>
  <block id="721796b1cb3468f0daf819180184d460" category="inline-link">Rollenbasierte Zugriffssteuerung (Role Based Access Control, RBAC)</block>
  <block id="1d08c46b7567a29be0690a92b9722a58" category="list-text">Spezifische Berechtigungen für VMware vCenter Plug-in Weitere Informationen finden Sie unter<block ref="f351263ad3706bd0a472039400dece78" category="inline-link-rx"></block>.</block>
  <block id="acab4c655c4a7b4db67fc07e22b86222" category="list-text">*Verschlüsselte Kommunikationskanäle.* Alle externen Kommunikation erfolgt über HTTPS mit TLS.</block>
  <block id="47a37e2d5fc8b7c936ad9b2b7a569a08" category="paragraph">Die folgende Tabelle enthält die Details zum offenen Anschluss.</block>
  <block id="10bd16a816f831080065e807daa36a9a" category="cell">TCP v4/v6-Portnummer</block>
  <block id="edf0320adc8658b25ca26be5351b6c4a" category="cell">8144</block>
  <block id="d4a973e303ec37692cc8923e3148eef7" category="cell">8080</block>
  <block id="2c25c3d66f80eeaa8d6e5a144c6f942e" category="cell">HTTPS-Verbindungen für OVA GUI</block>
  <block id="14b3e670eec63cc0cc456fd904bbfbd9" category="cell">SSH (standardmäßig deaktiviert)</block>
  <block id="16fc18d787294ad5171100e33d05d4e2" category="cell">3306</block>
  <block id="4cbf9c234f6b34c242a110cb993252bd" category="cell">MySQL (nur interne Verbindungen; externe Verbindungen standardmäßig deaktiviert)</block>
  <block id="29ab4efbdb7c727c81ee1382593bc5e2" category="cell">Nginx (Datensicherungsservices)</block>
  <block id="89f152cad33314315b4995ed1ca71535" category="inline-link">Erstellen und/oder Importieren eines SSL-Zertifikats in das SnapCenter Plug-in für VMware vSphere (SCV)</block>
  <block id="450adc59e39f23172756ac9369494a2d" category="list-text">*Unterstützung für Zertifizierungsstelle (CA) signierte Zertifikate.* SnapCenter Plug-in für VMware vSphere unterstützt die Funktion von CA signierten Zertifikaten. Siehe<block ref="9f83d87d5d9f604d96288df21d450fac" category="inline-link-rx"></block>.</block>
  <block id="05a1aa8021df4579874c4eeb8788e5c9" category="list-text">*Passwortrichtlinien.* die folgenden Kennwortrichtlinien sind in Kraft:</block>
  <block id="2c87609dbbc3630573c64e271de8207d" category="list-text">Alle Anmeldeinformationen werden mit SHA256 Hashing gespeichert.</block>
  <block id="0f1a6fa0a65f9d5c3c4a16b070104d7a" category="list-text">*Basis Betriebssystem-Image.* das Produkt wird mit Debian Base OS für OVA ausgeliefert, mit eingeschränktem Zugriff und Shell-Zugriff. So wird die Angriffsfläche reduziert. Jedes Betriebssystem der SnapCenter Version wird mit den neuesten Sicherheits-Patches aktualisiert, die für maximale Sicherheit verfügbar sind.</block>
  <block id="83cd5867ba912e517fa1100299fd1cf3" category="paragraph">NetApp entwickelt Softwarefunktionen und Sicherheits-Patches zu den SnapCenter Plug-ins für die VMware vSphere Appliance und gibt sie anschließend dem Kunden als gebündelte Software-Plattform frei. Da diese Appliances bestimmte Linux Unterbetriebssystem-Abhängigkeiten sowie unsere proprietäre Software umfassen, empfiehlt NetApp, am Unterbetriebssystem keine Änderungen vorzunehmen, da dies ein hohes Potenzial hat, die NetApp Appliance zu beeinträchtigen. Dies könnte sich darauf auswirken, inwieweit NetApp die Appliance unterstützt. NetApp empfiehlt, unsere neueste Code-Version für Appliances zu testen und zu implementieren, da sie veröffentlicht werden, um sicherheitsbezogene Probleme zu patchen.</block>
  <block id="5afeee4e3c6d47363e83195b12c74872" category="paragraph">Hier finden Sie einen Überblick über wichtige ONTAP Funktionen, einschließlich Datensicherungsfunktionen, Storage-Effizienz-Empfehlungen und Disaster Recovery-Optionen <block ref="f7503abce54bbe0e3218519d659c8356" category="inline-link-macro-rx"></block> Diese Informationen sind entscheidend für die ordnungsgemäße Architektur und das Management der Applikationsumgebung auf ONTAP Storage-Systemen.</block>
  <block id="c7eca250a9863785d63364853c46c00d" category="doc">MySQL Tiering mit FabricPool</block>
  <block id="1bc6cee680286aae1b12889369b7f18a" category="summary">MySQL auf ONTAP</block>
  <block id="dac8ea4fbfd87a535663c227b91f50e3" category="doc">I/O-Planer</block>
  <block id="215dca219378b291ae287eb076489fdd" category="paragraph">Der Linux-Kernel ermöglicht eine Steuerung auf niedriger Ebene über die Art und Weise, wie I/O-Vorgänge zum Blockieren von Geräten geplant werden.</block>
  <block id="dc36d23ef487690f1698c69d9e49cee2" category="paragraph">Die Standardwerte auf verschiedenen Linux-Distributionen variieren erheblich. MySQL empfiehlt, dass Sie verwenden<block ref="722d122e81cbbe543bd5520bb8678c0e" prefix=" " category="inline-code"></block> Oder A<block ref="30e482a8ab57cfc19075dece53b0a56b" prefix=" " category="inline-code"></block> I/O-Scheduler mit nativem asynchronem I/O (AIO) unter Linux. Im Allgemeinen zeigen NetApp Kunden und interne Tests mit NoOps bessere Ergebnisse.</block>
  <block id="6def78482bd1915cb81f0f5c19ee8fe6" category="paragraph">Die InnoDB Storage Engine von MySQL verwendet das asynchrone I/O-Subsystem (native AIO) unter Linux, um Lese- und Schreibanforderungen für Datendateiseiten durchzuführen. Dieses Verhalten wird vom gesteuert<block ref="2c03186a22d036ce7dad84be5de2f2ce" prefix=" " category="inline-code"></block> Die standardmäßig aktivierte Konfigurationsoption. Bei nativem AIO hat der Typ des I/O-Planers einen größeren Einfluss auf die I/O-Performance. Durchführung von Benchmarks zur Bestimmung des I/O-Planers, der die besten Ergebnisse für Ihren Workload und Ihre Umgebung liefert</block>
  <block id="e7b09beaf26efc7d8bee91786cf794b5" category="paragraph">Anweisungen zur Konfiguration des I/O-Planers finden Sie in der entsprechenden Dokumentation zu Linux und MySQL.</block>
  <block id="6e8775bd755a8835ce86806d669677ea" category="doc">Storage-Konfiguration</block>
  <block id="f2d5298faec5552ae38d966f7d72f836" category="inline-link-macro">Enterprise-Applikationen auf ONTAP Storage-Konfiguration</block>
  <block id="7ed6bedda4cf07c9134434f7ec06939a" category="paragraph">Weitere Informationen zur Konfiguration von Speicher, der für MySQL-Datenbanken verwendet wird, finden Sie unter <block ref="43de4a40eabec5647493f6e009ce9cb1" category="inline-link-macro-rx"></block></block>
  <block id="2f09ac000b4a1808cb795b7bdbb20ecc" category="doc">innodb_Log_file_size</block>
  <block id="b8674b2897b288ca55b74328df4780b3" category="paragraph">Die Auswahl der richtigen Größe für die InnoDB-Protokolldateigröße ist wichtig für die Schreibvorgänge und für eine anständige Wiederherstellungszeit nach einem Serverabsturz.</block>
  <block id="b61bad6f7bf48bf9abda0c86c9beed79" category="paragraph">Da so viele Transaktionen in der Datei angemeldet sind, ist die Größe der Protokolldatei für Schreibvorgänge wichtig. Wenn Datensätze geändert werden, wird die Änderung nicht sofort in den Tablespace zurückgeschrieben. Stattdessen wird die Änderung am Ende der Protokolldatei aufgezeichnet und die Seite als verschmutzt markiert. InnoDB verwendet sein Protokoll, um zufällige I/O in sequenzielle I/O-Vorgänge zu konvertieren</block>
  <block id="e87d83a3c0af4df83efb4784b5182f8f" category="paragraph">Wenn das Protokoll voll ist, wird die fehlerhafte Seite nacheinander in den Tablespace geschrieben, um Speicherplatz in der Protokolldatei freizugeben. Angenommen, ein Server stürzt mitten in einer Transaktion ab, und die Schreibvorgänge werden nur in der Protokolldatei aufgezeichnet. Bevor der Server wieder live gehen kann, muss er eine Wiederherstellungsphase durchlaufen, in der die in der Protokolldatei aufgezeichneten Änderungen wiedergegeben werden. Je mehr Einträge in der Protokolldatei vorhanden sind, desto länger dauert es, bis der Server wiederhergestellt ist.</block>
  <block id="8321756b7fedf72543a1b0917bf92613" category="paragraph">In diesem Beispiel wirkt sich die Größe der Protokolldatei sowohl auf die Wiederherstellungszeit als auch auf die Schreib-Performance aus. Wenn Sie die richtige Zahl für die Größe der Protokolldatei wählen, gleichen Sie die Recovery-Zeit mit der Schreib-Performance ab. Normalerweise ist alles zwischen 128M und 512M ein gutes Preis-Leistungs-Verhältnis.</block>
  <block id="d4ae77cd65c244ceb4277b27553d6931" category="doc">MySQL-Datenbanken auf ONTAP</block>
  <block id="598132a821e8cc696fbbae934047d991" category="paragraph">MySQL und seine Varianten, darunter MariaDB und Percona MySQL, ist die weltweit beliebteste Datenbank.</block>
  <block id="478f00c3805e92ad9e8a7cd4f335a020" category="admonition">Diese Dokumentation zu ONTAP und der MySQL-Datenbank ersetzt die zuvor veröffentlichte _TR-4722: MySQL-Datenbank unter NetApp ONTAP Best Practices._</block>
  <block id="9793e07572d1520fdffd0e4db62df588" category="paragraph">Zu den Merkmalen von MySQL gehören:</block>
  <block id="04b90043b7bbdc843dd2b77f2014f14f" category="list-text">*Lower TCO.* MySQL ist ein leistungsfähiges, kostenloses Open-Source-Datenbankmanagementsystem, das seit Jahren verfügbar ist. Sie ist sehr stabil. Es hat Community-Unterstützung, die Pflege, Debuggen und neue Funktionen hinzufügen hilft. Wenn eine Webanwendung mehr als eine Datenbank benötigt oder einen Lastausgleich oder eine gemeinsame Nutzung erfordert, können Sie Datenbankinstanzen einfach nur mit Hardwarekosten einrichten, anstatt kommerzielle Datenbanken, die für jede Instanz eine einzelne Lizenz benötigen.</block>
  <block id="ae129f31dc6bc29ee6e28e9dbd8bd904" category="list-text">*Zuverlässigkeit, Leistung und Benutzerfreundlichkeit.* eines der Merkmale von MySQL ist die außergewöhnliche Leistung und Skalierbarkeit, weshalb so viele webbasierte Unternehmen es nutzen. MySQL nutzt mehrere wichtige Stärken, um eine schnelle Performance zu liefern. Da der Wettbewerb immer nur einen Mausklick (oder Touchscreen) entfernt ist, sind schnelle Antworten auf Kundenanfragen und -Aktivitäten von größter Bedeutung. Die Datenbank, die webbasierte Applikationen bereitstellt, muss sowohl bei Lese- (einfachen als auch bei komplexen Abfragen) als auch bei Schreibvorgängen eine extrem hohe Performance bieten.</block>
  <block id="ce921a1775ad78848c0ef06b4c2aaff3" category="list-text">*Datenbankentwicklung, -Design und -Administration.* MySQL Workbench bietet eine integrierte Entwicklungs-, Design- und Administrationsumgebung, um Entwickler und DBAs produktiver zu machen. Verschiedene Entwickler suchen nach verschiedenen Funktionen in einer Datenbank, und MySQL bietet eine Reihe von Funktionen. Es kann sowohl auf einem Laptop als auch auf einem Desktop-PC angemessen ausgeführt werden. Die IT-Abteilung kann sich leicht an die Umgebung anpassen und so sicherstellen, dass sie nicht mit vorhandenen Webservern oder Anwendungen kollidiert.</block>
  <block id="26ab39333494c60fdfe1fbf67fcb9c4a" category="list-text">*Umfassende Transaktionsunterstützung.* MySQL ist eine der robustesten transaktionalen Datenbankengines auf dem Markt. Es ist die Lösung für vollständige Datenintegrität und bietet Funktionen wie vollständige atomare, konsistente, isolierte, dauerhafte Transaktionsunterstützung; Unterstützung von Multiversionstransaktionen; und uneingeschränkte Verriegelung auf Zeilenebene. Sie ermöglicht die sofortige Deadlock-Identifizierung durch servererzwungene referenzielle Integrität.</block>
  <block id="f9ab99873ba8416ec0975ef4f4fb655a" category="list-text">*Datensicherheit.* MySQL ist weltweit bekannt als das sicherste und zuverlässigste Datenbankmanagementsystem, das in gängigen Web-Anwendungen wie WordPress, Drupal, Joomla, Facebook, Google, und Twitter. Die Datensicherheit und Unterstützung für die Transaktionsverarbeitung, die mit der aktuellen Version von MySQL einhergehen, kann jedem Unternehmen zugute kommen, insbesondere E-Commerce-Unternehmen, die häufig Geldtransfers durchführen.</block>
  <block id="2cb5bda4a8945e058ff550f4991ba8b6" category="list-text">*Pluggable Architecture.* die Architektur der MySQL-Speicherengine ermöglicht es einem Datenbankexperten, eine spezielle Speicherengine für eine bestimmte Anwendung auszuwählen, ohne die Codierungsanforderungen für Anwendungen verwalten zu müssen. Die MySQL Server-Architektur isoliert Applikationsprogrammierer und DBA von allen Details der Low-Level-Implementierung auf Storage-Ebene und bietet so ein konsistentes und einfaches Applikationsmodell sowie eine API. Obwohl verschiedene Funktionen in verschiedenen Storage Engines verwendet werden, ist die Applikation von diesen Unterschieden abgeschirmt.</block>
  <block id="e0780e103bd4ebcb0ee7f25b644eca40" category="paragraph">Die effiziente und modulare MySQL Architektur bietet enorme Vorteile, wenn Sie sich auf eine bestimmte Applikationsanforderungen – wie Data Warehousing, Transaktionsverarbeitung oder HA-Situationen – konzentrieren möchten, während Sie Schnittstellen und Services nutzen, die unabhängig von einer einzelnen Storage Engine sind.</block>
  <block id="35701e1bcd40c8e1a520fc33d0e14842" category="doc">innodb_Flush_Method</block>
  <block id="138738e11d5fda5c496edaa92e32e158" category="paragraph">Der Parameter innodb_flush_method gibt an, wie InnoDB die Protokoll- und Datendateien öffnet und löscht.</block>
  <block id="c262c8cd82b96f69fbbc058d7a35683b" category="section-title">Optimierungen</block>
  <block id="d1e67ebe6122765789852eb430c42c75" category="paragraph">In der InnoDB-Optimierung wird durch die Einstellung dieses Parameters die Datenbankleistung ggf. optimiert.</block>
  <block id="51ca63a7fb332d4d18e7139ea5787c50" category="paragraph">Die folgenden Optionen sind für das Spülen der Dateien über InnoDB:</block>
  <block id="a9b8d4c72b58a9554274cba7904d47e2" category="list-text"><block ref="e590322920bebc1156ab585bd6597d76" prefix="" category="inline-code"></block>. InnoDB verwendet die<block ref="4d0b2ade287f8f35e993511729bc75a1" prefix=" " category="inline-code"></block> Systemaufruf, um sowohl die Daten- als auch die Protokolldateien zu leeren. Diese Option ist die Standardeinstellung.</block>
  <block id="8198b1fd4bf2fafa4f4e8ffb4a8ac900" category="list-text"><block ref="a48be70a21bca2cf4b3e481efed66ae4" prefix="" category="inline-code"></block>. InnoDB verwendet die<block ref="a48be70a21bca2cf4b3e481efed66ae4" prefix=" " category="inline-code"></block> Option zum Öffnen und Leeren der Protokolldateien und fsync() zum Leeren der Datendateien. InnoDB wird nicht verwendet<block ref="a48be70a21bca2cf4b3e481efed66ae4" prefix=" " category="inline-code"></block> Direkt, weil es Probleme mit ihm auf vielen Sorten von UNIX.</block>
  <block id="f89f9147df5dde99a7944d2028b59e7e" category="list-text"><block ref="6a334fd488ef92b18584207148410cc4" prefix="" category="inline-code"></block>. InnoDB verwendet die<block ref="6a334fd488ef92b18584207148410cc4" prefix=" " category="inline-code"></block> Option (oder<block ref="42d27f470f62deaad644fef8618b59bb" prefix=" " category="inline-code"></block> Unter Solaris), um die Datendateien zu öffnen und zu verwenden<block ref="4d0b2ade287f8f35e993511729bc75a1" prefix=" " category="inline-code"></block> Um sowohl die Daten als auch die Protokolldateien zu löschen. Diese Option ist auf einigen GNU/Linux-Versionen, FreeBSD und Solaris verfügbar.</block>
  <block id="5e90100e134d805a66f8cda2e73f5298" category="list-text"><block ref="d66655d6d13113f23421f282ed1eaeb7" prefix="" category="inline-code"></block>. InnoDB verwendet die<block ref="6a334fd488ef92b18584207148410cc4" prefix=" " category="inline-code"></block> Option beim Spülen von E/A, wird jedoch übersprungen<block ref="4d0b2ade287f8f35e993511729bc75a1" prefix=" " category="inline-code"></block> Systemaufruf danach. Diese Option ist für einige Arten von Dateisystemen ungeeignet (z. B. XFS). Wenn Sie sich nicht sicher sind, ob Ihr Dateisystem einen erfordert<block ref="4d0b2ade287f8f35e993511729bc75a1" prefix=" " category="inline-code"></block> Systemaufruf – zum Beispiel zum Beibehalten aller Dateimetadaten – verwendet den<block ref="6a334fd488ef92b18584207148410cc4" prefix=" " category="inline-code"></block> Wählen Sie stattdessen.</block>
  <block id="c680d437163cc6bab4f9bdb35c3073d0" category="section-title">Beobachtung</block>
  <block id="907dee0040812e8e7d1fd00b870b5063" category="paragraph">In den NetApp-Labortests ist der<block ref="e590322920bebc1156ab585bd6597d76" prefix=" " category="inline-code"></block> Auf NFS und SAN kam die Standardoption zum Einsatz. Im Vergleich dazu war sie ein großartiger Performance-Improvisator<block ref="6a334fd488ef92b18584207148410cc4" prefix=" " category="inline-code"></block>. Bei Verwendung der Spülmethode als<block ref="6a334fd488ef92b18584207148410cc4" prefix=" " category="inline-code"></block> Bei ONTAP konnten wir beobachten, dass der Client viele Single-Byte-Schreibvorgänge am Rand des 4096. Blocks in serieller Form schreibt. Diese Schreibvorgänge haben die Latenz über das Netzwerk erhöht und die Performance beeinträchtigt.</block>
  <block id="2f0b9319cf6d59e07ea4b1ef65a12be1" category="doc">Open_File_Limits</block>
  <block id="11e52b21a9795b7dcf947027b0ec5d01" category="paragraph">Der<block ref="2f0b9319cf6d59e07ea4b1ef65a12be1" prefix=" " category="inline-code"></block> Parameter bestimmt die Anzahl der Dateien, die das Betriebssystem mysqld zum Öffnen zulässt.</block>
  <block id="e0732f22b2900006e8fcb6367fd162f7" category="paragraph">Der Wert dieses Parameters zur Laufzeit ist der vom System zulässige Realwert und kann sich von dem Wert unterscheiden, den Sie beim Serverstart angeben. Der Wert ist 0 auf Systemen, bei denen MySQL die Anzahl der geöffneten Dateien nicht ändern kann. Die effektive<block ref="3d39e9c5aa2f78830dd6993cec18e93e" prefix=" " category="inline-code"></block> Der Wert basiert auf dem Wert, der beim Systemstart (falls vorhanden) angegeben wurde, und den Werten von<block ref="0bc91339c0d774f560a9a38fc9dfac30" prefix=" " category="inline-code"></block> Und<block ref="023a3b50ddf424c9a1d51984190a0c92" prefix=" " category="inline-code"></block> Mit diesen Formeln:</block>
  <block id="6b840ff0a7667f4642a0844269657fc4" category="list-text">10 +<block ref="0bc91339c0d774f560a9a38fc9dfac30" prefix=" " category="inline-code"></block> + <block ref="023a3b50ddf424c9a1d51984190a0c92" prefix="(" category="inline-code"></block> 2 x)</block>
  <block id="d3de183489c20b8efa2947eeff3028d7" category="list-text"><block ref="0bc91339c0d774f560a9a38fc9dfac30" prefix="" category="inline-code"></block> X 5</block>
  <block id="2c08922fbaba089e7c2982df43fd352a" category="list-text">Betriebssystemgrenze, wenn positiv</block>
  <block id="8ca153937fcbdf56497ad779a91f31d1" category="list-text">Wenn die Betriebssystemgrenze unendlich ist:<block ref="3d39e9c5aa2f78830dd6993cec18e93e" prefix=" " category="inline-code"></block> Wert wird beim Start angegeben; 5,000 wenn keine</block>
  <block id="98038bb4026a70f5ee4041522c6eebe4" category="paragraph">Der Server versucht, die Anzahl der Dateideskriptoren mit dem Maximum dieser vier Werte zu ermitteln. Wenn so viele Deskriptoren nicht abgerufen werden können, versucht der Server, so viele zu erhalten, wie das System zulässt.</block>
  <block id="3ee58d04a0dc9b2551698643e0421005" category="doc">innodb_lru_Scan_depth</block>
  <block id="29d0f4f8b383d39e73abd11ac73ca28a" category="paragraph">Der<block ref="3ee58d04a0dc9b2551698643e0421005" prefix=" " category="inline-code"></block> Parameter beeinflusst die Algorithmen und Heuristiken des Flush-Vorgangs für den InnoDB Pufferpool.</block>
  <block id="eeb16232629bd788f0d29c104105bba2" category="paragraph">Dieser Parameter ist in erster Linie an Performance-Experten interessiert, die I/O-intensive Workloads optimieren. Dieser Parameter gibt für jede Pufferpoolinstanz an, wie weit der Seitenauflauf des Seitenreinigers in der LRU-Seitenliste (Least Recently Used) weiter scannen soll, und sucht nach verschmutzten Seiten, die bereinigt werden sollen. Dieser Hintergrundvorgang wird einmal pro Sekunde durchgeführt.</block>
  <block id="39359bf2914e4e1cf84a9dea580fd20a" category="paragraph">Sie können den Wert nach oben oder unten anpassen, um die Anzahl der freien Seiten zu minimieren. Stellen Sie den Wert nicht wesentlich höher ein als erforderlich, da die Scans erhebliche Performancekosten verursachen können. Ziehen Sie außerdem in Betracht, diesen Parameter anzupassen, wenn Sie die Anzahl der Pufferpool-Instanzen ändern, da<block ref="f2c8312d381c16c6c95a727c3f61a4c7" prefix=" " category="inline-code"></block> Definiert den Umfang der Arbeit, die durch den Seitenreinigungsfaden jede Sekunde durchgeführt wird.</block>
  <block id="513a275422fae2456617321a2f3fc0af" category="paragraph">Eine Einstellung, die kleiner als die Standardeinstellung ist, eignet sich für die meisten Workloads. Ziehen Sie in Betracht, diesen Wert nur zu erhöhen, wenn Sie freie I/O-Kapazität bei einem typischen Workload haben. Wenn ein schreibintensiver Workload die I/O-Kapazität aussättigt, verringern Sie den Wert umgekehrt, insbesondere wenn ein großer Puffer-Pool vorhanden ist.</block>
  <block id="62812b938ba1113b81bd7f612ad0e6f8" category="doc">innodb_Buffer_Pool_size</block>
  <block id="d7a8b502d05f5e477158eb80c1fb8dae" category="paragraph">Der InnoDB Pufferpool ist der wichtigste Teil jeder Tuning-Aktivität.</block>
  <block id="5cb6c45d18482180f34ae727b53379fb" category="paragraph">InnoDB setzt stark auf den Pufferpool für das Caching von Indizes und Rudern der Daten, den adaptiven Hash-Index, den Insert-Puffer und viele andere interne Datenstrukturen. Der Puffer-Pool puffert Änderungen an Daten, damit Schreibzugriffe nicht sofort in den Storage übernommen werden müssen, was die Performance verbessert. Der Pufferpool ist integraler Bestandteil von InnoDB und muss entsprechend angepasst werden. Berücksichtigen Sie beim Festlegen der Größe des Puffer-Pools die folgenden Faktoren:</block>
  <block id="03f07291794c3b9cb00d04cb9f30be81" category="list-text">Stellen Sie für eine dedizierte InnoDB-Maschine die Pufferpoolgröße auf 80 % oder mehr verfügbaren RAM ein.</block>
  <block id="7b0119b7fa59f87d23d5c65da456b226" category="list-text">Wenn es sich nicht um einen dedizierten MySQL-Server handelt, stellen Sie die Größe auf 50 % des RAM ein.</block>
  <block id="a6a9695e1464f5554c0006c55facfadf" category="doc">Dateideskriptoren</block>
  <block id="5ef6471f819ed2d47303473cc87d9305" category="paragraph">Für die Ausführung benötigt der MySQL Server Dateideskriptoren.</block>
  <block id="8e222c68dd214db9f8a1b5b572ee6267" category="paragraph">Sie werden verwendet, um neue Verbindungen zu öffnen, Tabellen im Cache zu speichern, temporäre Tabellen zum Beheben komplizierter Abfragen zu erstellen und auf persistente zuzugreifen. Wenn mysqld nicht in der Lage ist, neue Dateien zu öffnen, wenn nötig, kann es nicht mehr richtig funktionieren. Ein häufiges Symptom dieses Problems ist Fehler 24, „zu viele geöffnete Dateien“. Die Anzahl der Dateideskriptoren, die mysqld gleichzeitig öffnen kann, wird durch das definiert<block ref="3d39e9c5aa2f78830dd6993cec18e93e" prefix=" " category="inline-code"></block> In der Konfigurationsdatei festgelegte Option <block ref="86d0d007043d911697753b35e2c18f35" prefix="(" category="inline-code"></block>). Aber<block ref="3d39e9c5aa2f78830dd6993cec18e93e" prefix=" " category="inline-code"></block> Hängt auch von den Grenzen des Betriebssystems ab. Diese Abhängigkeit macht die Einstellung der Variable komplizierter.</block>
  <block id="07561a91f81dfe3c8e4364aac8bdbea4" category="paragraph">MySQL kann seine Einstellung nicht festlegen<block ref="3d39e9c5aa2f78830dd6993cec18e93e" prefix=" " category="inline-code"></block> Option höher als unter angegeben<block ref="dd1c6d8164dfd1cee0afa39b177e843b" prefix=" " category="inline-code"></block>. Daher müssen Sie diese Grenzwerte explizit auf Betriebssystemebene festlegen, damit MySQL Dateien nach Bedarf öffnen kann. Es gibt zwei Möglichkeiten, die Dateibegrenzung in Linux zu überprüfen:</block>
  <block id="84e705ac120a887df441f4161dc29409" category="list-text">Der<block ref="2eabb4efed7dffb32ea1170eab71b798" prefix=" " category="inline-code"></block> Befehl schnell gibt Ihnen eine detaillierte Beschreibung der Parameter, die erlaubt oder gesperrt werden. Die durch die Ausführung dieses Befehls vorgenommenen Änderungen sind nicht dauerhaft und werden nach einem Neustart des Systems gelöscht.</block>
  <block id="a4c404dc92855948bc4c007a86091dbe" category="list-text">Änderungen an<block ref="b803f460349bd101b1de260021ef0e60" prefix=" " category="inline-code"></block> Die Datei ist dauerhaft und wird durch einen Systemneustart nicht beeinträchtigt.</block>
  <block id="cbcab8220d4ffddbdc44f9936125d83d" category="paragraph">Stellen Sie sicher, dass Sie sowohl die harten als auch die weichen Grenzwerte für Benutzer mysql ändern. Die folgenden Auszüge stammen aus der Konfiguration:</block>
  <block id="97dc47f90c600a96fac6642560ffaceb" category="paragraph">Aktualisieren Sie gleichzeitig dieselbe Konfiguration in<block ref="90f16be5b82ca0aa94088c89fe00b3dd" prefix=" " category="inline-code"></block> Um die offenen Dateigrenzen vollständig zu verwenden.</block>
  <block id="395ec860c9530814e94538b7121a8319" category="doc">innodb_Flush_log_at_trx_commit</block>
  <block id="2f2c7742844f13de59d435b9099c78cc" category="paragraph">Wenn eine Datenänderung vorgenommen wird, wird nicht sofort in den Storage geschrieben.</block>
  <block id="0b36b8f791a48c7b4692e7df069dabc8" category="paragraph">Stattdessen werden die Daten in einem Protokollpuffer aufgezeichnet, einem Teil des Speichers, den InnoDB Pufferänderungen zuweist, die in der Protokolldatei aufgezeichnet werden. InnoDB leert den Puffer in die Protokolldatei, wenn eine Transaktion durchgeführt wird, wenn der Puffer voll wird, oder einmal pro Sekunde, je nachdem, welches Ereignis zuerst eintritt. Die Konfigurationsvariable, die diesen Prozess steuert, ist innodb_flush_log_at_trx_commit. Die Wertoptionen umfassen:</block>
  <block id="280a38864b81c14ba3db52801e087ed0" category="list-text">Wenn Sie es einstellen<block ref="cab9a35054c49f0ba619a6e6943f461b" prefix=" " category="inline-code"></block>, InnoDB schreibt die geänderten Daten (im InnoDB-Pufferpool) in die Log-Datei (ib_logfile) und leert die Log-Datei (Write to Storage) jede Sekunde. Es tut jedoch nichts, wenn die Transaktion durchgeführt wird. Bei einem Stromausfall oder Systemabsturz können die nicht gespeicherten Daten nicht wiederhergestellt werden, da sie weder auf die Protokolldatei noch auf die Laufwerke geschrieben werden.</block>
  <block id="5967bb5566cb7cd8bdb0b372ceb21565" category="list-text">Wenn Sie es einstellen<block ref="1ab7a7611b59147e84a38b6f3e7d9d09" prefix=" " category="inline-code"></block>, InnoDB schreibt den Protokollpuffer in das Transaktionsprotokoll und leert für jede Transaktion auf eine dauerhafte Speicherung. Beispielsweise schreibt InnoDB für alle Transaction Commits in das Protokoll und schreibt anschließend in den Speicher. Langsamer Speicher beeinträchtigt die Performance, beispielsweise wird die Anzahl der InnoDB-Transaktionen pro Sekunde reduziert.</block>
  <block id="9e9b3a43cb7a1b13c5ee3f6519d7f60e" category="list-text">Wenn Sie es einstellen<block ref="44d4dfee9b1c95f8768bec989cd3baf5" prefix=" " category="inline-code"></block>, InnoDB schreibt den Protokollpuffer bei jedem Commit in die Protokolldatei, schreibt aber keine Daten in den Speicher. InnoDB leert die Daten einmal pro Sekunde. Selbst bei einem Stromausfall oder Systemabsturz sind die Daten von Option 2 in der Protokolldatei verfügbar und können wiederhergestellt werden.</block>
  <block id="14f3e0328e25aa02b37bd6817a442a58" category="paragraph">Wenn die Leistung das Hauptziel ist, setzen Sie den Wert auf 2. Da InnoDB einmal pro Sekunde auf die Laufwerke schreibt, nicht für jede Transaktion, verbessert sich die Performance erheblich. Bei einem Stromausfall oder Absturz können die Daten aus dem Transaktions-Log wiederhergestellt werden.</block>
  <block id="4a34cbb1957909093a2e216fc1cd0962" category="paragraph">Wenn die Datensicherheit das Hauptziel ist, setzen Sie den Wert auf 1, sodass InnoDB für jeden Transaktionscommit zu den Laufwerken leert. Möglicherweise ist die Performance jedoch beeinträchtigt.</block>
  <block id="53be3047aa6f8a62c640cc8b4d6089c6" category="admonition">*NetApp empfiehlt* Setzen Sie den innodb_flush_log_trx_commit Wert auf 2, um eine bessere Leistung zu erzielen.</block>
  <block id="2199371f8380c97ad11a03fba3b501c9" category="doc">innodb_io_Capacity</block>
  <block id="ac165f23bb7435219b226ed6e76c5fa4" category="paragraph">Im InnoDB Plug-in wurde ein neuer Parameter namens innodb_io_Capacity aus MySQL 5.7 hinzugefügt.</block>
  <block id="b4f38c42ef968074288f239b42e92b7f" category="paragraph">Er steuert die maximale Anzahl von IOPS, die InnoDB durchführt (einschließlich der Spülrate von schmutzigen Seiten sowie der Batch-Größe des Insert Buffer [ibuf]). Der innodb_io_capacity Parameter setzt eine Obergrenze für IOPS durch InnoDB-Hintergrundaufgaben, wie das Leeren von Seiten aus dem Pufferpool und das Zusammenführen von Daten aus dem Änderungspuffer.</block>
  <block id="9679a08c293f29d9546c42207b09d418" category="paragraph">Legen Sie den Parameter innodb_io_Capacity auf die ungefähre Anzahl von E/A-Vorgängen fest, die das System pro Sekunde durchführen kann. Halten Sie die Einstellung idealerweise so niedrig wie möglich, aber nicht so niedrig, dass Hintergrundaktivitäten langsamer werden. Ist die Einstellung zu hoch, werden die Daten aus dem Puffer-Pool entfernt und Puffer für das Caching zu schnell eingefügt, um einen wesentlichen Vorteil zu erzielen.</block>
  <block id="668b6acc98c3469094062ed50b43e43a" category="admonition">*NetApp empfiehlt*, wenn Sie diese Einstellung über NFS verwenden, das Testergebnis von IOPS (SysBench/FiO) analysieren und den Parameter entsprechend einstellen. Verwenden Sie den kleinstmöglichen Wert zum Spülen und Spülen, um mit dem Schritt zu bleiben, es sei denn, Sie sehen mehr geänderte oder schmutzige Seiten als Sie im InnoDB-Puffer-Pool möchten.</block>
  <block id="038b11d42ee14bd77b6370c575c63b16" category="admonition">Verwenden Sie keine Extremwerte wie 20,000 oder mehr, es sei denn, Sie haben bewiesen, dass niedrigere Werte für Ihre Arbeitsbelastung nicht ausreichen.</block>
  <block id="62385f5ceb285bca676cb0561555d719" category="paragraph">Der InnoDB_IO_Capacity Parameter regelt Spülraten und zugehörige I/O.</block>
  <block id="c957ef06af970a7526a73e741b47fef1" category="admonition">Sie können die Leistung ernsthaft beeinträchtigen, indem Sie diesen Parameter oder den innodb_io_Capacity_max-Parameter zu hoch einstellen und I/O-Operationen mit vorzeitigem Spülen verschwenden.</block>
  <block id="d32067c550345cae14e678b4def6aa22" category="doc">MySQL über SAN</block>
  <block id="b238d5dd75fe5ed855c5b3047e074050" category="paragraph">Es gibt zwei Optionen zur Konfiguration von MySQL mit SAN unter Verwendung des üblichen zwei-Volume-Modells.</block>
  <block id="58d94bb6e53e154e2f4b16efa09f4c0d" category="paragraph">Kleinere Datenbanken können auf einem Standard-LUN-Paar platziert werden, sofern die I/O- und Kapazitätsanforderungen innerhalb der Grenzen eines einzigen LUN-Filesystems liegen. Eine Datenbank, die etwa 2.000 zufällige IOPS benötigt, kann beispielsweise auf einem einzelnen Filesystem auf einer einzelnen LUN gehostet werden. In ähnlicher Weise würde eine Datenbank mit einer Größe von nur 100 GB auf eine einzige LUN passen, ohne ein Management-Problem zu verursachen.</block>
  <block id="c33bcb4f520265bb106616e844397ffb" category="paragraph">Bei größeren Datenbanken sind mehrere LUNs erforderlich. Beispielsweise würde eine Datenbank, die 100.000 IOPS benötigt, höchstwahrscheinlich mindestens acht LUNs benötigen. Eine einzelne LUN würde zu einem Engpass werden, da die Anzahl der SCSI-Kanäle zu Laufwerken nicht ausreicht. Eine 10-TB-Datenbank wäre ähnlich schwierig zu managen auf einer einzigen 10-TB-LUN. Logical Volume Manager sind so konzipiert, die Performance- und Kapazitätsfunktionen mehrerer LUNs miteinander zu verbinden, um Performance und Management zu verbessern.</block>
  <block id="428e88a1415b00f5eb396829b4bd9a2c" category="paragraph">In beiden Fällen sollte ein Paar ONTAP Volumes ausreichend sein. Bei einer einfachen Konfiguration würde die Datendatei-LUN wie die Protokoll-LUN in ein dediziertes Volume platziert werden. Bei einer logischen Volume Manager-Konfiguration befinden sich alle LUNs in der Datendatei-Volume-Gruppe in einem dedizierten Volume, und die LUNs der Log-Volume-Gruppe befinden sich in einem zweiten dedizierten Volume.</block>
  <block id="e8c31916b755be39cb0a66804a1d8f8b" category="paragraph">*NetApp empfiehlt*, zwei Dateisysteme für MySQL-Bereitstellungen auf SAN zu verwenden:</block>
  <block id="fe9d8ca2c46747e16ed31f64638e66e6" category="list-text">Das erste Dateisystem speichert alle MySQL-Daten einschließlich Tablespace, Daten und Index.</block>
  <block id="04d82ed32fa1eeaa6df117c178062441" category="list-text">Das zweite Filesystem speichert alle Protokolle (binäre Protokolle, langsame Protokolle und Transaktionsprotokolle).</block>
  <block id="15bcb76b7e8b441c0d2a6e723f70c20c" category="paragraph">Es gibt mehrere Gründe für die Trennung von Daten auf diese Weise, unter anderem:</block>
  <block id="02774797d31a8f1c6d805860038c32a3" category="list-text">Die I/O-Muster von Datendateien und Protokolldateien unterscheiden sich. Eine Trennung würde mehr Optionen mit QoS-Steuerung ermöglichen.</block>
  <block id="6cab2c793e807e2d0c57f5b0d96505c1" category="list-text">Für eine optimale Nutzung der Snapshot Technologie müssen Datendateien unabhängig wiederhergestellt werden können. Das Komminglieren von Datendateien mit Protokolldateien beeinträchtigt die Wiederherstellung von Datendateien.</block>
  <block id="553ad1f7b6f5cfee021e5cf56e56a289" category="list-text">NetApp SnapMirror bietet zwar eine einfache Disaster Recovery-Funktion mit einem geringen RPO für eine Datenbank, erfordert jedoch unterschiedliche Replizierungspläne für die Dateien und Protokolle.</block>
  <block id="ff5f52a69a35dd41da3e3c4b810e4f94" category="admonition">Mit diesem grundlegenden Layout für zwei Volumes wird die Lösung zukunftssicher, sodass alle ONTAP Funktionen bei Bedarf genutzt werden können.</block>
  <block id="7b755794e9de5716b2d6305bd10bee1b" category="paragraph">*NetApp empfiehlt* das Formatieren Ihres Laufwerks mit dem ext4-Dateisystem aufgrund der folgenden Features:</block>
  <block id="fa92f58d5035dec5e24a787f76504783" category="list-text">Erweiterter Ansatz für Blockverwaltungsfunktionen, die im Journaling-Dateisystem (JFS) verwendet werden, und verzögerte Zuweisungsfunktionen des erweiterten Dateisystems (XFS).</block>
  <block id="a72d73cde02c10703b72dcae6bc7c812" category="list-text">Ext4 erlaubt Dateisysteme mit bis zu 1 Exbibyte (2^60 Bytes) und Dateien mit bis zu 16 Tebibyte (16 * 2^40 Bytes). Im Gegensatz dazu unterstützt das ext3-Dateisystem nur eine maximale Filesystem-Größe von 16 TB und eine maximale Dateigröße von 2 TB.</block>
  <block id="56b4168424fa999bc383d24daf2da4eb" category="list-text">In ext4-Dateisystemen weist die Multiblockzuweisung (mballoc) mehreren Blöcken einer Datei in einem einzigen Vorgang zu, anstatt sie einzeln zuzuweisen, wie in ext3. Diese Konfiguration reduziert den Overhead beim mehrmaligen Aufrufen des Block Allocator und optimiert die Zuweisung von Speicher.</block>
  <block id="632635d22b347f0140fb15d0eb0ed09e" category="list-text">Obwohl XFS der Standard für viele Linux-Distributionen ist, verwaltet es Metadaten anders und ist nicht für einige MySQL-Konfigurationen geeignet.</block>
  <block id="aff8b2ed0a4719f014e5baeb861ea7d4" category="paragraph">*NetApp empfiehlt* die Verwendung von 4k-Blockgrößenoptionen mit dem mkfs-Dienstprogramm, um die bestehende Block-LUN-Größe auszurichten.</block>
  <block id="0a24d0336b7b0b29a9daa97f88499884" category="paragraph"><block ref="018d13c1d8b9abcae080b8abbc7c2d8b" prefix="" category="inline-code"></block></block>
  <block id="86fc8cb3bf2cae621315896a94b35f67" category="paragraph">NetApp LUNs speichern Daten in physischen 4-KB-Blöcken, wodurch acht logische 512-Byte-Blöcke entstehen.</block>
  <block id="5f441ceabc94de2a9cced94d9f53a2d0" category="paragraph">Wenn Sie nicht dieselbe Blockgröße einrichten, werden I/O-Vorgänge nicht korrekt an physischen Blöcken ausgerichtet und können in zwei verschiedene Laufwerke in einer RAID-Gruppe geschrieben werden, was zu Latenz führt.</block>
  <block id="236ac851d05b8822524001920948f23d" category="admonition">Es ist wichtig, dass Sie den I/O so ausrichten, dass reibungslose Lese-/Schreibvorgänge erfolgen. Wenn die I/O jedoch bei einem logischen Block beginnt, der nicht am Anfang eines physischen Blocks liegt, ist die I/O falsch ausgerichtet. I/O-Vorgänge werden nur ausgerichtet, wenn sie an einem logischen Block beginnen – dem ersten logischen Block in einem physischen Block.</block>
  <block id="e6cf2549be4da18bf404cacc6100516a" category="summary">MySQL Konfiguration</block>
  <block id="282155126a94a0702cfd80daf38d4362" category="doc">Konfigurationsübersicht</block>
  <block id="13b506e9cda8a01b4cd60e08f3f1faf6" category="paragraph">Für eine optimale Performance empfiehlt NetApp einige wichtige MySQL Konfigurationsparameter (aufgelistet in Tabelle 1).</block>
  <block id="3225a10b07f1580f10dee4abc3779e6c" category="cell">Parameter</block>
  <block id="c82a6100dace2b41087ba6cf99a5976a" category="cell">Werte</block>
  <block id="b10db909b8fda84e70bf9b308d0938d9" category="cell">256 MIO.</block>
  <block id="c81e728d9d4c2f636f067f89cc14862c" category="cell">2</block>
  <block id="7ccc31934ae8244d8263d3c09bcee186" category="cell">innodb_doublewrite</block>
  <block id="e590322920bebc1156ab585bd6597d76" category="cell">Fsync</block>
  <block id="adb0c1ec32461889a5093441599260eb" category="cell">11 G</block>
  <block id="774412967f19ea61d448977ad9749078" category="cell">8192</block>
  <block id="311887a53ec7390fc383fa2ad813f012" category="cell">innodb_Buffer_Pool_Instances</block>
  <block id="c9f0f895fb98ab9159f51fd0297e236d" category="cell">8</block>
  <block id="1006f82d8df7d2325439b28ea691737c" category="cell">Open_File_Limit</block>
  <block id="3c9b5f1cd6a030bcb7bed9eac80589fb" category="cell">65535</block>
  <block id="c9f5a4d3ede4d084dda0a788ed06783c" category="paragraph">Um die in diesem Abschnitt beschriebenen Parameter einzustellen, müssen Sie sie in der MySQL-Konfigurationsdatei (my.cnf) ändern. Die Best Practices von NetApp wurden in internen Tests durchgeführt.</block>
  <block id="5382aaf8b3d2fdeb6717f9805b0dd511" category="doc">Container</block>
  <block id="6a554ff1dc93539a626e576bf0d28a02" category="paragraph">Die Containerisierung von MySQL-Datenbanken nimmt immer mehr zu.</block>
  <block id="bcc002a9f2e2ade112438f50a6630498" category="paragraph">Das Low-Level-Container-Management wird fast immer über Docker durchgeführt. Container-Managementplattformen wie OpenShift und Kubernetes vereinfachen das Management großer Container-Umgebungen noch. Die Vorteile der Containerisierung sind niedrigere Kosten, da keine Hypervisor-Lizenz erforderlich ist. Darüber hinaus ermöglichen Container die Ausführung mehrerer Datenbanken isoliert voneinander, während gleichzeitig der gleiche zugrunde liegende Kernel und das gleiche Betriebssystem verwendet werden. Container können in Mikrosekunden bereitgestellt werden.</block>
  <block id="14d9b10c6196045941347a9e85704b50" category="inline-link-macro">Astra Trident-Dokumentation</block>
  <block id="d4f640fe6950a1baff001f5601c7fbd7" category="paragraph">NetApp bietet mit Astra Trident erweiterte Management-Funktionen für Storage. Mit Astra Trident kann ein in Kubernetes erstellter Container automatisch seinen Storage auf der entsprechenden Tier bereitstellen, Richtlinien für den Export anwenden, Richtlinien für NetApp-Snapshot-Kopien festlegen und sogar einen Container auf einen anderen klonen. Weitere Informationen finden Sie im <block ref="2b8a155fc083396b96b18cee0ba5eab0" category="inline-link-macro-rx"></block>.</block>
  <block id="b8c3891a902a70c4f7f774363652f4b4" category="summary">MySQL-Dateistruktur</block>
  <block id="5713a921d815fd7d19875846450f8ea8" category="doc">Dateistruktur</block>
  <block id="4955922857da5499a2f1be602a96b0ff" category="paragraph">InnoDB fungiert als mittlere Schicht zwischen Speicher und MySQL-Server, es speichert die Daten auf den Laufwerken.</block>
  <block id="8a6fab0b8bb36427eda4071adfd7780b" category="inline-image-macro">Fehler: Grafikbild nicht gefunden</block>
  <block id="ca9f55f63ab99a97723ebf2d32c2516c" category="paragraph"><block ref="ca9f55f63ab99a97723ebf2d32c2516c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5d416cf65dd1e2c908bf430f957c89f8" category="paragraph">MySQL I/O wird in zwei Typen unterteilt:</block>
  <block id="e8a320970c929abda9ae744b0b9e8f5f" category="list-text">Zufällige Datei-I/O</block>
  <block id="85430c0aa096ec282f2a14156baa312e" category="list-text">Sequenzielle Datei-I/O</block>
  <block id="9251924a311c0050a0cc5b44a82c2b29" category="paragraph"><block ref="9251924a311c0050a0cc5b44a82c2b29" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b7b9a4c6983139a2673988826094a3cf" category="paragraph">Datendateien werden zufällig gelesen und überschrieben, was zu einem hohen IOPS-Wert führt. Daher wird SSD-Speicher empfohlen.</block>
  <block id="322f79fd77365edecd173807cb429ca2" category="paragraph">Redo-Log-Dateien und binäre Log-Dateien sind Transaktionsprotokolle. Sie werden sequenziell geschrieben, sodass Sie mit dem Schreib-Cache eine gute Performance auf der Festplatte erzielen können. Ein sequenzieller Lesevorgang findet bei der Wiederherstellung statt, jedoch verursacht er selten ein Performance-Problem, da die Größe der Protokolldatei normalerweise kleiner ist als die von Datendateien und sequenzielle Lesevorgänge schneller sind als zufällige Lesevorgänge (die bei Datendateien auftreten).</block>
  <block id="a898d206a27508975fea2e241af2f04e" category="paragraph">Der Double-Write-Puffer ist eine Besonderheit von InnoDB. InnoDB schreibt zunächst gerötete Seiten in den Double-Write-Puffer und schreibt dann die Seiten an die richtigen Positionen in den Datendateien. Dieser Prozess verhindert eine Beschädigung der Seite. Ohne den Double-Write-Puffer kann die Seite beschädigt werden, wenn während des Write-to-Drive-Prozesses ein Stromausfall auftritt. Da das Schreiben in den Doppelschreibpuffer sequenziell ist, wird es für HDDs stark optimiert. Bei der Wiederherstellung werden sequenzielle Lesevorgänge durchgeführt.</block>
  <block id="363512900e45bc17bdd6edfa50582862" category="paragraph">Da ONTAP NVRAM bereits einen Schreibschutz bietet, ist keine doppelte Schreibpufferung erforderlich. MySQL hat einen Parameter,<block ref="02d3c518a4019ea00e34e16491d826b4" prefix=" " category="inline-code"></block>, Um den Double-Write-Puffer zu deaktivieren. Diese Funktion kann die Leistung erheblich verbessern.</block>
  <block id="49a7df723922bddb4df4002b51087a1c" category="paragraph">Der Insert-Puffer ist ebenfalls eine Besonderheit von InnoDB. Wenn sich nicht eindeutige sekundäre Indexblöcke nicht im Speicher befinden, fügt InnoDB Einträge in den Insert-Puffer ein, um zufällige I/O-Vorgänge zu vermeiden. Der Insert-Puffer wird in regelmäßigen Abständen in die sekundären Indexbäume der Datenbank eingebunden. Der Insert-Puffer reduziert die Anzahl der I/O-Vorgänge, indem I/O-Anfragen an denselben Block zusammengeführt werden. Zufällige I/O-Vorgänge können sequenziell sein. Der Einfügepuffer ist auch für HDDs stark optimiert. Sowohl sequenzielle Schreibvorgänge als auch Lesevorgänge erfolgen im normalen Betrieb.</block>
  <block id="6a0190340f27f29279bbfd319800289d" category="paragraph">Rückgängig-Segmente sind wahlfrei E/A-orientiert. Um die Multiversionsparallelität (MVCC) zu gewährleisten, muss InnoDB alte Bilder in den Undo-Segmenten registrieren. Beim Lesen vorheriger Bilder aus den Rückgängigmachungssegmenten sind zufällige Lesevorgänge erforderlich. Wenn Sie eine lange Transaktion mit wiederholbaren Lesevorgängen ausführen (wie z. B. mysqldump – einzelne Transaktion) oder eine lange Abfrage ausführen, können zufällige Lesevorgänge auftreten. Daher ist das Speichern von undo-Segmenten auf SSDs in dieser Instanz besser. Wenn Sie nur kurze Transaktionen oder Abfragen ausführen, stellen die zufälligen Lesevorgänge kein Problem dar.</block>
  <block id="a27e0d4b650aa6db30fdd95b54c94b27" category="paragraph">*NetApp empfiehlt* aufgrund der InnoDB I/O-Eigenschaften das folgende Speicherdesign-Layout.</block>
  <block id="defc1bfda928f419df5e4af79c98343e" category="list-text">Ein Volume zur Speicherung zufälliger und sequenzieller I/O-orientierter MySQL-Dateien</block>
  <block id="7fd750411093ebd1faa0d99dd2608514" category="list-text">Ein weiteres Volume zur Speicherung rein sequenzieller I/O-orientierter Dateien von MySQL</block>
  <block id="0561a3b014eef0e5125fa63e1626cf57" category="paragraph">Dieses Layout hilft Ihnen auch bei der Entwicklung von Datensicherungsrichtlinien und -Strategien.</block>
  <block id="a53db665fd1a9734a7a0e119671a0cd0" category="paragraph">Die NFS-Performance unter Linux hängt von einem Parameter namens ab<block ref="453f2cc2326f82af1053f4aa4b75400b" prefix=" " category="inline-code"></block>.</block>
  <block id="ffb6da058affe733896beb9aa49ecac8" category="paragraph">Dieser Parameter regelt die Anzahl der noch ausstehenden NFS-Operationen, die auf einem Linux-Betriebssystem zulässig sind.</block>
  <block id="61b7a3955d9b57d4216605991a54fb5b" category="paragraph">Der Standardwert für die meisten 2.6-abgeleiteten Kernel, einschließlich RH5 und OL5, ist 16. Diese Standardeinstellung verursacht jedoch häufig Leistungsprobleme. Das gegenteilige Problem tritt bei neueren Kerneln auf, in denen der<block ref="453f2cc2326f82af1053f4aa4b75400b" prefix=" " category="inline-code"></block> Der Wert ist standardmäßig auf 65536 gesetzt. Er kann zu Storage-Problemen führen, indem das System mit übermäßigen Anforderungen überflutet wird. RHEL 7 und RHEL 8 haben den Standardwert 65536. Die Lösung besteht darin, diesen Wert statisch einzustellen. Verwenden Sie für jedes Linux-Betriebssystem, das NetApp NFS-Storage mit einer MySQL-Datenbank verwendet, den Wert 128. Um diesen Wert in Red hat Enterprise Linux festzulegen, geben Sie den folgenden Eintrag in /etc/sysctl.conf ein:</block>
  <block id="0dc9054baf963698b15466653cd51cae" category="paragraph">Einstellen<block ref="453f2cc2326f82af1053f4aa4b75400b" prefix=" " category="inline-code"></block>:</block>
  <block id="2e7b2d8e38618228d5ef0f9f8709c045" category="paragraph">Bestätigen Sie, dass der Wert eingestellt ist:</block>
  <block id="1fabb1810f890946d2e0967a8f855598" category="admonition">Es gibt einen anderen Parameter, der sehr ähnlich benannt ist<block ref="9efd3427cde637b95ad2d74946670fee" prefix=" " category="inline-code"></block>. Dieser Wert legt fest, wie viele Steckplätze einer TCP-Sitzung beim ersten Aufbau zugewiesen werden. Sie müssen diesen Wert nicht ändern.</block>
  <block id="9166d970028a28a614af39e6286371b7" category="paragraph">Sie können diesen Parameter mit deaktivieren<block ref="8cafbd8d9096941261e87f4f9152ab92" prefix=" " category="inline-code"></block> Für Benchmarks oder wenn Sie sich mehr um Top-Performance als um Datenintegrität oder mögliche Ausfälle sorgen. InnoDB verwendet eine Datei-Flush-Technik namens Double-Write. Bevor die Seiten in die Datendateien geschrieben werden, schreibt InnoDB sie in einen zusammenhängenden Bereich, den sogenannten Double-Write-Puffer. Nachdem das Schreiben und der Flush in den Double-Write-Puffer abgeschlossen sind, schreibt InnoDB die Seiten an die richtigen Positionen in der Datendatei. Falls das Betriebssystem oder ein mysqld-Prozess während eines Page Write abstürzt, kann InnoDB später während der Crash-Wiederherstellung eine gute Kopie der Seite aus dem Double-Write-Puffer finden.</block>
  <block id="3dfd4b9a526f8a8cf17021e34638b375" category="admonition">*NetApp empfiehlt* den Double-Write-Puffer zu deaktivieren. ONTAP NVRAM dient dieselbe Funktion. Die doppelte Pufferung beeinträchtigt die Leistung unnötig.</block>
  <block id="dd5a2a602f713562e0f9f0fd8385660e" category="doc">MySQL über NFS</block>
  <block id="0e5e83102103fcdd25af430bf7327034" category="paragraph">Die MySQL-Dokumentation empfiehlt, NFSv4 für NAS-Bereitstellungen zu verwenden.</block>
  <block id="ca0d9fdc80b88e73b548638af421788f" category="section-title">ONTAP NFS-Übertragungsgrößen</block>
  <block id="efcd0ba3fcbee9896a25804677e70b4b" category="paragraph">Standardmäßig beschränkt ONTAP die NFS-I/O-Größe auf 64K. Zufällige IO mit einer MySQL-Datenbank verwendet eine viel kleinere Blockgröße, die weit unter dem 64K Maximum liegt. I/O mit großen Blöcken wird in der Regel parallelisiert, sodass die 64K-Maximalgröße ebenfalls keine Einschränkung darstellt.</block>
  <block id="4655f686de75b23f16d530ed7351c447" category="paragraph">Es gibt einige Workloads, bei denen das 64K-Maximum eine Einschränkung darstellt. Insbesondere Vorgänge mit einem Thread, wie z. B. Backup-Vorgänge mit vollständiger Tabelle, werden schneller und effizienter ausgeführt, wenn die Datenbank weniger, aber größere I/O-Vorgänge ausführen kann. Die optimale I/O-Handhabungsgröße für ONTAP mit Datenbank-Workloads beträgt 256.000. Die unten aufgeführten NFS-Mount-Optionen für spezifische Betriebssysteme wurden entsprechend von 64K auf 256K aktualisiert.</block>
  <block id="3ab93db30f3dded2c8d71859afbb53f6" category="admonition">Verringern Sie niemals die maximal zulässige Übertragungsgröße auf ONTAP unter den Wert rsize/wsize der aktuell gemounteten NFS-Dateisysteme. Dies kann bei einigen Betriebssystemen zu Hängebleiben oder sogar Datenbeschädigungen führen. Wenn beispielsweise NFS-Clients derzeit auf 65536 rsize/wsize gesetzt sind, dann könnte die maximale Übertragungsgröße für ONTAP ohne Auswirkung auf die Clients selbst begrenzt werden, zwischen 65536 und 1048576 angepasst werden. Wenn Sie die maximale Übertragungsgröße unter 65536 verringern, können die Verfügbarkeit oder die Daten beeinträchtigt werden.</block>
  <block id="5ea0bb5d4dab46d7971fef94ccde9369" category="paragraph">*NetApp empfiehlt*</block>
  <block id="09c6aa928c90ba68a4e03deadfeaa644" category="paragraph">Einstellen der folgenden Einstellung für NFSv4 fstab (/etc/fstab):</block>
  <block id="0ae3c9648bc2d8c33fa57415604da370" category="paragraph"><block ref="a63a3dc825ff52908de7c9dfcb29ffa5" prefix="" category="inline-code"></block></block>
  <block id="3e0b2c100b093560f63ad57c6849bc8a" category="admonition">Ein häufiges Problem mit NFSv3 waren die gesperrten InnoDB-Protokolldateien nach einem Stromausfall. Durch die Verwendung von Zeit oder das Wechseln von Protokolldateien wurde dieses Problem behoben. NFSv4 verfügt jedoch über Sperrvorgänge und verfolgt die offenen Dateien und Delegationen.</block>
  <block id="62e4eb800d20b46085ccb975da78bafe" category="sidebar">ONTAP ist die Grundlage für Datenmanagement und Datensicherung für zahlreiche Enterprise-Applikationen und Datenbanktechnologien. Auf den folgenden Seiten finden Sie Anleitungen zu Best Practices und Implementierungsverfahren für ONTAP- und Enterprise-Applikationen und -Infrastrukturen.</block>
  <block id="78898e52fcbdc5337204a384f2456d4f" category="sidebar">Microsoft SQL Server</block>
  <block id="4f60acc41a8bf3fa75e7f74768637787" category="sidebar">Microsoft SQL Server Datensicherung</block>
  <block id="b8529ff730dcf8dd2178d72de271dc4d" category="sidebar">Open-Source-Datenbanken</block>
  <block id="bb9a5a6fadabab849d2e87f0898d7601" category="sidebar">MariaDB und MySQL auf ONTAP</block>
  <block id="5ad2a11eceac3ebd7cbf3b534ebdb1db" category="sidebar">PostgreSQL auf ONTAP</block>
  <block id="c30dd1a85cf86d95b11c1a08f70130ce" category="sidebar">Oracle Datenbank</block>
  <block id="4948dede9f4e7c3dfe48c38f7902f6e5" category="sidebar">Oracle auf ONTAP</block>
  <block id="d71074394b511143c8d1108e74a81abb" category="sidebar">Oracle Datensicherung</block>
  <block id="f4d8825927d11df25770df5e00d6a52e" category="sidebar">Oracle-Migration</block>
  <block id="86083f3ea21c2385b4f013aae3c57858" category="sidebar">SAP HANA</block>
  <block id="677f2e7e550075f7bbbdac91e0918f2f" category="sidebar">SAP Lösungen</block>
  <block id="1b83f2b1c0b7fb3af048c2a59624fe3b" category="sidebar">SAP HANA mit AFF und FC.</block>
  <block id="6ab3c3f05076d213f0b1feff267607c6" category="sidebar">SAP HANA mit AFF und NFS</block>
  <block id="56079badd056a19303cc26e6a4fcc7e0" category="sidebar">VMware</block>
  <block id="f07084a11252c9bca97503ea9a627c89" category="sidebar">Virtual Volumes (VVols) mit ONTAP</block>
  <block id="2d90ac09cbf108bddad31dd341f8614e" category="sidebar">VMware Site Recovery Manager mit ONTAP</block>
  <block id="b0dae11b82e63781abdc8f893c41b3c0" category="sidebar">Enterprise-Applikationen</block>
  <block id="999bc6b18351bbe817d26f559ba408ae" category="sidebar">SAP</block>
  <block id="2d2eef88dbdd0c34bde24e2632d9944f" category="sidebar">SAP HANA und AnyDB</block>
  <block id="399bd1ee587245ecac6f39beaa99886f" category="sidebar">PostgreSQL</block>
  <block id="f4f70727dc34561dfde1a3c529b6205c" category="sidebar">Einstellungen</block>
  <block id="3dd7c32443d5846be0a8fd75cb08b70e" category="sidebar">Konfiguration des Dateisystems</block>
  <block id="c476a4701643b158f9f5d57bcc91951d" category="sidebar">Snapshot Technologie</block>
  <block id="35084d885dea7b061e6894c1cf3036d9" category="sidebar">Workloads</block>
  <block id="7d219314ccabde6609510141bb175a6c" category="sidebar">Shared Instance oder dedizierte Instanz</block>
  <block id="d5363ae19ecaede49e2ced297df7737a" category="sidebar">Speicherkonfiguration</block>
  <block id="459f656cac9c4d74b9f3f16ebb2a76c8" category="sidebar">Datenbankdateien und Dateigruppen</block>
  <block id="500c09aa1bb9af431f2c18348e69bfd0" category="sidebar">Tempdb-Dateien</block>
  <block id="6fb6843bd9a214011969c02729c7d671" category="sidebar">Überlegungen zum Storage</block>
  <block id="4c5d94eb4dc4bff93f6a96a08ab7b244" category="sidebar">Datensicherheit</block>
  <block id="cf91513c6fc63cebe4b63a6647238d6d" category="sidebar">RAID</block>
  <block id="83db97189c47f7bb4edd879e8756f6e6" category="sidebar">Kapazitätsgrenzen</block>
  <block id="4d2caccc34711835f6ff99da411ac04e" category="sidebar">Storage Virtual Machines</block>
  <block id="af81930661b267e8f1e68c4d66e9ee56" category="sidebar">Failover und Switchover</block>
  <block id="dfd1f50170457b961c15bb13ad7e3bed" category="sidebar">Datendatei- und Redo-Blockgrößen</block>
  <block id="49f83bf3a15b8626eb91fde93c6b1788" category="sidebar">Oracle RAC</block>
  <block id="13d80777c8fd43e555c1f5b1b72d7ef0" category="sidebar">Host-Konfiguration</block>
  <block id="7e6bb0931a72759d39514aa924b420bc" category="sidebar">AIX</block>
  <block id="6bb83af717367dd4a47f75801ae7a2b0" category="sidebar">Linux mit ASMlib und AFD</block>
  <block id="619615da0f93507e22a6054ef2aea4f1" category="sidebar">Logische Schnittstellen</block>
  <block id="aca8e861c6f30fe2d42d0310a387312b" category="sidebar">Ethernet-Konfiguration</block>
  <block id="63a5b8bd41978e8124f9ccdfa9063e9e" category="sidebar">FC SAN-Konfiguration</block>
  <block id="d63f66214ae30c5b9b10653f1e503492" category="sidebar">LUN-Ausrichtung</block>
  <block id="f6556bc360e8c25d9e29515d2d52cd66" category="sidebar">Anzahl der LUNs und LUN-Größe</block>
  <block id="d552d63771786b001d365cf747f74f6a" category="sidebar">LUN-Größe wird zugewiesen</block>
  <block id="c3f378ef942f6bf228a43aaacc628fea" category="sidebar">LVM-Striping</block>
  <block id="254f642527b45bc260048e30704edb39" category="sidebar">Konfiguration</block>
  <block id="f3a78e25ce9f95fc3c61ccc39f32fb4d" category="sidebar">Oracle Direct NFS (dNFS)</block>
  <block id="989cefa74de0e10a575103f446258d99" category="sidebar">NFS-Lease und -Sperren</block>
  <block id="0d695ec265a3b0b5e7e32e33ffe4ed22" category="sidebar">NFS-Caching</block>
  <block id="eb4d10d6eda7c9266cd36c4eb0a223cf" category="sidebar">ASM Reclamation Utility</block>
  <block id="297e2ac2ec0bd88ad598062f4c07ee45" category="sidebar">Tiering-Richtlinien</block>
  <block id="9af6f452cd88c83f2bde555de8f93690" category="sidebar">Senden von Daten an einen Objektspeicher</block>
  <block id="08af6d4e6b562e2d0b418d7198f5a0f7" category="sidebar">Daten werden aus dem Objektspeicher abgerufen</block>
  <block id="02d01636975b3ae0c0ab22368cea8d54" category="sidebar">Tiering-Strategien</block>
  <block id="7fbd108e1fc6910c941094e95a677878" category="sidebar">Ganze Dateien</block>
  <block id="eb43c2427eb06b9f561363863b4a4f0b" category="sidebar">Teildateien</block>
  <block id="1afe200fa26ba361f59b603b22ad6392" category="sidebar">Wählen Sie Dateien aus</block>
  <block id="46880cc1d7a1624f1d6fa77e7ee02fb7" category="sidebar">RPO, TRO und SLAs</block>
  <block id="448d15345bb99c834095da225c529b8a" category="sidebar">Datenverfügbarkeit</block>
  <block id="5869e10a9dea6d88d61bb10040557f35" category="sidebar">Datenintegrität</block>
  <block id="e2ac7be9b8940191426986b2ca575aa2" category="sidebar">Grundlagen von Backup und Recovery</block>
  <block id="7b68149402c05a52968bda6af0435c8a" category="sidebar">Snapshot basierte Online-Backups</block>
  <block id="49ba0ee205d016d8236db9c1e8c130e5" category="sidebar">Storage Snapshot optimierte Backups</block>
  <block id="2c6d98297c340e390e0783220b038545" category="sidebar">Physische Architektur</block>
  <block id="13a854bdd11f8f57a0b25c00631f1430" category="sidebar">Logische Architektur</block>
  <block id="5e7988aeba0e1d3c15c5c78a0db738d1" category="sidebar">SyncMirror</block>
  <block id="3f23f85f537c810b6eca3c767c3ff00c" category="sidebar">Oracle Failover</block>
  <block id="5783cab279142a801ff0fd0a03b607d5" category="sidebar">Einzelne Instanz auf MetroCluster</block>
  <block id="ea98d1b4d8c0f4b9e705df8dcdf77730" category="sidebar">Einzelne Instanz auf SM-BC</block>
  <block id="39520db4a78ddf352897eac9b11c5890" category="sidebar">Oracle RAC auf SM-BC</block>
  <block id="5ba8ee2f32815884475d1f2244ba16a6" category="sidebar">Ausfallszenarien</block>
  <block id="e31593850dc03f8f10d036df5dc8633b" category="sidebar">Migration der Oracle Datenbank</block>
  <block id="5102abd5a9cc202678054b832caf678d" category="sidebar">Verfahren</block>
  <block id="1495d3ed3ebff783c0f480b583372450" category="sidebar">Host-Datenkopie</block>
  <block id="d81ca5686c955ed50927409eb8c14bb0" category="sidebar">Import fremder LUNs</block>
  <block id="2fea59b7e470acac5ec1589d504da14e" category="sidebar">Abschluss</block>
  <block id="e9cc85ef98d982c3c3e53d6b82293126" category="sidebar">Protokollkonvertierung</block>
  <block id="fbbd0e8905df3950eca4d1d8f55881ad" category="sidebar">Zusätzliche Anmerkungen</block>
  <block id="ac0465a970688dc3c326dcdd8fe2805e" category="sidebar">Performance-Optimierung und Benchmarking</block>
  <block id="7cb9c3cd8b9873d39a1fe87c083cd55c" category="sidebar">Veraltete NFS-Sperren</block>
  <block id="c0916addb4f26afa58c5a6df4f463fa5" category="sidebar">Unified Storage</block>
  <block id="c0032c6bab44eeeb6886c7a4aa67cf77" category="sidebar">Virtualisierungs-Tools</block>
  <block id="1c77ac70000b6804e930748d5df7be5e" category="sidebar">Richtlinienbasiertes Management von Virtual Volumes und Storage</block>
  <block id="217601d383b816e6a2548e57b5006f92" category="sidebar">Klonen</block>
  <block id="8f2db90dd4a6fbd95ba8f0bc54fd6b27" category="sidebar">QoS</block>
  <block id="09b4a81ec7b05cbacc7cbfa13e006254" category="sidebar">Richtlinienbasiertes Storage-Management</block>
  <block id="2e8526cbe762cb1b8393d935a3b0bf16" category="sidebar">Empfohlene Einstellungen</block>
  <block id="10a764f91b59ce3c8931d55c2fd54222" category="sidebar">Implementierung von VVols Storage</block>
  <block id="30f6724a02fc69093960468c0a2fbcd4" category="sidebar">Produktsicherheit</block>
  <block id="3390e3575b3e341afa2b7172ff5b33a7" category="sidebar">SnapCenter Plug-in für VMware vSphere</block>
  <block id="62a004b95946bb97541afa471dcca73a" category="sidebar">MySQL</block>
  <block id="7f1a6761f7160e33a32105202e47303b" category="sidebar">Containerisierung</block>
  <block id="bc65796c5a1bad360243a1bbe58272c2" category="sidebar">Allgemeine Storage-Konfiguration</block>
  <block id="bd57f4f74ca087a92a48b23d45753729" category="paragraph">Der ONTAP-Tools VASA Provider managt FCP- und iSCSI-Initiatorgruppen sowie NVMe-Subsysteme in ONTAP, die auf erkannten Initiatoren von gemanagten ESXi-Hosts basieren. Es ist jedoch nicht in Fibre-Channel-Switches integriert, um das Zoning zu managen. Bevor eine Bereitstellung stattfinden kann, muss das Zoning nach Best Practices erfolgen. Nachfolgend ein Beispiel für das Einzel-Initiator-Zoning für vier ONTAP-Systeme:</block>
  <block id="6b14e3f4a37881185acf7a766f8f6272" category="paragraph">Einzel-Initiator-Zoning:</block>
  <block id="17ccf64e30cb518fd7ca87ce752ad738" category="paragraph"><block ref="17ccf64e30cb518fd7ca87ce752ad738" category="inline-image-macro-rx" type="image"></block></block>
  <block id="58b5cd2a94730c2e044c14891f1e0e87" category="paragraph">Weitere Best Practices finden Sie in folgenden Dokumenten:</block>
  <block id="fc9e4d789d968936f8ff5ae5a99847e0" category="paragraph"><block ref="fc9e4d789d968936f8ff5ae5a99847e0" category="inline-link-rx"></block></block>
  <block id="d748a2834a7220eef4ec4775a51632f9" category="paragraph"><block ref="d748a2834a7220eef4ec4775a51632f9" category="inline-link-rx"></block></block>
  <block id="4047245d73abc6e3ae8bf58ec063e52e" category="paragraph">Die im Lieferumfang enthaltenen SCPs sind für die meisten allgemeinen Anwendungen geeignet, aber Ihre Anforderungen können unterschiedlich sein.</block>
  <block id="80dad10df0d1a031764e7c648c46aa23" category="paragraph">*Erwägen Sie die Verwendung von max IOPS zur Steuerung unbekannter VMs oder zum Testen von VMs.*</block>
  <block id="93e4f73afe8b787b33161ec273ca087f" category="paragraph">Erstmals in VASA Provider 7.1 verfügbar, können maximale IOPS verwendet werden, um IOPS bei einem unbekannten Workload auf ein bestimmtes vVol zu beschränken und so Auswirkungen auf andere, kritischere Workloads zu vermeiden. Tabelle 4 enthält weitere Informationen zum Performance-Management.</block>
  <block id="bdbd10905a1446f944699405bca52654" category="paragraph">*Stellen Sie sicher, dass Sie ausreichend Daten-LIFs haben.*
Erstellen Sie mindestens zwei LIFs pro Node und HA-Paar. Je nach Workload werden weitere erforderlich.</block>
  <block id="4e0d7e0587bf99c9b7a64a84fd42f6bd" category="paragraph">Weitere Best Practice-Leitfäden zu dem von Ihnen gewählten Protokoll finden Sie in den Leitfäden von NetApp und VMware. Im Allgemeinen gibt es keine anderen Änderungen als die bereits erwähnten.</block>
  <block id="97f87e9ab1d660463c63beb8745fd9e5" category="paragraph">*Beispiel einer Netzwerkkonfiguration mit VVols über NFS v3*</block>
  <block id="c80b3cc8b5013bd4039769fb0f783e60" category="paragraph"><block ref="c80b3cc8b5013bd4039769fb0f783e60" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d81c587aad705c1101db78ffea8e5bc3" category="paragraph"><block ref="d81c587aad705c1101db78ffea8e5bc3" category="inline-image-macro-rx" type="image"></block></block>
</blocks>